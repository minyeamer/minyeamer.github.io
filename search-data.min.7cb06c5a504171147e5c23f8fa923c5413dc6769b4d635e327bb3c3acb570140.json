[{"id":0,"href":"/blog/2023-04-02/","title":"2023-04-02 Log","section":"Posts","content":"Spark UDF # ìì‹ ì˜ ê¸°ëŠ¥ì„ ì •ì˜í•  ìˆ˜ ìˆëŠ” ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ë‚´ë¶€ë¥¼ ì´í•´í•˜ì§€ ì•Šê³ ë„ ìŠ¤íŒŒí¬ SQLì—ì„œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì¿¼ë¦¬ ê°€ëŠ¥ ìŠ¤íŒŒí¬ SQLì´ í•˜ìœ„ í‘œí˜„ì‹ì˜ í‰ê°€ ìˆœì„œë¥¼ ë³´ì¥í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— UDF ë‚´ë¶€ì—ì„œ null ê²€ì‚¬ Copy python from pyspark.sql.types import LongType def cubed(s): return s * s * s spark.udf.register(\u0026#34;cubed\u0026#34;, cubed, LongType()) spark.range(1, 9).createOrReplaceTempView(\u0026#34;udf_test\u0026#34;) spark.sql(\u0026#34;SELECT id, cubed(id) AS id_cubed FROM udf_test\u0026#34;).show() Pandas UDF # ì…ë ¥ê³¼ ì¶œë ¥ì´ ëª¨ë‘ íŒë‹¤ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ì¸ API ì§€ì› Copy python import pandas as pd from pyspark.sql.functions ipmort col, pandas_udf from pyspark.sql.types import LongType def cubed(a: pd.Series) -\u0026gt; pd.Series: return a * a * a cubed_udf = pandas_udf(cubed, returnType=LongType()) df = spark.range(1, 4) df.select(\u0026#34;id\u0026#34;, cubed_udf(col(\u0026#34;id\u0026#34;))).show() Spark Shell # $SPARK_HOME í´ë”ì—ì„œ ./bin/spark-sql ëª…ë ¹ì–´ ì‹¤í–‰ Copy bash spark-sql\u0026gt; CREATE TABLE people (Name STRING, age INT) JDBC # user, password, url, dbtable, query, driver ì—°ê²° ì†ì„± ì§€ì • íŒŒí‹°ì…”ë‹ì„ ìœ„í•œ numPartitions, partitionColumn, lowerBound, upperBound ì†ì„± PostgreSQL # Copy python jdbcDF1 = (spark .read # .write .format(\u0026#34;jdbc\u0026#34;) .opiton(\u0026#34;url\u0026#34;, \u0026#34;jdbc:postgresql://[DBSERVER]\u0026#34;) .option(\u0026#34;dbtable\u0026#34;, \u0026#34;[SCHEMA].[TABLENAME]\u0026#34;). .option(\u0026#34;user\u0026#34;, \u0026#34;[USERNAME]\u0026#34;) .option(\u0026#34;password\u0026#34;, \u0026#34;[PASSWORD]\u0026#34;) .load()) # .save() SQL ê³ ì°¨ í•¨ìˆ˜ # ì¤‘ì²©ëœ êµ¬ì¡°ë¥¼ ê°œë³„ í–‰ìœ¼ë¡œ ë¶„í•´\nCopy sql SELECT id, collect_list(value = 1) AS values FROM (SELECT id, EXPLODE(values) AS value FROM table) x GROUP BY id ë°°ì—´ ìœ í˜• í•¨ìˆ˜ # array_distinct(array): ë°°ì—´ ë‚´ì˜ ì¤‘ë³µì„ ì œê±° array_intersect(array, array): ì¤‘ë³µë˜ì§€ ì•Šì€ ë‘ ë°°ì—´ì˜ êµì°¨ì ì„ ë°˜í™˜ array_union(array, array): ì¤‘ë³µ í•­ëª© ì—†ì´ ë‘ ë°°ì—´ì˜ ê²°í•©ì„ ë°˜í™˜ array_except(array, array): ë°°ì—´1ì—ëŠ” ì¡´ì¬í•˜ì§€ë§Œ ë°°ì—´2ì—ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìš”ì†Œë¥¼ ë°˜í™˜ array_join(array, string): êµ¬ë¶„ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°ì—´ ìš”ì†Œë¥¼ ì—°ê²° array_max(array): Nullê°’ì„ ì œì™¸í•œ ë°°ì—´ì˜ ìµœëŒ“ê°’ì„ ë°˜í™˜ array_min(array): Nullê°’ì„ ì œì™¸í•œ ë°°ì—´ì˜ ìµœì†Ÿê°’ì„ ë°˜í™˜ array_position(array, T): ë°°ì—´ì—ì„œ ì§€ì •ëœ ìš”ì†Œì˜ ì²«ë²ˆì§¸ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜ array_remove(array, T): ë°°ì—´ì—ì„œ ì§€ì •ëœ ìš”ì†Œì™€ ë™ì¼í•œ ëª¨ë“  ìš”ì†Œë¥¼ ì œê±° array_overlap(array, array): Nullì´ ì•„ë‹Œ ë™ì¼í•œ ê°’ì´ ë‘ ë°°ì—´ì— ìˆì„ ê²½ìš° trueë¥¼ ë°˜í™˜ array_sort(array): ë°°ì—´ì„ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  Nullì€ ë§¨ ëì— ìœ„ì¹˜ concat(array, ...): ë¬¸ìì—´, ë°”ì´ë„ˆë¦¬, ë°°ì—´ ë“±ì„ ì—°ê²° flatten(array\u0026lt;array\u0026gt;): ë°°ì—´ ì•ˆì˜ ë°°ì—´ë“¤ì„ ë‹¨ì¼ ë°°ì—´ë¡œ í”Œë«í™” array_repeat(T, Int): ì§€ì •ëœ ìš”ì†Œê°€ í¬í•¨ëœ ë°°ì—´ì„ ì§€ì •í•œ íšŸìˆ˜ë§Œí¼ ë°˜í™˜ reverse(array): ë¬¸ìì—´ì˜ ì—­ìˆœ ë˜ëŠ” ë°°ì—´ì—ì„œ ìš”ì†Œì˜ ì—­ìˆœì„ ë°˜í™˜ sequence(T, T), ì‹œì‘ë¶€í„° ëì„ í¬í•¨í•œ ì¼ë ¨ì˜ ìš”ì†Œë¥¼ ìƒì„± shuffle(array): ì£¼ì–´ì§„ ë°°ì—´ì˜ ë¬´ì‘ìœ„ ìˆœì—´ì„ ë°˜í™˜ slice(array, Int, Int): ë°°ì—´ì—ì„œ ì§€ì •ëœ ì‹œì‘ê³¼ ë ì¸ë±ìŠ¤ì— ëŒ€í•œ í•˜ìœ„ ì§‘í•©ì„ ë°˜í™˜ array_zip(array, array, ...): ë³‘í•©ëœ êµ¬ì¡° ë°°ì—´ì„ ë°˜í™˜ element_at(array, Int): ì§€ì •ëœ ì¸ë±ìŠ¤ì—ì„œ ì§€ì •ëœ ë°°ì—´ì˜ ìš”ì†Œë¥¼ ë°˜í™˜ cardinality(array): ì§€ì •ëœ ë°°ì—´ ë˜ëŠ” ë§µì˜ í¬ê¸°ë¥¼ ë°˜í™˜ ë§µ í•¨ìˆ˜ # map_form_arrays(array, array): ì£¼ì–´ì§„ í‚¤/ê°’ ë°°ì—´ ìŒì—ì„œ ë§µì„ ìƒì„±í•˜ì—¬ ë°˜í™˜ map_from_entries(array\u0026lt;struct\u0026gt;): ì£¼ì–´ì§„ ë°°ì—´ì—ì„œ ìƒì„±ëœ ë§µì„ ë°˜í™˜ map_concat(map, ...): ì…ë ¥ëœ ë§µì˜ ê²°í•©ì„ ë°˜í™˜ element_at(map, K): ì£¼ì–´ì§„ í‚¤ì— ëŒ€í•œ ê°’ì„ ë°˜í™˜í•˜ê³  ì—†ì„ ê²½ìš° Nullì„ ë°˜í™˜ cardinality(array): ì§€ì •ëœ ë°°ì—´ ë˜ëŠ” ë§µì˜ í¬ê¸°ë¥¼ ë°˜í™˜ ê³ ì°¨ í•¨ìˆ˜ # transform(values, value -\u0026gt; lambda expression) í˜•íƒœì˜ ëŒë‹¤ì‹ ì‚¬ìš© Copy python # transform(): ë°°ì—´ì˜ ê° ìš”ì†Œì— í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ë°°ì—´ì„ ìƒì„± spark.sql(\u0026#34;\u0026#34;\u0026#34; SELECT celsius, transform(celsius, t -\u0026gt; ((t * 9) div 5) + 32) AS fahrenheit FROM tC \u0026#34;\u0026#34;\u0026#34;).show() # filter(): ì…ë ¥í•œ ë°°ì—´ì˜ ìš”ì†Œ ì¤‘ ì°¸ì¸ ìš”ì†Œë§Œ ë°°ì—´ë¡œ ë°˜í™˜ spark.sql(\u0026#34;\u0026#34;\u0026#34; SELECT celsius, filter(celsius, t -\u0026gt; t \u0026gt; 38) AS high FROM tC \u0026#34;\u0026#34;\u0026#34;).show() # exists(): ì…ë ¥í•œ ë°°ì—´ì˜ ìš”ì†Œ ì¤‘ ë¶ˆë¦° í•¨ìˆ˜ë¥¼ ë§Œì¡±ì‹œí‚¤ë©´ ì°¸ì„ ë°˜í™˜ spark.sql(\u0026#34;\u0026#34;\u0026#34; SELECT celsius, exists(celsius, t -\u0026gt; t \u0026gt; 38) AS high FROM tC \u0026#34;\u0026#34;\u0026#34;).show() # reduce(): ìš”ì†Œë¥¼ ë³‘í•©í•˜ê³  ë°°ì—´ì˜ ìš”ì†Œë¥¼ ë‹¨ì¼ê°’ìœ¼ë¡œ ì¤„ì„ spark.sql(\u0026#34;\u0026#34;\u0026#34; SELECT celsius, reduce(celsius, 0, (t, acc) -\u0026gt; t + acc, acc -\u0026gt; (acc div size(celsius) * 9 div 5) + 32 ) AS avgFahrenheit FROM tC \u0026#34;\u0026#34;\u0026#34;).show() SQL ì‘ì—… # Union # Copy python bar = departureDelays.union(foo) bar.createOrReplaceTempView(\u0026#34;bar\u0026#34;) bar.filter(expr(\u0026#34;\u0026#34;\u0026#34;origin == \u0026#39;SEA\u0026#39; AND destination == \u0026#39;SFO\u0026#39; AND date LIKE \u0026#39;01010%\u0026#39; AND delay \u0026gt; 0\u0026#34;\u0026#34;\u0026#34;)).show() JOIN # Copy python foo.join( airports, airports.IATA == foo.origin ).select(\u0026#34;City\u0026#34;, \u0026#34;State\u0026#34;, \u0026#34;date\u0026#34;, \u0026#34;delay\u0026#34;, \u0026#34;distance\u0026#34;, \u0026#34;destination\u0026#34;).show() Window # rank(), dense_rank(), percent_rank(), ntile(), row_number() cume_dist(), first_value(), last_value(), lag(), lead() Copy sql CREATE TABLE departureDelaysWindow AS SELECT origin, destination, SUM(delay) AS TotalDelays FROM departureDelays WHERE origin IN (\u0026#39;SEA\u0026#39;, \u0026#39;SFO\u0026#39;, \u0026#39;JFK\u0026#39;) AND destination IN (\u0026#39;SEA\u0026#39;, \u0026#39;SFO\u0026#39;, \u0026#39;JFK\u0026#39;, \u0026#39;DEN\u0026#39;, \u0026#39;ORD\u0026#39;, \u0026#39;LAX\u0026#39;, \u0026#39;ATL\u0026#39;) GROUP BY origin, destination; Copy python spark.sql(\u0026#34;\u0026#34;\u0026#34; SELECT origin, destination, TotalDelays, rank FROM ( SELECT origin, destination, TotalDelays, dense_rank() OVER (PARTITION BY origin ORDER BY TotalDelays DESC) AS rank FROM departureDelaysWindow ) t WHERE rank \u0026lt;= 3 \u0026#34;\u0026#34;\u0026#34;).show() Modification # Copy python from pyspark.sql.functions import * # ì—´ ì¶”ê°€ foo2 = (foo.withColumn( \u0026#34;status\u0026#34;, expr(\u0026#34;CASE WHEN delay \u0026lt;= 10 THEN \u0026#39;On-time\u0026#39; ELSE \u0026#39;Delayed\u0026#39; END\u0026#34;) )) # ì—´ ì‚­ì œ foo3 = foo2.drop(\u0026#34;delay\u0026#34;) # ì¹¼ëŸ¼ëª… ë°”ê¾¸ê¸° foo4 = foo3.withColumnRenamed(\u0026#34;status\u0026#34;, \u0026#34;flight_status\u0026#34;) # í”¼ë²— SELECT * FROM ( SELECT destination, CAST(SUBSTRING(date, 0, 2) AS int) AS month, delay FROM departureDelays WHERE origin = \u0026#39;SFA ) PIVOT ( CAST AVG(delay) AS DECIMAL(4, 2) AS AvgDelay, MAX(delay) AS MaxDelay FOR month IN (1 JAN, 2 FEB) ) "},{"id":1,"href":"/blog/10000-recipe/","title":"[Python] ë§Œê°œì˜ ë ˆì‹œí”¼ ë°ì´í„° ìˆ˜ì§‘","section":"Posts","content":"ìµœê·¼ ë ˆì‹œí”¼ ìƒì„±ì„ ëª©ì ìœ¼ë¡œ í•œ ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ê²Œ ë˜ì—ˆëŠ”ë°\nëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë§Œê°œì˜ ë ˆì‹œí”¼ ë°ì´í„° í¬ë¡¤ë§ì„ ì§„í–‰í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\nìŠ¤í‚¤ë§ˆ êµ¬ì„± # ê¸°ì¡´ì—” ë ˆì‹œí”¼ ëª…ì¹­ê³¼ ìŒì‹ ì¬ë£Œ ì •ë³´ë§Œì„ ìˆ˜ì§‘í•  ê³„íšì´ì—ˆì§€ë§Œ,\në§Œê°œì˜ ë ˆì‹œí”¼ì˜ ê° í˜ì´ì§€ë¥¼ ì‚´í´ë³´ë©´ì„œ ì¶”ê°€ì ìœ¼ë¡œ ê°€ì ¸ê°ˆë§Œí•œ ë°ì´í„°ê°€ ìˆìŒì„ í™•ì¸í•˜ì—¬\nìš°ì„ ì ìœ¼ë¡œ í…Œì´ë¸” ê´€ê³„ ë° ìŠ¤í‚¤ë§ˆë¥¼ êµ¬ì„±í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\nì´ˆê¸°ì— ë§Œê°œì˜ ë ˆì‹œí”¼ì™€ ê³µê³µë°ì´í„°ë¥¼ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì‚¼ì•˜ê¸° ë•Œë¬¸ì—,\në§Œê°œì˜ ë ˆì‹œí”¼ì— ëŒ€í•œ DB _10000, ê³µê³µë°ì´í„°ì— ëŒ€í•œ DB foodë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\n_10000 DB ë‚´ í…Œì´ë¸”ì€ ë§Œê°œì˜ ë ˆì‹œí”¼ ë‚´ ê°ê°ì˜ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¡œ êµ¬ì„±ë˜ë©°,\ní¬ê²Œ ì¹´í…Œê³ ë¦¬, ë ˆì‹œí”¼, ì‚¬ìš©ì ë‹¨ìœ„ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në§Œê°œì˜ ë ˆì‹œí”¼ ë°ì´í„° ìˆ˜ì§‘ # í¬ë¡¤ë§ì—ì„œ ë°ì´í„° ìš”ì²­ ë° ê°€ê³µì„ ìœ„í•´ ì •ì˜ëœ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì´ ìˆëŠ”ë°,\në³„ë„ë¡œ ì½”ë“œë¥¼ ë³´ì—¬ì£¼ì§€ëŠ” ì•Šê³  í•´ë‹¹ í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•Œ ê°„ë‹¨íˆ ì–´ë–¤ ë™ì‘ì„ í•˜ëŠ”ì§€ë§Œ ì „ë‹¬ë“œë¦½ë‹ˆë‹¤.\nì¹´í…Œê³ ë¦¬ ì¶”ì¶œ # ë§Œê°œì˜ ë ˆì‹œí”¼ ì¹´í…Œê³ ë¦¬ëŠ” ë ˆì‹œí”¼ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œ ê°„ë‹¨í•˜ê²Œ ì¶”ì¶œí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,\nê°œë°œì ë„êµ¬ ë˜ëŠ” requestsì— ëŒ€í•œ ì‘ë‹µì—ì„œ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\nì—¬ê¸°ì„œ get_headers() í•¨ìˆ˜ëŠ” User-Agent ë“± ê¸°ë³¸ì ì¸ ë¸Œë¼ìš°ì € ì •ë³´ê°€ ë‹´ê¸´ í—¤ë”ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\nCopy python url = \u0026#34;https://www.10000recipe.com/recipe/list.html\u0026#34; headers = get_headers(url, referer=url) headers[\u0026#34;upgrade-insecure-requests\u0026#34;] = \u0026#39;1\u0026#39; response = session.get(url, params=params, headers=headers) source = BeautifulSoup(response.text, \u0026#34;html.parser\u0026#34;) cate_list = source.select_one(\u0026#34;div.cate_list\u0026#34;) pattern = \u0026#34;javascript:goSearchRecipe([\\d\\w()\u0026#39;,]+)\u0026#34; raw_cat = [(re_get(pattern, cat.attrs[\u0026#34;href\u0026#34;]),cat.text) for cat in cate_list.select(\u0026#34;a\u0026#34;) if \u0026#34;href\u0026#34; in cat.attrs] cat_map = lambda catType, catId, catName: {\u0026#34;categoryId\u0026#34;:catId, \u0026#34;categoryType\u0026#34;:catType, \u0026#34;categoryName\u0026#34;:catName} categories = [cat_map(*literal_eval(data), name) for data, name in raw_cat] categories = pd.DataFrame(categories) categories = categories[categories[\u0026#34;categoryId\u0026#34;]!=\u0026#39;\u0026#39;] categories.head() ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ì˜ ë°ì´í„°ë¥¼ íšë“í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ncategoryId categoryType categoryName 63 cat4 ë°‘ë°˜ì°¬ 56 cat4 ë©”ì¸ë°˜ì°¬ 54 cat4 êµ­/íƒ• 55 cat4 ì°Œê°œ 60 cat4 ë””ì €íŠ¸ ë ˆì‹œí”¼ ëª©ë¡ ì¶”ì¶œ # ë ˆì‹œí”¼ ê²€ìƒ‰ í˜ì´ì§€ëŠ” ê²€ìƒ‰ì–´, ì •ë ¬ ê¸°ì¤€, í˜ì´ì§€, ì¹´í…Œê³ ë¦¬ë¥¼ ì¿¼ë¦¬ë¡œ ë°›ìŠµë‹ˆë‹¤.\në ˆì‹œí”¼ ëª©ë¡ì„ ì¶”ì¶œí•˜ëŠ”ë° ê²€ìƒ‰ì–´ë‚˜ ì¹´í…Œê³ ë¦¬ëŠ” í•„ìš”í•˜ì§€ ì•Šê³  ë™ì¼í•œ ì •ë ¬ ê¸°ì¤€ì—ì„œ ìˆ˜ì§‘í•˜ê¸° ë•Œë¬¸ì—\në°ì´í„° ìˆ˜ì§‘ ì‹œì—ëŠ” í˜ì´ì§€ì— ë°˜ë³µë¬¸ì„ ì ìš©í•˜ì—¬ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ë²”ìœ„ë¥¼ ê°€ì ¸ì˜¬ ê²ƒì…ë‹ˆë‹¤.\nCopy python ORDER_MAP = {\u0026#34;ì •í™•ìˆœ\u0026#34;:\u0026#34;accuracy\u0026#34;, \u0026#34;ìµœì‹ ìˆœ\u0026#34;:\u0026#34;date\u0026#34;, \u0026#34;ì¶”ì²œìˆœ\u0026#34;:\u0026#34;reco\u0026#34;} get_params = lambda **kwargs: {k:v for k,v in kwargs.items() if v} uri = \u0026#34;https://www.10000recipe.com/recipe/\u0026#34; def fetch(session: requests.Session, query=str(), sortType=\u0026#34;ì¶”ì²œìˆœ\u0026#34;, page=1, cat1=str(), cat2=str(), cat3=str(), cat4=str(), **kwargs) -\u0026gt; List[str]: url = uri+\u0026#34;list.html\u0026#34; params = get_params(q=query, order=ORDER_MAP[sortType], page=page, cat1=cat1, cat2=cat2, cat3=cat3, cat4=cat4) headers = get_headers(url, referer=url) headers[\u0026#34;upgrade-insecure-requests\u0026#34;] = \u0026#39;1\u0026#39; response = session.get(url, params=params, headers=headers) return parse(response.text, **kwargs) def parse(response: str, **kwargs) -\u0026gt; List[str]: source = BeautifulSoup(response, \u0026#39;html.parser\u0026#39;) uris = source.select(\u0026#34;a.common_sp_link\u0026#34;) ids = [uri.attrs[\u0026#34;href\u0026#34;].split(\u0026#39;/\u0026#39;)[-1] for uri in uris if \u0026#34;href\u0026#34; in uri.attrs] return ids ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ë¡œëŠ” ë¬¸ìì—´ íƒ€ì…ì˜ ë ˆì‹œí”¼ ID ëª©ë¡ì„ íšë“í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në ˆì‹œí”¼ ì •ë³´ ì¶”ì¶œ # ë ˆì‹œí”¼ IDë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ë ˆì‹œí”¼ ìƒì„¸ ì •ë³´ í˜ì´ì§€ì—ì„œ\në ˆì‹œí”¼ ì •ë³´ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì†ŒìŠ¤ì½”ë“œ ë‚´ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ê°€ JSON í˜•ì‹ìœ¼ë¡œ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì—\nì¼ì¼íˆ HTML íƒœê·¸ë¥¼ íŒŒì‹±í•  í•„ìš” ì—†ì´ ë°ì´í„°ë¥¼ í•œë²ˆì— JSON ì˜¤ë¸Œì íŠ¸ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në°ì´í„°ë¥¼ ê°€ê³µí•˜ëŠ” map_recipe() í•¨ìˆ˜ ë‚´ì—ì„œ\ncast_int()ëŠ” ë°ì´í„°ë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜í•  ë•Œ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ê¸°ë³¸ê°’ 0ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì´ê³ ,\nhier_get()ì€ ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ì˜ì— ë‹¨ê³„ë³„ í‚¤ ëª©ë¡ì— ëŒ€í•œ ê°’ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\nCopy python uri = \u0026#34;https://www.10000recipe.com/recipe/\u0026#34; def fetch(session: requests.Session, recipeId: str, **kwargs) -\u0026gt; Dict: url = uri+recipeId # https://www.10000recipe.com/recipe/6997297 headers = get_headers(url, referer=uri+\u0026#34;list.html\u0026#34;) headers[\u0026#34;upgrade-insecure-requests\u0026#34;] = \u0026#39;1\u0026#39; response = session.get(url, headers=headers) return parse(response.text, recipeId, **kwargs) def parse(response: str, recipeId: str, **kwargs) -\u0026gt; Dict: source = BeautifulSoup(response, \u0026#39;html.parser\u0026#39;) raw_json = source.select_one(\u0026#34;script[type=\\\u0026#34;application/ld+json\\\u0026#34;]\u0026#34;).text try: data = json.loads(raw_json) except: data = literal_eval(raw_json) return map_recipe(data, recipeId, source, **kwargs) def map_recipe(data: Dict, recipeId: str, source=None, **kwargs) -\u0026gt; Dict: recipe_info = {\u0026#34;recipeId\u0026#34;: recipeId} recipe_info[\u0026#34;name\u0026#34;] = data.get(\u0026#34;name\u0026#34;) recipe_info[\u0026#34;author\u0026#34;] = hier_get(data, [\u0026#34;author\u0026#34;,\u0026#34;name\u0026#34;]) recipe_info[\u0026#34;ratingValue\u0026#34;] = cast_int(hier_get(data, [\u0026#34;aggregateRating\u0026#34;,\u0026#34;ratingValue\u0026#34;])) recipe_info[\u0026#34;reviewCount\u0026#34;] = cast_int(hier_get(data, [\u0026#34;aggregateRating\u0026#34;,\u0026#34;reviewCount\u0026#34;])) recipe_info[\u0026#34;totalTime\u0026#34;] = data.get(\u0026#34;totalTime\u0026#34;) recipe_info[\u0026#34;recipeYield\u0026#34;] = data.get(\u0026#34;recipeYield\u0026#34;) try: recipe_info[\u0026#34;recipeIngredient\u0026#34;] = \u0026#39;,\u0026#39;.join(data[\u0026#34;recipeIngredient\u0026#34;]) except: recipe_info[\u0026#34;recipeIngredient\u0026#34;] = extract_ingredient(source, **kwargs) recipe_info[\u0026#34;recipeInstructions\u0026#34;] = \u0026#39;\\n\u0026#39;.join( [step.get(\u0026#34;text\u0026#34;,str()) for step in data.get(\u0026#34;recipeInstructions\u0026#34;,list()) if isinstance(step, dict)]) recipe_info[\u0026#34;createDate\u0026#34;] = data.get(\u0026#34;datePublished\u0026#34;) return recipe_info def extract_ingredient(source: Tag, **kwargs) -\u0026gt; str: cont_ingre = source.select_one(\u0026#34;div.cont_ingre\u0026#34;) if cont_ingre: return [ingre.split() for ingre in cont_ingre.select_one(\u0026#34;dd\u0026#34;).text.split(\u0026#39;,\u0026#39;)] else: return str() ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy python { \u0026#34;recipeId\u0026#34;: \u0026#34;6997297\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;ë‘ë¶€ì§œì¡°\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;í˜¸ì´í˜¸ì´\u0026#34;, \u0026#34;ratingValue\u0026#34;: 5, \u0026#34;reviewCount\u0026#34;: 1, \u0026#34;totalTime\u0026#34;: \u0026#34;PT20M\u0026#34;, \u0026#34;recipeYield\u0026#34;: \u0026#34;1 servings\u0026#34;, \u0026#34;recipeIngredient\u0026#34;: \u0026#34;ë‘ë¶€ 30g,ë¼ì´ìŠ¤í˜ì´í¼ 2ì¥,ë¼ì§€ê³ ê¸° 5g,...\u0026#34;, \u0026#34;recipeInstructions\u0026#34;: \u0026#34;ë¶€ìœ„ëŠ” ìƒê´€ì—†ì§€ë§Œ ì €ëŠ” ì €ë ´í•˜ê³ ...\u0026#34;, \u0026#34;createDate\u0026#34;: \u0026#34;2023-02-19T13:37:04+09:00\u0026#34; } ì‹¤ì§ˆì ìœ¼ë¡œ í™œìš©í•  ë°ì´í„°ëŠ” ë ˆì‹œí”¼ëª… nameê³¼ ì¬ë£Œëª…ì¸ recipeIngredientì´ë©°,\ní‰ì , ë¦¬ë·° ìˆ˜, ì¡°ë¦¬ìˆœì„œ ë“±ë„ ì¶”ê°€ì ì¸ ë¶„ì„ì„ í†µí•´ í™œìš©ì„±ì„ ê¸°ëŒ€í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nìš”ë¦¬ í›„ê¸° ì¶”ì¶œ # ë™ì¼í•œ ë ˆì‹œí”¼ ìƒì„¸ ì •ë³´ í˜ì´ì§€ì—ì„œ ìš”ë¦¬ í›„ê¸°ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në‹¨, ìš”ë¦¬ í›„ê¸°ëŠ” JSON í˜•ì‹ìœ¼ë¡œ ì •ë¦¬ë˜ì–´ ìˆì§€ ì•Šê¸° ë•Œë¬¸ì—\nHTML ì†ŒìŠ¤ë¥¼ íŒŒì‹±í•˜ì—¬ ëŒ€ìƒ ë¬¸ìì—´ì„ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.\në°ì´í„°ë¥¼ ê°€ê³µí•˜ëŠ” map_review() í•¨ìˆ˜ ë‚´ì—ì„œ\nre_get()ì€ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ì— ë§¤ì¹­ë˜ëŠ” ë¬¸ìì—´ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ì´ê³ ,\nselect_text()ëŠ” BeautifulSoup íƒœê·¸ì—ì„œ\nCSS Selectorë¡œ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\nCopy python GENDER = {\u0026#34;info_name_m\u0026#34;:\u0026#34;M\u0026#34;, \u0026#34;info_name_f\u0026#34;:\u0026#34;F\u0026#34;} uri = \u0026#34;https://www.10000recipe.com/recipe/\u0026#34; rid_ptn = \u0026#34;replyReviewDiv_(\\d+)\u0026#34; uid_ptn = \u0026#34;/profile/review.html\\?uid=([\\d\\w]+)\u0026#34; date_ptn = \u0026#34;(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\u0026#34; def fetch(session: requests.Session, recipeId: str, **kwargs) -\u0026gt; List[Dict]: url = uri+recipeId headers = get_headers(url, referer=uri+\u0026#34;list.html\u0026#34;) headers[\u0026#34;upgrade-insecure-requests\u0026#34;] = \u0026#39;1\u0026#39; response = session.get(url, headers=headers) return parse(response.text, recipeId, **kwargs) def parse(response: str, recipeId: str, **kwargs) -\u0026gt; List[Dict]: source = BeautifulSoup(response, \u0026#39;html.parser\u0026#39;) reply_divs = source.select(\u0026#34;div.view_reply\u0026#34;) review_div = [div for div in reply_divs if div.select_one(\u0026#34;div.reply_tit\u0026#34;).text.strip().startswith(\u0026#34;ìš”ë¦¬ í›„ê¸°\u0026#34;)] if review_div: review_list = review_div[0].select(\u0026#34;div.reply_list\u0026#34;) return [map_review(review, recipeId, **kwargs) for review in review_list] else: return list() def map_review(data: Tag, recipeId: str, **kwargs) -\u0026gt; Dict: review_info = dict() review_info[\u0026#34;reviewId\u0026#34;] = re_get(rid_ptn, data.select(\u0026#34;div\u0026#34;)[-1].attrs.get(\u0026#34;id\u0026#34;)) review_info[\u0026#34;recipeId\u0026#34;] = recipeId review_info[\u0026#34;userId\u0026#34;] = re_get(uid_ptn, data.select_one(\u0026#34;a\u0026#34;).attrs.get(\u0026#34;href\u0026#34;)) review_info[\u0026#34;contents\u0026#34;] = select_text(data, \u0026#34;p.reply_list_cont\u0026#34;) detail = data.select_one(\u0026#34;h4.media-heading\u0026#34;) if detail: review_info[\u0026#34;userName\u0026#34;] = select_text(detail, \u0026#34;b\u0026#34;) gender = detail.select_one(\u0026#34;b\u0026#34;).attrs.get(\u0026#34;class\u0026#34;) review_info[\u0026#34;userGender\u0026#34;] = GENDER.get(gender[0]) if gender else None review_info[\u0026#34;createDate\u0026#34;] = re_get(date_ptn, detail.text) return review_info ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì—¬ê¸°ì„œ ìš”ë¦¬ í›„ê¸°ì™€ ë³„ë„ë¡œ ì‚¬ìš©ì ëª…ì¹­ê³¼ ì„±ë³„ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy python { \u0026#34;reviewId\u0026#34;: \u0026#34;395018\u0026#34;, \u0026#34;recipeId\u0026#34;: \u0026#34;6843136\u0026#34;, \u0026#34;userId\u0026#34;: \u0026#34;58031746\u0026#34;, \u0026#34;contents\u0026#34;: \u0026#34;ì •ë§ ê°„ë‹¨í•œë° ì¤‘ë¶ˆë¡œí•˜ë‹ˆ ì¢€ íƒœì›Œë¨¹ì—ˆ... ë§›ì€ ìˆë„¤ìš¬ã…‹ã…‹ã…‹ã…‹ã…‹ë‹¤ìŒì—” ì¤‘ë¶ˆì´ë‘ ì•½ë¶ˆ ì‚¬ì´ë¡œ í•¨ ë”í•´ë°”ì•¼ê² ì–´ìš¬ã…‹ã…‹ã…‹ã„±ã…‹ã…‹ê°ì‚¼ë‘¥..â™¡â™¡\u0026#34;, \u0026#34;userName\u0026#34;: \u0026#34;ë‚˜ì°¡as\u0026#34;, \u0026#34;userGender\u0026#34;: \u0026#34;F\u0026#34;, \u0026#34;createDate\u0026#34;: \u0026#34;2020-11-09 17:14:02\u0026#34; } ëŒ“ê¸€ ì¶”ì¶œ # ë ˆì‹œí”¼ ìƒì„¸ ì •ë³´ í˜ì´ì§€ì—ì„œ ëŒ“ê¸€ì€ ë¯¸ë¦¬ë³´ê¸°ë§Œì´ ì œê³µë˜ë©°\nì „ì²´ ëŒ“ê¸€ì„ í™•ì¸í•˜ê¸° ìœ„í•´ì„œëŠ” ë³„ë„ì˜ í˜ì´ì§€ì— ì ‘ì†í•´ì•¼ í•©ë‹ˆë‹¤.\ní•´ë‹¹ í˜ì´ì§€ì˜ ì¶œë ¥ ê²°ê³¼ì—ì„œë„ ìš”ë¦¬ í›„ê¸°ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ\nHTML ì†ŒìŠ¤ë¥¼ íŒŒì‹±í•˜ì—¬ ëŒ€ìƒ ë¬¸ìì—´ì„ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.\nCopy python GENDER = {\u0026#34;info_name_m\u0026#34;:\u0026#34;M\u0026#34;, \u0026#34;info_name_f\u0026#34;:\u0026#34;F\u0026#34;} uri = \u0026#34;https://www.10000recipe.com/recipe/\u0026#34; cid_ptn = \u0026#34;replyCommentDiv_(\\d+)\u0026#34; uid_ptn = \u0026#34;/profile/recipe_comment.html\\?uid=([\\d\\w]+)\u0026#34; date_ptn = \u0026#34;(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2})\u0026#34; def fetch(session: requests.Session, recipeId: str, page=1, **kwargs) -\u0026gt; List[Dict]: url = uri+\u0026#34;ajax.html\u0026#34; params = dict(q_mode=\u0026#34;getListComment\u0026#34;, seq=recipeId, page=page) headers = get_headers(url, referer=uri+recipeId) headers[\u0026#34;upgrade-insecure-requests\u0026#34;] = \u0026#39;1\u0026#39; response = session.get(url, params=params, headers=headers) return parse(response.text, recipeId, **kwargs) def parse(response: str, recipeId: str, **kwargs) -\u0026gt; List[Dict]: source = BeautifulSoup(response, \u0026#39;html.parser\u0026#39;) comment_list = source.select(\u0026#34;div.reply_list\u0026#34;) return [map_comment(comment, recipeId, **kwargs) for comment in comment_list] def map_comment(data: Tag, recipeId: str, **kwargs) -\u0026gt; Dict: comment_info = dict() comment_info[\u0026#34;commentId\u0026#34;] = re_get(cid_ptn, data.select(\u0026#34;div\u0026#34;)[-1].attrs.get(\u0026#34;id\u0026#34;)) comment_info[\u0026#34;recipeId\u0026#34;] = recipeId comment_info[\u0026#34;userId\u0026#34;] = re_get(uid_ptn, data.select_one(\u0026#34;a\u0026#34;).attrs.get(\u0026#34;href\u0026#34;)) comment_info[\u0026#34;contents\u0026#34;] = select_text(data, \u0026#34;div.media-body\u0026#34;).split(\u0026#39;|\u0026#39;)[-1] detail = data.select_one(\u0026#34;h4.media-heading\u0026#34;) if detail: comment_info[\u0026#34;userName\u0026#34;] = select_text(detail, \u0026#34;b\u0026#34;) gender = detail.select_one(\u0026#34;b\u0026#34;).attrs.get(\u0026#34;class\u0026#34;) comment_info[\u0026#34;userGender\u0026#34;] = GENDER.get(gender[0]) if gender else None comment_info[\u0026#34;createDate\u0026#34;] = re_get(date_ptn, detail.text) return comment_info review = fetch(session, \u0026#34;6843136\u0026#34;) review[0] ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në°ì´í„° êµ¬ì¡°ëŠ” ìš”ë¦¬ í›„ê¸°ì™€ ë™ì¼í•©ë‹ˆë‹¤.\nCopy python { \u0026#34;commentId\u0026#34;: \u0026#34;39693405\u0026#34;, \u0026#34;recipeId\u0026#34;: \u0026#34;6843136\u0026#34;, \u0026#34;userId\u0026#34;: \u0026#34;89382542\u0026#34;, \u0026#34;contents\u0026#34;: \u0026#34;ì‹ ê³ ê·¸ëŸ¬ë„¤ì—¬..ì¬ë£Œì–‘ì´..ã…œ\u0026#34;, \u0026#34;userName\u0026#34;: \u0026#34;íœ˜ì•„ì—¬\u0026#34;, \u0026#34;userGender\u0026#34;: \u0026#34;F\u0026#34;, \u0026#34;createDate\u0026#34;: \u0026#34;2022-03-18 00:02\u0026#34; } "},{"id":2,"href":"/blog/2023-03-25/","title":"2023-03-25 Log","section":"Posts","content":"Spark SQL # ë°ì´í„° ì†ŒìŠ¤ì™€ JDBC/ODBC ì»¤ë„¥í„° ë˜ëŠ” ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‚¬ì´ë¥¼ ì—°ê²° SparkSessionì˜ sql() í•¨ìˆ˜ë¥¼ í†µí•´ SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰ Copy python # ì„ì‹œë·° ìƒì„± df = (spark.read.format(\u0026#34;csv\u0026#34;) .option(\u0026#34;inferSchema\u0026#34;, \u0026#34;true\u0026#34;) .option(\u0026#34;header\u0026#34;, \u0026#34;true\u0026#34;) .load(csv_file)) df.createOrReplaceTempView(\u0026#34;us_delay_flights_tbl\u0026#34;) # ì„ì‹œë·°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¿¼ë¦¬ spark.sql(\u0026#34;\u0026#34;\u0026#34;SELECT distance, origin, destination FROM us_delay_flights_tbl WHERE distance \u0026gt; 1000 ORDER BY distance DESC\u0026#34;\u0026#34;\u0026#34;).show(10) SQL Table # ê´€ë¦¬í˜• í…Œì´ë¸”: ë©”íƒ€ë°ì´í„°ì™€ íŒŒì¼ ì €ì¥ì†Œì˜ ë°ì´í„°ë¥¼ ëª¨ë‘ ê´€ë¦¬ ë¹„ê´€ë¦¬í˜• í…Œì´ë¸”: ë©”íƒ€ë°ì´í„°ë§Œ ê´€ë¦¬í•˜ê³  ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì§ì ‘ ê´€ë¦¬ ê´€ë¦¬í˜• í…Œì´ë¸”ì—ì„œ DROP TABLEê³¼ ê°™ì€ SQL ëª…ë ¹ì€ ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚­ì œ Copy python # ê´€ë¦¬í˜• í…Œì´ë¸” ìƒì„± spark.sql(\u0026#34;CREATE DATABASE learn_spark_db\u0026#34;) spark.sql(\u0026#34;USE learn_spark_db\u0026#34;) spark.sql(\u0026#34;\u0026#34;\u0026#34;CREATE TABLE managed_us_delay_flights_tbl ( data STRING, delay INT, distance INT, origin STRING, destination STRING)\u0026#34;\u0026#34;\u0026#34;) # ë¹„ê´€ë¦¬í˜• í…Œì´ë¸” ìƒì„± spark.sql(\u0026#34;\u0026#34;\u0026#34;CREATE TABLE us_delay_flights_tbl ( date STRING, delay INT, distance INT, origin STRING, destination STRING) USING csv OPTIONS (PATH \u0026#39;data.csv\u0026#39;)\u0026#34;\u0026#34;\u0026#34;) SQL View # ê¸°ì¡´ í…Œì´ë¸”ì„ í† ëŒ€ë¡œ ë·°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©°, ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì¢…ë£Œë˜ë©´ ì‚¬ë¼ì§ ì„ì‹œ ë·°: ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë‚´ ë‹¨ì¼ SparkSessionì— ì—°ê²° ì „ì—­ ì„ì‹œ ë·°: ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë‚´ ì—¬ëŸ¬ SparkSessionì„ ë§Œë“¤ ìˆ˜ ìˆìŒ Copy sql -- SQL ì˜ˆì œ CREATE OR REPLACE GLOBAL TEMP VEIW us_origin_airport_SFO_global_tmp_view AS SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = \u0026#39;SFO\u0026#39; Copy python # íŒŒì´ì¬ ì˜ˆì œ df_sfo = spark.sql(\u0026#34;\u0026#34;\u0026#34;SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = \u0026#39;SFO\u0026#39;\u0026#34;\u0026#34;\u0026#34;) df_sfo.createOrReplaceGlobalTempView(\u0026#34;us_origin_airport_SFO_global_tmp_view\u0026#34;) Data Source # DataFrameReader # ì•„ë˜ì™€ ê°™ì´ ê¶Œì¥ë˜ëŠ” ì‚¬ìš© íŒ¨í„´ì´ ì¡´ì¬\nDataFrameReader.format(args).option(\u0026quot;Key\u0026quot;, \u0026quot;value\u0026quot;).schema(args).loads() format(): \u0026ldquo;parquet\u0026rdquo;, \u0026ldquo;csv\u0026rdquo;, \u0026ldquo;json\u0026rdquo; ë“±ì´ ê°€ëŠ¥í•˜ë©° ê¸°ë³¸ì ìœ¼ë¡œëŠ” \u0026ldquo;parquet\u0026rdquo; option(): í‚¤/ê°’ ìŒì„ ì§€ì •í•˜ë©° ê¸°ë³¸ ëª¨ë“œë¡œ PERMISSIVE ì ìš© schema(): ìŠ¤í‚¤ë§ˆë¥¼ ìœ ì¶”í•  ìˆ˜ ìˆëŠ” DDL ë¬¸ìì—´ ë˜ëŠ” StructType ì œê³µ load(): ë°ì´í„° ì†ŒìŠ¤ì˜ ê²½ë¡œì´ë©°, option()ì— ì§€ì •ëœ ê²½ìš° ë¹„ì›Œë‘˜ ìˆ˜ ìˆìŒ DataFrameWriter # ì•„ë˜ì™€ ê°™ì´ ê¶Œì¥ë˜ëŠ” ì‚¬ìš© íŒ¨í„´ì´ ì¡´ì¬\nDataFrameWriter.format(args).option(args).bucketBy(args).partitionBy(args).save(path) format(): \u0026ldquo;parquet\u0026rdquo;, \u0026ldquo;csv\u0026rdquo;, \u0026ldquo;json\u0026rdquo; ë“±ì´ ê°€ëŠ¥í•˜ë©° ê¸°ë³¸ì ìœ¼ë¡œëŠ” \u0026ldquo;parquet\u0026rdquo; option(): í‚¤/ê°’ ìŒì„ ì§€ì •í•˜ë©° ê¸°ë³¸ ëª¨ë“œ ì˜µì…˜ì€ error ë˜ëŠ” errorifexists bucketBy(): ë²„í‚· ê°œìˆ˜ ë° ë²„í‚· ê¸°ì¤€ ì¹¼ëŸ¼ëª… save(): ë°ì´í„° ì†ŒìŠ¤ì˜ ê²½ë¡œ saveAsTable(): ì €ì¥í•  í…Œì´ë¸” Parquet # ë‹¤ì–‘í•œ I/O ìµœì í™”ë¥¼ ì œê³µí•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì¹¼ëŸ¼ ê¸°ë°˜ íŒŒì¼ í˜•ì‹ íŒŒì¼€ì´ íŒŒì¼ì€ ë°ì´í„° íŒŒì¼, ë©”íƒ€ë°ì´í„°, ì—¬ëŸ¬ ì••ì¶• íŒŒì¼ ë° ì¼ë¶€ ìƒíƒœ íŒŒì¼ì´ í¬í•¨ JSON # ë‹¨ì¼ ë¼ì¸ ëª¨ë“œì™€ ë‹¤ì¤‘ ë¼ì¸ ëª¨ë“œê°€ ìˆê³ , ë‹¤ì¤‘ ë¼ì¸ ëª¨ë“œëŠ” multilineì„ trueë¡œ ì„¤ì • compression, dateFormat, multiline, allowUnquoted ë“± ì˜µì…˜ ì‚¬ìš© ê°€ëŠ¥ CSV # ê¸°ë³¸ì ìœ¼ë¡œ ì‰¼í‘œë¡œ ê° ë°ì´í„°ë¥¼ êµ¬ë¶„í•˜ë©°, ë‹¤ë¥¸ êµ¬ë¶„ ê¸°í˜¸ë¡œ í•„ë“œë¥¼ ë¶„ë¦¬í•  ìˆ˜ ìˆìŒ inferSchema, sep, escape, header ë“± ì˜µì…˜ ì‚¬ìš© ê°€ëŠ¥ Avro # ìŠ¤íŒŒí¬ 2.4ì— ë‚´ì¥ëœ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì†Œê°œëœ í˜•ì‹ìœ¼ë¡œ ì¹´í”„ì¹´ì—ì„œ ë©”ì‹œì§€ë¥¼ ì§ë ¬í™”í•  ë•Œ ì‚¬ìš© JSONì— ëŒ€í•œ ì§ì ‘ ë§¤í•‘, ì†ë„ì™€ íš¨ìœ¨ì„±, ë‹¤ì–‘í•œ ì–¸ì–´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°”ì¸ë”© ë“± ì´ì  ì œê³µ avroSchema, recordName, recordNamespace, ignoreExtension ë“± ì˜µì…˜ ì‚¬ìš© ê°€ëŠ¥ ORC # ìŠ¤íŒŒí¬ 2.xëŠ” ë²¡í„°í™”ëœ ORC ë¦¬ë”ë¥¼ ì§€ì› ë²¡í„°í™”ëœ ë¦¬ë”ëŠ” í–‰ ë¸”ë¡(1024ê°œ ë‹¨ìœ„)ì„ ì½ì–´ ì‘ì—…ì„ ê°„ì†Œí™”í•˜ê³ \nê²€ìƒ‰, í•„í„°, ì§‘ê³„, ì¡°ì¸ê³¼ ê°™ì€ ì§‘ì¤‘ì ì¸ ì‘ì—…ì— ëŒ€í•œ CPU ì‚¬ìš©ëŸ‰ ì¤„ì„ Image # ë”¥ëŸ¬ë‹ ë° ë¨¸ì‹ ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ íŒŒì¼ì„ ë„ì… Copy bash root |-- image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- height: integer (nullable = true) | |-- width: integer (nullable = true) | |-- nChannels: integer (nullable = true) | |-- mode: integer (nullable = true) | â””-- data: binary (nullable = true) â””-- label: integer (nullable = true) Binary File # ì•„ë˜ì™€ ê°™ì€ ì—´ì´ ìˆëŠ” ë°ì´í„° í”„ë ˆì„ ìƒì„± path: StringType modificationTime: TimestampType length: LongType content: BinaryType recursiveFileLookupì´ \u0026ldquo;true\u0026quot;ë¡œ ì„¤ì •ëœ ê²½ìš° label ì»¬ëŸ¼ì´ ì—†ìŒ "},{"id":3,"href":"/blog/2023-03-21/","title":"2023-03-21 Log","section":"Posts","content":"Map Reduce # MR APIëŠ” ë§ì€ ì–‘ì˜ ê¸°ë³¸ ì…‹ì—… ì½”ë“œê°€ í•„ìš”í•˜ê³ ,\nì¥ì•  ëŒ€ì‘ì´ ë¶ˆì•ˆì •í•˜ë©° ë°˜ë³µì ì¸ ë””ìŠ¤í¬ I/O ì‘ì—… ë°œìƒ ë¨¸ì‹ ëŸ¬ë‹, ìŠ¤íŠ¸ë¦¬ë° ë“± ë™ì ì´ê³  ë°˜ë³µì ì¸ ì»´í“¨íŒ… ì‘ì—…ì—ì„œ íš¨ìœ¨ ê°œì„ ì„ ìœ„í•´ ìŠ¤íŒŒí¬ ê°œë°œ Spark # DAGì˜ ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ì§ˆì˜ ìµœì í™” ëª¨ë“ˆì„ í†µí•´ ë³‘ë ¬ ìˆ˜í–‰ ëª¨ë“  ê²°ê³¼ëŠ” ë©”ëª¨ë¦¬ì— ìœ ì§€ë˜ë©°, ë””ìŠ¤í¬ I/Oë¥¼ ì œí•œì ìœ¼ë¡œ ì‚¬ìš© ë°ì´í„° í”„ë ˆì„ê³¼ ê°™ì€ ê³ ìˆ˜ì¤€ ë°ì´í„° ì¶”ìƒí™” ê³„ì¸µ ì•„ë˜ ë‹¨ìˆœí•œ ë…¼ë¦¬ ìë£Œêµ¬ì¡° êµ¬ì¶• ìŠ¤íŒŒí¬ SQL, ìŠ¤íŒŒí¬ MLlib, ìŠ¤íŒŒí¬ ì •í˜•í™” ìŠ¤íŠ¸ë¦¬ë° GraphX ë“± ëª¨ë“ˆ ì§€ì› ì €ì¥ê³¼ ì—°ì‚°ì„ ë¶„ë¦¬í•˜ì—¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì²˜ë¦¬ Spark Components # ì–´ë– í•œ ì½”ë“œë¡œ ì‘ì„±í•´ë„ ê³ ë„ë¡œ ê²½ëŸ‰í™”ëœ ë°”ì´íŠ¸ì½”ë“œë¡œ ë³€í™˜ë˜ì–´ ì›Œì»¤ ë…¸ë“œì˜ JVMì—ì„œ ì‹¤í–‰ ìŠ¤íŒŒí¬ SQL: SQL ê³„í†µì˜ ì§ˆì˜ë¥¼ ì¨ì„œ ë°ì´í„°ë¥¼ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ì½ì–´ë“¤ì´ëŠ” ê¸°ëŠ¥ ìŠ¤íŒŒí¬ MLlib: ê²½ì‚¬ í•˜ê°•ë²• ìµœì í™”ë¥¼ í¬í•¨í•œ ì €ìˆ˜ì¤€ ML ê¸°ëŠ¥ í¬í•¨ ìŠ¤íŒŒí¬ ì •í˜•í™” ìŠ¤íŠ¸ë¦¬ë°: ì¹´í”„ì¹´ ë“± ì‹¤ì‹œê°„ ì—°ê²° ë° ë°˜ì‘ì„ ìœ„í•œ ëª¨ë¸ GraphX: ê·¸ë˜í”„ ë³‘ë ¬ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ Spark Architecture # ìŠ¤íŒŒí¬ ë“œë¼ì´ë²„: ìŠ¤íŒŒí¬ ì´ê·¸ì œíí„°ë¥¼ ìœ„í•œ ìì› ìš”ì²­ ë° íƒœìŠ¤í¬ ë¶„ë°° SparkSession: ëª¨ë“  ìŠ¤íŒŒí¬ ì—°ì‚°ê³¼ ë°ì´í„°ì— ëŒ€í•œ í†µí•© ì—°ê²° ì±„ë„, ìŠ¤íŒŒí¬ SQL ì§ˆì˜ ê°€ëŠ¥ í´ëŸ¬ìŠ¤í„° ë§¤ë‹ˆì €: í´ëŸ¬ìŠ¤í„°ì—ì„œ ìì›ì„ ê´€ë¦¬ ë° í• ë‹¹í•˜ëŠ” ì±…ì„ ìŠ¤íŒŒí¬ ì´ê·¸ì œíí„°: í´ëŸ¬ìŠ¤í„°ì˜ ê° ì›Œì»¤ ë…¸ë“œì—ì„œ ë™ì‘í•˜ë©° íƒœìŠ¤í¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ì—­í•  Spark Application # ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í•µì‹¬ì—ëŠ” ìŠ¤íŒŒí¬ ë“œë¼ì´ë²„ê°€ ìˆìœ¼ë©°, ì´ ë“œë¼ì´ë²„ëŠ” SparkSession ê°ì²´ë¥¼ ìƒì„± ìŠ¤íŒŒí¬ ì¡: ë“œë¼ì´ë²„ëŠ” ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í•˜ë‚˜ ì´ìƒì˜ ìŠ¤íŒŒí¬ ì¡ìœ¼ë¡œ ë³€í™˜ ìŠ¤íŒŒí¬ ìŠ¤í…Œì´ì§€: ìŠ¤íŒŒí¬ ì—°ì‚°ì„ ì—¬ëŸ¬ ìŠ¤í…Œì´ì§€ë¡œ ë‚˜ë‰˜ì–´ ì‹¤í–‰, ìµœì†Œ ì‹¤í–‰ ë‹¨ìœ„ ìŠ¤íŒŒí¬ íƒœìŠ¤í¬: ê°œë³„ CPU ì½”ì–´ì— í• ë‹¹ë˜ì–´ ì‘ì—… Spark Calculation # íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜: ì›ë³¸ ë°ì´í„°ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  ìƒˆë¡œìš´ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë³€í˜•\n(select()ë‚˜ filter() ê°™ì€ ì—°ì‚°ìœ¼ë¡œ ì›ë³¸ ë°ì´í„° í”„ë ˆì„ì„ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ) íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì€ ì¦‰ì‹œ ê³„ì‚°ë˜ì§€ ì•Šê³  ë¦¬ë‹ˆì§€ í˜•íƒœë¡œ ê¸°ë¡,\nì•¡ì…˜ì´ ì‹¤í–‰ë  ë•Œ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ë¼ë¦¬ ì¬ë°°ì—´í•˜ê±°ë‚˜ í•©ì³ì„œ ë” íš¨ìœ¨ì ìœ¼ë¡œ ìµœì í™” íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°: orderBy(), groupBy(), filter(), select(), join() ì•¡ì…˜ ì—°ì‚°: show(), take(), count(), collect(), save() ì¢ì€ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜: í•˜ë‚˜ì˜ ì…ë ¥ íŒŒí‹°ì…˜ì„ ì—°ì‚°í•˜ì—¬ í•˜ë‚˜ì˜ ê²°ê³¼ íŒŒí‹°ì…˜ì„ ìƒì„± (filter, contains) ë„“ì€ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜: ë‹¤ë¥¸ íŒŒí‹°ì…˜ìœ¼ë¡œë¶€í„° ë°ì´í„°ë¥¼ ì½ì–´ ë“¤ì—¬ì„œ í•©ì¹˜ê³  ë””ìŠ¤í¬ì— ì‘ì„± (groupBy, orderBy) Spark RDD # ì˜ì¡´ì„±: ì–´ë–¤ ì…ë ¥ì„ í•„ìš”ë¡œ í•˜ê³  í˜„ì¬ì˜ RDDê°€ ì–´ë–»ê²Œ ë§Œë“¤ì–´ì§€ëŠ”ì§€ íŒŒí‹°ì…˜: ì‘ì—…ì„ ë‚˜ëˆ  íŒŒí‹°ì…˜ë³„ë¡œ ë³‘ë ¬ ì—°ì‚°í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë¶€ì—¬ ì—°ì‚° í•¨ìˆ˜: RDDì— ì €ì¥ë˜ëŠ” ë°ì´í„°ë¥¼ Iterator[T] í˜•íƒœë¡œ ë³€í™˜ ìŠ¤íŒŒí¬ 2.xëŠ” ê³ ìˆ˜ì¤€ ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ ëª…ë£Œí•¨ê³¼ ë‹¨ìˆœí•¨ì„ ê°€ì§\nì˜ˆì‹œë¡œ #1ê³¼ ê°™ì€ ê·¸ë£¹í™”ëŠ” #2ë¡œ ê°„ì†Œí™”í•  ìˆ˜ ìˆìŒ\nCopy python #1 agesRDD = (dataRDD. map(lambda x: (x[0], (x[1], 1)))) .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) .map(lambda x: (x[0], x[1][0]/x[1][1])) Copy python #2 avgDf = dataDf.groupby(\u0026#34;name\u0026#34;).agg(avg(\u0026#34;age\u0026#34;)) DataFrame # ìŠ¤íŒŒí¬ëŠ” ì´ì „ ë³€ê²½ ë‚´ì—­ì„ ë³´ê´€í•˜ì—¬ ì´ë¥¼ ë³´ì¡´í•œ ì±„ë¡œ ì¹¼ëŸ¼ì˜ ì´ë¦„ì´ë‚˜ íƒ€ì…ì„ ë³€ê²½ ê°€ëŠ¥ ìŠ¤íŒŒí¬ì˜ ê¸°ë³¸ ë°ì´í„° íƒ€ì…ì€ String, Byte, Integer, Float ë“± (íŒŒì´ì¬ ë°ì´í„° íƒ€ì…ë„ ì§€ì›) ë³µí•© ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ Map, Array, Struct, Date íƒ€ì… ë“±ì˜ ë³µí•© íƒ€ì… ë° ì •í˜•í™” íƒ€ì… ì§€ì› Schema # ë°ì´í„° í”„ë ˆì„ì„ ìœ„í•´ ì¹¼ëŸ¼ ì´ë¦„ê³¼ ì—°ê´€ëœ ë°ì´í„° íƒ€ì…ì„ ì •ì˜í•œ ê²ƒ ìŠ¤íŒŒí¬ê°€ ë°ì´í„° íƒ€ì…ì„ ì¶”ì¸¡í•´ì•¼ í•˜ëŠ” ì±…ì„ì„ ëœì–´ì£¼ì–´ ì´ì— ëŒ€í•œ ë³„ë„ì˜ ì¡ì„ ë§Œë“œëŠ” ê²ƒì„ ë°©ì§€ ë°ì´í„°ê°€ ìŠ¤í‚¤ë§ˆì™€ ë§ì§€ ì•ŠëŠ” ê²½ìš°, ì¡°ê¸°ì— ë¬¸ì œë¥¼ ë°œê²¬ ê°€ëŠ¥ í”„ë¡œê·¸ë˜ë° ìŠ¤íƒ€ì¼ ë˜ëŠ” DDLì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ì •ì˜ Copy python from pyspark.sql.types import * # í”„ë¡œê·¸ë˜ë° ìŠ¤íƒ€ì¼ schema = StructType([ StructField(\u0026#34;author\u0026#34;, StringType(), False), StructField(\u0026#34;title\u0026#34;, StringType(), False), StructField(\u0026#34;pages\u0026#34;, IntegerType(), False)]) # DDL schema = \u0026#34;author STRING, title STRING, pages INT\u0026#34; # ìŠ¤í‚¤ë§ˆë¡œ ë°ì´í„° í”„ë ˆì„ ìƒì„± df = spark.createDataFrame(data, schema) # ë°ì´í„° í”„ë ˆì„ì˜ ìŠ¤í‚¤ë§ˆ ì¶œë ¥ print(df.printSchema()) Column # Copy python df.select(expr(\u0026#34;Hits * 2\u0026#34;)) # í‘œí˜„ì‹ì„ ì‚¬ìš©í•œ ê³„ì‚° df.select(col(\u0026#34;Hits\u0026#34;) * 2) # ì¹¼ëŸ¼ëª…ì„ ì‚¬ìš©í•œ ê³„ì‚° # ê¸°ì¡´ ì¹¼ëŸ¼ì„ ì—°ê²°í•˜ì—¬ ìƒˆë¡œìš´ ì¹¼ëŸ¼ì„ ìƒì„± df .withColumn(\u0026#34;AuthorsId\u0026#34;, (concat(expr(\u0026#34;First\u0026#34;), expr(\u0026#34;Last\u0026#34;), expr(\u0026#34;Id\u0026#34;)))) .select(col(\u0026#34;AuthorsId\u0026#34;)) # ì¹¼ëŸ¼ê°’ì— ë”°ë¼ ì •ë ¬ df.sort(col(\u0026#34;Id\u0026#34;).desc) df.sort($\u0026#34;Id\u0026#34;.desc) # $ëŠ” ì¹¼ëŸ¼ì„ Column íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” ìŠ¤íŒŒí¬ì˜ í•¨ìˆ˜ Row # Copy python blog_row = Row(6, \u0026#34;Reynold\u0026#34;, \u0026#34;2015-03-02\u0026#34;) blog_row[1] # \u0026gt;\u0026gt; \u0026#39;Reynold\u0026#39; ; ì¸ë±ìŠ¤ë¡œ ê°œë³„ Rowì— ì ‘ê·¼ # Row ê°ì²´ë“¤ì„ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ rows = [Row(\u0026#34;Matei\u0026#34;, \u0026#34;CA\u0026#34;), Row(\u0026#34;Reynold\u0026#34;, \u0026#34;CA\u0026#34;)] df = spark.createDateFrame(rows, [\u0026#34;Authors\u0026#34;, \u0026#34;State\u0026#34;]) DataFrameReader # JSON, CSV ë“± ë‹¤ì–‘í•œ í¬ë§·ì˜ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ê°€ì ¸ì˜´ ë™ì¼í•˜ê²Œ ë°ì´í„° í”„ë ˆì„ì„ ë‚´ë³´ë‚´ê¸° ìœ„í•´ DataFrameWriter ì‚¬ìš© DataFrameWriterì˜ í¬ë§·ì€ ê¸°ë³¸ìœ¼ë¡œ parquet, ë°ì´í„° ì••ì¶•ì—ì„œëŠ” snapy ì‚¬ìš© Copy python from pyspark.sql.types import * # ë°ì´í„° ì½ê¸° schema = StructType([StructField(...), ...]) file = \u0026#34;data.csv\u0026#34; df = spark.read_csv(file, header=True, schema=schema) # ë°ì´í„° ì“°ê¸° df.write.format(\u0026#34;parquet\u0026#34;).save(path) Projection # í•„í„°ë¥¼ ì´ìš©í•´ íŠ¹ì • ê´€ê³„ ìƒíƒœì™€ ë§¤ì¹­ë˜ëŠ” í–‰ë“¤ë§Œ ë°˜í™˜ filter()ë‚˜ where() ë©”ì„œë“œë¡œ í‘œí˜„ Copy python from pyspark.sql.functions import * # ì•ì—ì„œ 5ê°œ í–‰ ë°˜í™˜ df.show(5, truncate=False) # CallTypeì˜ uniqueí•œ ê°œìˆ˜ ë°˜í™˜ (df .select(\u0026#34;CallType\u0026#34;) .where(col(\u0026#34;CallType\u0026#34;).isNotNull()) # null íƒ€ì… ì œì™¸ .agg(countDistinct(\u0026#34;CallType\u0026#34;).alias(\u0026#34;DistinctCallTypes\u0026#34;)) .show()) # ì¹¼ëŸ¼ëª… ë³€ê²½ df.withColumnRenamed(\u0026#34;Delay\u0026#34;, \u0026#34;ResponseDelayedinMins\u0026#34;) # ì¹¼ëŸ¼ ë‚´ìš© ë³€ê²½ (df .withColumn(\u0026#34;IncidentDate\u0026#34;, to_timestamp(col(\u0026#34;CallDate\u0026#34;), \u0026#34;MM/dd/yyyy\u0026#34;)) .drop(\u0026#34;CallDate\u0026#34;)) # ë‚ ì§œ ì¹¼ëŸ¼ ì§ˆì˜ (df .select(year(\u0026#34;IncidentDate\u0026#34;)) .distinct() .orderBy(year(\u0026#34;IncidentDate\u0026#34;)) .show()) Aggregation # count(), min(), max(), sum(), avg() ë“± ì—°ì‚° Copy python (df .select(\u0026#34;CallType\u0026#34;) .groupBy(\u0026#34;CallType\u0026#34;) .count() .orderBy(\u0026#34;count\u0026#34;, ascending=False) .show(n=10, truncate=False)) Dataset API # ì •ì  íƒ€ì… APIì™€ ë™ì  íƒ€ì… APIë¡œ êµ¬ë¶„ ë°ì´í„° í”„ë ˆì„ì€ Dataset[Row]ìœ¼ë¡œ í‘œí˜„ë˜ë©°,\nRowëŠ” ì„œë¡œ ë‹¤ë¥¸ íƒ€ì…ì˜ ê°’ì„ ì €ì¥í•  ìˆ˜ ìˆëŠ” í¬ê´„ì  JVM ê°ì²´ ë°ì´í„°ì„¸íŠ¸ëŠ” Dataset[T]ë¡œ í‘œí˜„ë˜ë©°, ì—„ê²©í•˜ê²Œ íƒ€ì…ì´ ì •í•´ì§„ JVM ê°ì²´ì˜ ì§‘í•© ë™ì ìœ¼ë¡œ íƒ€ì…ì´ ë¶€ì—¬ë˜ëŠ” íŒŒì´ì¬ê³¼ Rì—ì„œëŠ” ë°ì´í„°í”„ë ˆì„, ìë°” ë“±ì—ì„œëŠ” ë°ì´í„°ì„¸íŠ¸ ì‚¬ìš© ìŠ¤ì¹¼ë¼ì—ì„œëŠ” ì¼€ì´ìŠ¤ í´ë˜ìŠ¤ë¡œ ë°ì´í„°ì„¸íŠ¸ ì •ì˜ Copy scala case class DeviceIoTData (battery_level: Long, ...) ds = spark.read.json(\u0026#34;devices.json\u0026#34;).as[DeviceIoTData] // ë°ì´í„°ì„¸íŠ¸ì—ì„œë„ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ë˜ëŠ” ì•¡ì…˜ ìˆ˜í–‰ ê°€ëŠ¥ // ëŒë‹¤ í•¨ìˆ˜ì˜ ì¸ìëŠ” DeviceIoTì˜ JVM ê°ì²´ë¡œ ê°œë³„ ë°ì´í„° í•„ë“œì— ì ‘ê·¼ ê°€ëŠ¥ ds.filter(d =\u0026gt; d.temp \u0026gt; 30 \u0026amp;\u0026amp; d.humidity \u0026gt; 70) Spark SQL # ì •í˜•í™” ë°ì´í„° ê´€ë ¨ ì‘ì—…ì„ ë‹¨ìˆœí™”í•  ìˆ˜ ìˆë„ë¡ ì¶”ìƒí™” ë¹ ë¥¸ ë°ì´í„° íƒìƒ‰ì„ ìœ„í•œ ëŒ€í™”í˜• ìŠ¤íŒŒí¬ SQL ì…¸ì„ ì œê³µ í‘œì¤€ ë°ì´í„°ë² ì´ìŠ¤ì˜ JDBC/ODBC ì»¤ë„¥í„°ë¥¼ í†µí•´ ì™¸ë¶€ì˜ ë„êµ¬ë“¤ê³¼ ì—°ê²°í•  ìˆ˜ ìˆëŠ” ì¤‘ê°„ ì—­í•  ìµœì í™”ëœ ì§ˆì˜ ê³„íšê³¼ JVMì„ ìœ„í•œ ìµœì í™”ëœ ì½”ë“œ ìƒì„± Catalyst Optimizer # ì—°ì‚° ì¿¼ë¦¬ë¥¼ ì‹¤í–‰ ê³„íšìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´\në¶„ì„ \u0026gt; ë…¼ë¦¬ì  ìµœì í™” \u0026gt; ë¬¼ë¦¬ ê³„íš ìˆ˜ë¦½ \u0026gt; ì½”ë“œ ìƒì„± ê³¼ì •ì„ ê±°ì¹¨ ì–¸ì–´ì— ìƒê´€ì—†ì´ ì‚¬ìš©ìê°€ ì‹¤í–‰í•œ ì‘ì—…ì€ ë™ì¼í•œ ê³¼ì •ì„ ê±°ì³ ë°”ì´íŠ¸ ì½”ë“œë¡œ ë³€í™˜ íŒŒì´ì¬ì—ì„œ df.explain(True) í•¨ìˆ˜ë¥¼ í†µí•´ ìŠ¤í…Œì´ì§€ë³„ ìƒì„¸ ë‚´ìš© í™•ì¸ ê°€ëŠ¥ Optimization Flow # ë¶„ì„: ì¿¼ë¦¬ë¥¼ ìœ„í•œ ì¶”ìƒ ë¬¸ë²• íŠ¸ë¦¬ ìƒì„± ë…¼ë¦¬ì  ìµœì í™”: ì—¬ëŸ¬ ê³„íšë“¤ì„ ìˆ˜ë¦½í•˜ê³  ë¹„ìš© ê¸°ë°˜ ì˜µí‹°ë§ˆì´ì €ë¥¼ í†µí•´ ìµœì í™” ë¬¼ë¦¬ ê³„íš ìˆ˜ë¦½: ë…¼ë¦¬ ê³„íšì„ ë°”íƒ•ìœ¼ë¡œ ë¬¼ë¦¬ì  ì—°ì‚°ìë¥¼ ì‚¬ìš©í•´ ìµœì í™”ëœ ë¬¼ë¦¬ ê³„íš ìƒì„± ì½”ë“œ ìƒì„±: ê° ë¨¸ì‹ ì—ì„œ ì‹¤í–‰í•  íš¨ìœ¨ì ì¸ ìë°” ë°”ì´íŠ¸ ì½”ë“œë¥¼ ìƒì„± í¬ê´„ ì½”ë“œ ìƒì„±ì„ í†µí•´ ì „ì²´ ì¿¼ë¦¬ë¥¼ í•˜ë‚˜ì˜ í•¨ìˆ˜ë¡œ í•©ì¹˜ê³  CPU ë ˆì§€ìŠ¤í„° ì‚¬ìš©ì„ ì—†ì•° "},{"id":4,"href":"/blog/2023-02-19/","title":"2023-02-19 Log","section":"Posts","content":"Collaborative Filtering # ì‚¬ìš©ìì™€ ì•„ì´í…œ ê°„ì˜ ìƒí˜¸ ìƒê´€ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬\nìƒˆë¡œìš´ ìƒˆë¡œìš´ ì‚¬ìš©ì-ì•„ì´í…œ ê´€ê³„ë¥¼ ì°¾ëŠ” ì¶”ì²œ ì‹œìŠ¤í…œ Aì™€ Bê°€ ìœ ì‚¬í•œ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì¼ ê²½ìš° Aê°€ êµ¬ë§¤í•˜ì§€ ì•Šì€ ì•„ì´í…œ ì¤‘ Bê°€ ì„ í˜¸í•˜ëŠ” ì•„ì´í…œì„ ì¶”ì²œ Memory-based CF # ê·¼ì ‘ ì´ì›ƒ ë°©ë²• ì•„ì´í…œ ë˜ëŠ” ì‚¬ìš©ì ê°„ì˜ ê´€ê³„ë¥¼ ê³„ì‚°ì— ì¤‘ì ìœ¼ë¡œ ë‘ëŠ” ë°©ì‹ ì‚¬ìš©ìê°€ ì•„ì§ í‰ê°€í•˜ì§€ ì•Šì€ ì•„ì´í…œì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•¨ Item-based CF # ë™ì¼í•œ ì‚¬ìš©ìì˜ ì´ì›ƒ ì•„ì´í…œ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ì´í…œì— ëŒ€í•œ ì‚¬ìš©ìì˜ ì„ í˜¸ë„í‰ê°€ ì´ë¯¸ í‰ê°€í–ˆê±°ë‚˜ ìƒí˜¸ì‘ìš©í•œ ì‚¬ìš©ìë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ì•„ì´í…œê³¼ ìœ ì‚¬í•œ ì•„ì´í…œì„ íƒìƒ‰ User-based CF # ìƒˆë¡œìš´ ì•„ì´í…œì„ í‰ê°€í•  ë•Œ, ìœ ì‚¬í•œ ì•„ì´í…œì— ëŒ€í•´ ë¹„ìŠ·í•œ ì ìˆ˜ë¥¼ ë§¤ê¸´\në‹¤ë¥¸ ì‚¬ìš©ìë“¤ì„ ì°¾ê³ , í•´ë‹¹ ì‚¬ìš©ìê°€ ìƒí˜¸ ì‚¬ìš©í•œ ì  ì—†ëŠ” ì•„ì´í…œì— ëŒ€í•œ ì‚¬ìš©ì ì ìˆ˜ë¥¼ ì˜ˆì¸¡ Model-based CF # ì‚¬ìš©ì-ì•„ì´í…œì˜ ìˆ¨ê²¨ì§„ íŠ¹ì„± ê°’ì„ ê³„ì‚°í•˜ì—¬ í•™ìŠµ í™•ì¥ì„±ê³¼ ì˜ˆì¸¡ ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ, ì˜ˆì¸¡ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ Latent Factor Models, MDP, Decision Tree, Bayesian Network ë“± Latent Factor Model # ì ìˆ˜ íŒ¨í„´ì—ì„œ ì¶”ë¡ ëœ 20-100ê°œì˜ ë²¡í„°ë¡œ ì•„ì´í…œë“¤ê³¼ ì‚¬ìš©ìë“¤ì„ ëª¨ë‘ íŠ¹ì„±í™”í•˜ì—¬ ì ìˆ˜ë¥¼ ì„¤ëª… Matrixë¥¼ ì‚¬ìš©ì-ì ì¬ìš”ì¸, ì•„ì´í…œ-ì ì¬ìš”ì¸ìœ¼ë¡œ ê°ê° ë¶„í•´í•˜ì—¬ í•™ìŠµ í–‰ë ¬ë¶„í•´(Matrix Factorization) ë°©ë²• ë“± ë°ì´í„°ê°€ í´ìˆ˜ë¡ ë‚˜íƒ€ë‚˜ëŠ” ì„±ëŠ¥ì´ ì¢‹ìŒ í‰ê°€ ì§€í‘œ # ìƒê´€ê³„ìˆ˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ íƒ€ë‹ˆëª¨í†  ê³„ìˆ˜ í˜‘ì—… í•„í„°ë§ í•œê³„ì  # Cold Start Problem: ê¸°ì¡´ì˜ ê²½í—˜ì´ ì—†ëŠ” ì‚¬ìš©ìë‚˜ ì•„ì´í…œì— ëŒ€í•œ ì¶”ì²œì´ ì–´ë ¤ì›€ Long Tail: ì‚¬ìš©ìë“¤ì˜ ê´€ì‹¬ì„ ë§ì´ ë°›ì€ ì†Œìˆ˜ì˜ ì•„ì´í…œì— ì§‘ì¤‘ë˜ëŠ” ë¹„ëŒ€ì¹­ì  ì ë¦¼ í˜„ìƒ ë°œìƒ ê³„ì‚°ëŸ‰ì´ ë§ì€ ì•Œê³ ë¦¬ì¦˜ì´ê¸° ë•Œë¬¸ì—, ì‚¬ìš©ìê°€ ì¦ê°€í• ìˆ˜ë¡ ê³„ì‚° ì‹œê°„ì´ ê¸¸ì–´ì ¸ íš¨ìœ¨ì„± ì €í•˜ References # Blossomindy\u0026rsquo;s Research Blog ì¶”ì²œì‹œìŠ¤í…œ1 - ì¶”ì²œì‹œìŠ¤í…œì´ë€?, ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì˜ ì¢…ë¥˜ "},{"id":5,"href":"/blog/2023-02-18/","title":"2023-02-18 Log","section":"Posts","content":"ì¶”ì²œ ì‹œìŠ¤í…œ # í˜‘ì—… í•„í„°ë§(Collaborative Filtering, CF) ë‚´ìš© ê¸°ë°˜ í•„í„°ë§(Content-Based Filtering, CBF) ì§€ì‹ ê¸°ë°˜ í•„í„°ë§(Knowledge-Based Filtering, KBF) ë”¥ëŸ¬ë‹(Deep Learning) í•˜ì´ë¸Œë¦¬ë“œ í•„í„°ë§(í˜‘ì—…í•„í„°ë§ \u0026amp; ë”¥ëŸ¬ë‹) í˜‘ì—… í•„í„°ë§ ê°œìš” # êµ¬ë§¤ ë° ì†Œë¹„í•œ ì œí’ˆì— ëŒ€í•œ ì†Œë¹„ìì˜ í‰ê°€ íŒ¨í„´ì´ ë¹„ìŠ·í•œ ì§‘ë‹¨ ì†ì—ì„œ\nì„œë¡œ ì ‘í•˜ì§€ ì•Šì€ ì œí’ˆì„ ì¶”ì²œ ì†Œë¹„ìë“¤ì˜ í‰ê°€ ì •ë„ê°€ í•„ìš” (ì‹ ê·œ, íœ´ë©´ ê³ ê°)\n-\u0026gt; ì¡°íšŒ, í´ë¦­ ë“±ì„ í†µí•´ ê°„ì ‘ì ìœ¼ë¡œ ë°ì´í„°í™” ë‚´ìš© ê¸°ë°˜ í•„í„°ë§ ê°œìš” # ì œí’ˆì˜ ë‚´ìš©ì„ ë¶„ì„í•´ì„œ ì¶”ì²œ ì§€ì‹ ê¸°ë°˜ í•„í„°ë§ ê°œìš” # íŠ¹ì • ë¶„ì•¼ ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ì•„ ê·¸ ë¶„ì•¼ì— ëŒ€í•œ ì „ì²´ì ì¸ ì§€ì‹ êµ¬ì¡°ë¥¼ ë§Œë“¤ì–´ì„œ í™œìš© í˜‘ì—… í•„í„°ë§ # í˜‘ì—… í•„í„°ë§ ì•Œê³ ë¦¬ì¦˜ # ëª¨ë“  ì‚¬ìš©ì ê°„ í‰ê°€ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë“±) ì¶”ì²œ ëŒ€ìƒê³¼ ë‹¤ë¥¸ ì‚¬ìš©ìê°„ ìœ ì‚¬ë„ ì¶”ì¶œ ì¶”ì²œ ëŒ€ìƒì´ í‰ê°€í•˜ì§€ ì•Šì€ ì•„ì´í…œì— ëŒ€í•œ ì˜ˆìƒ í‰ê°€ê°’ ê³„ì‚°\n(í‰ê°€ê°’ = ë‹¤ë¥¸ ì‚¬ìš©ì í‰ê°€ * ë‹¤ë¥¸ ì‚¬ìš©ì ìœ ì‚¬ë„) ì•„ì´í…œ ì¤‘ì—ì„œ ì˜ˆìƒ í‰ê°€ê°’ ê°€ì¥ ë†’ì€ Nê°œ ì¶”ì²œ ì´ì›ƒì„ ê³ ë ¤í•œ CF # KNN ë°©ë²• Thresholding ë°©ë²• ì‚¬ìš©ì ê¸°ë°˜ CF # ë°ì´í„°ê°€ í’ë¶€í•œ ê²½ìš° ì •í™•í•œ ì¶”ì²œ ê²°ê³¼ì— ëŒ€í•œ ìœ„í—˜ì„± ì¡´ì¬ ë°ì´í„° í¬ê¸°ê°€ ì ê³  ì‚¬ìš©ìì— ëŒ€í•œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ì•„ì´í…œ ê¸°ë°˜ CF # ê³„ì‚°ì´ ë¹ ë¦„ ì—…ë°ì´íŠ¸ì— ëŒ€í•œ ê²°ê³¼ ì˜í–¥ì´ ì ìŒ ë°ì´í„° í¬ê¸°ê°€ í¬ê³  ì¶©ë¶„í•œ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì„±ê³¼ì¸¡ì •ì§€í‘œ # ì •í™•ë„(accuracy) = ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡ëœ ì•„ì´í…œ ìˆ˜ / ì „ì²´ ì•„ì´í…œ ìˆ˜ ì •ë°€ë„(precision) = ì˜¬ë°”ë¥´ê²Œ ì¶”ì²œëœ ì•„ì´í…œ ìˆ˜ / ì „ì²´ ì•„ì´í…œ ìˆ˜ ì¬í˜„ìœ¨(recall) = ì˜¬ë°”ë¥´ê²Œ ì¶”ì²œëœ ì•„ì´í…œ ìˆ˜ / ì‚¬ìš©ìê°€ ì‹¤ì œ ì„ íƒí•œ ì „ì²´ ì•„ì´í…œ ìˆ˜ ì¡°í™”í‰ê· (F1 score) = (2 * ì •ë°€ë„ * ì¬í˜„ìœ¨) / (ì •ë°€ë„ + ì¬í˜„ìœ¨) ë²”ìœ„(coverage) = ì¶”ì²œì´ ê°€ëŠ¥í•œ ì‚¬ìš©ì(ì•„ì´í…œ) ìˆ˜ / ì „ì²´ ì‚¬ìš©ì(ì•„ì´í…œ) ìˆ˜ "},{"id":6,"href":"/blog/2023-02-12/","title":"2023-02-12 Log","section":"Posts","content":"1ê°• - ì±„ê¶Œì‹œì¥ì— ëª°ë¦¬ëŠ” ê°œì¸íˆ¬ììë“¤ ì™œ? # ğŸ“Œ êµ­ë‚´ ì±„ê¶Œì‹œì¥, ì˜¬í•´ ë“¤ì–´ ëœ¨ê±°ìš´ ìƒí™© # ê°œì¸íˆ¬ììë“¤ì˜ ì±„ê¶Œ ìˆœë§¤ìˆ˜ ê·œëª¨ëŠ” ì—°ê°„ 4ì¡°ì› ë‚´ì™¸ë¡œ ì£¼ì‹ì— ë¹„í•´ ë§¤ìš° ì‘ìŒê¸ˆë¦¬\nâ†’ ìƒí’ˆì€ ì±„ê¶Œì´ ì•„ë‹ˆì–´ë„ ì´ë¯¸ ë§ì´ íˆ¬ìí•˜ê³  ìˆê¸° ë•Œë¬¸ ì˜¬í•´ ë“¤ì–´ì„œëŠ” 9ì›” ì¤‘ìˆœê¹Œì§€ ì´ë¯¸ 13ì¡°ì› ìˆœë§¤ìˆ˜. ì§€ë‚œ ëª‡ ë…„ê°„ ì—°ê°„ ìˆœë§¤ìˆ˜ ê·œëª¨ì˜ 3ë°°ë¥¼ ë„˜ì–´ì„œëŠ” ìƒí™© ì´ëŸ¬í•œ í˜„ìƒì€ êµ­ë‚´ ë¿ ì•„ë‹ˆë¼ í•´ì™¸ì—ì„œë„ ë‚˜íƒ€ë‚¨. ì±„ê¶Œìœ¼ë¡œì˜ ìê¸ˆ ì´ë™ ì»¤ì§ ğŸ“Œ ì±„ê¶Œì— ëŒ€í•œ ê´€ì‹¬ì´ ë†’ì•„ì§„ ê°€ì¥ í° ì´ìœ ëŠ” ì±„ê¶Œì˜ ê°€ê²©ì´ ë‚®ì•„ì¡Œê¸° ë•Œë¬¸ # ì±„ê¶Œì˜ ê°€ê²©ì€ ê¸ˆë¦¬ì™€ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì›€ì§ì„. ì¦‰ ê¸ˆë¦¬ê°€ ì˜¤ë¥¸ ê²ƒì´ ì±„ê¶Œ íˆ¬ìì— ëŒ€í•œ ê´€ì‹¬ì´ ëŠ˜ì–´ë‚œ ì£¼ëœ ì´ìœ  ìì‚°ì‹œì¥ì—ì„œ í•œ ìì‚°ì˜ ë§¤ë ¥ë§Œìœ¼ë¡œ ê´€ì‹¬ì´ ëŠ˜ì–´ë‚˜ëŠ” ê²ƒì€ ì•„ë‹˜.\nëŒ€ì•ˆì ì¸ íˆ¬ì ëŒ€ìƒ ì˜ ë§¤ë ¥ë„ê°€ ë–¨ì–´ì§€ëŠ” ê²½ìš°ì—ë„ ê·¸ëŸ° í˜„ìƒ ë‚˜íƒ€ë‚¨ ì±„ê¶Œì˜ ê°€ì¥ í° ëŒ€ì•ˆì  íˆ¬ì ëŒ€ìƒì€ ì£¼ì‹ì¸ë°,\nì˜¬í•´(2022 ê¸°ì¤€) ë“¤ì–´ í•œêµ­ë¿ ì•„ë‹ˆë¼ ê¸€ë¡œë²Œ ì£¼ì‹ì‹œì¥ì€ ë¶ˆì•ˆí•œ ì›€ì§ì„ì„ ë³´ì´ê³  ìˆìŒ ì•„ì´ëŸ¬ë‹ˆí•˜ê²Œë„, ìµœê·¼ ì£¼ê°€ í•˜ë½ì˜ ì£¼ëœ ì´ìœ ê°€ ê¸´ì¶•ê³¼ ê¸ˆë¦¬ ìƒìŠ¹. ì±„ê¶Œê°€ê²©ê³¼ ì£¼ì‹ ê°€ê²©ì´ ë™ì‹œì— í•˜ë½.\nê·¸ë ‡ë‹¤ë©´ ë‘ ê°€ì§€ ëª¨ë‘ ë§¤ë ¥ì´ ì»¤ì¡Œì–´ì•¼ í•˜ëŠ”ë° ì™œ ì±„ê¶Œì´ ë” ê°ê´‘ì„ ë°›ì„ê¹Œ? âœ… ë¶ˆí™•ì‹¤ì„±ì´ ì»¤ì¡Œê¸° ë•Œë¬¸. ì±„ê¶Œì€ ì£¼ì‹ì— ë¹„í•´ì„œëŠ” ë¶ˆí™•ì‹¤ì„±ì´ í™•ì—°íˆ ì‘ì€ ìì‚°\nğŸ“Œ ë¶€ë™ì‚° ì‹œì¥ì˜ ë¶ˆì•ˆë„ ì±„ê¶Œìœ¼ë¡œì˜ ìê¸ˆ ì´ë™ì„ ë¶€ì¶”ê¸°ê³  ìˆìŒ # ìš°ë¦¬ë‚˜ë¼ ìì‚°ê°€ë“¤ì˜ íˆ¬ì íŒ¨í„´ì€ ë¶€ë™ì‚° ë³´ìœ  í›„ íŒ”ê³  ì˜ˆê¸ˆ.\nì´í›„ì— ì‹œì¥ ìƒí™©ì— ë”°ë¼ì„œ ë‹¤ì‹œ ë¶€ë™ì‚°ì´ë‚˜ ì£¼ì‹ìœ¼ë¡œ.\nì¦‰, ê³ ì •ì´ìí˜• ìƒí’ˆì€ ëŒ€ê¸°ì„± ìê¸ˆì˜ í˜•íƒœ ê·¸ëŸ¬ë‚˜ ì§€ê¸ˆì€ ì£¼ì‹ê³¼ í•¨ê»˜ ë¶€ë™ì‚°ë„ ìœ„í—˜í•˜ë‹¤ëŠ” ì¸ì‹ í¼ì ¸ ìˆìŒ. ì§€ë‚œ 5ë…„ê°„ ê¸‰ê²©í•˜ê²Œ ìƒìŠ¹í–ˆê³ ,\nìì‚°ê°€ë¿ ì•„ë‹ˆë¼ ì²­ë…„ì¸µ ì£¼íƒ ë§¤ìˆ˜ ê¸‰ì¦ìœ¼ë¡œ ì¶”ê°€ì ì¸ ë§¤ìˆ˜ ìˆ˜ìš” ì‹¤ì¢…ëœ ìƒí™© ë˜í•œ ìš°ë¦¬ë‚˜ë¼ëŠ” ê°€ê³„ë¶€ì±„ ë¹„ìœ¨ì´ ë†’ì€ ìˆ˜ì¤€ìœ¼ë¡œ í•œë²ˆ ë¶€ë™ì‚° ì‹œì¥ì´ ë¶ˆì•ˆí•´ì§€ë©´,\níšŒë³µì— ì‹œê°„ì´ ê±¸ë¦´ ê°€ëŠ¥ì„± ì—­ì‹œ ë†’ìŒ âœ… ê²°êµ­ ê¸ˆë¦¬ ìƒìŠ¹ ì™¸ì— ê°œì¸ë“¤ì´ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ìì‚° ì¤‘\nëŒ€í‘œì ì¸ ì£¼ì‹ê³¼ ë¶€ë™ì‚°ì˜ ê¸°ëŒ€ìˆ˜ìµë¥ ì´ ë‚®ì•„ì§„ ê²ƒì´ ì±„ê¶Œì— ëŒ€í•œ ê´€ì‹¬ ê¸‰ì¦ì˜ ì´ìœ \nğŸ“Œ ê¸€ë¡œë²Œ ì±„ê¶Œì‹œì¥ì—ì„œ ì˜ ì•Œë ¤ì§„ ì±„ê¶Œì™• ì œí”„ë¦¬ ê±´ë“¤ë½ # ìµœê·¼ ì¸í„°ë·°ì—ì„œ ì¥ê¸°ì±„ì— ì ê·¹ì ìœ¼ë¡œ íˆ¬ìí•˜ë¼ê³  ë°í˜ ì œí”„ë¦¬ ê±´ë“¤ë½ì€ ì›ë˜ ê°€ìˆ˜ì˜€ëŠ”ë°, ëˆì„ ë²Œê¸° ìœ„í•´ íˆ¬ìë¥¼ ì‹œì‘.\nì§€ê¸ˆì€ ë”ë¸”ë¼ì¸ ìºí”¼íƒˆì´ë¼ëŠ” íšŒì‚¬ì˜ CEOë¡œ 140ì¡°ì›ì˜ ìê¸ˆì„ êµ´ë¦¬ê³  ìˆê³ , ê°œì¸ ìì‚°ì€ 2.6ì¡°ì›ì— ë‹¬í•¨ ì‚¬ì‹¤ 2021ë…„ ì´ˆê¹Œì§€ë§Œ í•´ë„ ê·¸ëŠ” ì¸í”Œë ˆì´ì…˜ ìš°ë ¤ê°€ ì‹¬í•´ì§ˆ ê²ƒì´ê¸° ë•Œë¬¸ì— ê¸ˆë¦¬ê°€ ì˜¤ë¥¼ ê²ƒì„ ì˜ˆê²¬,\nì±„ê¶Œì„ ë§¤ë„í•˜ë¼ê³  ê¶Œìœ í–ˆì—ˆìŒ. ê·¸ ë‹¹ì‹œë§Œ í•´ë„ ë¬¼ê°€ì— ëŒ€í•œ ê´€ì‹¬ì€ ì†Œìˆ˜ë§Œ ê°€ì§ í•˜ì§€ë§Œ, ì´ì œëŠ” ë°˜ëŒ€ë¡œ ì±„ê¶Œì„ ë§¤ìˆ˜í•´ì„œ ê¸ˆë¦¬ê°€ í•˜ë½í•  ë•Œ ë§¤ë„í•´ 10~15% ì´ìµì„ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì´ë¼ ì „ë§. ì£¼ì‹ ì¢…ëª©ì„ ì˜ ê³ ë¥´ë©´ ì´ë³´ë‹¤ ìˆ˜ìµë¥ ì´ ë†’ê² ì§€ë§Œ,\nì±„ê¶Œì˜ ê²½ìš° í˜¹ì‹œ ê¸ˆë¦¬ê°€ ì˜¬ë¼ë„ ë§Œê¸° ë³´ìœ í•˜ë©´ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì¢‹ì€ íˆ¬ì ëŒ€ì•ˆ ğŸ“Œ ê¸ˆë¦¬ê°€ ì˜¬ëë‹¤ê³  ì±„ê¶Œ íˆ¬ìí•  ë•Œ ì•„ë¬´ë ‡ê²Œë‚˜ í•˜ëŠ” ê²ƒì€ ê¸ˆë¬¼ # ì§€ê¸ˆì€ ì¸í”Œë ˆì´ì…˜ ì‹œëŒ€. ì–¸ì œê¹Œì§€ ì–´ëŠ ì •ë„ë¡œ ì¸í”Œë ˆì´ì…˜ì´ ë†’ì•„ì§ˆ ê²ƒì¸ì§€ íŒë‹¨í•˜ê¸° ì–´ë ¤ìš´ ìƒíƒœì—ì„œ\nì±„ê¶Œì„ ì˜ ëª¨ë¥´ê³  íˆ¬ìí•˜ëŠ” ê²ƒì€ ìê¸° ìì‚°ì˜ ì‹¤ì§ˆ ê°€ì¹˜ë¥¼ ë‚®ì¶”ëŠ” í–‰ìœ„ê°€ ë  ìˆ˜ ìˆìŒ ì˜ˆë¥¼ ë“¤ì–´ OECDëŠ” ìš°ë¦¬ë‚˜ë¼ì˜ ë¬¼ê°€ìƒìŠ¹ë¥ ì„ 5% ì´ìƒìœ¼ë¡œ ì „ë§í–ˆëŠ”ë°, ì§€ê¸ˆ 3ë…„ë§Œê¸° íšŒì‚¬ì±„ì˜ ê²½ìš° ê¸ˆë¦¬ê°€ 4.7%ëŒ€ì„.\në§Œì•½ ì•ìœ¼ë¡œ 3ë…„ê°„ ë¬¼ê°€ê°€ ê³„ì† 5% ì´ìƒì„ ìœ ì§€í•˜ë©´ ì´ìëŠ” ë°›ì§€ë§Œ, ë‚´ê°€ íˆ¬ìí•œ ì›ê¸ˆì˜ ì‹¤ì§ˆ ê°€ì¹˜ëŠ” ë–¨ì–´ì§€ëŠ” ê²ƒ.\nì§€ê¸ˆ 100ë§Œì›ìœ¼ë¡œ ì‚´ ìˆ˜ ìˆëŠ” ë¬¼ê±´ì„ 3ë…„ í›„ì—ëŠ” ëª» ì‚¬ê²Œ ë¨ ë”°ë¼ì„œ íˆ¬ì ê¸°ê°„ì´ë‚˜, ê¸ˆë¦¬ ì „ë§, ë˜ ì‹ ìš©ìœ„í—˜ ë“±ì— ëŒ€í•œ ì ì ˆí•œ ë¶„ì„ì„ í†µí•´ì„œ ê°€ê¸‰ì  ê³ ì • ì´ìê°€ ë†’ê³ ,\nì¤‘ë„ ë§¤ë„ ë“±ì„ í™œìš©í•´ ìˆ˜ìµë¥ ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ìˆì–´ì•¼ í•¨. ì´ëŠ” ì±„ê¶Œì„ ë³¸ì§ˆì„ ì•Œì•„ì•¼ ê°€ëŠ¥í•œ ì¼ ì œí”„ë¦¬ ê±´ë“¤ë½ì´ 4%ë„ ë˜ì§€ ì•ŠëŠ” ë¯¸êµ­ì±„ ê¸ˆë¦¬ í™˜ê²½ì—ì„œ 10~15% ì±„ê¶Œ íˆ¬ì ìˆ˜ìµë¥ ì„ ë‚¼ ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ëŠ” ê²ƒì€\nì±„ê¶Œê³¼ ê´€ë ¨ëœ ê°ì¢… ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì´ìš©í•´ ë§¤ë§¤ì— í™œìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ ì±„ê¶Œ íˆ¬ì, ì™œ ì–´ë µê²Œ ëŠê»´ì§€ë‚˜? # ì‚¬ì‹¤ ë§ì€ ì‚¬ëŒë“¤ì´ ì±„ê¶Œì— íˆ¬ìí•œ ì ì´ ì—†ë‹¤ê³  ìƒê°í•˜ì§€ë§Œ, ì´ëŠ” ë°˜ì€ ë§ê³  ë°˜ì€ í‹€ë¦° ì–˜ê¸°.\nì±„ê¶Œê³¼ ë¹„ìŠ·í•œ ì„±ê²©ì„ ê°–ëŠ” ê¸ˆìœµìƒí’ˆì—ëŠ” ì´ë¯¸ ë§ì´ íˆ¬ìí•´ ì™”ê¸° ë•Œë¬¸. ì‚¬ì‹¤ ì˜ˆê¸ˆë„ ì±„ê¶Œì˜ í•œ ì¢…ë¥˜ë¼ê³  ë³¼ ìˆ˜ ìˆìŒ. ì¤‘ê°„ ë§¤ë„ì‹œ ìë³¸ì´ë“ì„ ì–»ì„ ìˆ˜ëŠ” ì—†ì§€ë§Œ,\ní•´ì§€í•˜ë©´ ë˜ë¯€ë¡œ ìœ ë™ì„±ì´ ì—†ëŠ” ê²ƒë„ ì•„ë‹˜ ì±„ê¶Œí˜• í€ë“œë„ ë§ˆì°¬ê°€ì§€. ìµœê·¼ì—ëŠ” ê°œì¸ì˜ ì±„ê¶Œí˜• í€ë“œ ê°€ì…ì´ ê±°ì˜ ì¤„ì–´ë“¤ì—ˆì§€ë§Œ,\nMMFë‚˜ ì¦ê¶Œì‚¬ì˜ CMA ìƒí’ˆì—ëŠ” ê°€ì…ë˜ì–´ ìˆëŠ” ê²½ìš°ê°€ ë§ì„ ê²ƒ. ì§ì ‘ì€ ì•„ë‹ˆì§€ë§Œ ê°„ì ‘ì ì¸ í˜•íƒœë¡œ íˆ¬ìí•˜ê³  ìˆëŠ” ì…ˆ ë˜í•œ ì´ë¯¸ ë§ì€ ì‚¬ëŒë“¤ì´ ìì‹ ì˜ ëª©ì ì— ë”°ë¼ ì±„ê¶Œì— íš¨ìœ¨ì ìœ¼ë¡œ íˆ¬ìí•˜ê³  ìˆìŒ.\në§ì€ ì‚¬ëŒë“¤ì´ ì±„ê¶Œìœ¼ë¡œ ìì‹ ì˜ ê¸ˆìœµì  ëª©í‘œë¥¼ ì´ë£¨ëŠ” ê²ƒì€ ê²°êµ­ ì±„ê¶Œì˜ ë³¸ì§ˆì— ëŒ€í•´ ì˜ ì•Œê¸° ë•Œë¬¸.\nì§€ê¸ˆì´ë¼ë„ ì±„ê¶Œì„ ë°°ìš¸ ì´ìœ ëŠ” ì¶©ë¶„ ğŸ“Œ ì±„ê¶Œì„ ì˜ ê³µë¶€í•˜ë©´, ê¸ˆìœµì‹œì¥ ì „ë°˜ì„ ì´í•´í•˜ëŠ” ë° í° ë„ì›€ì´ ë¨ # ì‚¬ì‹¤ ì±„ê¶Œì€ ì£¼ì‹ì— ë¹„í•´ì„œ í›¨ì”¬ ë” ì˜¤ë˜ëœ ê¸ˆìœµìƒí’ˆ. ì£¼ì‹ì˜ ì‹œì‘ì€ ì£¼ì‹íšŒì‚¬ì™€ í•¨ê»˜ ì¶œë°œí•˜ëŠ”ë°,\n17ì„¸ê¸° ë„¤ëœë€ë“œë™ì¸ë„íšŒì‚¬ê°€ ì²« ì‚¬ë¡€ë¡œ ì—¬ê²¨ì§€ê³  ìˆìŒ. ê·¸ëŸ°ë° ì±„ê¶Œì€ ì´ë³´ë‹¤ ë” ì˜¤ë˜ ì „ì— ì „ìŸê³¼ í•¨ê»˜ ì‹œì‘. ê³¼ê±° ì™•êµ­ë“¤ì€ ì „ìŸì„ ë§ì´ ì¹˜ë¤˜ëŠ”ë°,\nì „ìŸì—ëŠ” ëˆì´ ë§ì´ ë“¤ì–´ê°€ê³  ì„¸ê¸ˆìœ¼ë¡œ ì´ë¥¼ ê°ë‹¹í•  ìˆ˜ ì—†ì—ˆìŒ.\në”°ë¼ì„œ ì™•êµ­ë“¤ì€ ì±„ê¶Œì„ ë°œí–‰í•´ ìê¸ˆì„ ì¡°ë‹¬í•˜ê³  ë‚˜ì¤‘ì— ì›ê¸ˆê³¼ ì´ìë¥¼ ì§€ê¸‰í•˜ëŠ” ë°©ì‹ì„ í™œìš©í–ˆìŒ í•˜ì§€ë§Œ, ì±„ê¶Œì˜ ê°€ê²©ì¸ ê¸ˆë¦¬ëŠ” í˜„ëŒ€ì ì¸ ì˜ë¯¸ì˜ ì±„ê¶Œë³´ë‹¤ë„ í›¨ì”¬ ë” ê¸´ ì—­ì‚¬ë¥¼ ê°€ì§.\nì–´ì°Œ ë³´ë©´ ì¸ê°„ ì—­ì‚¬ì—ì„œ ì‰ì—¬ê°€ ë°œìƒí•œ í›„ì— ê°€ì¥ ë¨¼ì € ë‚˜íƒ€ë‚œ ê°œë…ì´ ê¸ˆë¦¬ì¼ ìˆ˜ ìˆìŒ âœ… ì´ ê°™ì€ ì ì€ ì±„ê¶Œê³¼ ì±„ê¶Œì˜ ê°€ê²©ì´ ê¸ˆë¦¬ë¥¼ ì˜ ì´í•´í•˜ë©´,\nê·¸ ê²½ì œê°€ ì–´ë–¤ ìƒí™©ì— ì²˜í•´ ìˆëŠ”ì§€ë¥¼ ì•Œ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•¨\nğŸ“Œ ê¸ˆë¦¬ëŠ” ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ê²½ì œ ìƒí™©ì„ íŒë‹¨í•˜ê²Œ í•´ ì¤„ê¹Œ? # ê¸ˆë¦¬ëŠ” ì–´ë–¤ ê²½ì œì˜ ê±´ê°•í•œ ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì²™ë„ê°€ ë¨ ê¸ˆìœµì‹œì¥ì— ìœ„í—˜ì´ ì—†ê³  ë¬¼ê°€ê°€ ì•ˆì •ëœ ìƒíƒœì—ì„œ ê¸ˆë¦¬ê°€ ë†’ë‹¤ëŠ” ì–˜ê¸°ëŠ” ê·¸ ë‚˜ë¼ê°€ ì„±ì¥ë¥ ì´ ë†’ë‹¤ëŠ” ì ì„ ì˜ë¯¸í•¨.\nì¦‰, ëˆì„ ë¹Œë ¤ê°€ëŠ” ì‚¬ëŒë“¤ì´ ë†’ì€ ê¸ˆë¦¬ì— ë¹Œë ¤ê°€ë„ íˆ¬ì ë“±ì„ í†µí•´ ì¥ì‚¬ë¥¼ ì˜ í•´ì„œ ê°šì„ ìˆ˜ ìˆëŠ” ìƒí™©ì„ì„ ì˜ë¯¸í•¨ í•˜ì§€ë§Œ ì´ì™€ í•¨ê»˜ ìœ„í—˜ì´ ì»¤ì§€ë©´ì„œ ë‚˜íƒ€ë‚˜ëŠ” ê¸ˆë¦¬ ê¸‰ë“±ì€ ê·¸ ë‚˜ë¼ ë˜ëŠ” ê·¸ ë‚˜ë¼ì˜ ê²½ì œ ì£¼ì²´ ì¤‘\nìƒë‹¹ ìˆ˜ê°€ ìì‹ ì˜ ë¶€ì±„ë¥¼ ê°šì§€ ëª»í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸.\nê°šì§€ ëª»í•  ìœ„í—˜ì´ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ì˜ í˜•íƒœë¡œ ê¸ˆë¦¬ì— ë°˜ì˜ë˜ëŠ” ê²ƒ âœ… ê¸ˆë¦¬ê°€ ì¤‘ìš”í•œ ì´ìœ  ì¤‘ í•˜ë‚˜ëŠ” ì •ì±…ë‹¹êµ­ì´ ê¸ˆë¦¬ë¥¼ í†µí•´ ì •ì±…ì„ ìˆ˜í–‰í•œë‹¤ëŠ” ì .\nì£¼ì‹ì€ ê±°ë˜í•˜ëŠ” ì‚¬ëŒë“¤ì´ ì œí•œë˜ì–´ ìˆëŠ” ë°ë‹¤, ì‹¤ì œë¡œ ì£¼ê°€ì— ì ìš©ì„ ë°›ëŠ” ì£¼ì²´ëŠ” ê¸°ì—…ê³¼ ì£¼ì‹ íˆ¬ìì ë¿.\ní•˜ì§€ë§Œ, ê¸ˆë¦¬ëŠ” ê´‘ë²”ìœ„í•œ ì‚¬ëŒì—ê²Œ ì˜í–¥. ë¶€ì±„ê°€ ë§ì€ ì •ë¶€ë„ ì˜í–¥ ìš°ë¦¬ê°€ ë•Œë•Œë¡œ ê²ªëŠ” ê²½ì œ ìœ„ê¸°ê°€ ì£¼ë¡œ ì±„ê¶Œì‹œì¥ìœ¼ë¡œë¶€í„° ì¶œë°œí•œë‹¤ëŠ” ì ë„ ì¤‘ìš”. ìê¸° ëˆì„ ìƒëŠ” ê²ƒë³´ë‹¤ ë‚¨ì—ê²Œ ê°šì§€ ëª»í•˜ëŠ” ê²ƒì´ ê²½ì œì—ì„œëŠ” ë” í° ì¶©ê²©ì´ê¸° ë•Œë¬¸. âœ… ê²°êµ­ ì±„ê¶Œì‹œì¥ì˜ ìƒí™©ê³¼ ê¸ˆë¦¬ë¥¼ ê³µë¶€í•˜ë©´ í˜„ì¬ ê²½ì œì˜ ê±´ê°•ì„±, ì •ì±… ê¸°ì¡°,\në‚˜ì•„ê°€ ê²½ì œ ìœ„ê¸° ë°œìƒ ê°€ëŠ¥ì„± ë“±ì„ ê°€ëŠ í•˜ëŠ” ë°ë„ ë„ì›€ì´ ë  ê²ƒ\n2ê°• - ì•Œì•¼ì•¼ ë²ˆë‹¤, ì±„ê¶Œì´ë€? # ğŸ“Œ ì±„ê¶Œì€ í•œë§ˆë””ë¡œ ëˆì„ ë¹Œë¦¬ë©´ì„œ ë°œí–‰í•œ ì¦ê¶Œ # ëˆì„ ë¹Œë¦¬ë ¤ë©´ ê²°êµ­ ì–¸ì œ ê°šì„ ê±´ì§€, ë¹Œë¦° ê¸°ê°„ ë™ì•ˆ ì–¼ë§ˆë‚˜ ì´ìë¥¼ ì§€ê¸‰í•  ê±´ì§€,\nì–¸ì œ ì´ìë¥¼ ì§€ê¸‰í•´ì•¼ í•  ê±´ì§€ê°€ ì •í•´ì ¸ì•¼ í•¨ ì´ë¥¼ ì±„ê¶Œ íˆ¬ì ìš©ì–´ë¡œ ì„¤ëª…í•˜ë©´ â†’ ë§Œê¸°ì™€ í˜„ê¸ˆ íë¦„ì˜ ì¡°ê±´ì´ ì‚¬ì „ì— ê²°ì •ëœ ìœ ê°€ì¦ê¶Œ.\nì—¬ê¸°ì„œ ì¤‘ìš”í•œ ê²ƒì€ ì‚¬ì „ì— ê²°ì •ëœë‹¤ëŠ” ì . ë°œí–‰ ì‹œì ì— ê²°ì •ë˜ì–´ ëª¨ë“  ê²ƒì´ ì •í•´ì ¸ ìˆë‹¤ëŠ” ê²Œ ë‹¤ë¦„.\nì£¼ì‹ê³¼ ë¹„êµí•´ ë³´ë©´ ì£¼ì‹ì€ ë°°ë‹¹ì„ ì£¼ì§€ë§Œ, ë°°ë‹¹ì€ ì •í•´ì ¸ ìˆì§€ ì•ŠìŒ. ë˜í•œ ë§Œê¸°ë„ ì—†ìŒ ì±„ê¶Œ ë°œí–‰ì€ ê²°êµ­ ë‚¨ì˜ ëˆì„ ë¹Œë¦¬ëŠ” ê²ƒìœ¼ë¡œë¶€í„° ì¶œë°œí•˜ê¸° ë•Œë¬¸ì— ì£¼ì‹ê³¼ ë°œí–‰ìê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ.\nì£¼ì‹ì˜ ê²½ìš°ì—ëŠ” ë¯¼ê°„ ê¸°ì—…ë§Œ ë°œí–‰ ê°€ëŠ¥. ğŸ“Œ ì™œ? â†’ ì£¼ì‹ì€ ì´ìµì´ ë§ì´ ë‚˜ë©´ ê·¸ê²ƒì´ ìœ ë³´ë˜ì–´ ê¸°ì—… ê°€ì¹˜ì— í¬í•¨ë˜ê±°ë‚˜, ë°°ë‹¹ìœ¼ë¡œ ì§€ê¸‰ë˜ëŠ” ê°œë… # ê³µê³µê¸°ê´€ì€ ì´ìµ ê·¹ëŒ€í™”ê°€ ì²«ë²ˆì§¸ ëª©í‘œê°€ ì•„ë‹˜.\nì˜ˆë¥¼ ë“¤ì–´ ì •ë¶€ëŠ” ì„¸ê¸ˆì„ ê±·ê³  ì¨ì„œ ëˆì„ ë§ì´ ë‚¨ê¸°ëŠ” ê²ƒì´ ëª©í‘œê°€ ì•„ë‹˜.\nì´ëŸ¬í•œ ê¸°ê´€ì´ ë°œí–‰í•œ ì£¼ì‹ì˜ ê¸°ëŒ€ ë°°ë‹¹ì€ 0. ë”°ë¼ì„œ ì£¼ê°€ê°€ í˜•ì„±ë  ìˆ˜ ì—†ìŒ. ì±„ê¶Œì€ ì´ìì™€ ì›ê¸ˆì„ ê°šì„ ê²ƒì´ë¼ëŠ” ì•½ì†ë§Œ í•˜ë©´ ë°œí–‰í•  ìˆ˜ ìˆìŒ. ì •ë¶€ì²˜ëŸ¼ ì„¸ê¸ˆì„ ê±·ì–´ì„œ ê°šì„ ìˆ˜ë„ ìˆê³ ,\nê°€ì§€ê³  ìˆëŠ” ìì‚°ì„ íŒ”ì•„ì„œ ê°šì„ ìˆ˜ë„ ìˆìŒ. â†’ ì±„ê¶Œ ë°œí–‰ìëŠ” ì£¼ì‹ ë°œí–‰ìì— ë¹„í•´ í›¨ì”¬ ê´‘ë²”ìœ„ ğŸ“Œ ìš©ì–´ ì¤‘ì— ì œì¼ ê¸°ë³¸ì ì¸ ê²ƒì€ ì±„ê¶Œì„ êµ¬ì„±í•˜ëŠ” ìš”ì†Œ # âœ… ì•¡ë©´ì€ ëˆì„ ë¹Œë ¤ ì¤„ ë•Œ ë‹¨ìœ„ë¡œ í•´ì„í•  ìˆ˜ ìˆëŠ”ë°, ê°€ê²© ê³„ì‚°ì˜ ë‹¨ìœ„ì´ê¸°ë„ í•¨.\nì£¼ì‹ì—ì„œ ë°œí–‰í•  ë•Œ ì•¡ë©´ê°€ë¼ëŠ” ê°œë…ì´ ìˆëŠ”ë°, ì´ëŠ” ë³´í†µ 5000ì›ì´ê³ , ìš”ì¦˜ì€ 500ì›ìœ¼ë¡œë„ ë°œí–‰.\nê·¸ë¦¬ê³  ë°°ë‹¹ì˜ ê¸°ì¤€ì´ ë¨. ì´ì²˜ëŸ¼ ê¸ˆë¦¬ëŠ” ì´ ì•¡ë©´ì— ëŒ€í•œ ë¹„ìœ¨ì„ ì˜ë¯¸í•¨ âœ… ë§Œê¸°ëŠ” ì£¼ì‹ê³¼ ë‹¤ë¥¸ ì . ì£¼ì‹ì€ ë§Œê¸°ê°€ ì—†ìŒ. ê¸°ì—…ì´ ì‚´ì•„ ìˆëŠ” í•œ ì£¼ì‹íšŒì‚¬ì˜ ì£¼ì‹ì€ ê³„ì† ì¡´ì¬.\nì˜ë„ì ìœ¼ë¡œ ìƒì¥ íì§€ë¥¼ ì‹œí‚¤ëŠ” ê²½ìš°ì—ë„ ì£¼ì‹ì€ ì¡´ì¬í•¨. ì£¼ì‹íšŒì‚¬ê°€ ì—†ì–´ì ¸ì•¼ ì£¼ì‹ë„ ì—†ì–´ì§.\nê·¸ë ‡ì§€ë§Œ, ë¹Œë¦¬ëŠ” ëˆì€ ì–¸ì  ê°€ ê°šì•„ì•¼ í•¨. ë¹Œë ¤ì£¼ëŠ” ì‚¬ëŒë„ ì›ê¸ˆì„ ëŒë ¤ ë°›ê¸° ë•Œë¬¸ì— ë¹Œë ¤ì¤Œ. âœ… í‘œë©´ì´ìœ¨, ë˜ëŠ” í‘œë©´ê¸ˆë¦¬ë„ ì¤‘ìš”í•¨.\ní‘œë©´ê¸ˆë¦¬ëŠ” ë°œí–‰í•  ë•Œ ì•ìœ¼ë¡œ íŠ¹ì • ì‹œì ì— ì§€ê¸‰í•  ì´ìë¥¼ ê³„ì‚°í•˜ëŠ” ê¸ˆë¦¬ì„.\në³´í†µ ë°œí–‰ ë‹¹ì‹œì˜ ì‹œì¥ê¸ˆë¦¬ì™€ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì—ì„œ ê²°ì •ë¨. ê·¸ë˜ì•¼ ë§¤ìˆ˜ìê°€ ë§¤ìˆ˜í•  ìˆ˜ ìˆê¸° ë•Œë¬¸.\ní‘œë©´ê¸ˆë¦¬ë¥¼ ì‹œì¥ê¸ˆë¦¬ë³´ë‹¤ ë‚®ì¶”ê±°ë‚˜ ë†’ì´ëŠ” ê²½ìš°ê°€ ìˆëŠ”ë°, ì´ ê²½ìš°ì—ëŠ” ê·¸ë§Œí¼ ë” ì‹¸ê±°ë‚˜ ë¹„ì‹¸ê²Œ ë°œí–‰ë¨. í‘œë©´ì´ìœ¨ì€ ì‹œì¥ê¸ˆë¦¬ê°€ ë³€í•´ë„ ë§Œê¸° ë•Œê¹Œì§€ ë³€í•˜ì§€ ì•ŠìŒ. ì¦‰ ê³ ì •ëœ ì´ìì„.\nì´ê²ƒì´ ìˆê¸° ë•Œë¬¸ì— ì±„ê¶Œ íˆ¬ìì˜ ì˜ë¯¸ê°€ ìˆëŠ” ê²ƒ. ì£¼ì‹ ë°°ë‹¹ì´ ì‹œê¸°ì— ë”°ë¼ ë‹¤ë¥¸ ê²ƒê³¼ í° ì°¨ì´ âœ… ê²½ê³¼ ê¸°ê°„ê³¼ ì”ì¡´ ê¸°ê°„ì´ë¼ëŠ” ìš©ì–´ë„ ì•Œì•„ì•¼ í•¨.\nì±„ê¶Œì´ ë°œí–‰ëœ ì´í›„ì—ëŠ” ì‹œê°„ì´ ê°ˆìˆ˜ë¡ ì²˜ìŒì— ì•½ì†í•œ ë§Œê¸°ê°€ ì ì  ê°€ê¹Œì›Œì§.\nì¦‰ í˜„ì¬ë¶€í„° ì›ê¸ˆ ìƒí™˜ ë•Œê¹Œì§€ì˜ ê¸°ê°„ì€ ì ì  ì§§ì•„ì§.\në§Œì•½ ì²˜ìŒì— 3ë…„ ë§Œê¸°ë¡œ ë°œí–‰ëœ ì±„ê¶Œì´ 1ë…„ ì§€ë‚¬ë‹¤ë©´ ê²½ê³¼ ê¸°ê°„ì€ 1ë…„ì´ê³ , ì”ì¡´ ê¸°ê°„ì€ 2ë…„ì„.\nì´ ì‹œì ì—ì„œ ê±°ë˜ê°€ ë  ê²½ìš° ê¸ˆë¦¬ëŠ” 2ë…„ë§Œê¸° ê¸ˆë¦¬ë¥¼ ì ìš©ë°›ê²Œ ë¨ ğŸ“Œ ê°€ê²© ê³„ì‚°ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì›ë¦¬ # ì–´ë–¤ ìì‚°ì˜ ê°€ê²©ì´ë¼ëŠ” ê²ƒì´ ê·¸ ìì‚°ì„ ë³´ìœ í•¨ìœ¼ë¡œì¨ ì–»ê²Œ ë˜ëŠ” í˜„ê¸ˆì„ í˜„ì¬ê°€ì¹˜ë¡œ í™˜ì‚°í•œ ê²ƒì´ë€ ì . í˜„ì¬ê°€ì¹˜ë¼ëŠ” ê²ƒì€ ë¯¸ë˜ ë°œìƒí•˜ëŠ” í˜„ê¸ˆ íë¦„ì´ ì§€ê¸ˆ ì–¼ë§ˆë¡œ í‰ê°€ë˜ì–´ì•¼ í•˜ëŠ”ê°€ë¥¼ ì˜ë¯¸í•¨. ex) 1ë…„ í›„ì— ë°›ëŠ” 100ë§Œì›ì€ í˜„ì¬ë¡œ ë³´ë©´ ê·¸ë³´ë‹¤ ë‚®ê²Œ í‰ê°€ë˜ì–´ì•¼ í•¨.\nì‹œì¥ê¸ˆë¦¬ì— ë”°ë¼ì„œ í˜„ì¬ 95ë§Œì›ì„ íˆ¬ìí•´ ë†“ìœ¼ë©´ 1ë…„ í›„ì— 100ë§Œì›ì´ ë  ìˆ˜ ìˆê¸° ë•Œë¬¸.\në°˜ëŒ€ë¡œ ì§€ê¸ˆ 100ë§Œì›ì„ 1ë…„ê°„ íˆ¬ìí•´ ë†“ìœ¼ë©´ 105ë§Œì›ì´ ë  ìˆ˜ ìˆìŒ.\nì´ ê²½ìš° 1ë…„ í›„ 105ë§Œì›ì˜ í˜„ì¬ê°€ì¹˜ê°€ 100ë§Œì›ì´ë¼ê³  í‘œí˜„í•  ìˆ˜ ìˆìŒ ì±„ê¶Œì€ ì¢…ë¥˜ì— ë”°ë¼ ë§Œê¸°ê¹Œì§€ ì—¬ëŸ¬ ë²ˆ ì´ìë¥¼ ì£¼ëŠ” ì±„ê¶Œë„ ìˆê³  ê·¸ë ‡ì§€ ì•Šì€ ì±„ê¶Œë„ ìˆìŒ.\ní•˜ì§€ë§Œ, ì´ë¥¼ ì¼ë°˜í™”í•´ì„œ ì“°ë©´ ìœ„ì™€ ê°™ì€ ì‹ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒ.\ní‘œë¥¼ ë³´ë©´ ê°€ê²© PëŠ” ì•ìœ¼ë¡œ ë“¤ì–´ì˜¬ ì´ìì™€ ì›ê¸ˆì„ ê°ê°ì˜ ê¸°ê°„ì— ëŒ€í•œ í• ì¸ë¥ ë„ í˜„ì¬ê°€ì¹˜í™”í•´ì„œ í•©í•œ ê²ƒì„ ê·¸ëŸ°ë° ì±„ê¶Œì˜ ê²½ìš°ì—ëŠ” ê°€ê²© ê³„ì‚°ì´ ë” ì‰¬ì›€. ì¼ë°˜ì ì¸ ì±„ê¶Œì˜ ê²½ìš° Cê°€ ëª¨ë‘ ê°™ê¸° ë•Œë¬¸.\nê·¸ë¦¬ê³  ìš°ë¦¬ê°€ ì–˜ê¸°í•˜ëŠ” ì‹œì¥ê¸ˆë¦¬ëŠ” yì¸ë°, ì±„ê¶Œ ê³„ì‚°í•  ë•Œ yë„ ê°™ìŒ. ì—„ë°€í•˜ê²Œ ë§í•˜ë©´ yê°€ ë‹¤ ë‹¬ë¼ì•¼ê² ì§€ë§Œ,\nìš°ë¦¬ê°€ ì“°ëŠ” ì‹œì¥ê¸ˆë¦¬ëŠ” ì´ê²ƒì„ ê°€ì¤‘í‰ê· í•´ ë†“ì€ ê¸ˆë¦¬ì´ê¸° ë•Œë¬¸ì— í•œ ê°€ì§€ë§Œ ì“°ë©´ ë¨ ê·¸ëŸ°ë° ì´ ì‹ìœ¼ë¡œë¶€í„° ì¬ë¯¸ ìˆëŠ” ì‚¬ì‹¤ì„ ìœ ì¶”í•  ìˆ˜ ìˆìŒ. ê¸ˆë¦¬ yê°€ í´ìˆ˜ë¡ ê°€ê²© PëŠ” ì‘ì•„ì§„ë‹¤ëŠ” ì .\nyê°€ ë¶„ëª¨ì— ìˆìœ¼ë‹ˆ ë‹¹ì—°í•œ ì–˜ê¸°. ë˜í•œ í‘œë©´ì´ì Cê°€ í´ìˆ˜ë¡ ê°€ê²© Pë„ ì»¤ì§ âœ… ê·¸ë ‡ë‹¤ë©´ ì‹¤ì œë¡œ ì±„ê¶Œ ê°€ê²©ì„ ê³„ì‚°í•  ë•Œ ì´ê²ƒì„ ë‹¤ ê³„ì‚°ê¸°ë¡œ ê³„ì‚°í•´ì•¼ í•˜ë‚˜? â†’ ê·¸ë ‡ì§€ ì•ŠìŒ.\nì‹œì¥ì—ì„œëŠ” ì‹œì¥ê¸ˆë¦¬ë¡œ ê±°ë˜ë˜ê³ , ê°€ê²© ê³„ì‚°ì€ ê¸°ê³„ê°€ ì•Œì•„ì„œ í•¨\nì±„ê¶Œ, ìƒê°ë³´ë‹¤ ë„“ì€ ê¸°ëŒ€ìˆ˜ìµê³¼ ìœ„í—˜ # ì•ì˜ ê°€ê²© ì‚°ì‹ì—ì„œ ì§ì‘í•  ìˆ˜ ìˆë“¯ì´ ê¸°ë³¸ì ìœ¼ë¡œ ì±„ê¶Œì€ ì£¼ì‹ì— ë¹„í•´ì„œ ë¶ˆí™•ì‹¤ì„±ì´ ì‘ì€ ìì‚°ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŒ.\në§Œê¸°, í‘œë©´ê¸ˆë¦¬ ë“± ë¯¸ë¦¬ ì •í•´ì§„ ê²ƒë“¤ì´ ë§ê¸° ë•Œë¬¸ í•˜ì§€ë§Œ, ì‹¤ì œë¡œ ìì‚°ë³„ ìœ„í—˜ê³¼ ìˆ˜ìµì˜ êµ¬ì¡°ë¥¼ ë³´ë©´ ì±„ê¶Œì€ ìƒë‹¹íˆ ë„“ì€ ìœ„í—˜ì„ ê°€ì§€ëŠ” ê²ƒìœ¼ë¡œ í‰ê°€ë¨.\nê·¸ë˜í”„ë¥¼ ë³´ë©´ íŠ¹ì •í•œ ì˜ˆê¸ˆë³´ë‹¤ ë” ì•ˆì „í•œ ì±„ê¶Œì´ ìˆëŠ” ë°˜ë©´, ì£¼ì‹ë³´ë‹¤ ë” ìœ„í—˜ì´ í° ì±„ê¶Œë„ ìˆìŒ. ì´ëŸ¬í•œ ìœ„í—˜, ìˆ˜ìµ êµ¬ì¡°ê°€ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì€ ì±„ê¶Œ ë°œí–‰ìê°€ ì›Œë‚™ ë‹¤ì–‘í•˜ê³ , ë§Œê¸°ë„ ì²œì°¨ë§Œë³„ì´ê¸° ë•Œë¬¸.\në¬¼ë¡  ë¶ˆí™•ì‹¤ì„±ì´ë¼ëŠ” ì¸¡ë©´ì—ì„œ ë³´ë©´ ì£¼ì‹ì´ ë¶ˆí™•ì‹¤ì„±í•œ ìš”ì†Œê°€ ë” ë§ì€ ê²ƒì€ ë¶„ëª….\ní•˜ì§€ë§Œ, ì‹¤ì œì ìœ¼ë¡œ ê°€ê²©ì´ ì›€ì§ì¼ ìˆ˜ ìˆëŠ” ë²”ìœ„ë‚˜ íˆ¬ììˆ˜ìµë¥ ì˜ ê´€ì ì—ì„œ ë³´ë©´ ì£¼ì‹ì˜ ê°€ê²© ë³€ë™ ë²”ìœ„,\níˆ¬ììˆ˜ìµë¥ ë³´ë‹¤ ë” í° ë³€ë™ì„±ê³¼ ì†ì‹¤ì„ ë‚´ëŠ” ì±„ê¶Œë“¤ë„ ì¡´ì¬ âœ… ì˜ˆê¸ˆë³´ë‹¤ ì•ˆì •ì ì¸ ì±„ê¶Œì€ ë‹¨ê¸° êµ­ì±„ë¥¼ ë“¤ ìˆ˜ ìˆìŒ.\nì€í–‰ì€ ê·¹ë‹¨ì ì¸ ê²½ìš° ë§í•˜ê³  ì˜ˆê¸ˆì„ ëŒë ¤ì¤„ ìˆ˜ ì—†ëŠ” ê²½ìš°ê°€ ìˆì§€ë§Œ,\nìêµ­ í†µí™” êµ­ì±„ëŠ” ê·¸ëŸ° ê²½ìš°ê°€ ë‚˜íƒ€ë‚  ê°€ëŠ¥ì„±ì´ ì—†ê³ ,\në‹¨ê¸° êµ­ì±„ì˜ ê²½ìš° ê¸ˆë¦¬ ë³€ë™ì— ë”°ë¥¸ ê°€ê²© ë³€ë™ì„± ìì²´ë„ ì‘ê¸° ë•Œë¬¸\nğŸ“Œ ì±„ê¶Œê³¼ ì£¼ì‹ì˜ ì°¨ì´ì  # ì±„ê¶Œì€ ì´ìµ ê·¹ëŒ€í™”ë¥¼ ëª©í‘œë¡œ í•˜ëŠ” ê¸°ê´€ì´ ì•„ë‹ˆë”ë¼ë„ ë°œí–‰í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ì£¼ì‹ê³¼ ë‹¤ë¦„.\nì£¼ì‹ì€ ì£¼ì‹íšŒì‚¬ë§Œ ë°œí–‰. ì´ ë•Œë¬¸ì— ì±„ê¶Œ ì¢…ëª©ì´ ë„ˆë¬´ ë§ì•„ì ¸ ë³µì¡í•˜ê²Œ ëŠê»´ì§€ê¸´ í•˜ì§€ë§Œ,\në°˜ëŒ€ë¡œ ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì±„ê¶Œì€ ë” ë§ì€ ê¸°íšŒë¥¼ ì œê³µí•´ ì£¼ê¸°ë„ í•¨ ì±„ê¶Œê³¼ ì£¼ì‹ì€ ê°ê° íƒ€ì¸ ìë³¸, ìê¸° ìë³¸ìœ¼ë¡œ ë¶ˆë¦¼. ì˜ˆë¥¼ ë“¤ì–´ íšŒì‚¬ ì…ì¥ì—ì„œ ë³¼ ë•Œ ì±„ê¶Œì€ ë¹Œë¦° ëˆì´ì§€ë§Œ,\nì£¼ì‹ì€ ìŠ¤ìŠ¤ë¡œ ì£¼ì¸ìœ¼ë¡œ ì°¸ì—¬í•˜ê² ë‹¤ê³  ë“¤ì–´ì˜¨ ëˆ ì£¼ì‹ì„ ë³´ìœ í•˜ë©´ íŠ¹ì •ë˜ì§€ ì•Šì€ ë°°ë‹¹ì„ ë°›ëŠ” ë°˜ë©´ ì±„ê¶Œì„ ë³´ìœ í•˜ë©´ ì´ìë¥¼ ë°›ìœ¼ë©°,\në§Œê¸°ê°€ ë„ë˜í•˜ë©´ ì›ê¸ˆë„ ëŒë ¤ë°›ëŠ”ë‹¤ëŠ” íŠ¹ì§•ì´ ìˆìŒ. ì£¼ì‹ì€ íšŒì‚¬ê°€ ë§í•˜ì§€ ì•ŠëŠ” í•œ,\nê·¸ë¦¬ê³  ë§¤ì… ì†Œê°ë˜ì§€ ì•ŠëŠ” í•œ ë§Œê¸°ê°€ ë˜ì§€ ì•ŠìŒ âœ… ì±„ê¶Œì€ ì›Œë‚™ ë‹¤ì–‘í•œ ë©´ëª¨ë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì— ì£¼ì‹ë³´ë‹¤ ë” ìœ„í—˜í•˜ê³ , ì˜ˆê¸ˆë³´ë‹¤ ë” ì•ˆì „í•œ ì±„ê¶Œë„ ì¡´ì¬í•¨.\nê·¸ë§Œí¼ ì±„ê¶Œ íˆ¬ììì—ê²ŒëŠ” ê¸°íšŒê°€ ë§ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŒ\n3ê°• - ì±„ê¶Œ, ì–´ë–¤ ì¢…ë¥˜ê°€ ìˆë‚˜ìš”? # ğŸ“Œ ì±„ê¶Œì˜ ë°œí–‰ ì£¼ì²´ ë¶„ë¥˜ # í•˜ë‚˜ì˜ ìì‚°êµ°ì€ ë‹¤ì–‘í•œ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜ê°€ ê°€ëŠ¥.\nê·¸ ì¤‘ì—ì„œë„ ê°€ì¥ ëŒ€í‘œì ì¸ ë¶„ë¥˜ì€ ë°œí–‰ìê°€ ëˆ„êµ¬ëƒì— ë”°ë¼ ë¶„ë¥˜í•˜ëŠ” ê²ƒ. ì±„ê¶Œì˜ ë°œí–‰ìëŠ” í¬ê²ŒëŠ” ê³µê³µê¸°ê´€ì´ ë°œí–‰í•œ ì±„ê¶Œê³¼ ë¯¼ê°„ê¸°ì—…ì´ ë°œí–‰í•œ ì±„ê¶Œì´ ìˆìŒ.\nâš ï¸ ê³µê³µê¸°ê´€ì—ëŠ” ì •ë¶€ì™€ ì¤‘ì•™ì€í–‰ë„ í¬í•¨.\nì´ì™¸ì—ë„ ê³µì‚¬ì±„ë‚˜ ì§€ë°©ìì¹˜ë‹¨ì²´ê°€ ë°œí–‰í•œ ì±„ê¶Œë„ ê³µê³µê¸°ê´€ ë°œí–‰ ì±„ê¶Œì— í¬í•¨.\në¯¼ê°„ê¸°ì—…ì˜ ê²½ìš°ì—ëŠ” ì¼ë°˜ íšŒì‚¬ì™€ ê¸ˆìœµê¸°ê´€ì„ ë‚˜ëˆ„ê³ ,\nê¸ˆìœµê¸°ê´€ì„ ë‹¤ì‹œ ì€í–‰ê³¼ ê¸°íƒ€ ê¸ˆìœµê¸°ê´€ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì´ ì¼ë°˜ì ì¸ ë¶„ë¥˜ë²• ë³´ì¦ ìœ ë¬´ë³„ë¡œë„ ì±„ê¶Œì„ ë¶„ë¥˜í•  ìˆ˜ ìˆìŒ.\në³´ì¦ì´ë¼ëŠ” ê²ƒì€ ë°œí–‰ìê°€ ì›ë¦¬ê¸ˆ ìƒí™˜ì„ í•˜ì§€ ëª»í•˜ê²Œ ëœ ê²½ìš°ì— ëˆ„êµ°ê°€ê°€ ê·¸ê±¸ ëŒ€ì‹ í•´ ì£¼ëŠ” ê²½ìš°ë¥¼ ì–˜ê¸°.\në³´ì¦ìëŠ” ìˆ˜ìˆ˜ë£Œë¥¼ ë°›ê³  ê·¸ ì¼ì„ í•´ì¤Œ. ì˜ˆë¥¼ ë“¤ì–´ì„œ ë³´ì¦ ë³´í—˜íšŒì‚¬ê°€ ê·¸ëŸ° ì¼ì„ í•´ ì¤„ ìˆ˜ ìˆìŒ. ì´ë ‡ê²Œ ë˜ë©´ ì‚¬ëŠ” ì‚¬ëŒ ì…ì¥ì—ì„œëŠ” ë‹¹ì—°íˆ ë” ì•ˆì „í•´ì§.\ní•˜ì§€ë§Œ, ìµœê·¼ ë“¤ì–´ ë³´ì¦ì±„ê¶Œì€ ê±°ì˜ ë°œí–‰ë˜ì§€ ì•ŠëŠ”ë°,\në³´ì¦ì´ ë“¤ì–´ê°„ ì±„ê¶Œì€ ê²°êµ­ ë³´ì¦ìì˜ ì‹ ìš©ìœ¼ë¡œ ë°œí–‰ëœ ì±„ê¶Œê³¼ ë§ˆì°¬ê°€ì§€ì—¬ì„œ ê¸ˆë¦¬ê°€ ë‚®ì„ ìˆ˜ ë°–ì— ì—†ê¸° ë•Œë¬¸. ì´ì™¸ì— ë‹´ë³´ì±„ê¶Œë„ ìˆëŠ”ë°, ì´ê²ƒì€ ë³´ì¦ì±„ê¶Œê³¼ ë‹¬ë¦¬ ë°œí–‰ìê°€ ê°šì„ ìˆ˜ê°€ ì—†ì„ ë•Œ\në³´ìœ í•˜ê³  ìˆëŠ” ìì‚° ì¤‘ ì¼ë¶€ë¥¼ íŒ”ì•„ì„œ ê°šë„ë¡ ì²˜ìŒë¶€í„° ì •í•´ì§„ ì±„ê¶Œì„.\nì´ë ‡ê²Œ ë˜ë©´ ì´ ë‹´ë³´ì— ëŒ€í•´ì„œëŠ” ìš°ì„ ê¶Œì„ ê°–ê¸° ë•Œë¬¸ì— íˆ¬ììëŠ” ì„ í˜¸.\nê·¸ëŸ°ë° ì´ ê²½ìš°ì—ë„ ê¸ˆë¦¬ê°€ ë‚®ì•„ì„œ ë°œí–‰ì€ ê±°ì˜ ì—†ìŒ ì±„ê¶Œì˜ êµ¬ì„± ìš”ì†Œ ì¤‘ í•˜ë‚˜ì¸ ë§Œê¸°, ì¦‰ ìƒí™˜ê¸°ê°„ ë³„ë¡œë„ ë‚˜ëˆŒ ìˆ˜ ìˆìŒ.\nì£¼ë¡œ ì¥ê¸°, ì¤‘ê¸°, ë‹¨ê¸°ë¡œ ë‚˜ë‰˜ëŠ”ë°, ë¯¸êµ­ì˜ ê²½ìš° ê¸°ì¤€ì€ ë³´í†µ 1ë…„ 10ë…„ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ ,\nìš°ë¦¬ë‚˜ë¼ì˜ ê²½ìš°ëŠ” 1ë…„ 5ë…„ ì •ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•¨. ë‹¤ë§Œ, ì´ ê°™ì€ ë¶„ë¥˜ëŠ” ì •í•´ì§„ ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—\nìœ ì—°í•˜ê²Œ ë¶„ë¥˜ë  ìˆ˜ë„ ìˆì–´ ì£¼ì˜í•  í•„ìš” ğŸ“Œ êµ­ì±„ëŠ” ì±„ê¶Œì´ ì¶œë°œí•œ ì‹œì‘ì ì´ì í•œ ë‚˜ë¼ ì±„ê¶Œì˜ ê¸°ì¤€ì´ ë˜ëŠ” ì±„ê¶Œ. # ì£¼ë¡œ í•´ë‹¹êµ­ í†µí™”ë¡œ ë°œí–‰ë˜ê¸° ë•Œë¬¸ì— ê°€ê²©ì€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ë¶€ë„ ìœ„í—˜ì´ ì—†ìŒ.\në¬¼ë¡  ì •ë¶€ê°€ ì™¸í™”ê°€ í•„ìš”í•  ë•ŒëŠ” ë‹¬ëŸ¬ë‚˜ ìœ ë¡œë¡œ ë°œí–‰í•˜ê¸°ë„ í•˜ì§€ë§Œ, ê·œëª¨ëŠ” í¬ì§€ ì•ŠìŒ êµ­ì±„ëŠ” ë‹¤ì–‘í•œ ë§Œê¸°ë¡œ ë°œí–‰ë¨. ìš°ë¦¬ë‚˜ë¼ì—ì„œëŠ” ê³¼ê±°ì— 3ë…„ì´ ì£¼ëœ ë°œí–‰ ì±„ê¶Œì´ì—ˆì§€ë§Œ,\nì§€ê¸ˆì€ 2ë…„, 5ë…„, 10ë…„, 20ë…„, 30ë…„, ê¸¸ê²ŒëŠ” 50ë…„ ë§Œê¸° ì±„ê¶Œë„ ë°œí–‰.\nâ†’ ìˆ˜ìš”ìë“¤ì´ ì›í•œ ê²ƒë„ ìˆì§€ë§Œ, ì •ë¶€ê°€ ìê¸°ë“¤ì˜ ë¶€ì±„ë¥¼ ë§Œê¸°ë³„ë¡œ ë‚˜ëˆ  ë†“ê¸° ìœ„í•œ ê²ƒ.\ní•œë²ˆì— ìƒí™˜ ê·œëª¨ê°€ ì»¤ì§€ë©´ ë¶€ë‹´ì´ ì»¤ì§€ê¸° ë•Œë¬¸ ğŸ“Œ êµ­ì±„ ì¤‘ì— íŠ¹ë³„í•œ ê²ƒìœ¼ë¡œëŠ” ì†Œë¹„ìë¬¼ê°€ê°€ ì˜¤ë¥¼ ë•Œ ì§€ê¸‰ë˜ëŠ” ì´ìë„ ê°™ì´ ì˜¬ë¼ê°€ëŠ” ë¬¼ê°€ì—°ë™ì±„ê¶Œ # ì´ ì±„ê¶Œì€ ë¬¼ê°€ê°€ ì˜¤ë¥¼ ë•Œ ë¹„ì‹¸ì§€ê³  ë‚´ë¦´ ë•Œ ì‹¸ì§. ì£¼ë¡œ 10ë…„ ë§Œê¸°ë¡œ ë°œí–‰ë¨ êµ­ì±„ëŠ” ê¸°ê´€íˆ¬ììë“¤ì´ë‚˜, ìì‚°ê°€ë“¤ì´ ê·¹ë„ë¡œ ì•ˆì •ì ì´ë©´ì„œ\nìˆ˜ìµì— í¬ê²Œ ê°œì˜ì¹˜ ì•Šì„ ë•Œ ì‚¬ëŠ” ì±„ê¶Œìœ¼ë¡œ ê°œì¸íˆ¬ììë“¤ì—ê²ŒëŠ” ì í•©í•˜ë‹¤ê³  ë³¼ ìˆ˜ ì—†ìŒ. âœ… êµ­ì±„ ê¸ˆë¦¬ëŠ” ê·¸ ë‚˜ë¼ ì „ì²´ ì±„ê¶Œ ì‹œì¥ì˜ ê¸°ì¤€ ê¸ˆë¦¬ê°€ ë˜ê³ ,\nê°€ì¥ ë§ì´ ê±°ë˜ë˜ê¸° ë•Œë¬¸ì— ì±„ê¶Œ íˆ¬ììë¼ë©´ êµ­ì±„ì˜ ê±°ë˜ ìƒí™©ì— ê´€ì‹¬ì„ ê°€ì§ˆ í•„ìš”ê°€ ìˆìŒ\nğŸ“Œ êµ­ì±„ì™€ ë¹„ìŠ·í•œ ì±„ê¶Œìœ¼ë¡œ í•œêµ­ì€í–‰ì´ ë°œí–‰í•˜ëŠ” í†µì•ˆì¦ê¶Œ # í†µì•ˆì¦ê¶Œì€ ê¸°ë³¸ì ìœ¼ë¡œ í•œêµ­ì€í–‰ì´ ì‹œì¤‘ì— ëˆì´ ë§ì´ í’€ë ¸ë‹¤ê³  ìƒê°ë  ë•Œ ë°œí–‰í•˜ëŠ” ì±„ê¶Œìœ¼ë¡œ\nì£¼ë¡œ 1ë…„ê³¼ 2ë…„ ë§Œê¸°ë¡œ ë°œí–‰ë¨. ì¦‰ í†µí™”ëŸ‰ ì¡°ì ˆ ëª©ì ì˜ ì±„ê¶Œì„. í•œêµ­ì€í–‰ ì—­ì‹œ ì •ë¶€ì— ê°€ê¹ê¸° ë•Œë¬¸ì— ìƒí™˜ì„ ëª»í•  ìœ„í—˜ì€ ì—†ìŒ. ëˆì„ ì°ì–´ì„œ ê°šìœ¼ë©´ ë˜ê¸° ë•Œë¬¸.\ní•˜ì§€ë§Œ, êµ­ì±„ì™€ ë¹„ìŠ·í•˜ê²Œ ê¸ˆë¦¬ê°€ ë‚®ê¸° ë•Œë¬¸ì— ê°œì¸ íˆ¬ìì ì…ì¥ì—ì„œëŠ” íˆ¬ì ë§¤ë ¥ì´ í¬ì§€ ì•ŠìŒ ğŸ“Œ ê°œì¸íˆ¬ììë“¤ì´ ê´€ì‹¬ì„ ê°€ì§ˆ ë§Œí•œ ì±„ê¶Œ 3ì¸ë°© # ê³µì‚¬ì±„ # íŠ¹ìˆ˜ì±„ë¼ê³ ë„ í•˜ëŠ”ë°, íŠ¹ë³„ë²•ì— ì˜í•´ì„œ ë§Œë“¤ì–´ì§„ ê³µì‚¬,\nì˜ˆë¥¼ ë“¤ì–´ ìˆ˜ìì›ê³µì‚¬, ë„ë¡œê³µì‚¬, ì£¼íƒê¸ˆìœµê³µì‚¬ ë“±ì´ ë°œí–‰í•œ ì±„ê¶Œì„ ì˜ë¯¸í•¨. ì´ëŸ¬í•œ ì±„ê¶Œì€ êµ­ì±„ë³´ë‹¤ëŠ” ê¸ˆë¦¬ê°€ ì¡°ê¸ˆ ë†’ìŒ.\ní•˜ì§€ë§Œ, íŠ¹ë³„ë²• ìì²´ì— ì •ë¶€ê°€ í•´ë‹¹ ê³µì‚¬ì— ì†ì‹¤ì´ ë°œìƒí–ˆì„ ë•Œ\nì´ë¥¼ ë³´ì „í•˜ëŠ” í•­ëª©ì´ ìˆëŠ” ê²½ìš°ê°€ ëŒ€ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì— ì‚¬ì‹¤ìƒ ë¶€ë„ ìœ„í—˜ì´ ë§¤ìš° ë‚®ë‹¤ê³  í•  ìˆ˜ ìˆìŒ. âœ… ì•ˆì „ì„±ì„ ì¤‘ì‹œí•˜ëŠ” íˆ¬ììë“¤ ì¤‘ êµ­ì±„ë³´ë‹¤ëŠ” ì¡°ê¸ˆ ë” ë†’ì€ ê¸ˆë¦¬ë¥¼ ì›í•˜ëŠ” íˆ¬ììë“¤ì€ ê³µì‚¬ì±„ íˆ¬ì ê°€ëŠ¥\nê¸ˆìœµì±„ # ê¸ˆìœµì±„ëŠ” ë§ ê·¸ëŒ€ë¡œ ê¸ˆìœµê¸°ê´€ì´ ë°œí–‰í•œ ì±„ê¶Œ ê³µê³µê¸°ê´€ì˜ ì„±ê²©ì„ ê°€ì§€ë©´ì„œ ê¸ˆìœµê¸°ê´€ì´ê¸°ë„ í•œ ì‚°ì—…ì€í–‰, ì¤‘ì†Œê¸°ì—…ì€í–‰, ìˆ˜ì¶œì…ì€í–‰ ë“±ì´ ë°œí–‰í•œ ì±„ê¶Œë„ ìˆì§€ë§Œ,\nì‹œì¤‘ì€í–‰ì´ ë°œí–‰í•˜ëŠ” ì±„ê¶Œë„ ìˆê³ , ì¹´ë“œì‚¬ì™€ ìºí”¼íƒˆì‚¬ ë“± ì—¬ì‹ ì „ë¬¸ì—…ì²´ê°€ ë°œí–‰í•˜ëŠ” ì±„ê¶Œë„ ìˆìŒ. ì—¬ì‹ ì „ë¬¸ì—…ì²´ëŠ” ìˆ˜ì‹  ê¸°ëŠ¥ ì˜ˆë¥¼ ë“¤ì–´ ì˜ˆê¸ˆì„ ë°›ëŠ” ê¸°ëŠ¥ì€ ì—†ê³ \nì±„ê¶Œì´ë‚˜ ì–´ìŒ ë°œí–‰ì„ í†µí•´ì„œë§Œ ìê¸ˆì„ ì¡°ë‹¬í•  ìˆ˜ ìˆëŠ” ê¸ˆìœµê¸°ê´€. âœ… ì´ëŸ¬í•œ ë‹¤ì–‘í•œ ê¸ˆìœµê¸°ê´€ì€ ë‹¤ ìœ„í—˜ë„ê°€ ë‹¤ë¦„.\në”°ë¼ì„œ ê¸ˆìœµì±„ ë‚´ì—ì„œ ì ì ˆí•œ ì±„ê¶Œì„ ì°¾ì„ ê²½ìš° ì•ˆì „ì„±ê³¼ ëª¨ë‘ ë‹¬ì„±í•  ìˆ˜ ìˆìŒ\níšŒì‚¬ì±„ # ì¼ë°˜ ê¸°ì—…ì´ ë°œí–‰í•˜ëŠ” íšŒì‚¬ì±„ ì—­ì‹œ íˆ¬ììì—ê²ŒëŠ” ë§¤ë ¥ì ì¸ ì±„ê¶Œ. ê¸°ì—…ë“¤ì€ íˆ¬ìë‚˜ ìš´ì˜ ìê¸ˆì„ ë§ˆë ¨í•˜ê¸° ìœ„í•´ì„œ íšŒì‚¬ì±„ë¥¼ ë°œí–‰í•˜ëŠ”ë°,\ní¬ê³  ìš°ëŸ‰í•œ íšŒì‚¬ê°€ ë°œí–‰í•œ ì±„ê¶Œì¼ìˆ˜ë¡ ì•ˆì „í•œ ëŒ€ì‹  ê¸ˆë¦¬ê°€ ë‚®ê³ ,\në‹¤ì†Œ ì‘ê³  ì‹ ìš©ë„ê°€ ë–¨ì–´ì§€ëŠ” ì±„ê¶Œì€ ì¡°ê¸ˆ ëœ ì•ˆì „í•œ ëŒ€ì‹  ê¸ˆë¦¬ê°€ ë†’ìŒ. ì´ëŸ¬í•œ ìœ„í—˜ì€ ì±„ê¶Œì´ ë°œí–‰ë  ë•Œ ì‹ ìš©í‰ê°€íšŒì‚¬ê°€ ë¶€ì—¬í•œ ë“±ê¸‰ìœ¼ë¡œ í™•ì¸ë˜ëŠ”ë°,\nê³µì‚¬ì±„, ê¸ˆìœµì±„ì—ë„ ë§ˆì°¬ê°€ì§€ë¡œ ë“±ê¸‰ì´ ë¶€ì—¬ë˜ì–´ íˆ¬ìì— ë„ì›€ì„ ì£¼ê³  ìˆìŒ ğŸ“Œ íšŒì‚¬ì±„ì˜ ì¢…ë¥˜ì™€ íŠ¹ì§• # íšŒì‚¬ì±„ëŠ” ì¼ë°˜ì ì¸ ì±„ê¶Œ ì´ì™¸ì—ë„ ë§ì€ ì¢…ë¥˜ê°€ ìˆìŒ.\nê¸°ë³¸ì ìœ¼ë¡œ ë°œí–‰í•˜ëŠ” ê¸°ì—…ì˜ ì‹ ìš©ë“±ê¸‰ë³„ë¡œ ì¢…ë¥˜ê°€ ë‚˜ë‰˜ì§€ë§Œ,\nì—¬ëŸ¬ ê°€ì§€ ì¡°ê±´ë“¤ì´ ë¶€ì—¬ë˜ë©´ì„œ ë‹¤ì–‘í•œ íˆ¬ì ê¸°íšŒë¥¼ ì œê³µí•´ ì¤Œ ì¦ê¶ŒíšŒì‚¬ì—ì„œ ë°œí–‰í•˜ëŠ” ELSë‚˜ DLSëŠ” íšŒì‚¬ì±„ë¡œ ë¶„ë¥˜ë˜ëŠ”ë°, ì¼ë°˜ì ì¸ íšŒì‚¬ì±„ì™€ëŠ” ë‹¤ë¥¸ í˜•íƒœ ê¸°ë³¸ì ìœ¼ë¡œ ë°œí–‰í•˜ëŠ” ì¦ê¶Œì‚¬ì˜ ì‹ ìš©ë„ì— ë”°ë¼ ê°€ê²©ì´ ê²°ì •ë˜ê¸°ë„ í•˜ì§€ë§Œ,\níŠ¹ì •í•œ ì¡°ê±´ì´ ë§Œì¡±ë  ê²½ìš° ë” ë†’ì€ ê¸ˆë¦¬ë¥¼ ì£¼ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì— íˆ¬ììë“¤ì—ê²Œ ê´€ì‹¬. ELSëŠ” ì£¼ê°€ì§€ìˆ˜ë‚˜ íŠ¹ì • ê¸°ì—…ì˜ ì£¼ê°€ ë³€ë™ì— ë”°ë¼ì„œ ì´ì ì§€ê¸‰ì˜ í˜•íƒœê°€ ë‹¬ë¼ì§€ëŠ” ì±„ê¶Œì´ê³ ,\nDLSëŠ” ì£¼ê°€ ì´ì™¸ì— ê¸ˆë¦¬ë‚˜ ì›ìì¬ ê°€ê²© ë“± ë‹¤ì–‘í•œ ìƒí’ˆì˜ ê°€ê²©ì„ ê¸°ì´ˆë¡œ ì´ìì§€ê¸‰ í˜•íƒœê°€ ë‹¬ë¼ì§€ëŠ” ì±„ê¶Œì„. âœ… ë‹¤ë§Œ, ì´ëŸ¬í•œ ì±„ê¶Œì€ ê¸°ì´ˆìì‚°ì˜ ê°€ê²©ì´ í¬ê²Œ ì›€ì§ì¼ ê²½ìš° ì´ìë¥¼ ì§€ê¸‰ë°›ì§€ ëª»í•˜ê±°ë‚˜\nì›ê¸ˆë„ ë°›ì§€ ëª»í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤ëŠ” ì¸¡ë©´ì—ì„œ ì¼ë°˜ì ì¸ ì±„ê¶Œê³¼ ë‹¤ë¦„.\në”°ë¼ì„œ íˆ¬ìì— ìˆì–´ì„œ ë§¤ìš° ì£¼ì˜ë¥¼ ê¸°ìš¸ì—¬ì•¼ í•¨\nì£¼ì‹ê³¼ ì±„ê¶Œì˜ ì¤‘ê°„ í˜•íƒœë¡œ ì „í™˜ì‚¬ì±„ë‚˜ ì‹ ì£¼ì¸ìˆ˜ê¶Œë¶€ì‚¬ì±„ ë“±ë„ ë°œí–‰ë¨. ë³´í†µ ì‘ì€ ê¸°ì—…ì´ ì¢‹ì€ ì‹ ìš©ë“±ê¸‰ì„ ë°›ì„ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— íŠ¹ì •í•œ ì¡°ê±´ì´ ë§Œì¡±ë˜ë©´ ì£¼ì‹ìœ¼ë¡œ ì „í™˜ë˜ê±°ë‚˜\nì‹ ì£¼ë¥¼ ë°›ì„ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°œí–‰í•˜ëŠ” ì±„ê¶Œì¸ë°, ì£¼ê°€ê°€ ì •í•´ì§„ ìˆ˜ì¤€ë³´ë‹¤ ì˜¤ë¥´ë©´ ì „í™˜í•˜ê±°ë‚˜\nì‹ ì£¼ë¥¼ ë°›ì•„ì„œ íŒ” ìˆ˜ ìˆê¸° ë•Œë¬¸ì— íˆ¬ììë¡œì„œëŠ” ì¼ì¢…ì˜ ì„ íƒê¶Œì„ ê°–ê²Œ ë¨. ë§Œì•½ ì£¼ê°€ê°€ ì•ˆ ì˜¤ë¥´ë©´ ì±„ê¶Œì˜ í˜•íƒœë¡œ ë³´ìœ í•  ìˆ˜ë„ ìˆìŒ.\në‹¤ë§Œ, ì´ëŸ¬í•œ ì±„ê¶Œì„ ë°œí–‰í•˜ëŠ” ê¸°ì—…ì€ ì¼ë°˜ì ìœ¼ë¡œ ì‹ ìš©ë“±ê¸‰ì´ ë‚®ê³ ,\nì£¼ì‹ì„ ì¤€ë‹¤ëŠ” ì ì„ ê°•ì¡°í•´ í‘œë©´ì´ìë¥¼ ë‚®ê²Œ ë°œí–‰í•˜ëŠ” ê²½ìš°ê°€ ë§ì•„ ê°œë³„ ì¢…ëª©ë³„ë¡œ ì˜ ì„ ë³„í•´ì„œ íˆ¬ìí•´ì•¼ í•¨ ìµœê·¼ì—ëŠ” ê¸ˆìœµê¸°ê´€ë“¤ì´ ë°œí–‰í•˜ëŠ” ì‹ ì¢…ìë³¸ì¦ê¶Œì´ ìˆìŒ. ê¸ˆìœµê¸°ê´€ë“¤ì€ ê°ë…ì›ì˜ ìê¸°ìë³¸ ê¸°ì¤€ì„ ë§ì¶”ê¸° ìœ„í•´ì„œ ì¦ìë„ í•˜ì§€ë§Œ,\në•Œë¡œëŠ” ìë³¸ìœ¼ë¡œ ì¸ì •ë°›ëŠ” ì±„ê¶Œì„ ë°œí–‰í•˜ê¸°ë„ í•¨. ì´ê²ƒì´ ì‹ ì¢…ìë³¸ì¦ê¶Œ ìë³¸ìœ¼ë¡œ ì¸ì •ë°›ê¸° ìœ„í•´ì„œëŠ” ë§Œê¸°ê°€ ê¸¸ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— 10ë…„ ë˜ëŠ” ê·¸ ì´ìƒìœ¼ë¡œ ë°œí–‰ë˜ê³ ,\nê¸ˆìœµê¸°ê´€ì´ ë¶€ë„ê°€ ë‚¬ì„ ê²½ìš° ì¼ë°˜ì ì¸ ì±„ê¶Œë³´ë‹¤ ìƒí™˜ ìš°ì„ ìˆœìœ„ê°€ ë‚®ëŠ”ë°,\në³´í†µ ìë³¸ìœ¼ë¡œì„œ ì¸ì •ë°›ì§€ ëª»í•˜ëŠ” ì‹œê¸°ê°€ ë˜ë©´ ê¸ˆìœµê¸°ê´€ì´ ë˜ì‚¬ê°€ê³ ,\në¶€ì±„ë¹„ìœ¨ì´ ë†’ì„ ìˆ˜ ë°–ì— ì—†ëŠ” ê¸ˆìœµê¸°ê´€ì˜ ì¼ë°˜ ì±„ê¶Œê³¼ ì‹ ì¢…ìë³¸ì¦ê¶Œì˜ ìƒí™˜ìš°ì„  ìˆœìœ„ ì°¨ì´ëŠ”\ní° ì˜ë¯¸ê°€ ì—†ê¸° ë•Œë¬¸ì— ê°œì¸íˆ¬ììë“¤ì´ ê´€ì‹¬ì„ ê°–ëŠ” ì±„ê¶Œì„. íŠ¹íˆ ê¸ˆë¦¬ê°€ ë†’ë‹¤ëŠ” ì ì´ ë§¤ë ¥ ì–‘ë„ì„±ì •ê¸°ì˜ˆê¸ˆ # CDë¼ê³  í•˜ëŠ”ë°, ì€í–‰ì´ ë°œí–‰. ì¼ë°˜ ì˜ˆê¸ˆê³¼ ë‹¤ë¥¸ ì ì€ ë§¤ë§¤ê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì .\nê¸°ì—…ì–´ìŒì€ ê¸°ì—…ì´ ë°œí–‰í•˜ëŠ” 1ë…„ ì´ë‚´ ì–´ìŒì´ê³ ,\ní‘œì§€ì–´ìŒì€ ê³¼ê±°ì—ëŠ” ì¢…í•©ê¸ˆìœµì‚¬ê°€ ì§€ê¸ˆì€ ëŒ€í˜• ì¦ê¶Œì‚¬ê°€ ë°œí–‰í•˜ëŠ” ë‹¨ê¸° ìê¸ˆ ì¡°ë‹¬ ìˆ˜ë‹¨ì„. í™˜ë§¤ì¡°ê±´ë¶€ì±„ê¶Œ # íˆ¬ìì ì…ì¥ì—ì„œëŠ” ì±„ê¶Œì„ ì ì‹œ ë³´ìœ í•˜ëŠ” ëŒ€ê°€ë¡œ ì´ìë¥¼ ë°›ëŠ” ìƒí’ˆì´ê³ ,\nì •í•´ì§„ ê¸°ê°„ì´ ë˜ë©´ ì›ë˜ ë³´ìœ í•˜ê³  ìˆë˜ ê¸°ê´€ì´ ë‹¤ì‹œ ì‚¬ ê°€ëŠ” ê±°ë˜ ë³´í†µ ì±„ê¶Œì„ ë³´ìœ í•œ ê¸°ê´€ì´ ë‹¨ê¸°ë¡œ ìê¸ˆì„ ì¡°ë‹¬í•  ë•Œ ì‚¬ìš© ì½œ # ë§¤ì¼ë§¤ì¼ ë“¤ì–´ì˜¤ê³  ë‚˜ê°€ëŠ” ìê¸ˆì´ ë§ì•„ì•¼ í•˜ëŠ” ê¸ˆìœµê¸°ê´€ë“¤ì´ ë‹¨ê¸° ìê¸ˆ ê³¼ë¶€ì¡±,\nì‰ì—¬ ìƒíƒœì¼ ë•Œ ì´ˆë‹¨ê¸°ë¡œ ê±°ë˜í•˜ëŠ” ìƒí’ˆ âœ… ì´ëŸ¬í•œ ë‹¨ê¸°ê¸ˆìœµìƒí’ˆì„ ì•Œì•„ ë‘ë©´ ë‚´ê°€ ëˆì„ ë§ê¸´ ê¸ˆìœµê¸°ê´€ì´\në‹¨ê¸° ìœ ë™ì„±ì„ ì–´ë–»ê²Œ ê´€ë¦¬í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ìˆê¸° ëŒ€ë¬¸ì— ê´€ì‹¬ì„ ê°€ì§ˆ í•„ìš”ê°€ ìˆìŒ\nğŸ“Œ êµ­ì±„ ì„ ë¬¼ ì‹œì¥ # êµ­ì±„ ì„ ë¬¼ì‹œì¥ì€ ì£¼ê°€ì§€ìˆ˜ì„ ë¬¼ì²˜ëŸ¼ êµ­ì±„ ê°€ê²©ì´ ë³€í•  ë•Œ ê°™ì´ ë³€í•˜ëŠ” ì„ ë¬¼ì„ ì˜ë¯¸ ì‘ì€ ì¦ê±°ê¸ˆë§Œ ë‚´ê³  ê±°ë˜ê°€ ê°€ëŠ¥í•œë° 3ë…„ 5ë…„ 10ë…„ êµ­ì±„ ì„ ë¬¼ì‹œì¥ì´ ìˆìŒ ì£¼ì‹ì‹œì¥ì—ì„œ ì„ ë¬¼ì„ ë§¤ë„í•¨ìœ¼ë¡œì¨ ì£¼ê°€ê°€ ë–¨ì–´ì§ˆ ë•Œ ì´ìµì„ ì–»ì„ ìˆ˜ ìˆëŠ” ê²ƒì²˜ëŸ¼,\nì±„ê¶Œì‹œì¥ì—ì„œë„ êµ­ì±„ì„ ë¬¼ì„ ë§¤ë„í•˜ë©´ ê¸ˆë¦¬ê°€ ì˜¤ë¥¼ ë•Œ, ì¦‰ ì±„ê¶Œê°€ê²©ì´ ë–¨ì–´ì§ˆ ë•Œ ì´ìµì„ ì–»ì„ ìˆ˜ ìˆìŒ âœ… ì¦‰, ì±„ê¶Œì‹œì¥ì—ì„œë„ í—·ì§€ê°€ ê°€ëŠ¥í•¨. ë˜í•œ êµ­ì±„ì„ ë¬¼ì‹œì¥ì—ëŠ” ì§€ê¸ˆë„ ê°œì¸íˆ¬ììë“¤ì´ ì§„ì…í•´ ìˆìŒ.\n4ê°• - ì±„ê¶Œíˆ¬ì, ë³€ìˆ˜ëŠ” ì „ë§! ì±„ê¶Œ ê°€ê²© ì „ë§ ë¹„ë²• ê³µê°œí•©ë‹ˆë‹¤ # ğŸ“Œ ì‹œì¥ê¸ˆë¦¬ ì „ë§ì€ ì£¼ê°€ì§€ìˆ˜, í™˜ìœ¨ ì „ë§ê³¼ í•¨ê»˜ ê¸ˆìœµì‹œì¥ì˜ ì›€ì§ì„ì„ ê°€ëŠ í•˜ëŠ” ë° ê°€ì¥ ì¤‘ìš” # ì‹œì¥ê¸ˆë¦¬ ê·¸ ìì²´ê°€ ì±„ê¶Œì˜ ê°€ê²©ì„ ì˜ë¯¸í•˜ê¸° ë•Œë¬¸. ì±„ê¶Œì˜ ê°€ê²© ì‚°ì‹ì€ í‘œë©´ì´ìì™€ ë§Œê¸°, ê·¸ë¦¬ê³  ì‹œì¥ê¸ˆë¦¬ë¡œ ì´ë¤„ì ¸ ìˆìŒ.\nê·¸ëŸ°ë° ë‹¤ë¥¸ ë‘ ê°€ì§€ê°€ ì •í•´ì ¸ ìˆê³ , ì‹œì¥ê¸ˆë¦¬ë§Œ ì‹œì¥ì—ì„œ ê²°ì •ë˜ë©° ì‹œì‹œê°ê° ë³€í™”í•˜ë¯€ë¡œ\nì±„ê¶Œì˜ ê°€ê²©ì„ ë³€ë™ì‹œí‚¤ëŠ” ìœ ì¼í•œ ìš”ì†ŒëŠ” ì‹œì¥ê¸ˆë¦¬ë¼ê³  í•  ìˆ˜ ìˆìŒ ëª¨ë“  ìì‚°ì—ì„œ ê·¸ë ‡ë“¯ ê°€ê²©ì„ ì „ë§í•˜ëŠ” ê²ƒì€ ìµœì ì˜ íˆ¬ì ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ê¸° ìœ„í•¨\nâ†’ âœ… ì¦‰, ì‹œì¥ê¸ˆë¦¬ ì „ë§ì„ í•´ì•¼ ì±„ê¶Œì„ ì‚¬ê³  íŒŒëŠ” ìµœì ì˜ íˆ¬ì ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŒ ğŸ“Œ í”¼ì…” ë°©ì •ì‹ # í”¼ì…” ë°©ì •ì‹ì„ ë³´ë©´ ìš°ë¦¬ê°€ ì±„ê¶Œì˜ ê°€ê²©ì„ ê³„ì‚°í•˜ëŠ” ê¸ˆë¦¬ì¸ ëª…ëª© ê¸ˆë¦¬ëŠ”\nê°œë…ì ìœ¼ë¡œ ì‹¤ì§ˆê¸ˆë¦¬ì™€ ê¸°ëŒ€ì¸í”Œë ˆì´ì…˜ì˜ í•©ìœ¼ë¡œ ì´ë¤„ì ¸ ìˆë‹¤ëŠ” ì ì„ ì•Œ ìˆ˜ ìˆìŒ. ì´ëŸ¬í•œ ê´€ê³„ëŠ” ì´ë¯¸ í˜„ëŒ€ ê²½ì œí•™ì˜ ì‹œì‘ê³¼ í•¨ê»˜ ì œì‹œëœ ê°œë….\nê¸°ë³¸ì ìœ¼ë¡œ ëˆ„êµ°ê°€ì— ëˆì„ ë¹Œë ¤ì¤„ ë•ŒëŠ” ì•ìœ¼ë¡œ ë¬¼ê°€ê°€ ì–¼ë§ˆë‚˜ ì˜¤ë¥¼ ê²ƒì¸ì§€ë¥¼ ê°ì•ˆí•˜ê¸° ë•Œë¬¸. ì¦‰, ì ì–´ë„ ë¬¼ê°€ê°€ ì˜¤ë¥´ëŠ” ë§Œí¼ ë³´ìƒë°›ì§€ ëª»í•˜ë©´ ëˆì„ ë¹Œë ¤ì¤„ ì´ìœ ê°€ ì—†ìŒ.\nê·¸ëŸ°ë° ì´ ê°™ì€ ë³´ìƒì€ ìµœì†Œí•œë„ì„. ëˆì„ ë¹Œë ¤ì¤„ ë•ŒëŠ” ê·¸ ì´ìƒì˜ ë³´ìƒì„ ë°›ê³  ì‹¶ê¸° ë•Œë¬¸ì„.\në‚´ê°€ ëˆì„ ì“°ì§€ ëª»í•˜ëŠ” ê¸°ê°„ì˜ ê¸°íšŒ ë¹„ìš©ì— ëŒ€í•œ ë³´ìƒì„ ë°›ì•„ì•¼ ëˆì„ ë¹Œë ¤ì¤„ ì˜ì§€ê°€ ìƒê¹€ âœ… ì´ ìˆ˜ì‹ì—ì„œ ê¸°ëŒ€ì¸í”Œë ˆì´ì…˜ê³¼ ê¸°íšŒ ë¹„ìš©ì— ëŒ€í•œ ë³´ìƒ ëª¨ë‘ ê²½ì œì  ìƒí™©ì´ ì˜í–¥ì„ ì¤€ë‹¤ëŠ” ì ì„ ì•Œ ìˆ˜ ìˆìŒ.\nğŸ“Œ ì‹¤ì§ˆê¸ˆë¦¬ëŠ” ê¸°íšŒ ë¹„ìš©ì— ëŒ€í•œ ì´ì•¼ê¸° # ëˆì„ ë¹Œë ¤ ì£¼ëŠ” ì‚¬ëŒë¶€í„° ìƒê°í•´ ë³´ë©´, ì´ ì‚¬ëŒì€ ëˆì„ ë¹Œë ¤ì¤„ ìˆ˜ë„ ìˆì§€ë§Œ, ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŒ. ex) ì–´ë–¤ ê°€ê³„ê°€ ì—´ì‹¬íˆ ì €ì¶•í•´ 1ì–µì›ì˜ ëˆì´ ìˆë‹¤ê³  ê°€ì •.\nì´ ê²½ìš° ì´ ì‚¬ëŒì€ ì´ê²ƒì„ ì±„ê¶Œì„ ì‚¬ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì§ì ‘ ê°€ê²Œë¥¼ ì°¨ë¦¬ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŒ ë§Œì•½ ì§ì ‘ ê°€ê²Œë¥¼ ì°¨ë ¤ì„œ ë²Œìˆ˜ ìˆëŠ” ìˆœìˆ˜í•œ ì´ìµì´ 1ë…„ì— 1ì²œë§Œì›ì´ë©´\nì´ ì‚¬ëŒì€ 1ì–µì›ìœ¼ë¡œ 20%ì˜ ìˆ˜ìµë¥ ì„ ì˜¬ë ¸ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŒ.\nì—¬ê¸°ì—ì„œ ìˆœìˆ˜í•œ ì´ìµì€ ê°ì¢… ì›ì¬ë£Œ ê°’ì€ ë¬¼ë¡  ë‚˜ì™€ ì¢…ì—…ì›ì˜ ì¸ê±´ë¹„ ë“±ì„ ëª¨ë‘ í•©í•œ ê²ƒì„ ê·¸ëŸ°ë° ìœ„í—˜ì´ í¬ì§€ ì•Šì€ ì‹œì¥ê¸ˆë¦¬ê°€ 10%ì— í¬ê²Œ ë¯¸ì¹˜ì§€ ëª»í•˜ëŠ” ìˆ˜ì¤€,\nì˜ˆë¥¼ ë“¤ì–´ 5%ë©´ ì´ ì‚¬ëŒì€ ëˆì„ ë¹Œë ¤ì£¼ëŠ” ê²ƒë³´ë‹¤ ë‚´ê°€ ì§ì ‘ ì‚¬ì—…ì„ í•˜ëŠ” ê²ƒì´\në‚˜ì€ ì„ íƒì¼ ìˆ˜ ìˆìŒ ì¦‰, ë” ë§ì€ ì´ìë¥¼ ì£¼ëŠ” ê²½ìš°ì— ëˆì„ ë¹Œë ¤ì¤„ ê²ƒì„ ë°˜ëŒ€ë¡œ ëˆì„ ë¹Œë¦¬ëŠ” ìª½ì€ 5%ë¡œ ë¹Œë ¤ì„œ ê°€ê²Œë¥¼ ì°¨ë¦¬ê³  10%ë¥¼ ë²Œ ìˆ˜ ìˆë‹¤ë©´ ì¢‹ì€ ì¼ì„.\ní•˜ì§€ë§Œ, ê·¸ë ‡ì§€ ì•Šë”ë¼ë„, ì˜ˆë¥¼ ë“¤ì–´ 6%ë¡œ ë¹Œë¦¬ëŠ” ê²½ìš°ì—ë„ ë‚¨ëŠ” ê²ƒì´ ìˆê¸° ë•Œë¬¸ì—\në” ë†’ì€ ì‹œì¥ê¸ˆë¦¬ë¥¼ ë°›ì•„ë“¤ì¼ ìˆ˜ ìˆì„ ê²ƒì„ âœ… ê²°êµ­ ì´ëŸ¬í•œ ì˜ì‚¬ ê²°ì •ì€ ì•ìœ¼ë¡œ ê²½ì œê°€ ì–´ë–¤ ëª¨ìŠµì„ ë³´ì¼ ê²ƒì¸ê°€ì— ì˜ì¡´í•˜ê²Œ ë¨.\nê²½ì œê°€ ì¢‹ì•„ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©´ ê°€ê²Œë¥¼ ì°¨ë ¤ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ì´ìµì´ ë” ì»¤ì§ˆ ê²ƒì´ë¼ê³  ì˜ˆìƒí•  ìˆ˜ ìˆê¸° ë•Œë¬¸\nâœ… ëª…ëª©ê¸ˆë¦¬ ì¤‘ ì‹¤ì§ˆê¸ˆë¦¬ ë¶€ë¶„ì€ ê²½ê¸° ì‚¬ì´í´ê³¼ í•¨ê»˜ ìƒìŠ¹ê³¼ í•˜ë½ì„ ë°˜ë³µí•  ê²ƒì´ë¼ê³  ì˜ˆìƒí•  ìˆ˜ ìˆìŒ.\nê¸°ëŒ€ ì¸í”Œë ˆì´ì…˜ # ë„í‘œë¥¼ ë³´ë©´ ê°€ìš´ë° í‘œì‹œëœ ì›ì´ ê²½ê¸° ì‚¬ì´í´ì„ ì˜ë¯¸. ì˜¤ë¥¸ìª½ ìœ„ë¶€í„° íšŒë³µ, í™•ì¥, ìˆ˜ì¶•, ì¹¨ì²´ê¸°ë¡œ íšŒì „í•˜ëŠ”ë°,\nê°ê°ì˜ ê²½ìš° ì‹¤ì§ˆê¸ˆë¦¬ê°€ ì–´ë–¤ ë°©í–¥ì˜ ì••ë ¥ì„ ë°›ëŠ”ì§€ê°€ ë„¤ëª¨ ë°•ìŠ¤ ì•ˆì— í‘œì‹œë˜ì–´ ìˆìŒ ê·¸ëŸ°ë° ì ì„  ë„¤ëª¨ ë°•ìŠ¤ë¥¼ ë³´ë©´ ì €ì ê³¼ ê³ ì ì´ ê°ê° ê²½ê¸°ì˜ ê³ ì , ì €ì ë³´ë‹¤ ë¨¼ì € ê¸°ë¡ë¨ì„ ì•Œ ìˆ˜ ìˆìŒ.\nì´ëŠ” ì±„ê¶Œì‹œì¥ë„ ì£¼ì‹ì²˜ëŸ¼ ì‹¤ì œ ìƒí™©ì„ ì‚¬ì „ ë°˜ì˜í•˜ê¸° ë•Œë¬¸. ì‹œì°¨ëŠ” ê²½ê¸° ì‚¬ì´í´ë§ˆë‹¤ ë‹¤ë¥´ì§€ë§Œ, ì„ í–‰ì„±ì€ ë¶„ëª…íˆ ë‚˜íƒ€ë‚¨ í†µí™” ì¬ì • ì •ì±…ë„ ì˜í–¥ì„ ë¯¸ì¹¨ í•œí¸, ì´ëŸ¬í•œ ê²½ê¸° ì‚¬ì´í´ê³¼ í•¨ê»˜ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•˜ëŠ” ë¶€ë¶„ì´ ìˆìŒ. ë°”ë¡œ ì •ë¶€ì˜ ì •ì±…ì„.\nì •ë¶€ëŠ” í†µí™”, ì¬ì •ì •ì±…ì„ í†µí•´ ê²½ê¸° ì‚¬ì´í´ì˜ ì§„í­ì„ ì•ˆì •ì‹œí‚¤ë ¤ í•˜ê¸° ë•Œë¬¸ì—\në•Œë•Œë¡œ ê²½ê¸° ì‚¬ì´í´ì— ë”°ë¥¸ ê¸ˆë¦¬ ë³€ë™ì— ì˜í–¥ì„ ë¯¸ì¹¨ íŠ¹íˆ í†µí™”ì •ì±…ì˜ ê²½ìš° ë‹¨ê¸°ê¸ˆë¦¬ì˜ ì§„í­ì„ ë” í¬ê²Œ ë§Œë“œëŠ” ì„±ê²©ì„ ê°–ëŠ”ë°,\nê²½ê¸° í™•ì¥ì´ ê³¼ì—´ë¡œ ì´ì–´ì§ˆ ê²½ìš° ì¤‘ì•™ì€í–‰ì´ ê³¼ì—´ì„ ë§‰ê¸° ìœ„í•´ ê¸ˆë¦¬ë¥¼ í¬ê²Œ ì˜¬ë ¤ ëŒ€ì‘í•˜ê¸° ë•Œë¬¸. ë°˜ë©´ ê²½ê¸° í™•ì¥ì´ ì¹¨ì²´ë¡œ ì´ì–´ì§ˆ ê²½ìš°ì—ëŠ” ê¸ˆë¦¬ë¥¼ í¬ê²Œ ë‚´ë ¤ ëŒ€ì‘í•´ ë‹¨ê¸°ê¸ˆë¦¬ë„ í¬ê²Œ ë‚´ë¦¬ëŠ” í˜„ìƒì´ ë‚˜íƒ€ë‚¨.\nì¦‰, í†µí™”ì •ì±…ì€ ê²½ê¸° ì‚¬ì´í´ì— ë”°ë¥¸ ê¸ˆë¦¬ ë³€ë™ í­ì„ ì¡°ê¸ˆ ë” í‚¤ìš°ëŠ” ì—­í• ì„ í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì  ì¬ì •ì •ì±…ì€ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²½ìš°ê°€ ë§ìŒ.\nê²½ê¸°ê°€ ì¢‹ì„ ë•ŒëŠ” ì„¸ìˆ˜ê°€ ë§ì´ ê±·í˜€ êµ­ì±„ ë°œí–‰ì´ ì¤„ì–´ë“œëŠ” ë°˜ë©´,\nê²½ê¸°ê°€ ë‚˜ì˜ë©´ ì„¸ìˆ˜ê°€ ì¤„ì–´ë“œëŠ” ë°ë‹¤ ì¬ì •ì •ì±…ì„ ì“°ê¸° ìœ„í•´ êµ­ì±„ ë°œí–‰ì„ ëŠ˜ë¦¬ê¸° ë•Œë¬¸ í•œí¸, ì´ëŸ¬í•œ ì •ì±… ì—­ì‹œ ì‹¤ì œ ì •ì±…ë§Œí¼ì´ë‚˜ ì •ì±…ì— ëŒ€í•œ ê¸°ëŒ€ê°€ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì ì„ ê¸°ì–µí•´ì•¼ í•¨.\nì˜ˆë¥¼ ë“¤ì–´ í†µí™”ì •ì±…ì˜ ê²½ìš° ì•ìœ¼ë¡œ ê¸´ì¶•ì„ í•˜ê² ë‹¤ëŠ” ë°œì–¸ ë§Œìœ¼ë¡œë„ ì‹œì¥ê¸ˆë¦¬ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŒ.\në”°ë¼ì„œ ì‹¤ì œ ì •ì±…ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒ ë§Œí¼ì´ë‚˜ ì‹œì¥ì—ì„œ í˜•ì„±ëœ ì •ì±… ê¸°ëŒ€ë¥¼ ì‚´í´ì•¼ í•  í•„ìš”ê°€ ìˆìŒ í†µí™”ì •ì±…ì€ ê²½ê¸° ì‚¬ì´í´ì— ì—°ë™í•˜ê³ , ì´ì— ë”°ë¼ ê²½ê¸° í™•ì¥ ë•ŒëŠ” ê¸ˆë¦¬ ìƒìŠ¹ ë°©í–¥ìœ¼ë¡œ\nìˆ˜ì¶• ë•ŒëŠ” í•˜ë½ ë°©í–¥ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì ì„ í‘œì‹œ. ë‹¤ë§Œ, ì•ì„œ ì§€ì í•œ ëŒ€ë¡œ ì§„í­ì„ í¬ê²Œ í•  ìˆ˜ ìˆë‹¤ëŠ” ì ê³¼\nì‹¤ì œ ì •ì±…ë§Œí¼ ê¸°ëŒ€ê°€ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì ì— ëŠ”ëŠ” ìœ ì˜í•  í•„ìš”ê°€ ìˆìŒ ğŸ“Œ ìˆ˜ìµë¥  ê³¡ì„  # ìˆ˜ìµë¥ ê³¡ì„ ì€ ì‹œì¥ê¸ˆë¦¬ì™€ ì±„ê¶Œ ë§Œê¸°ê¹Œì§€ì˜ ê¸°ê°„ì„ ì¶•ìœ¼ë¡œ ë§Œë“  ê·¸ë˜í”„.\nì‹œì¥ì—ì„œëŠ” 1ë…„ë§Œê¸° ê¸ˆë¦¬ì™€ 3ë…„ë§Œê¸°, 10ë…„ë§Œê¸° ê¸ˆë¦¬ê°€ ê°ê° ë‹¤ë¥´ê¸° ë•Œë¬¸ ì´ ê°™ì€ ìˆ˜ìµë¥ ê³¡ì„ ì„ ì‚´í´ë³´ëŠ” ì´ìœ ëŠ”, ë‚˜ì¤‘ì— ì „ëµì—ë„ ë„ì›€ì´ ë˜ì§€ë§Œ,\nê·¼ë³¸ì ìœ¼ë¡œëŠ” ì‹œì¥ì—ì„œ ë‹¨ê¸°ê¸ˆë¦¬ì™€ ì¥ê¸°ê¸ˆë¦¬ê°€ ëŠ˜ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ì›€ì§ì´ì§€ëŠ” ì•Šì„ ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ê¸° ìœ„í•´ì„œ. ë§Œê¸°ë³„ë¡œ ê¸ˆë¦¬ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì†Œë“¤ì„ ì‚´í”¼ëŠ” ê²ƒë„ ì±„ê¶Œ ê°€ê²©ì„ ì „ë§í•˜ëŠ” ë° ì¤‘ìš” ê¸°ë³¸ì ìœ¼ë¡œ ë‹¨ê¸°ê¸ˆë¦¬ëŠ” í†µí™”ì •ì±…ì—, ì¥ê¸°ê¸ˆë¦¬ëŠ” ê²½ì œ ì „ë§ê³¼ ì±„ê¶Œ ìˆ˜ê¸‰ ë“±ì˜ ì˜í–¥ì„ ë” ë°›ëŠ” ê²½í–¥ì´ ìˆìŒ.\níŠ¹íˆ 2ë…„ ë˜ëŠ” 3ë…„ ë§Œê¸° ì´í•˜ ì±„ê¶Œ ê¸ˆë¦¬ëŠ” ì •ì±…ê¸ˆë¦¬ë¥¼ ì˜¬ë¦¬ê±°ë‚˜ ì˜¬ë¦´ ê²ƒì´ í™•ì‹¤í•´ì§€ë©´ ê°™ì´ ì˜¤ë¥´ê³ ,\në°˜ëŒ€ì˜ ê²½ìš° ë‚´ë¦¬ëŠ” ê²½í–¥ì´ ê°•í•¨ ë°˜ë©´, ì¥ê¸°ê¸ˆë¦¬ëŠ” í†µí™”ì •ì±… ë°©í–¥ê³¼ ê°™ì´ ì›€ì§ì´ëŠ” ê²½ìš°ë„ ìˆì§€ë§Œ, ê¸ˆë¦¬ë¥¼ ì˜¬ë¦¬ëŠ” ê²ƒì´\nê²°êµ­ ê²½ì œë¥¼ ë‚˜ì˜ê²Œ í•  ê²ƒì´ë¼ëŠ” ê¸°ëŒ€ë¡œ ì´ì–´ì§€ë©´ ë–¨ì–´ì§€ê¸°ë„ í•¨. ì´ì— ë”°ë¼ ìˆ˜ìµë¥ ê³¡ì„ ì˜ ê¸°ìš¸ê¸°ëŠ” ì™„ë§Œí•´ì§€ê±°ë‚˜,\nì‹¬ì§€ì–´ ì¥ë‹¨ê¸°ê¸ˆë¦¬ê°€ ì—­ì „ë˜ê¸°ë„ í•¨. ë˜í•œ - ì¥ê¸°ì±„ê¶Œì— ëŒ€í•œ ìˆ˜ìš”ê°€ ê°•ë ¥í•  ë•Œë„ ë¹„ìŠ·í•œ í˜„ìƒì´ ë‚˜íƒ€ë‚¨ âœ… ë”°ë¼ì„œ ì—¬ëŸ¬ ìš”ì¸ì„ ë™ì‹œì— ê°ì•ˆí•´ ì¥ë‹¨ê¸° ê¸ˆë¦¬ë¥¼ ì „ë§í•´ì•¼ í•¨\n5ê°• - ì•Œì•¼ì•¼ ì„±ê³µí•œë‹¤, ì±„ê¶Œíˆ¬ì ìœ„í—˜: ê¸ˆë¦¬ ìœ„í—˜ê³¼ ì‹ ìš©ìœ„í—˜ # íˆ¬ìì— ìˆì–´ì„œ ìœ„í—˜ì´ë€ ë¬´ì—‡ì¼ê¹Œ? # ëª¨ë“  ìì‚° íˆ¬ìëŠ” ìœ„í—˜ì„ ë‚´í¬í•¨. ì¦‰, íˆ¬ìì˜ ê²°ê³¼ê°€ ìƒê°í•œ ëŒ€ë¡œ ë‚˜íƒ€ë‚˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ í¼.\nì‚¬ê±°ë‚˜ íŒ” ë‹¹ì‹œ í˜„ì¬ ê°€ê²©ì€ ì •í•´ì§€ì§€ë§Œ, ë¯¸ë˜ ê°€ê²©ì´ë‚˜ ìƒí™©ì€ ì •í•´ì§€ì§€ ì•Šì€ ë¯¸ì§€ì˜ ì˜ì—­ì´ê¸° ë•Œë¬¸ ì±„ê¶Œì€ ê¸°ë³¸ì ìœ¼ë¡œ ì•ˆì „í•œ ìì‚°ì´ì§€ë§Œ, ê·¹ë‹¨ì ìœ¼ë¡œëŠ” êµ­ì±„ë„ ìƒí™˜ë°›ì§€ ëª»í•  ê°€ëŠ¥ì„±ì„ ì™„ì „íˆ ë°°ì œí•  ìˆ˜ëŠ” ì—†ìŒ.\n0.000001%ì˜ í™•ë¥ ì´ë¼ë„ ê°€ëŠ¥ì„±ì´ 0ì´ë¼ê³ ëŠ” ë³¼ ìˆ˜ ì—†ë‹¤ëŠ” ì–˜ê¸° í•˜ì§€ë§Œ, íˆ¬ìì˜ ìœ„í—˜ì„ ì‚¬ì „ì— ì–´ëŠ ì •ë„ ì¸¡ì •í•  ìˆ˜ ìˆìŒ.\nì˜ˆë¥¼ ë“¤ì–´ ì£¼ì‹ì‹œì¥ì—ì„œ ì„±ì¥ì£¼ëŠ” ì¡°ê¸ˆ ë” ê°€ê²© ë³€ë™ì„±ì´ í¬ê³ ,\në¶€ë™ì‚° ì‹œì¥ì—ì„œ íŠ¹ì • ì§€ì—­ì˜ ë¶€ë™ì‚°ì€ ë‹¤ë¥¸ ì§€ì—­ì˜ ë¶€ë™ì‚°ë³´ë‹¤ ì¡°ê¸ˆ ë” ìœ„í—˜í•˜ë‹¤ëŠ” íŒë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆìŒ ì´ëŸ¬í•œ íŠ¹ì§•ì„ ì•Œê³  ìˆë‹¤ë©´, ë‚´ ì„±ê²© ì¦‰ ë‚´ê°€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³  ë†’ì€ ìˆ˜ìµë¥ ì„ ì˜¬ë¦¬ê³  ì‹¶ì€ì§€,\në‚®ì§€ë§Œ ì•ˆì „í•œ ìˆ˜ìµë¥ ì„ ì›í•˜ëŠ”ì§€ì— ë”°ë¼ ì•Œë§ì€ ìì‚°ì„ ì„ íƒí•  ìˆ˜ ìˆìŒ ì±„ê¶Œ íˆ¬ì, ë¹„êµì  ì•ˆì „í•˜ì§€ë§Œ ìœ„í—˜ ì¡´ì¬ # ì±„ê¶Œ íˆ¬ìëŠ” ì•ì„œ ìì‚°ë³„ ê¸°ëŒ€ìˆ˜ìµê³¼ ìœ„í—˜ ë„í‘œì—ì„œ ì‚´í´ë´¤ë“¯ì´ ë„“ì€ ë²”ìœ„ì˜ ìœ„í—˜ì„ ë‚´í¬í•˜ê³  ìˆì§€ë§Œ,\nëŒ€ì²´ë¡œ ì£¼ì‹ íˆ¬ìì— ë¹„í•´ì„œëŠ” ëœ ìœ„í—˜í•˜ë‹¤ê³  ì—¬ê²¨ì§.\níŠ¹íˆ ë§Œê¸°ê¹Œì§€ ë³´ìœ í•  ê²½ìš°ì—ëŠ” ê³ ì •ëœ ì´ìê°€ ì§€ê¸‰ë˜ê¸° ë•Œë¬¸ì— ë§¤ë„í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ìœ„í—˜ì´ í†µì œë¨.\në˜í•œ ê·¸ëŸ¬í•œ ì„±ê²© ë•Œë¬¸ì— ê°€ê²© ë³€ë™ì„±ë„ ì£¼ì‹ì— ë¹„í•´ ì‘ì€ í¸. ê·¸ë ‡ì§€ë§Œ, ì±„ê¶Œì„ ì ê·¹ì ìœ¼ë¡œ íˆ¬ìí•˜ê³ , ìˆ˜ìµë¥ ì„ ë†’ì´ê³  ì‹¶ì€ ê²½ìš°ì—ëŠ” ê°ì¢… ìœ„í—˜ì„ ê°ìˆ˜í•  ìˆ˜ ìˆìŒ.\nê·¸ë¦¬ê³  ëŒ€í‘œì ì¸ ìœ„í—˜ì€ ê°€ê²© ë³€ë™ ìœ„í—˜ì„ ì˜ë¯¸í•˜ëŠ” ê¸ˆë¦¬ ìœ„í—˜ê³¼ ì¥ë‹¨ê¸°ê¸ˆë¦¬ ì°¨ì´ê°€ ì„œë¡œ ë‹¤ë¥´ê²Œ ì›€ì§ì—¬ì„œ ë‚˜íƒ€ë‚˜ëŠ” ìœ„í—˜,\nì¹˜ëª…ì ìœ¼ë¡œ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ë¶€ë„ìœ„í—˜ê³¼ ë¶€ë„ìœ„í—˜ì˜ í¬ê¸°ë¡œ ë³€í•˜ëŠ” ì‹ ìš©ìœ„í—˜,\nì›í•˜ëŠ” ì‹œê¸°ì— ë§¤ë„ë¥¼ í•  ìˆ˜ ì—†ëŠ” ìœ ë™ì„± ìœ„í—˜ ë“±ì´ë¼ê³  í•  ìˆ˜ ìˆìŒ ê·¸ëŸ°ë° ì´ ê°™ì€ ìœ„í—˜ ì¤‘ ë¹ˆë„ ìˆ˜ ì¸¡ë©´ì—ì„œëŠ” ê¸ˆë¦¬ ìœ„í—˜ì´, ìœ„í—˜ì˜ í¬ê¸° ì¸¡ë©´ì—ì„œëŠ” ì‹ ìš©ìœ„í—˜ì´ ê°€ì¥ í¼.\në”°ë¼ì„œ ì´ë²ˆ ì‹œê°„ì—ëŠ” ì´ ë‘ê°€ì§€ ìœ„í—˜ì„ ì‚¬ì „ì— ì¸¡ì •í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•˜ê² ìŒ.\nì¤‘ê°„ì— ìˆ˜ì‹ì´ í•˜ë‚˜ ë‚˜ì˜¤ì§€ë§Œ, ì‹œìŠ¤í…œì—ì„œ ê³„ì‚°ë˜ê¸° ë•Œë¬¸ì— ì—¬ëŸ¬ë¶„ì€ ê°œë…ë§Œ ì˜ ì´í•´í•˜ë©´ ë¨ ê¸ˆë¦¬ ìœ„í—˜ê³¼ ë“€ë ˆì´ì…˜ # ì•ì„œ ìš°ë¦¬ëŠ” ì‹œì¥ê¸ˆë¦¬ê°€ ì±„ê¶Œ ê°€ê²©ì„ ì›€ì§ì´ëŠ”ì£¼ëœ ìš”ì¸ì´ê³ ,\nê¸ˆë¦¬ë¥¼ ì „ë§í•˜ë©´ ì±„ê¶Œ ê°€ê²© ë³€ë™ì„ ì˜ˆìƒí•  ìˆ˜ ìˆë‹¤ê³  í–ˆìŒ.\nê·¸ëŸ°ë° ì¤‘ìš”í•œ ê²ƒì€ ì´ëŸ¬í•œ ì‹œì •ê¸ˆë¦¬ ë³€ë™ì— ë”°ë¥¸ ì±„ê¶Œ ê°€ê²© ë³€ë™ì´ ì±„ê¶Œë³„ë¡œ ë‹¤ë¥´ë‹¤ëŠ” ì .\nì¦‰ ì‹œì¥ê¸ˆë¦¬ê°€ 1% ì˜¤ë¥´ê±°ë‚˜ ë‚´ë¦´ ë•Œ ê°ê° ì±„ê¶Œì˜ ê°€ê²©ì€ ë‹¤ë¥´ê²Œ ì›€ì§ì„.\nê·¸ëŸ°ë° ì´ëŸ¬í•œ ì •ë³´ë¥¼ ì•Œê³  ìˆìœ¼ë©´ ì–´ë–¤ ì¥ì ì´ ìˆì„ê¹Œ? ë§Œì•½ ê¸ˆë¦¬ê°€ ì˜¬ë¼ ì±„ê¶Œ ê°€ê²©ì´ ë–¨ì–´ì§ˆ ê²ƒì´ë¼ê³  ì „ë§ì´ í™•ì‹¤í•˜ë©´ ìš°ë¦¬ëŠ” ì–´ë–»ê²Œ ëŒ€ì‘í•´ì•¼ í• ê¹Œ?\nì±„ê¶Œì„ íŒ”ê±°ë‚˜ ë­”ê°€ ê¸ˆë¦¬ê°€ ì˜¤ë¥¼ ë•Œ ê°€ê²©ì´ ê°™ì´ ì˜¤ë¥´ëŠ” ìì‚°ì„ ì‚¬ë©´ ë  ê²ƒì„.\nì£¼ì‹ì‹œì¥ì—ì„œ ì£¼ê°€ê°€ ë–¨ì–´ì§ˆ ê²ƒ ê°™ìœ¼ë©´ ì„ ë¬¼ì„ ë§¤ë„í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ì›ë¦¬. ë˜í•œ ë“œë¬¼ê¸´ í•˜ì§€ë§Œ,\nì±„ê¶Œì˜ ê²½ìš°ì—ëŠ” ì‹œì¥ê¸ˆë¦¬ê°€ ì˜¤ë¥¼ ë•Œ ë°›ê²Œ ë˜ëŠ” í‘œë©´ ì´ìë„ ê°™ì´ ì˜¤ë¥´ëŠ” ì±„ê¶Œì„ ì‚¬ë©´ ë  ê²ƒì„ í•˜ì§€ë§Œ, ê¸ˆë¦¬ ì „ë§ì€ ê¸°ë³¸ì ìœ¼ë¡œ í™•ì‹¤í•˜ì§€ ì•ŠìŒ. ë”°ë¼ì„œ ì²˜ìŒì— ì±„ê¶Œì„ ì‚´ ë•Œ\në‚´ê°€ ê¸ˆë¦¬ê°€ ë³€í™”ë  ìœ„í—˜ì— ëŒ€í•´ ì–´ë–¤ ìƒê°ì„ ê°–ê³  ìˆëŠ”ì§€ë¥¼ ê°ì•ˆí•´ ì‚¬ëŠ” ì±„ê¶Œì„ ì„ íƒí•  ìˆ˜ ìˆìŒ.\nì¦‰ ìœ„í—˜ì„ íšŒí”¼í•˜ëŠ” ì‚¬ëŒì´ë©´ ê¸ˆë¦¬ê°€ ë³€í•´ë„ ê°€ê²©ì´ ëœ ë³€í•˜ëŠ” - ì±„ê¶Œì„,\nê³ ìˆ˜ìµì„ ì›í•˜ëŠ” ì‚¬ëŒì´ë©´ ê¸ˆë¦¬ê°€ ì¡°ê¸ˆ ë³€í•´ë„ ê°€ê²©ì´ ë” í¬ê²Œ ë³€í•˜ëŠ” ì±„ê¶Œì„ ì„ íƒí•˜ë©´ ë¨ ì´ëŸ¬í•œ ê²½ìš°ì— ì‚¬ìš©ë˜ëŠ” ê°œë…ì´ ë“€ë ˆì´ì…˜ì„.\në“€ë ˆì´ì…˜ì€ 1%ì˜ ê¸ˆë¦¬ ë³€ë™ì— ëŒ€í•´ ì±„ê¶Œ ê°€ê²©ì´ ì–¼ë§ˆë‚˜ ë³€í•˜ëŠ”ê°€ë¥¼ ì¸¡ì •í•œ ì§€í‘œë¡œ ê° ì±„ê¶Œë³„ë¡œ ë‹¤ë¦„ ë“€ë ˆì´ì…˜ì˜ ê°œë… # ë“€ë ˆì´ì…˜ì€ ì–´ë–»ê²Œ ê³„ì‚°ë ê¹Œ/ ì•ì„œì„œ ì–˜ê¸°í•œ ê²ƒì²˜ëŸ¼, ë“€ë ˆì´ì…˜ ìˆ˜ì‹ì„ ì™¸ìš°ê±°ë‚˜ í•  í•„ìš”ëŠ” ì—†ìŒ.\në§¤ë§¤í•˜ëŠ” ì‹œìŠ¤í…œì´ ê°œë³„ ì±„ê¶Œì˜ ë“€ë ˆì´ì…˜ì„ ë‹¤ ê³„ì‚°í•´ ì¤Œ. ë‹¤ë§Œ, ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ ìˆ˜ì‹ì„ ì†Œê°œí•¨.\nê°œë…ì ìœ¼ë¡œ ë³´ë©´ ë“€ë ˆì´ì…˜ì€ ì±„ê¶Œ í˜„ê¸ˆíë¦„ì˜ ê°€ì¤‘í‰ê·  ìƒí™˜ê¸°ê°„ì„ ì²˜ìŒì— íˆ¬ììë“¤ì´ ìˆ˜ì‹ì„ ë§Œë“  ê²ƒì€ ì±„ê¶Œì— íˆ¬ìí•œ ì‚¬ëŒìœ¼ë¡œì„œ ê°–ëŠ” ê¸°ë³¸ì ì¸ ì§ˆë¬¸,\nì´ ì±„ê¶Œì„ ì‚¬ì„œ ì–¼ë§ˆ ì •ë„ ì§€ë‚˜ë©´ ë‚´ê°€ ì²˜ìŒì— íˆ¬ìí•œ ì›ê¸ˆ ë¶€ë¶„ì´ íšŒìˆ˜ë˜ëŠ” ê±¸ê¹Œ?ì— ëŒ€í•´ ë‹µí•˜ê¸° ìœ„í•´ì„œì„.\nì±„ê¶Œì€ ì¤‘ê°„ì— ì´ìë¥¼ ì§€ê¸‰í•˜ëŠ” ê²½ìš°ê°€ ëŒ€ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì— ì´ ìˆ˜ì¹˜ëŠ” ë§Œê¸°ê¹Œì§€ì˜ ê¸°ê°„ë³´ë‹¤ ì§§ê²Œ ë¨.\në§Œì•½ ë§Œê¸° ë•Œë§Œ ì´ìì™€ ì›ê¸ˆì„ ì£¼ëŠ” ì±„ê¶Œì˜ ê²½ìš°ì—ëŠ” ë§Œê¸°ê¹Œì§€ì˜ ê¸°ê°„ê³¼ ë“€ë ˆì´ì…˜ì´ ê°™ìŒ.\nê·¸ëŸ°ë° ì‹ì´ ë³µì¡í•´ì§„ ê²ƒì€, ë¯¸ë˜ì— ë“¤ì–´ì˜¤ëŠ” ëˆì„ ë‹¤ í˜„ì¬ê°€ì¹˜í™” í•´ì•¼í•˜ê¸° ë•Œë¬¸.\në‚´ì¼ ë°›ëŠ” 10ì›ì˜ ì˜¤ëŠ˜ì˜ 10ì›ê³¼ ì‹¤ì§ˆì ìœ¼ë¡œ ë‹¤ë¥´ë‹¤ëŠ” ì ì„ ë°˜ì˜ ê·¸ëŸ°ë° íˆ¬ììë“¤ì€ ì´ëŸ¬í•œ ì‹ì„ ì¡°ê¸ˆ ë³€í˜•í•˜ë©´ 1%ì˜ ê¸ˆë¦¬ ë³€ë™ì— ë”°ë¥¸ ì±„ê¶Œê°€ê²© ë³€ë™ë¶„ìœ¼ë¡œ ë°”ë€ë‹¤ëŠ” ì ì„ ë°œê²¬í–ˆìŒ.\nì¦‰ ê¸ˆë¦¬ ë³€ë™ì— ë”°ë¥¸ ì±„ê¶Œ ê°€ê²©ì˜ ë¯¼ê°ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŒì„ ë°œê²¬ ê·¸ë¦¼ì˜ ì›ì ì— ëŒ€í•´ ë³¼ë¡í•œ ê³¡ì„ ì€ ì–´ë–¤ ì±„ê¶Œì˜ ê°€ê²©ê³¼ ê¸ˆë¦¬ì™€ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ëƒ„.\nê³¡ì„ ì´ ì´ë ‡ê²Œ ìƒê¸´ ê²ƒì€ ìˆ˜ì‹ì´ ë‹¤í•­ì‹ì´ê¸° ë•Œë¬¸. ì—¬ê¸°ì—ì„œ ë“€ë ˆì´ì…˜ì€ ê¸ˆë¦¬ê°€ ê¸ˆë¦¬1ì—ì„œ ê¸ˆë¦¬2ë¡œ ì˜¤ë¥¼ ë•Œ ê°€ê²©ì´ ê°€ê²©1ì—ì„œ ê°€ê²©2ë¡œ ì›€ì§ì´ëŠ” ì§ì„ ì˜ ê¸°ìš¸ê¸°ë¥¼ ì˜ë¯¸í•¨.\nì¡°ê¸ˆ ì–´ë ¤ìš´ í‘œí˜„ìœ¼ë¡œëŠ” ê¸ˆë¦¬ 1 ìƒí™©ì—ì„œ 1ì°¨ ë¯¸ë¶„ê°’, ì¦‰ ê°€ê²©ê³¡ì„ ê³¼ ì ‘í•˜ëŠ” ì§ì„ ì˜ ê¸°ìš¸ê¸°ë¥¼ ì˜ë¯¸.\në”°ë¼ì„œ ê¸ˆë¦¬ê°€ ì¡°ê¸ˆ ë³€í•œë‹¤ë©´ ê±°ì˜ ì •í™•í•˜ê²Œ ê¸ˆë¦¬ ë³€ë™ì— ëŒ€í•œ ê°€ê²©ë³€ë™ì„ ì‚¬ì „ì— ì¸¡ì • ê°€ëŠ¥ ì£¼ì˜í•  ì ì´ ìˆìŒ. ê¸ˆë¦¬ê°€ í¬ê²Œ ë³€í•˜ë©´ ê°€ê²© ë³€ë™ë¶„ì„ ë“€ë ˆì´ì…˜ìœ¼ë¡œ ë‹¤ ê²Œì‚°í•  ìˆ˜ ì—†ìŒ.\nê¸°ê´€íˆ¬ììë“¤ì€ ì´ëŸ¬í•œ ì˜¤ì°¨ë¥¼ 2ì°¨ ë¯¸ë¶„ê°’ìœ¼ë¡œ ë˜ ê²Œì‚°. í•˜ì§€ë§Œ, ê°œì¸ ì…ì¥ì—ì„œëŠ” ë“€ë ˆì´ì…˜ ë§Œìœ¼ë¡œë„\nì–´ë–¤ ì±„ê¶Œì´ ì–´ëŠ ì •ë„ ê¸ˆë¦¬ ë¯¼ê°ë„ë¥¼ ê°–ëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ ë§¤ìš° ìœ ìš©í•œ ì§€í‘œ ì‹ ìš© ìœ„í—˜ì´ë€ ë¬´ì—‡ì¼ê¹Œ? # ì´ì œ ë‚˜íƒ€ë‚˜ëŠ” ê²½ìš°ëŠ” ë§ì´ ì—†ìœ¼ë‚˜, í•œë²ˆ ë°œìƒí•˜ë©´ íˆ¬ììì—ê²Œ í° íƒ€ê²©ì„ ì¤„ ìˆ˜ ìˆëŠ” ì‹ ìš©ìœ„í—˜ì— ëŒ€í•´ ì‚´í´ë³´ê² ìŒ.\nì‹ ìš©ìœ„í—˜ì€ ë¯¼ê°„ ë°œí–‰ìê°€ ë°œí–‰í•˜ëŠ” ì±„ê¶Œì´ ê°–ëŠ” ê³ ìœ ì˜ ìœ„í—˜ìœ¼ë¡œ ë‹¤ë¥¸ ë§ë¡œ í‘œí˜„í•˜ë©´\nìƒí™˜ ê°€ëŠ¥ì„±ì˜ ë³€í™”ì— ë”°ë¥¸ ì±„ê¶Œ ê°€ê²© ë³€í™” ê°€ëŠ¥ì„±ì„ ì˜ë¯¸í•¨ ìš°ë¦¬ëŠ” ì£¼ë³€ì—ì„œ ëˆì„ ê¼­ ê°šì„ ê²ƒìœ¼ë¡œ ë¯¿ì–´ì§€ëŠ” ì‚¬ëŒì—ê²Œ ëˆì„ ë¹Œë ¤ ì¤„ ë•ŒëŠ”\nì‹¬ì§€ì–´ ì›ê¸ˆë§Œ ëŒë ¤ ë°›ê¸°ë¡œ í•˜ê³  ë¹Œë ¤ì¤„ ë•Œê°€ ìˆìŒ. ë°˜ë©´ ê°šì„ ê°€ëŠ¥ì„±ì´ ì‘ì€ ì‚¬ëŒí•œí…ŒëŠ” ëˆì„ ìˆ«ì œ ì•ˆ ë¹Œë¦¬ ì£¼ê±°ë‚˜,\në¹Œë ¤ì¤€ë‹¤ê³  í•´ë„ ë†’ì€ ê¸ˆë¦¬ë¥¼ ìš”êµ¬í•¨. ì´ëŸ¬í•œ ê¸ˆë¦¬ ì°¨ì´ëŠ” ê²°êµ­ ì‹ ìš©ìœ„í—˜ì´ ê¸ˆë¦¬ë¡œ í‘œí˜„ëœë‹¤ëŠ” ì ì„ ì˜ë¯¸.\nì±„ê¶Œì‹œì¥ì—ì„œëŠ” ì´ëŸ¬í•œ ë³´ìƒì„ ì‹ ìš© í”„ë¦¬ë¯¸ì—„ì´ë¼ê³  ë¶€ë¥´ëŠ”ë°, ë°œí–‰ìì˜ ìœ„í—˜ì´ í´ìˆ˜ë¡ ì´ í”„ë¦¬ë¯¸ì—„ì€ ì»¤ì§ ì´ëŸ¬í•œ í”„ë¦¬ë¯¸ì—„ì€ ê³§ ì´ììˆ˜ìµì´ê¸°ë„ í•¨. ë”°ë¼ì„œ ì ì ˆí•œ ì±„ê¶Œì„ ì„ íƒí•œë‹¤ë©´\në¬´ì¡°ê±´ ì•ˆì „í•œ ì±„ê¶Œì„ ì„ íƒí•  ê²½ìš°ë³´ë‹¤ ë†’ì€ ìˆ˜ìµë¥  ë‹¬ì„±.\në‹¤ë§Œ, ë„ˆë¬´ ìœ„í—˜í•œ ì±„ê¶Œì„ ì„ íƒí•œë‹¤ë©´ ì´ìë¥¼ ë°›ê¸°ëŠ”ì»¤ë…• ì›ê¸ˆë„ ì†ì‹¤ì„ ë³¼ ìˆ˜ ìˆìŒ ê·¸ëŸ°ë° ì´ëŸ¬í•œ ìƒí™©ìœ¼ë¡œë¶€í„° íˆ¬ììë¥¼ ë³´í˜¸í•˜ê¸° ìœ„í•´ ì±„ê¶Œ ë°œí–‰ìëŠ” ë°œí–‰ì‹œì—\ní•´ë‹¹ ì±„ê¶Œì˜ ì‹ ìš©ë„ë¥¼ ì‹ ìš©í‰ê°€íšŒì‚¬ì— ì˜í•´ ë¶€ì—¬ ë°›ì•„ì•¼ í•¨. ì‹ ìš©í‰ê°€ íšŒì‚¬ëŠ” íŠ¹ì • ì±„ê¶Œì˜ ì±„ë¬´ ë³€ì œëŠ¥ë ¥,\nì¦‰ ìƒí™˜ ê°€ëŠ¥ì„±ì„ ìƒëŒ€ì , ì ˆëŒ€ì  ê¸°ì¤€ìœ¼ë¡œ ë“±ê¸‰ì„ ë§¤ê¸°ëŠ” íšŒì‚¬ì¸ë°, ì²˜ìŒ ë°œí–‰ë  ë•Œì™€ 1ë…„ì— í•œë²ˆì”©,\nê·¸ë¦¬ê³  ì–´ë–¤ íŠ¹ì •í•œ ì´ìŠˆê°€ ë°œìƒí•  ë•Œ ì‹ ìš©ë“±ê¸‰ì„ ë¶€ì—¬í•˜ê±°ë‚˜ ë³€í™”ì‹œí‚´ ì±„ê¶Œ íˆ¬ììë¼ë©´ ê¼­ ì•Œì•„ì•¼ í•  ì‹ ìš©ë“±ê¸‰ # ë”°ë¼ì„œ êµ­ì±„ë‚˜ ì•„ë‹Œ ê³µê³µ ë¶€ë¬¸ê³¼ ë¯¼ê°„ ë¶€ë¬¸ì´ ë°œí–‰í•œ ì±„ê¶Œì— íˆ¬ìí•˜ëŠ” íˆ¬ììë¼ë©´ ì‹ ìš©ë“±ê¸‰ì„ ê¼­ ì•Œì•„ì•¼ í•¨ ì‹ ìš©ë“±ê¸‰ì€ ê¸°ë³¸ì ìœ¼ë¡œ ìƒí™˜ ëŠ¥ë ¥ì— ì´ˆì ì„ ë§ì¶”ê¸° ë•Œë¬¸ì—,\nì–¼ë§ˆë‚˜ ëˆì„ ë§ì´ ë²„ëŠ”ê°€ì™€ í•¨ê»˜ ì§€ê¸ˆ ì–¼ë§ˆë‚˜ ë§ì€ í˜„ê¸ˆì„± ìì‚°ì„ ê°€ì§€ê³  ìˆëŠ”ì§€,\nê°šì•„ì•¼ í•  ë¶€ì±„ëŠ” ì–¼ë§ˆë‚˜ ë§ì€ì§€ ë“±ì„ í† ëŒ€ë¡œ ë¶€ì—¬ë¨.\në¯¸ë˜ì˜ ë§¤ì¶œê³¼ ì´ìµ ì„±ì¥ì„±ì— ì´ˆì ì„ ë§ì¶”ëŠ” ì£¼ì‹ê³¼ëŠ” ë‹¤ë¥¸ ì ‘ê·¼ë²•ì´ í•„ìš”í•¨ ì‹ ìš©í‰ê°€ íšŒì‚¬ì˜ ì‹ ìš©ë“±ê¸‰ í‘œí˜„ # AAAë“±ê¸‰ë¶€í„° Dë“±ê¸‰ ê¹Œì§€ ìˆìœ¼ë©°,\nAAAì™€ D ë“±ê¸‰ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë“±ê¸‰ì€ +, 0, -ë¥¼ ë¶™ì—¬ 3ê°œì˜ í•˜ìœ„ë“±ê¸‰ìœ¼ë¡œ ë‚˜ë‰¨ ê°œì¸íˆ¬ììë“¤ì€ ì´ ì¤‘ BBBë“±ê¸‰ ì´ìƒ ì±„ê¶Œë§Œì„ ì ‘ê·¼í•˜ê¸¸ ê¶Œí•¨.\nì¼ë°˜ì ìœ¼ë¡œ BBBë“±ê¸‰ ì´ìƒì„ íˆ¬ìë“±ê¸‰, BBë“±ê¸‰ ì´í•˜ë¶€í„°ëŠ” íˆ¬ê¸°ë“±ê¸‰ìœ¼ë¡œ ë¶„ë¥˜ ì—¬ê¸°ì—ì„œ ì¤‘ìš”í•œ ê²ƒì€ BBBë“±ê¸‰. ì¼ë°˜ì ìœ¼ë¡œ Aë“±ê¸‰ ì´ìƒì´ ë¶€ì—¬ëœ ì±„ê¶Œì€ ë¶€ë„ í™•ë¥ ì´ ë§¤ìš° ì‘ìŒ.\nê·¸ëŸ°ë° BBB ë“±ê¸‰ì„ ë³´ë©´ í™˜ê²½ ë³€í™”ê°€ ì§€ê¸‰ í™•ì‹¤ì„±ì„ ì €í•˜í•œë‹¤ê³  í‘œí˜„ë˜ì–´ ìˆìŒ.\nì´ì— ë”°ë¼ ë¶€ë„ìœ¨ ì—­ì‹œ Aë“±ê¸‰ ì´ìƒë³´ë‹¤ëŠ” ì˜ë¯¸ ìˆê²Œ ë†’ì•„ì§€ê¸° ì‹œì‘í•¨.\nì´ë¥¼ ë°˜ì˜í•´ ê¸ˆë¦¬ê°€ ë†’ì•„ ìœ„í—˜ ì„ í˜¸ë„ì— ë”°ë¼ íˆ¬ì ì—¬ë¶€ê°€ ê°ˆë¦¬ëŠ” ë“±ê¸‰ì´ë¼ê³  í•  ìˆ˜ ìˆìŒ ì‹ ìš©ë“±ê¸‰ì—ë§Œ ì˜ì¡´í•˜ì§€ ë§ì # ê·¸ëŸ°ë° ì‹ ìš©í‰ê°€ íšŒì‚¬ì˜ ì‹ ìš©ë“±ê¸‰ ì¡°ì •ì€ ë§ì€ ê²½ìš° ì‹œê¸°ì ìœ¼ë¡œ ëŠ¦ìŒ. ì¬ë¬´ì œí‘œë¥¼ í™•ì¸í•´ì•¼ í•˜ê³ ,\në“±ê¸‰ ë³€ê²½ì€ ê¸°ì—…ì—ê²Œ ë§¤ìš° ì¤‘ìš”í•œ ì‚¬ê±´ì´ê¸° ë•Œë¬¸ì— ì‹ ì¤‘ì„ ê¸°í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì  ë”°ë¼ì„œ íˆ¬ììë“¤ì€ ë³´ìœ í•˜ê³  ìˆëŠ” ì±„ê¶Œì˜ ì‹ ìš©ë“±ê¸‰ ë³€í™” ê°€ëŠ¥ì„±ì„ ìŠ¤ìŠ¤ë¡œ ì²´í¬í•  ëŠ¥ë ¥ì„ ê°€ì§€ëŠ” ê²ƒì´ ì¢‹ê³ ,\nì´ëŠ” ì¤‘ê°„ ì¤‘ê°„ ë°œí‘œë˜ëŠ” ì‹ ìš©í‰ê°€ íšŒì‚¬ì˜ ì‹ ìš©ë¶„ì„ ë¦¬í¬íŠ¸ì™€\nì¦ê¶ŒíšŒì‚¬ì—ì„œ ì œê³µí•˜ëŠ” ì‹ ìš©ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ í†µí•´ì„œ ì–»ì„ ìˆ˜ ìˆìŒ í•´ë‹¹ ë¦¬í¬íŠ¸ë“¤ì€ ì‹ ìš©ë“±ê¸‰ì´ ë¶€ì—¬ëœ ì±„ê¶Œë“¤ì˜ ê±°ë˜ë¥¼ ë¶„ì„í•˜ê³ , ì—¬ëŸ¬ í™˜ê²½ì˜ ë³€í™”, ê°œë³„ ê¸°ì—…ì˜ ë¬¸ì œ,\níŠ¹ì • ì±„ê¶Œì´ë‚˜ ì˜ˆë¥¼ ë“¤ì–´ Aë“±ê¸‰ íšŒì‚¬ì±„ ì²˜ëŸ¼ íŠ¹ì • ë²”ì£¼ì˜ ì±„ê¶Œë“¤ì—ì„œ ê°€ê²©ì´ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ê°€ ë“±ì„ ë‹¤ë¤„ì„œ\nì±„ê¶Œíˆ¬ììë“¤ì—ê²Œ ë„ì›€ì„ ì¤Œ ê·¸ëŸ°ë° ì´ëŸ¬í•œ ì‹ ìš©ë¶„ì„ì„ ì˜ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ë¶„ì„ ëŒ€ìƒì„ ì•Œì•„ì•¼ í•¨.\nì¼ë°˜ì ìœ¼ë¡œ ì™¸ë¶€í™˜ê²½ì˜ ë³€í™”ì™€ ìƒí™˜ì˜ì§€, ì§€ê¸‰ ëŠ¥ë ¥, ì¬ë¬´ ìƒíƒœ, ë‹´ë³´ ë“±ì´ ë¶„ì„ ëŒ€ìƒì¸ë°,\níˆ¬ììë“¤ì€ ë¦¬í¬íŠ¸ë¥¼ ì½ì„ ë•Œ ì´ëŸ¬í•œ ë¶€ë¶„ë“¤ì´ ê¼¼ê¼¼í•˜ê²Œ ë¶„ì„ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ì‚´í´ë³¼ í•„ìš”ê°€ ìˆìŒ í•œí¸, ì‹ ìš©í‰ê°€íšŒì‚¬ì˜ ë“±ê¸‰ ë¶€ì—¬ ë°©ë²•ë¡ ë„ ì°¸ê³ í•  í•„ìš”ê°€ ìˆëŠ”ë°,\në„í‘œë¥¼ ë³´ë©´ ì´ë“¤ì€ ê¸€ë¡œë²Œ íŠ¸ë Œë“œì™€ ë”ë¶ˆì–´ ê·œì œ, ê²½ì˜ì§„ì˜ ì§ˆì ì¸ ìˆ˜ì¤€ìœ¼ë¡œë¶€í„°,\në°œí–‰ ê·œëª¨ê¹Œì§€ ë§¤ìš° ë‹¤ì–‘í•œ ì •ë³´ë¥¼ í™œìš©í•¨ì„ ì•Œ ìˆ˜ ìˆìŒ.\në”°ë¼ì„œ ì‹ ìš©ìœ„í—˜ì´ í° ì±„ê¶Œì— íˆ¬ìí•˜ë ¤ëŠ” íˆ¬ììë¼ë©´ ë°œí–‰ ì‹œì˜ ì‹ ìš©ë“±ê¸‰ ë¦¬í¬íŠ¸ë¥¼ ê¼¼ê¼¼í•˜ê²Œ ì‚´í´ë³¼ ê²ƒì„ ê¶Œí•¨ 6ê°• - ì±„ê¶Œ ì–´ë–»ê²Œ íˆ¬ìí•´ì•¼ ë‚´ëˆ ë²Œê³  ì§€í‚¬ê¹Œ? ì±„ê¶Œ íˆ¬ì ì „ëµê³¼ ë°©ë²• # ì–´ë–¤ íˆ¬ìì—ì„œë„ ì¤‘ìš”í•œ ì‹œì  í¬ì°© # íˆ¬ìì— ìˆì–´ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ë¬´ì—‡ì¼ê¹Œ? ë„ˆë¬´ ë§ì€ ìš”ì¸ë“¤ì´ ìˆì§€ë§Œ,\níˆ¬ìì ì…ì¥ì—ì„œ ë³´ë©´ ì—­ì‹œ ì‚¬ê³  íŒŒëŠ” ì‹œì ì„ ì˜ ì•„ëŠ” ê²ƒì´ ì œì¼ ì¤‘ìš”í•¨.\në‚®ì€ ê°€ê²©ì— ì‚¬ê³  ë¹„ì‹¼ ê°€ê²©ì— íŒŒëŠ” ê²ƒì€ ëª¨ë“  íˆ¬ììë“¤ì´ ì›í•˜ëŠ” ê²ƒ ì±„ê¶Œì˜ ê²½ìš° ê¸°ë³¸ì ìœ¼ë¡œ ë§Œê¸°ê¹Œì§€ ë³´ìœ í•˜ëŠ” ë¶„ì´ ë§ì§€ë§Œ,\nì´ ê²½ìš°ì—ë„ ê°€ê²©ì´ ì‹¼ ì‹œì ì— ì‚¬ëŠ” ê²ƒê³¼ ë¹„ì‹¼ ì‹œì ì— ì‚¬ëŠ” ê²ƒì€ ë§¤ìš° í° ì°¨ì´ê°€ ìˆìœ¼ë©°,\nì‹œì ì„ ì˜ í¬ì°©í•´ ë‚¼ ìˆ˜ë§Œ ìˆë‹¤ë©´ ë§Œê¸° ë³´ìœ ë¥¼ ì„ íƒí•  ìˆ˜ë„, íŒ”ì•„ì„œ ìë³¸ì´ë“ì„ ë‚´ê³ ,\në˜ ë‹¤ì‹œ íˆ¬ìì— ë‚˜ì„¤ ìˆ˜ ìˆë‹¤ëŠ” ì˜µì…˜ì´ ìƒê¹€ ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì§€ë‚œ 4ì¼ì°¨ì—ì„œ ë°°ìš´ ì±„ê¶Œ ê°€ê²©, ì¦‰ ì‹œì¥ê¸ˆë¦¬ ì „ë§ì˜ ê¸°ì´ˆë¥¼ ì˜ í™œìš©í•´\níˆ¬ì ì‹œì ì„ ì„ íƒí•˜ëŠ” ê²ƒ ì¤‘ìš”. íŠ¹íˆ ì´ëŸ¬í•œ ê¸°ë³¸ì„ ì•Œê³  ìˆë‹¤ë©´,\nì‹œì¥ì—ì„œ í”íˆ ë‚˜íƒ€ë‚˜ëŠ” ì˜¤ë²„ìŠˆíŒ…ê³¼ ì–¸ë”ìŠˆíŒ…ì„ ìˆ˜ìµë¥ ì„ ë†’ì´ëŠ” ê¸°íšŒë¡œ ì‚¼ì„ ìˆ˜ ìˆìŒ ê·¸ëŸ°ë° íˆ¬ìì— ìˆì–´ì„œëŠ” ë³´ìœ  ê¸°ê°„ë„ ë§¤ìš° ì¤‘ìš”í•¨. ìê¸ˆì˜ ì„±ê²©ë„ íˆ¬ììë“¤ì˜ ì„±ê²©ë„ ë‹¤ ë‹¤ë¥´ê¸° ë•Œë¬¸.\nì–´ë–¤ ì‚¬ëŒì€ ì±„ê¶Œì„ ì‚¬ì„œ ë§Œê¸°ê¹Œì§€ ë³´ìœ í•˜ê³ ,\nì–´ë–¤ ì‚¬ëŒì€ ê³„ì† ì±„ê¶Œì„ ê±°ë˜í•´ ìë³¸ ì´ë“ì„ ê·¹ëŒ€í™”í•˜ë ¤ í•  ìˆ˜ ìˆìŒ.\në”°ë¼ì„œ íˆ¬ì ê¸°ê°„ê³¼ ì „ë§ì˜ ê¸°ê°„ì„ ì˜ ì¡°í™”í•  í•„ìš”ê°€ ìˆìŒ ë§Œì•½ ë§Œê¸° ë³´ìœ ë¥¼ ë¹„ë¡¯í•œ 3ë…„ ì´ìƒì˜ ê¸°ê°„ì„ ê³ ë ¤í•˜ëŠ” ì¥ê¸° íˆ¬ììë¼ë©´ ë‹¨ê¸°ì ì¸ ê°€ê²© íë¦„ë³´ë‹¤ëŠ”\nêµ­ë‚´ì™¸ ê²½ì œì˜ êµ¬ì¡°ì ì¸ ë¬¸ì œë¥¼ ì´í•´í•  í•„ìš”ê°€ ìˆìŒ. ì˜ˆë¥¼ ë“¤ë©´ ìµœê·¼ ë‚˜íƒ€ë‚˜ê³  ìˆëŠ” ë‹¬ëŸ¬í™” ê°•ì„¸ì™€\nê·¸ë³´ë‹¤ ë” ê¸´ ì¸êµ¬ ê³ ë ¹í™” ë¬¸ì œ, ë¯¸ì¤‘ íŒ¨ê¶Œ ì „ìŸê³¼ ê°™ì€ êµ¬ì¡°ì  ë¬¸ì œë¥¼ ì´í•´í•  í•„ìš”ê°€ ìˆëŠ”ë°,\nì´ëŸ¬í•œ ë¬¸ì œë“¤ì€ ëª¨ë‘ ì±„ê¶Œ ê°€ê²©, ì‹œì¥ê¸ˆë¦¬ì˜ ì¥ê¸°ì ì¸ ì¶”ì„¸ë¥¼ ê²°ì •í•¨.\në”°ë¼ì„œ ë‚´ê°€ ì±„ê¶Œì„ ë³´ìœ í•˜ëŠ” ê¸°ê°„ ë™ì•ˆì— ê°€ê²©ì— ê³„ì†í•´ì„œ ì˜í–¥ì„ ë¯¸ì¹¨.\në§Œì•½ ê³ ë ¹í™”ê°€ ì„±ì¥ë¥ ì„ ë–¨ì–´ëœ¨ë ¤ ê¸ˆë¦¬ë¥¼ ë‚´ë¦¬ëŠ” í˜ìœ¼ë¡œ ì‘ìš©í•œë‹¤ê³  ë¯¿ì–´ì§€ë©´,\nì±„ê¶Œì„ ì‚¬ì„œ ì¥ê¸° ë³´ìœ í•˜ë©´ ì´ìµì„ ì–»ì„ ìˆ˜ ìˆìŒ ì´ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì¤‘ê¸°ì™€ ë‹¨ê¸°ì—ë„ ê°ê°ì˜ ê¸°ê°„ì— ë” í¬ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ë“¤ì´ ìˆìŒ.\në‹¤ë§Œ, ê°œì¸íˆ¬ììë¼ë©´ ìœ ë™ì„± ë¬¸ì œ ë“±ì„ ê°ì•ˆí•´ ë‹¨ê¸° íˆ¬ìë³´ë‹¤ëŠ”\nê²½ê¸° ìˆœí™˜ ì‚¬ì´í´ ì „ë§ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì¤‘ê¸° íˆ¬ìë¥¼ ê¶Œí•¨. ê²½ê¸° ì „ë§ë„ ì–´ë ¤ìš´ ê²ƒì€ ë§ˆì°¬ê°€ì§€ì§€ë§Œ\nì±„ê¶Œê°€ê²©ì— ê°€ì¥ í™•ì‹¤í•œ ì˜í–¥ì„ ë¯¸ì¹˜ê¸° ë•Œë¬¸.\në˜í•œ ê²½ê¸° ìˆœí™˜ ì‚¬ì´í´ì„ ì•Œë©´ í†µí™”ì •ì±… ì „ë§ ë“±ì„ ì±„ê¶Œíˆ¬ìì— í™œìš©í•  ìˆ˜ë„ ìˆìŒ.\nì˜ˆë¥¼ ë“¤ì–´ í˜„ì¬ì˜ ê¸ˆë¦¬ ì¸ìƒ ì‚¬ì´í´ì´ ë§ˆë¬´ë¦¬ë  ë¬´ë µì— ì¤‘ê¸°ì  ê´€ì ì—ì„œ\nì±„ê¶Œì„ ë§¤ìˆ˜í•˜ê³  ê¸ˆë¦¬ê°€ ë–¨ì–´ì§ˆ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ëŠ” ê²ƒì€ ê°€ì¥ ì¼ë°˜ì ì¸ íˆ¬ì ë°©ë²•ì„ ë§Œê¸°ë³´ìœ ì™€ ì¤‘ë„ ë§¤ë„ëŠ” ì–´ë–»ê²Œ íŒë‹¨í• ê¹Œ? # í•œí¸, ì±„ê¶Œì„ ì‚¬ëŠ” ê°œì¸ë“¤ì€ ë•Œë•Œë¡œ ë§Œê¸° ë³´ìœ ì™€ ì¤‘ë„ ë§¤ë„ì˜ íŒë‹¨ ê¸°ë¡œì— ë†“ì¼ ìˆ˜ ìˆìŒ.\nê¸ˆë¦¬ê°€ ì˜¬ëë‹¤ê³  íŒë‹¨í•´ì„œ ì±„ê¶Œì„ ë§¤ìˆ˜í•œ ê²½ìš° ì´í›„ì— ê¸ˆë¦¬ê°€ ë” ì˜¬ë¼ ì†í•´ë¥¼ ë³¼ ìˆ˜ë„,\në‚´ë ¤ì„œ ì´ë“ì„ ë³¼ ìˆ˜ë„ ìˆëŠ”ë°, ì´ ê²½ìš° ì›ë˜ ì‚° ì±„ê¶Œì„ ë§Œê¸°ê¹Œì§€ ê·¸ëƒ¥ ë³´ìœ í•  ê²ƒì¸ì§€,\nì•„ë‹ˆë©´ ì¤‘ë„ì— íŒ”ê³  ë‹¤ì‹œ ë§¤ìˆ˜ì— ë‚˜ì„¤ ê²ƒì¸ì§€ ë“±ì„ ê³ ë¯¼í•˜ê²Œ ë¨ ì´ì™€ ê´€ë ¨í•´ì„œ ì¤‘ìš”í•œ ê°œë…ì€ ë‚´ê°€ ì˜ë„í•œ íˆ¬ì ê¸°ê°„ ì¤‘ ë°œìƒí•˜ëŠ” ì´ìˆ˜ìµë¥ ì„.\nì±„ê¶Œíˆ¬ìì— ìˆì–´ì„œ ì´ìˆ˜ìµë¥ ì€ ê¸°ê°„ ì¤‘ ì±„ê¶Œ ë§¤ë§¤ë¥¼ í†µí•´ ì–»ê²Œ ë˜ëŠ” ì´ìì†Œë“ê³¼ ìë³¸ì´ë“ì„ ë”í•œ ê°’ì¸ë°,\ní•œë²ˆ íˆ¬ìí•˜ê³  ë§Œê¸°ê¹Œì§€ ë³´ìœ í•œë‹¤ë©´ ì²˜ìŒ ê²°ì •ëœ ì´ìì†Œë“ì´ ì´ìˆ˜ìµë¥ ì´ ë˜ê³ ,\nì¤‘ê°„ì— ë§¤ë§¤ë¥¼ í•œë‹¤ë©´ ì´ìì†Œë“ê³¼ ìë³¸ì´ë“ë“¤ì˜ í•©ì´ ì´ìˆ˜ìµë¥ ì´ ë¨ ì˜ˆë¥¼ ë“¤ì–´ ì±„ê¶Œì„ ì‚¬ê³  ê¸ˆë¦¬ê°€ ë” ì˜¬ë¼ ì†í•´ì¸ ìƒíƒœë¥¼ ê°€ì •í•´ ë³´ë©´,\níˆ¬ììëŠ” ë§Œê¸°ê¹Œì§€ ë³´ìœ í•´ í™•ì •ëœ ì´ìì†Œë“ë§Œ ë…¸ë¦´ ìˆ˜ë„ ìˆì§€ë§Œ, ì¤‘ê°„ì— ì†í•´ë¥¼ ë³´ê³ ì„œë¼ë„ íŒ”ê³ ,\në” ë†’ì€ ê¸ˆë¦¬ì— ì±„ê¶Œì„ ë§¤ìˆ˜í•´ ì „ì²´ ê¸°ê°„ì˜ ì´ìì†Œë“ì„ ë” ë†’ì¼ ìˆ˜ ìˆìŒ.\në‹¨, ì´ëŸ¬í•œ ì „ëµì€ ì´ë ‡ê²Œ í•´ì„œ ì–»ê²Œ ë˜ëŠ” ì¶”ê°€ì ì¸ ì´ìì†Œë“ê³¼ ì²«ë²ˆì§¸ ë§¤ë„ì—ì„œ ë°œìƒí•œ\nìë³¸ì†ì‹¤ì„ ë¹„êµí•´ ì´ìì†Œë“ì´ í° ê²½ìš°ì—ë§Œ ì˜ë¯¸ê°€ ìˆìŒ í•œí¸, ë§Œê¸° ë³´ìœ ì™€ ì¤‘ë„ ë§¤ë„ ì˜ì‚¬ ê²°ì •ì„ í•  ë•ŒëŠ” ë‘˜ì¬ ì‹œê°„ì— ì±„ê¶Œ ìš©ì–´ì—ì„œ ì„¤ëª…í•œ ê²½ê³¼ ê¸°ê°„ì´ ì¤‘ìš”.\nì±„ê¶Œì„ ì‚¬ê³  ê²½ê³¼ ê¸°ê°„ì´ ë§ì´ ì§€ë‚œ ê²½ìš° ì±„ê¶Œì˜ ë“€ë ˆì´ì…˜ì€ ì§§ì•„ì§€ê²Œ ë˜ëŠ”ë°,\nì´ë ‡ê²Œ ë˜ë©´ ê¸ˆë¦¬ê°€ ì˜¬ë¼ì„œ ë‚˜íƒ€ë‚˜ëŠ” ìë³¸ ì†ì‹¤ì´ ì‘ì•„ì§.\nê·¸ ìƒíƒœì—ì„œ ë‚˜ë¨¸ì§€ ê¸°ê°„ì— ë†’ì€ ì´ì§€ì†Œë“ì„ ì–»ì„ ìˆ˜ ìˆë‹¤ë©´ ì´ìµì´ ë  ìˆ˜ ìˆìŒ ì¥ê¸°ì±„ê¶Œ, ë‹¨ê¸°ì±„ê¶Œ ì–´ë–¤ ì±„ê¶Œì— íˆ¬ìí• ê¹Œ? # í•œí¸, ì•ì—ì„œ ë°°ìš´ ìˆ˜ìµë¥ ê³¡ì„ ì„ ì±„ê¶Œ íˆ¬ìì— í™œìš©í•  ìˆ˜ ìˆìŒ.\nìˆ˜ìµë¥ ê³¡ì„ ì€ ì•ì„  ê°•ì˜ì—ì„œ ì‹œì¥ê¸ˆë¦¬ì™€ ë§Œê¸° ê°„ì˜ ê´€ê³„ë¥¼ ì˜ë¯¸í•œë‹¤ê³  ì„¤ëª…í–ˆëŠ”ë°,\nì´ëŸ¬í•œ ìˆ˜ìµë¥ ê³¡ì„ ì˜ í˜„ì¬ ëª¨ì–‘ê³¼ ì•ìœ¼ë¡œ ìˆ˜ìµë¥ ê³¡ì„ ì´ ì–´ë–»ê²Œ ë°”ë€” ê²ƒì¸ì§€ì— ëŒ€í•´\nì ì ˆíˆ ì˜ˆìƒí•˜ë©´ ì±„ê¶Œ íˆ¬ìë¥¼ í†µí•´ ëˆì„ ë²Œê³  ì§€í‚¤ëŠ” ë° ë„ì›€ì´ ë¨ ì¼ë°˜ì ìœ¼ë¡œ ìˆ˜ìµë¥ ê³¡ì„ ì€ ìš°ìƒí–¥ì˜ ëª¨ì–‘ì„ ê°–ì§€ë§Œ, ë•Œë•Œë¡œ í‰í‰í•˜ê±°ë‚˜ ì—­ì „ë˜ëŠ” ê²½ìš°ê°€ ìˆìŒ.\në§Œì•½ ìˆ˜ìµë¥ ê³¡ì„ ì´ í‰í‰í•˜ë‹¤ë©´, ë‹¨ê¸° ì±„ê¶Œì— íˆ¬ìí•˜ê³ , ë³´ìœ í•˜ê³  ìˆëŠ” ì¥ê¸° ì±„ê¶Œì„ íŒŒëŠ” ê²ƒì´ ì´ë“ì„.\nì¥ê¸°ì±„ê¶Œì— íˆ¬ìí•  ê²½ìš° ë§Œê¸°ê°€ ê¸¸ì–´ì„œ ë°œìƒí•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í”„ë¦¬ë¯¸ì—„ì„ ë°›ì„ ìˆ˜ ì—†ê¸° ë•Œë¬¸ ë¬¼ë¡  ìë³¸ì´ë“ì´ ëª©ì ì¸ íˆ¬ììëŠ” ê¸ˆë¦¬ ì „ë§ì— ê·¼ê±°í•´ ì¥ê¸°ì±„ê¶Œì„ ì‚´ ìˆ˜ ìˆìŒ.\nê·¸ëŸ¬ë‚˜, ìˆ˜ìµë¥ ê³¡ì„ ì€ ì¼ë°˜ì ìœ¼ë¡œ ìš°ìƒí–¥ì˜ ê²½í–¥ì„±ì„ ê°–ê¸° ë•Œë¬¸ì— ì •ìƒí™”ë˜ê¸° ì‹œì‘í•˜ë©´\nì¥ê¸°ê¸ˆë¦¬ ìƒìŠ¹ í­ì´ ë¹ ë¥¼ ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê³ ë ¤í•´ì•¼ í•¨. ê²Œë‹¤ê°€ ì¥ê¸°ì±„ê¶Œì€ ë“€ë ˆì´ì…˜ì´ í¬ê¸° ë•Œë¬¸ì—\nì¥ê¸°ê¸ˆë¦¬ ìƒìŠ¹ í­ì´ ë¹ ë¥´ë©´ ê°€ê²© í•˜ë½ í­ë„ í›¨ì”¬ í¬ê²Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŒ ìˆ˜ìµë¥ ê³¡ì„ ì´ ì—­ì „ë˜ì–´ ìˆì„ ë•Œì™€ ìˆ˜ìµë¥ ê³¡ì„ ì˜ ê¸°ìš¸ê¸°ê°€ ì¼ë°˜ì ì¸ ê²½ìš°ë³´ë‹¤ ê°€íŒŒë¥¼ ë•Œ\nê°ê° ì–´ë–»ê²Œ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì´ ë°”ëŒì§í• ì§€ë¥¼ ì„¤ëª…í–ˆìŒ.\nì¼ë‹¨ ì—­ì „ë˜ì–´ ìˆì„ ë•ŒëŠ” ì •ì±…ê¸ˆë¦¬ ì¸ìƒì´ ë¹ ë¥´ê²Œ ë‚˜íƒ€ë‚  ë•Œì„ì„ ê°ì•ˆí•  í•„ìš”ê°€ ìˆìŒ.\në”°ë¼ì„œ ë‹¨ê¸° íˆ¬ìë¡œëŠ” ì´ìì†Œë“ì´ ë§ê³  ê¸ˆë¦¬ê°€ ì˜¬ë¼ë„ íƒ€ê²©ì´ ì‘ì€ ë‹¨ê¸° ì±„ê¶Œì— ì§‘ì¤‘í•´ì•¼ í•¨.\në‹¤ë§Œ, ì´ëŸ¬í•œ ìƒí™©ì€ ê¸ˆë¦¬ ì¸ìƒ ì‚¬ì´í´ì˜ ë§ë¯¸ì— ê²½ê¸° ì¹¨ì²´ê°€ ë‚˜íƒ€ë‚˜ë©´ì„œ ì „ë°˜ì ìœ¼ë¡œ\nê¸ˆë¦¬ê°€ í¬ê²Œ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•¨. ë”°ë¼ì„œ ê²½ê¸° ì¹¨ì²´ë¡œ ê¸ˆë¦¬ ì¸ìƒì´ ì¤‘ë‹¨ë  ê²ƒìœ¼ë¡œ\nì˜ˆìƒë˜ëŠ” ì‹œì ë¶€í„°ëŠ” ì¥ê¸°ì±„ê¶Œì„ ë§¤ìˆ˜í•´ ìë³¸ì´ë“ì„ ê·¹ëŒ€í™”í•  í•„ìš”ê°€ ìˆìŒ ìˆ˜ìµë¥ ê³¡ì„ ì´ ì¼ë°˜ì ì¸ ê²½ìš°ë³´ë‹¤ ê°€íŒŒë¥¸ ê²½ìš°ëŠ” ì£¼ë¡œ ì •ì±…ê¸ˆë¦¬ë¥¼ í° í­ìœ¼ë¡œ ë‚´ë¦´ ê²½ìš°ì„.\nì´ ê²½ìš°ëŠ” ì´ìì†Œë“ ì¸¡ë©´ì—ì„œ ì¥ê¸°ì±„ê¶Œì´ ìƒëŒ€ì ìœ¼ë¡œ ìœ ë¦¬í•¨.\në‹¤ë§Œ, ì¸í•˜ ì‚¬ì´í´ì˜ ë§ˆì§€ë§‰ì´ ë˜ë©´ ì „ì²´ì ì¸ ê¸ˆë¦¬ëŠ” ì˜¤ë¥´ê²Œ ë˜ê³ ,\níŠ¹íˆ ì¸í•˜ê°€ ë§ˆë¬´ë¦¬ë˜ëŠ” ì£¼ëœ ì´ìœ ëŠ” ì•ìœ¼ë¡œì˜ ë¬¼ê°€ ìƒìŠ¹ì´ ì˜ˆìƒë˜ëŠ” ê²½ìš°ì´ê¸° ë•Œë¬¸ì—\nìƒë‹¹ ê¸°ê°„ ì¥ê¸°ì±„ê¶Œ íˆ¬ìë¥¼ ì¤‘ë‹¨í•´ì•¼ í•¨ ë¡¤ë§ íš¨ê³¼ # í•œí¸, ìˆ˜ìµë¥ ê³¡ì„ ì„ ì´ìš©í•˜ëŠ” ë°©ë²• ì¤‘ì—ëŠ” ìˆ˜ìµë¥ ê³¡ì„ ì´ ì¼ë°˜ì ì¸ ê¸°ìš¸ê¸°ë¥¼ ê°€ì§ˆ ë•Œ\n\u0026lsquo;ë¡¤ë§ íš¨ê³¼\u0026rsquo;ë¥¼ ì´ìš©í•œ ë°©ë²•ì´ ìˆìŒ ì¡°ê¸ˆ ì–´ë ¤ìš´ ê°œë…ì´ê¸´ í•˜ì§€ë§Œ, ë¡¤ë§ íš¨ê³¼ëŠ” ìˆ˜ìµë¥ ê³¡ì„ ì´ ì´ˆë‹¨ê¸°ë¶€í„° ì–´ëŠ ì •ë„ ë§Œê¸°ê¹Œì§€ëŠ” ê°€íŒŒë¥¸ ê³¡ì„ ì´ë‹¤ê°€,\ní•´ë‹¹ ë§Œê¸°ë¥¼ ì§€ë‚˜ê³  ë‚˜ë©´ í‰í‰í•´ì§€ëŠ” ì¼ë°˜ì ì¸ í˜•íƒœë¥¼ ê°–ëŠ” íš¨ê³¼ë¥¼ ì˜ë¯¸í•¨.\nì´ëŠ” ì—°ê¸ˆì´ë‚˜ ë³´í—˜ ë“± ì¥ê¸°ì±„ì— ëŒ€í•œ íŠ¹ìˆ˜í•œ ìˆ˜ìš”ê°€ ì¡´ì¬í•˜ê³ , ì¥ê¸°ì±„ì¼ìˆ˜ë¡ ê°€ê²© ë³€ë™ì„±ì´ ì»¤ì„œ\nê³µê²©ì ì¸ íˆ¬ììë“¤ì´ ì°¸ì—¬í•˜ê¸° ë•Œë¬¸ìœ¼ë¡œ ì•Œë ¤ì¡ŒëŠ”ë°, ê°œì¸íˆ¬ììë“¤ì€ ì´ë¥¼ ì´ìš©í•  ìˆ˜ ìˆìŒ íŠ¹íˆ ì—¬ëŸ¬ ì±„ê¶Œì„ ë†“ê³  ë§Œê¸°ì™€ ê¸ˆë¦¬ê°„ ê´€ê³„ë¥¼ ì ìœ¼ë¡œ ì°ì–´ ë³´ë©´ ì´ëŸ¬í•œ ê°€ìš´ë°ì—ì„œë„\nìƒëŒ€ì ìœ¼ë¡œ ì €í‰ê°€ëœ ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ìˆìŒ. ì´ëŸ¬í•œ ì €í‰ê°€ëŠ” ë‹¤ì–‘í•œ ì´ìœ ì— ì˜í•œ ê²ƒì¸ë°,\nì‹ ìš© ìœ„í—˜ë„ ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ì¼ì‹œì ì¸ ìˆ˜ê¸‰ ë¶ˆì¼ì¹˜ì™€ ë‹¨ê¸°ì ì¸ ìœ ë™ì„± ë¶€ì¡± ë“±ì´\nì´ìœ ê°€ ë  ìˆ˜ë„ ìˆì–´ íˆ¬ììì—ê²ŒëŠ” ê¸°íšŒì„ ìˆ˜ìµë¥  ê³¡ì„ ì˜ ëª¨ì–‘ì„ ì´ìš©í•œ ì±„ê¶Œíˆ¬ì # ê°€ìš´ë° ê³¡ì„ ì€ ì¼ë°˜ì ì¸ ìˆ˜ìµë¥ ê³¡ì„ ì´ê³ , ì ë“¤ì€ ê°ê° ì±„ê¶Œì˜ ë§Œê¸°, ê¸ˆë¦¬ë¥¼ ë‚˜íƒ€ë‚¸ ê²ƒì„.\nê·¸ëŸ°ë° ì¤‘ê°„ ìœ„ìª½ì— ë³´ë©´ under valuationì´ë¼ëŠ” ì ì´ ìˆìŒ\nê·¸ ì ì€ ì–´ë–¤ ì±„ê¶Œì´ ì¼ë°˜ì ì¸ ìˆ˜ìµë¥ ê³¡ì„ ë³´ë‹¤ ë†’ì€ ê¸ˆë¦¬ë¡œ ê±°ë˜ë˜ê³  ìˆëŠ” ê²½ìš°ì„.\nê·¸ë¦¬ê³  ë§Œê¸°ê°€ ì§§ì•„ì§ˆìˆ˜ë¡ ë§Œê¸° ë³€í™”ë³´ë‹¤ ê¸ˆë¦¬ ë³€í™”ê°€ í¬ê²Œ ë‚˜íƒ€ë‚¨.\në”°ë¼ì„œ under valuationì— í¬í•¨ëœ ì±„ê¶Œì„ ì‚¬ê³ ,\në¡¤ë§ íš¨ê³¼ë¼ê³  í‘œí˜„ëœ ê¸°ê°„ë§Œí¼ ë³´ìœ í•œ í›„ ë§¤ë„í•˜ë©´ ìˆ˜ìµë¥ ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŒ ë¬¼ë¡  ì „ì²´ì ìœ¼ë¡œ ìˆ˜ìµë¥ ê³¡ì„ ì´ ìƒí–¥í•˜ëŠ” ê²½ìš°ì—ëŠ” ì´ëŸ¬í•œ ì „ëµìœ¼ë¡œë„ ì†ì‹¤ì´ ë°œìƒí•  ìˆ˜ ìˆìŒ.\ní•˜ì§€ë§Œ, ì´ ê²½ìš°ì—ë„ ì†ì‹¤ í­ì€ ë‹¤ë¥¸ íˆ¬ì ëŒ€ì•ˆë³´ë‹¤ ë‚˜ì€ ì„±ê³¼ë¡œ ì´ì–´ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ìŒ ê°œì¸ íˆ¬ìì, ë„ˆë¬´ í° ì‹ ìš© ìœ„í—˜ì„ ì§€ì§€ ë§ì # ì‹ ìš© ìœ„í—˜ê³¼ ê´€ë ¨í•´ì„œ ê°œì¸íˆ¬ììë“¤ì— ëŒ€í•œ ê¶Œê³ ëŠ” ê°€ê¸‰ì  ì•ˆì „í•œ ì±„ê¶Œ\níŠ¹íˆ A ë“±ê¸‰ ì´ìƒ ì±„ê¶Œì— íˆ¬ìí•˜ìëŠ” ê²ƒì„. ë°œìƒí–ˆì„ ë•Œì˜ íƒ€ê²©ì´ ë„ˆë¬´ í¬ê¸° ë•Œë¬¸ ë¬¼ë¡  ê³¼ê±°ì—ëŠ” BBB, BB ë“± ìœ„í—˜ì±„ê¶Œ íˆ¬ìë„ ë§ì•˜ìŒ.\në¶€ë„ê°€ ë‚˜ë„ ì±„ê¶Œë‹¨ë“¤ì´ ê°œì¸ë“¤ì—ê²Œ ëŒ€ì²´ë¡œ ì›ë¦¬ê¸ˆì„ ì§€ê¸‰í•´ ì¤¬ê¸° ë•Œë¬¸. í•˜ì§€ë§Œ, ì´ì œëŠ” ê·¸ë ‡ì§€ ì•ŠìŒ íŠ¹íˆ ê°œì¸ì€ ê¸°ê´€íˆ¬ììì™€ ë‹¬ë¦¬ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬ì„±í•˜ê¸° ì–´ë ¤ì›€.\n100ê°œì˜ ìœ„í—˜í•œ ì±„ê¶Œì„ ì‚¬ë©´ 1~2ê°œë§Œ ë¶€ë„ê°€ ë‚  ë•Œ ì „ì²´ ì†ì‹¤ì´ í¬ì§€ ì•Šì§€ë§Œ,\nê°œì¸ì´ í•œ ë‘ê°œì˜ ì±„ê¶Œì„ ì‚¬ê³  í•˜ë‚˜ê°€ ë¶€ë„ê°€ ë‚˜ë©´ ì†ì‹¤ì´ ë§¤ìš° í¼.\nì´ëŸ¬í•œ ì ì„ ê³ ë ¤í•´ Aë“±ê¸‰ ì´ìƒ ì±„ê¶Œì—ë§Œ íˆ¬ìí•  ê²ƒìœ¼ë¡œ ê¶Œí•¨ ê°œì¸ ì±„ê¶Œíˆ¬ì, ì–´ë–¤ ë°©ë²•ì„ ì‚¬ìš©í• ê¹Œ? # ë§ˆì§€ë§‰ìœ¼ë¡œ ê°œì¸ì˜ ì±„ê¶Œ íˆ¬ì ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì†Œê°œí•˜ê² ìŒ.\nê°œì¸ì´ ì±„ê¶Œì— íˆ¬ìí•˜ëŠ” ë°©ë²•ì€ í¬ê²Œ ì§ì ‘ íˆ¬ìì™€ ê°„ì ‘ íˆ¬ìë¡œ ë‚˜ë‰¨ ì´ ì¤‘ ì§ì ‘ íˆ¬ìëŠ” ì¦ê¶Œì‚¬ì™€ ì€í–‰ì„ ì´ìš©í•  ìˆ˜ ìˆìŒ. íŠ¹íˆ ì¦ê¶Œì‚¬ ì´ìš©ì„ ê¶Œí•˜ëŠ”ë°,\nì¦ê¶Œì‚¬ì— ë”°ë¼ì„œ HTSë‚˜ MTSë¥¼ ì´ìš©í•´ ê±°ë˜ì†Œì—ì„œ ê±°ë˜ë˜ëŠ” ì±„ê¶Œì— íˆ¬ìí•  ìˆ˜ ìˆë„ë¡ ì—°ê²°í•´ ì£¼ê¸° ë•Œë¬¸.\nì´ ì™¸ì—ë„ ì¦ê¶Œì‚¬ëŠ” ë³¸ì¸ë“¤ì´ ì¸ìˆ˜í•˜ê±°ë‚˜ ì‚¬ ë†“ì€ ì±„ê¶Œì„ ê°œì¸ë“¤ì—ê²Œ íŒ”ê¸°ë„ í•¨.\nì´ëŸ¬í•œ ì±„ê¶Œì€ ì¦ê¶Œì‚¬ HTS/MTSì—ë„ ì†Œê°œê°€ ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ê³¨ë¼ì„œ ë§¤ìˆ˜í•  ìˆ˜ ìˆìŒ.\nì˜ˆë¥¼ ë“¤ì–´ ìµœê·¼ ì¦ê¶Œì‚¬ë“¤ì€ 2ë…„ì´ ë‚¨ì§€ ì•Šì€ ì¹´ë“œì‚¬ë‚˜ ìºí”¼íƒˆì‚¬ ì±„ê¶Œì„ 5%ê°€ ë„˜ëŠ” ê¸ˆë¦¬ì— íŒ”ê³  ìˆìŒ ì€í–‰ì—ì„œë„ íŠ¹ì •ê¸ˆì „ì‹ íƒ ê³„ì•½ì„ í†µí•´ ì±„ê¶Œì— ì§ì ‘ íˆ¬ìí•  ìˆ˜ ìˆìŒ.\níŠ¹ì •ê¸ˆì „ì‹ íƒì€ ëˆì„ ë§¡ê¸°ê³  íŠ¹ì •í•œ ìì‚°ì„ ì‚¬ ë‹¬ë¼ê³  ìš”ì²­í•  ìˆ˜ ìˆëŠ” ì‹ íƒì„.\ní•˜ì§€ë§Œ, ì€í–‰ ì°½êµ¬ë¥¼ ë°©ë¬¸í•´ ê³„ì•½ì„ ë§ºê³  ìš´ìš©ì§€ì‹œë¥¼ ë‚´ë ¤ì•¼ í•˜ëŠ” ë³µì¡í•œ ê³¼ì •ì„ ê±°ì¹˜ê²Œ ë¨.\ní° ì°¨ì´ëŠ” ì•„ë‹ ìˆ˜ë„ ìˆì§€ë§Œ, ê°™ì€ ì±„ê¶Œë„ ì€í–‰ì—ì„œëŠ” ì¡°ê¸ˆ ë” ë¹„ì‹¸ê²Œ ë§¤ìˆ˜í•˜ëŠ” ê²½í–¥ì´ ìˆìŒ ê°„ì ‘ì ì¸ íˆ¬ì ë°©ë²•ì„. ì´ëŠ” ìì‚°ìš´ìš©ì‚¬ì˜ í€ë“œë‚˜ ì±„ê¶ŒETFë¥¼ ì´ìš©í•œ ê²ƒì¸ë°,\níŠ¹íˆ ì±„ê¶ŒETFë¥¼ ì´ìš©í•˜ë©´ ìˆ˜ì‹œë¡œ í° ë¹„ìš©ì—†ì´ ê±°ë˜ê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆìŒ.\në‹¤ë§Œ, ETFëŠ” íŠ¹ì • ì±„ê¶Œì„ ë§¤ìˆ˜í•œ ê²½ìš°ì™€ ë‹¬ë¦¬ ê³„ì†í•´ì„œ ë“€ë ˆì´ì…˜ì´ ìœ ì§€ë¨.\nì˜ˆë¥¼ ë“¤ì–´ 3ë…„ë§Œê¸° ì±„ê¶Œ ETFëŠ” ê¸°ì´ˆìì‚°ì„ ë°”ê¿” ê³„ì† 3ë…„ ë§Œê¸°ë¥¼ ìœ ì§€í•¨.\në”°ë¼ì„œ ì‹œê°„ì— ê±¸ì³ ê°€ê²© ë³€ë™ì„±ì´ ì‘ì•„ì§€ëŠ” ì§ì ‘ ì±„ê¶Œê³¼ ë‹¬ë¦¬ ê°€ê²© ë³€ë™ì„±ì´ ê³„ì† ë†’ê²Œ ìœ ì§€ëœë‹¤ëŠ” ì ì„ ê°ì•ˆí•´ì•¼ í•¨ "},{"id":7,"href":"/blog/2023-02-05/","title":"2023-02-05 Log","section":"Posts","content":"ì¸ìŠ¤íƒ€ ë§ˆì¼€íŒ… # ì›ƒê¸´ ê¸€ê·€ ë“±ìœ¼ë¡œ ëª¨ì€ íŒ”ë¡œì›ŒëŠ” ìŠ¤í† ì–´ í™ë³´ë¥¼ ìœ„í•´ ìœ ì§€í•  ìˆ˜ ì—†ìŒ í™ë³´ìš© ì‚¬ì§„ì„ ë¨¼ì € ì˜¬ë ¤ë†“ê³  ì†Œë¹„ìë¥¼ ëŒ€ìƒìœ¼ë¡œ íŒ”ë¡œìš°ì™€ ì¢‹ì•„ìš”ë¥¼ ëˆŒëŸ¬ì„œ ëŒì–´ë“¤ì´ê¸° ì˜¤í”„ë¼ì¸ ë§¤ì¥ì˜ ê²½ìš° íƒœê·¸ë¥¼ í†µí•´ íŠ¹ì • ì§€ì—­ì˜ ì‚¬ëŒì„ ê²€ìƒ‰ ì¸ìŠ¤íƒ€ê·¸ë¨ ë´‡ì— ì–´ë·°ì§•ì— ê±¸ë¦¬ë”ë¼ë„ íƒ€ê²ŒíŒ…ìš© ì „ë‹¨ì§€ ê³„ì •ì´ê¸° ë•Œë¬¸ì— ìƒê´€ì—†ìŒ ì–´ë–»ê²Œ ì‚¬ì§„ ì°ì„ì§€ ëª¨ë¥¼ ê²½ìš° í•´ì‹œíƒœê·¸ë¡œ ë‹¤ë¥¸ ìŠ¤í† ì–´ë¥¼ ì°¸ê³ í•´ì„œ ë²¤ì¹˜ë§ˆí‚¹ ìœ íŠœë¸Œ ë…¸ì¶œ # ìƒí’ˆ ì¹´í…Œê³ ë¦¬ì™€ ì—°ê´€ì´ ìˆëŠ” ìœ íŠœë²„ ì°¾ê¸° (ì—…ë¡œë“œ ë‚ ì§œ ìµœì‹ ìˆœ) (ì¤‘ìœ„ ë…¸ì¶œ) ìœ íŠœë²„ ì´ë©”ì¼ ì£¼ì†Œë¥¼ í†µí•´ ì²´í—˜ë‹¨ ì œì•ˆì„œ ì „ë‹¬ ë˜ëŠ” ë‹¤ë¥¸ ìœ íŠœë¸Œ ê³„ì •ìœ¼ë¡œ ì‚¬ì… ìƒí’ˆ ì˜ìƒì„ ì˜¬ë¦¬ê¸° ê´€ë ¨ ë™ì˜ìƒ ë…¸ì¶œ ì¡°ê±´ - ì œëª©, ì„¤ëª…, ì–¸ì–´ ìë§‰ ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸, íƒœê·¸, ì‹œì²­ ê¸°ë¡ ì¹´í˜/ë¸”ë¡œê·¸ ë§ˆì¼€íŒ… # ëŒ€ê°€ì„±ì´ ë†’ì€ ë¸”ë¡œê·¸ë³´ë‹¤ëŠ” ì¹´í˜ê°€ ìœ ìš© ì¹´í˜ì—ì„œëŠ” ì¼ìƒì  í¬ìŠ¤íŠ¸ë„ ê°™ì´ ì˜¬ë ¤ ì‚¬ì´ì‚¬ì´ì— í™ë³´ (ë‹¤ë¥¸ ì•„ì´ë””ë¡œ ëŒ“ê¸€ ë‹¬ê¸°) ì¹´í˜ ë…¸ì¶œ ì‹œ ì¹´í…Œê³ ë¦¬ë³„ ìµœì í™” ê³ ë ¤ (ê²Œì‹œê¸€ ë‚´ìš©ì— í‚¤ì›Œë“œ ì‘ì—…) ê°€ì… ì¦‰ì‹œ íšŒì›ì˜ ê²½ìš° ë„¤ì´ë²„ ì•Œê³ ë¦¬ì¦˜ì— ì˜í•´ ë…¸ì¶œì´ ì–´ë ¤ì›€ ì¿ í‚¤ ì‚­ì œ, VPNìœ¼ë¡œ ì–´ë·°ì§• íšŒí”¼ ìµœì í™” ë¸”ë¡œê·¸ë¥¼ ë§Œë“œëŠ” ê²ƒë³´ë‹¤ëŠ” ì»¨íƒí•˜ëŠ” ê²ƒì´ ë‚˜ìŒ ë„¤ì´ë²„ í¼ì„ í†µí•´ ë¸”ë¡œê·¸ ì²´í—˜ë‹¨ ì œì•ˆ ì‚¬ì§„ ìµœì†Œ 5ì¥ ì´ìƒ, ê¸€ 15003000ì ì´ìƒ, ë…¸ì¶œ í‚¤ì›Œë“œ 35íšŒ ì´ìƒ ì–¸ê¸‰, ì˜ìƒ ìµœì†Œ 1ê°œ ë°•ë¦¬ë‹¤ë§¤ # í›„ë°œì£¼ìê°€ ì§„ì…í•˜ê¸° ì–´ë ¤ì›Œ ìˆ˜ìµì„±ë¿ ì•„ë‹ˆë¼ ì•ˆì •ì„±ë„ ë³´ì¥ í‚¤ì›Œë“œ # ì´ë¯¸ ì˜ë‚˜ê°€ëŠ” ìƒí’ˆì´ ìˆë‹¤ë©´ íŠ¹ì • í‚¤ì›Œë“œ ë‚´ì—ì„œ ìƒí’ˆ ì§€ìˆ˜ê°€ ë†’ìŒ ì €íš¨ìœ¨ ìƒí’ˆëª…ì„ ì§€ìš°ê¸° (ì†Œí˜• í‚¤ì›Œë“œë¥¼ ì³ë‚´ ê¸°ì¡´ í‚¤ì›Œë“œì˜ ë¹„ì¤‘ì„ ëŠ˜ë¦¬ê¸°) ìƒˆë¡œìš´ ì¤‘ì†Œ í‚¤ì›Œë“œì™€ ëŒ€í˜• í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ê¸° ë‹¨ì–´ ë°°ì—´ë„ ì¤‘ìš” (ì¤‘ìš”í•œ ë©”ì¸ í‚¤ì›Œë“œëŠ” ê±°ë¦¬ë¥¼ ê°€ê¹ê²Œ) í‚¤ì›Œë“œëŠ” ìˆëŠ”ë° ë…¸ì¶œì´ ë˜ì§€ ì•ŠëŠ” ê²½ìš° ì¹´í…Œê³ ë¦¬ë¥¼ í™•ì¸ (ë˜ëŠ” í‚¤ì›Œë“œì˜ ì¹´í…Œê³ ë¦¬ ì—°ê´€ë„, ì¹´í…Œê³ ë¦¬ë¥¼ ëª…í™•í•˜ê²Œ) ì¿ íŒ¡ì€ í‚¤ì›Œë“œ ì„ í˜¸ë„ì˜ ë¹„ì¤‘ì´ ë†’ìŒ (ê²€ìƒ‰ì–´ë³„ë¡œ ìƒìœ„ ë…¸ì¶œ ì§€ìˆ˜ê°€ ë‹¤ë¦„, ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸) ì¿ íŒ¡ì€ ë©”ì¸ í‚¤ì›Œë“œê°€ ì˜ì–´ì¼ ìˆ˜ ìˆìŒ (ì™¸êµ­ì¸ ìœ ì…ëŸ‰ ëŠ˜ë¦¬ê¸°) ëŒ€ëŸ‰ ë“±ë¡ vs ê°œë³„ ë“±ë¡ # ëŒ€ëŸ‰ ë“±ë¡ = ì¥ì‚¬, ê°œë³„ ë“±ë¡ = ì‚¬ì—… ê¸°ë³¸ê¸°ë¶€í„° ê°–ì¶”ê¸° (ê°œë³„ ë“±ë¡) ëŒ€ëŸ‰ ë“±ë¡ì˜ ì¬ê³  ê´€ë¦¬, CS ì²˜ë¦¬, ê²€ìƒ‰ ìµœì í™” ë“± ì–´ë ¤ì›€ ëŒ€ëŸ‰ ë“±ë¡ì˜ ì˜ë‚˜ê°€ëŠ” ìƒí’ˆë§Œ ì°¾ì•„ì„œ ë‹¤ë¥¸ ì‚¬ëŒì´ ë“±ë¡ì‹œí‚¬ ìˆ˜ ìˆìŒ ë§ˆì¼€íŒ… íšŒì‚¬ # CPC ë‹¨ê°€ ê¸°ì¤€ìœ¼ë¡œ ë¸”ë¡œê·¸ ë…¸ì¶œì€ ë‚¨ëŠ” ì¥ì‚¬ êµ¬ë§¤ ì‘ì—…, ë¦¬ë·° ì‘ì—… ì–´ë·°ì§• (ë¦¬ë·° ì•Œë°”) í‚¤ì›Œë“œ ê²€ìƒ‰ í›„ ìƒí’ˆì„ êµ¬ë§¤í•´ì„œ ê²€ìƒ‰ ìµœì í™” ìƒí’ˆ ì°œí•˜ê¸° ë° ì²´ë¥˜ ì‹œê°„ ì¦ê°€(3ë¶„)ë¡œ ì–´ë·°ì§• íšŒí”¼ ë™ì¼í•œ êµ¬ë§¤ìë¡œ ì¡íˆê¸° ì•Šê²Œ ì²˜ë¦¬ ê°€êµ¬ë§¤ëŠ” ì‹ ê³ ê°€ ë“¤ì–´ì˜¬ ì‹œ íŒë§¤ ì •ì§€ ë“± ìœ„í—˜ì´ ìˆìŒ ë ˆë“œì˜¤ì…˜ ì‹œì¥ # ìƒˆë¡œìš´ í‚¤ì›Œë“œë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ë¶„ì„ ê¸°ì¡´ ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹, í‰ì  ë‚®ì€ ìˆœì„ ê¸°ì¤€ìœ¼ë¡œ ì†Œë¹„ìê°€ ì¶”êµ¬í•˜ëŠ” ê°€ì¹˜ íŒŒì•… (ë°°ì†¡ìƒíƒœ, ë°°ì†¡ì†ë„, í’ˆì§ˆ, ì†ŒìŒ, ëƒ„ìƒˆ ë“±) ë‹¨ì  ëŒ€ì‘ê³¼ ì£¼ë¬¸ ë° ì œì‘ íŒë§¤ ì±„ë„ ë¦¬ìŠ¤íŒ… íŒë§¤ ì±„ë„ì— ëŒ€ì‘í•˜ëŠ” í‚¤ì›Œë“œ ë¦¬ìŠ¤íŒ… (ë„¤ì´ë²„, ì¿ íŒ¡ ë“± ë³„ë¡œ ì—°ê´€ ê²€ìƒ‰ì–´) ìµœì í™” ë¸”ë¡œê·¸ì™€ ì¹´í˜ ë¦¬ìŠ¤íŒ… ì—…ë¡œë“œ í‘œì¤€ ê·œê²© ì„¤ì • ë§¤ì¶œ ëŠ˜ë¦¬ê¸° # ë‹¨ìˆœ ë…¸ë™ ì‹œê°„ì„ ê°€ê³µí•˜ê¸° (í•œê±´ ì²˜ë¦¬í•  ì‹œê°„ìœ¼ë¡œ í•œë²ˆì— ì²˜ë¦¬, ì‡¼í•‘ëª° ê´€ë¦¬ ì†”ë£¨ì…˜, ì§ì›) ìƒí’ˆ ë“±ë¡ ì‹œ ëŒ€ëŸ‰ ë“±ë¡ í”„ë¡œê·¸ë¨ ë„ë§¤ ë‚©í’ˆì²˜ë¥¼ ì°¾ì•„ì„œ ì•ˆì •ì„±ì„ ë†’ì´ê¸° (ì„¸ê¸ˆê³„ì‚°ì„œ, ê²¬ì ì„œ ì–‘ì‹) ì§ì› ì±„ìš© # ìš°ì„  í”„ë¦¬ëœì„œ í›„ ì •ê·œ ì§ì› ì±„ìš© ê³„ì†í•´ì„œ ì¼ì„ ì˜í•˜ëŠ”ì§€ ì¼€ì–´í•˜ê³  ê´€ë¦¬ ì •ìœ¼ë¡œ ìš´ì˜í•˜ì§€ ì•Šê¸° ì§ì› ì±„ìš© ì‹œ ê¸°ê³„ë³´ë‹¤ëŠ” ë¶€í’ˆì„ ì‚¬ê³  ì •ë³´ë‹¤ëŠ” ì´ì„±ì„ í™œìš© 3PL # í¬ì¥ ì¸ë ¥, ì‚¬ë¬´ì‹¤ì´ ì—†ë‹¤ë©´ 3PL í™œìš© ê²½ê¸°ë„ê¶Œ, ì¸ì²œ, ë¶€ì‚° ë“± ë°°ëŒ€ì§€ì— ë”°ë¼ ê²°ì • í™”ë¬¼ëŸ‰ì— ë”°ë¼ ë‹¤ë¥¸ ê²½ìš° ë“± ì• ë§¤í•œ ê²½ìš°ëŠ” ë¯¿ì§€ ì•Šê¸° ì‹œê°„ëŒ€ë³„ ì£¼ë¬¸ ë§ˆê° í™•ì¸ ì—¬ëŸ¬ ì‡¼í•‘ëª° ë°œì£¼ë¥¼ í•œë²ˆì— ê´€ë¦¬ (í†µí•© ê´€ë¦¬ ì†”ë£¨ì…˜ì´ ìˆëŠ” ì—…ì²´) ì¡°ê±´ ì œì‹œí•  ë•Œ ë…¹ìŒ í•„ìˆ˜, ê³„ì•½ì„œ ê²¬ì ì„œ ë°›ê¸°, ë¬¼ë¥˜ê°€ ì¤„ì–´ë“¤ë©´ ê°€ê²© ì¸ìƒ ì—¬ë¶€ í™•ì¸ "},{"id":8,"href":"/blog/2023-02-04/","title":"2023-02-04 Log","section":"Posts","content":"ìƒí’ˆ í˜ì´ì§€ # ë¸Œëœë“œ ê°€ì¹˜ ì„¤ëª… ë‹¤ë¥¸ ìƒí’ˆê³¼ ë‹¤ë¥¸ ì´ìœ  ì„¤ëª… (ì „ë¬¸ì ì¸ ìš©ì–´ ì‚¬ìš©, ìœ ì‚¬í’ˆ ì£¼ì˜ ì•ˆë‚´) ì œí’ˆì˜ ê°€ì¹˜ë¥¼ ì¦ëª… (ì¶”ìƒì ì´ì§€ ì•Šì€ ì¬ì§ˆ, íš¨ê³¼, ì¸ê³¼ê´€ê³„, í”½í† ê·¸ë¨, íƒ€ê²ŸíŒ… ë“±) ë°°ì†¡ ì •ì±… ë° í´ë ˆì„ ëŒ€ë¹„ (í•´ì™¸ ì§ë°°ì†¡ ê¸°ê°„, ì´ˆê¸°ë¶ˆëŸ‰, A/S ê´€ë ¨ ë¬¸ì˜ ë“±) ë¦¬ë·° ê´€ë¦¬ # ìƒí’ˆ ê²€ìˆ˜ ì´ë¯¸ì§€ ì „ë‹¬, í†µê´€ ì™„ë£Œ ì•ˆë‚´, í¬í† ë¦¬ë·° ì•ˆë‚´, ë³µë¶™ ê¸ˆì§€ ì•„ë™ íƒ€ê²Ÿ ì œí’ˆì˜ ìƒí’ˆ í˜ì´ì§€ì— KC ì¸ì¦ ë¬¸ì œê°€ ìˆì„ ê²½ìš° ë¦¬ë·°ë¥¼ ìƒì„¸ í˜ì´ì§€ ëŒ€ì‹  í™œìš© ê³ ê°ì˜ ì˜ëª»ëœ í´ë ˆì„ì€ ì´ì„±ì ìœ¼ë¡œ ì„¤ëª…, í›„ë‹¨ ì¡°ì¹˜ëŠ” ê³ ê°ì˜ ë§Œì¡±ì„ ìœ„í•´ ì™•ë³µ ë°°ì†¡ë¹„ ì†í•´ë¥¼ ê°ìˆ˜í•˜ê³  ë°˜í’ˆ ìš•ì„¤ ë¦¬ë·°ëŠ” ì‹ ê³  ì²˜ë¦¬ ë§ˆìŒì— ë“¤ì§€ ì•Šì„ ì‹œ 7ì¼ ì´ë‚´ ë¬´ë£Œ ë°˜í’ˆ íƒë°° # GS Postbox ì‚¬ì—…ì ë“±ë¡ (2kg ì´í•˜ 2600ì›) í•˜ë£¨ ë°œì£¼ëŸ‰ì´ ë§ì•„ì§€ë©´ íƒë°° ê³„ì•½ (í•˜ë£¨ 50-100ê±´ íŒë§¤ ì¤‘ì´ë¼ê³  ì „ë‹¬, ë¯¸ë˜ ì„±ì¥ ì œì‹œ) ì œí’ˆì˜ ì‚¬ì´ì¦ˆì— ë§ëŠ” ë°•ìŠ¤ë¥¼ ì¤‘êµ­ íŒë§¤ìì—ê²Œ ë¯¸ë¦¬ ìš”êµ¬ íŒŒì† ìœ„í—˜ì´ ìˆëŠ” ê²½ìš° ì—ì–´ìº¡ ë˜ëŠ” ì—ì–´ìº¡ ë´‰íˆ¬ ê°ˆìƒ‰ ë°•ìŠ¤ëŠ” íˆ¬ëª… í…Œì´í”„ë³´ë‹¤ ìœ ìƒ‰ í…Œì´í”„ ì‚¬ìš© (ì·¨ê¸‰ì£¼ì˜ ë“± í”„ë¦°íŒ…ëœ í…Œì´í”„, ë‚´ë¶€ì¬ëŠ” íˆ¬ëª… í…Œì´í”„) ì§„ìƒ ì²˜ë¦¬ # ìì‹ ì˜ ì§ì±…ì„ ë‚®ì¶”ê¸°, ì§ì›ì´ë¼ì„œ ìì‹ ì˜ í•œê³„ë¥¼ ì „ë‹¬ ìƒëŒ€ê°€ ë°˜í’ˆ ì œí’ˆì„ ë³´ë‚´ì§€ ì•Šìœ¼ë©´ ë‚´ìš© ì¦ëª…ì„ ë³´ë‚´ê¸° ì¢‹ì€ ì‚¬ëŒì—ê²ŒëŠ” ì‚¬ì¥ìœ¼ë¡œ í• ì¸ í˜œíƒì„ ì£¼ê³  ì§„ìƒí•œí…ŒëŠ” ëŒ€ë¦¬ë¡œ ë³´ìƒí•  ë°©ì•ˆì´ ì—†ë‹¤ê³  ì „ë‹¬ ì§„ìƒí•œí…Œ ì˜ ëŒ€í•´ì¤„ í•„ìš”ê°€ ì—†ìŒ, ì–µì§€ë¡œ ì„œë¹„ìŠ¤ì˜ ê°•ë„ë¥¼ ë†’ì´ì§€ ì•Šê¸° CSê°€ ëŠ¦ì–´ì§€ëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆì–´ì•¼ í•¨ (ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ ì•ˆë‚´, í†¡í†¡ ìƒë‹´ ìë™ ì‘ë‹µ ë©”ì‹œì§€) ì „ë¬¸ì„±ê³¼ ì¹œìˆ™í•¨ì„ ë™ì‹œì— ê°–ì¶°ì•¼ í•¨ ì „í™” ìƒë‹´ # ì „í™” ìƒë‹´ ì²«ë§ˆë””ëŠ” \u0026lsquo;ì•ˆë…•í•˜ì„¸ìš” XXX ìŠ¤í† ì–´ ì…ë‹ˆë‹¤\u0026rsquo; \u0026lsquo;íŒë§¤ì²˜ê°€ ì—¬ëŸ¬ ê³³ ìˆëŠ”ë° ì–´ë””ì…” ì—°ë½ì£¼ì…¨ì–´ìš”?\u0026rsquo;, \u0026lsquo;ìƒí’ˆëª… ë§ì”€í•´ì£¼ì„¸ìš”\u0026rsquo; ë§ì€ ìƒí’ˆì„ ì·¨ê¸‰í•˜ëŠ” ê²ƒì„ ì•Œë ¤ì„œ ì œí’ˆ ì •ë³´ë¥¼ ì°¾ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì„ ëŠ¦ì¶”ê¸° \u0026lsquo;ê¸°ë‹¤ë ¤ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤\u0026rsquo; ë§ˆë¬´ë¦¬ ë©˜íŠ¸ \u0026lsquo;í˜¹ì‹œë¼ë„ ë˜ë‹¤ë¥¸ ë¬¸ì˜ê°€ ìˆìœ¼ì‹œë‹¤ë©´ í†¡í†¡ ìƒë‹´ì„ ì´ìš©í–Š ì£¼ì‹­ì‹œì˜¤\u0026rsquo; \u0026lsquo;ëŠ¦ì€ ì‹œê°„ì— ì—°ë½ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. XXX ìŠ¤í† ì–´ ì…ë‹ˆë‹¤\u0026rsquo; ì˜¨ë¼ì¸ ìƒë‹´ # ì•ˆë…•í•˜ì„¸ìš” XXX ìŠ¤í† ì–´ ì…ë‹ˆë‹¤ \u0026hellip; ì˜¤ë˜ ê¸°ë‹¤ë ¤ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤ \u0026hellip; í•­ìƒ ì¢‹ì€ í•˜ë£¨ ë˜ì‹­ì‹œì˜¤ ì‹œì‘ê³¼ ëì€ í™•ì‹¤í•˜ê²Œ, ì‹œì¥íŒì²˜ëŸ¼ ë³´ì´ê²Œ í•˜ì§€ ì•Šê¸° ë‹µì¥ ì£¼ê¸°ê°€ ëŠ¦ì–´ì§€ëŠ” ê²½ìš° ì „í™” ìƒë‹´ìœ¼ë¡œ ì²˜ë¦¬ [ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤ë¥¼ í™œìš©í•œ ê°€ìƒë²ˆí˜¸ ë§Œë“¤ê¸°]\nCopy text íœ´ëŒ€í° ë²ˆí˜¸ë¥¼ ìŠ¤í† ì–´ ë²ˆí˜¸ì— ì…ë ¥í•´ì„œ, ê°œì¸ì •ë³´ ìœ ì¶œì´ ìš°ë ¤ë˜ì‹œëŠ” ë¶„ë“¤ì´ ë§ìœ¼ì‹¤ í…ë°ìš”. https://smartplace.naver.com/ì—ì„œ ì—…ì²´ ë“±ë¡ì„ í•˜ë©´, \u0026#39;ìŠ¤ë§ˆíŠ¸ì½œ\u0026#39; ì„œë¹„ìŠ¤ë¥¼ í†µí•´ 0507ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê°€ìƒ ë²ˆí˜¸ë¥¼ ë§Œë“¤ì–´ì„œ íœ´ëŒ€í°ê³¼ ì—°ë™ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´í¸ì—ì„œ ì˜¤ëŠ” ì „í™”ëŠ” \u0026#39;ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤ì—ì„œ ì—°ê²°ë©ë‹ˆë‹¤\u0026#39;ë¼ê³  ì²˜ìŒì— ì¸íŠ¸ë¡œ ìŒì„±ì´ ë‚˜ì™€ì„œ \u0026#39;ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë³´ê³  ì—°ë½ ì™”êµ¬ë‚˜\u0026#39; í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”~ ì´ ì¸íŠ¸ë¡œ ìŒì•…ì´ ì•ˆ ë‚˜ì˜¤ë©´ ì£¼ë³€ ì§€ì¸ì´ë¼ê³  ìƒê°í•˜ë©´ ë˜ê³ , ì¸íŠ¸ë¡œ ìŒì•…ì´ ë‚˜ì˜¤ë©´ \u0026#39;ì•ˆë…•í•˜ì„¸ìš” (ìŠ¤í† ì–´ëª…)ì…ë‹ˆë‹¤\u0026#39; ë¼ê³  í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¤€ë¹„ëœ ìì„¸ì˜ ìƒë‹´ì›ê³¼ \u0026#39;ëˆ„êµ¬ì„¸ìš”?\u0026#39;ë¼ê³  ë¬»ëŠ” ìƒë‹´ì›ì€ ì²«ì¸ìƒë¶€í„°ê°€ ë‹¤ë¥´ë‹ˆê¹Œìš”. ê´‘ê³  # CPM (ë…¸ì¶œë‹¹), CPA,CPS (ì „í™˜ë‹¹), CPC (í´ë¦­ë‹¹) ì¼ì • ê´‘ê³  ê¸ˆì•¡ ì´ìƒ ì‹œ ì „í™˜ìœ¨ì€ ê·¸ëŒ€ë¡ ë° ê´‘ê³ ë¹„ê°€ ë§ì•„ ì˜¤íˆë ¤ ë§ˆì§„ ëŒ€ë¹„ ê´‘ê³  íš¨ìœ¨ ê°ì†Œ\n(íš¨ìœ¨ì ì¸ ê³¨ë“  ìŠ¤íŒŸ ì°¾ê¸°) íŒë§¤ë‹¹ ìˆœì´ìµ, ì „í™˜ìœ¨, ì…ì°°ê°€ë¥¼ í†µí•´ ê´‘ê³  ë§ˆì§„ì„ ê³„ì‚° ê´‘ê³ ê°€ í•„ìš”í•œ ìœ í˜• = MOQ ì¦ê°€ (í° ë§ˆì§„ì„ ë‚¼ í•„ìš”ê°€ ì—†ìŒ) ê´‘ê³ ë¹„ëŠ” PC ìµœì†Œ ë…¸ì¶œ ì…ì°°ê°€, ëª¨ë°”ì¼ 1ìœ„,2ìœ„,3ìœ„ í‰ê·  ì…ì°°ê°€ ë“± ì„¤ì • (ìë™ ê·œì¹™ ë§Œë“¤ê¸°) ëª¨ì˜ ì‹œë®¬ë ˆì´ì…˜ # ë¬¼ë¥˜ë¹„ ì ˆê° (ì¤‘êµ­ ë‚´ë¥™ ìš´ì†¡ë¹„, í•œêµ­ ìš´ì†¡ë¹„, í•œêµ­ ë‚´ë¥™ ìš´ì†¡ë¹„) ì‚¬ì—…ì í†µê´€ \u0026gt; ì„¸ê´€ ì¸ë³´ì´ìŠ¤, í™”ë®¬ ì •ë³´ ì—‘ì…€, ì›ì‚°ì§€ ì •ë³´, KC ì¸ì¦\n(ìš´ì†¡ ì¤‘ í™”ë¬¼ ë¶„ì‹¤ ìœ„í—˜) ê´€ì„¸, ë¶€ê°€ì„¸, í•´ì™¸ì†¡ê¸ˆ ìˆ˜ìˆ˜ë£Œ ì•„ì´í…œ ìœ„ë„ˆ ë°©ì–´ ìœ„í•´ ë¸Œëœë”© í•„ìˆ˜ ìœ ì‚¬ ë¸Œëœë”© # 1688 ì¸ë„¤ì¼ ëŒ€ì‹  ì§ì ‘ ì°ì€ ì‚¬ì§„, ë˜ëŠ” ì‚¬ì€í’ˆì„ ë„£ì€ ì‚¬ì§„ (ì„¸íŠ¸ ìƒí’ˆ) ëª¨ë¸ì— ìƒí‘œë¥¼ ê°ì¸í•˜ê¸°, ëŒ€ëŸ‰ ì£¼ë¬¸ ì‹œ ê³µì¥ì— ìƒí‘œ ê°ì¸ (ì¶”ê°€ê¸ˆ ë§í•˜ì§€ ì•Šê¸°, ë‹¨ì¡°ë¡­ê²Œ ì œì•ˆ, ì²«ì£¼ë¬¸ í—ˆë“¤ ë‚®ì¶”ê¸°) í¬ì¥ì— ìƒí‘œë¥¼ ê°ì¸í•˜ê¸° (í¬ì¥ì„ ë°”ê¿”ì„œ ëª¨ë¸ëª…ì„ ë°”ê¾¸ê¸°) êµ­ë‚´ ì¸ì¦ìœ¼ë¡œ ì°¨ë³„í™”ë¥¼ ë‘ê¸° (KC ì¸ì¦) ì£¼ë¬¸ ì œì‘ ì‹œ ìš°ì„  ìƒ˜í”Œì„ ë°›ì•„ë³´ê³  ê²°ì • ì‚¬ì… ê³¼ì • # ë°•ìŠ¤ì— Made in China í‘œì‹œ í•„ìˆ˜ (ê´€ì„¸ë²•ë ¹ì •ë³´í¬í„¸ì—ì„œ ì›ì‚°ì§€í‘œì‹œëŒ€ìƒ Y ì°¾ê¸°) ì§€ì ì¬ì‚°ê¶Œ ì¹¨í•´ ìƒí’ˆ ìˆ˜ì… ê¸ˆì§€ (ë¸Œëœë“œ ìƒí’ˆ ë“±) ë¬¼ë¥˜ë¹„ ì±…ì • (ë¶€í”¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ê²© ì±…ì •í•˜ëŠ” ìƒí’ˆ ë“±), ìˆ˜ì…(ì†Œí˜• í™”ë¬¼),\nCBM(ê°€ë¡œì„¸ë¡œë†’ì´ ë‹¨ìœ„), LCL(ë‹¤ë¥¸ ë¬¼í’ˆê³¼ ê°™ì´ ìš´ì†¡), FCL(ë³¸ì¸ ìƒí’ˆë§Œ ìš´ì†¡) íŒŒì†ë¥ ì„ ì¤„ì´ê¸° ìœ„í•´ 30% ì„ ê¸ˆ, ìƒ˜í”Œ í™•ì¸ í›„ 70% í›„ë¶ˆ, íŒŒì† ìƒí’ˆì€ ë‹¤ì‹œ ë°›ëŠ” ì¡°ê±´ìœ¼ë¡œ ê³„ì•½ êµ­ë‚´ ì¸ì¦ # 1381 ì¸ì¦ í‘œì¤€ ì •ë³´ ì„¼í„°ì— ì „í™”í•´ ìˆ˜ì… ë¬¼í’ˆì— í•„ìš”í•œ ì¸ì¦ ë° ì‹œí—˜ì†Œ ìœ„ì¹˜ í™•ì¸ ë‚´ë¶€ ì„œë¥˜ ë“±ì´ í•„ìš”í•œ ê²½ìš° ì œì¡°ì‚¬ì— ìš”ì²­ ì¸ì¦ì„ í†µê³¼í•˜ì§€ ëª»í•  ì‹œ ì œì¡°ì‚¬ì— ë¶€ì í•© ìš”ì²­ì„œë¥¼ ì „ë‹¬í•´ì„œ ì œí’ˆì„ ë‹¤ì‹œ ë°›ê¸° ëŒ€í–‰ì‚¬ë¥¼ í†µí•´ ì¸ì¦ ë°›ê¸° (KC ì¸ì¦ ëŒ€í–‰, ë‹¤ë¥¸ ì—…ì²´ì™€ ë¹„êµ) ê°€ì ¸ì˜¤ê¸° í˜ë“  ìƒí’ˆì€ ì„ ë°œì£¼ìê°€ ë˜ê¸° ìƒí’ˆ ë…¸ì¶œ # ì™¸ë¶€ëª°ì„ ì´ìš©í•˜ë©´ ë„¤ì´ë²„ ê²€ìƒ‰ì—”ì§„ì—ì„œë„ í‘œì‹œ ê°€ëŠ¥ (ê°€ê²©ë¹„êµ ë§¤ì¹­ ìš”ì²­) ìµœì €ê°€ ê²½ìŸ # 100ì›, 1000ì› ì°¨ì´ëŠ” ì˜ë¯¸ê°€ ì—†ê¸° ë–„ë¬¸ì— ê°€ê²©ì„ ì‹ ê²½ì“°ì§€ ì•Šê²Œ í•˜ëŠ” ê¸°ëŒ€ìš”ì†Œë¥¼ ë†’ì´ê¸° ë‹¤ë¥¸ ìƒí’ˆê³¼ì˜ ë¹„êµ ì‚¬ì§„, ê°€ê²© ëŒ€ë¹„ ì°¨ë³„í™”ëœ ì´ìœ  ì•Œë¦¬ê¸°, ì •ì§í•¨, ì‹ ë¢°ë„ ë‹¹ì¼ ë°°ì†¡, ë‚´ì¼ ë„ì°© ë³´ì¥, \u0026lsquo;ì§€ì—­ì— ë”°ë¼ ë°°ì†¡ì¼ìì— ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\u0026rsquo; ë‚®ì€ ê°€ê²©ì˜ ë¯¸ë¼ ìƒí’ˆì„ ì¶”ê°€ìƒí’ˆìœ¼ë¡œ ì²¨ë¶€ (ê¸°ì¡´ ìƒí’ˆê³¼ ë°°ì†¡ë¹„ë¥¼ í¬í•¨ì‹œí‚¤ê¸°) ì–´ëŠì •ë„ì˜ ê°€ê²©ì´ ë„˜ì–´ê°€ë©´ ê°€ê²©ë³´ë‹¤ëŠ” ë§Œì¡±ê°ì´ ì¤‘ìš” ë¸Œëœë”©ì´ ì—†ì„ ê²¨ì›… ì¸ë„¤ì¼ì„ ë°”ê¾¸ê³  ìµœëŒ€í•œ ë‹¤ë¥¸ ìƒí’ˆì„ì„ ì¸ì§€ì‹œí‚¤ê¸° ë¬´ì¡°ê±´ ì„ ë°œì£¼ìë¥¼ ì´ê¸¸ í•„ìš”ê°€ ì—†ê³  ë¹„êµë„ ê´œì°®ìŒ ìƒí’ˆí˜ì´ì§€ë¥¼ ë°°ë‚€ ê²½ìš° ë„¤ì´ë²„ ì €ì‘ê¶Œ ì‹ ê³  ì¢‹ì€ ìƒí’ˆì´ ìˆë‹¤ë©´ ì—¬ëŸ¬ ì±„ë„ì— ë†“ê³  íŒ”ê¸° (ì˜¥ì…˜, 11ë²ˆê°€, í‹°ëª¬, ìœ„ë©”í”„ ë“±) ë°˜í’ˆì´ ë“¤ì–´ì˜¨ ìƒí’ˆì€ ë‹¹ê·¼ë§ˆì¼“, ë²ˆê°œì¥í„° ë“±ì—ì„œ ì²˜ë¦¬ ì œì¡°ì‚¬ì™€ ìš°í˜¸ì ì¸ ê´€ê³„ë¥¼ ìœ ì§€ (ì•Œë¦¬ì™•ì™•ë³´ë‹¤ëŠ” ìœ„ì±—ìœ¼ë¡œ ì†Œí†µ, ì‹ ì œí’ˆ ì¶œì‹œì— ëŒ€í•œ í‹°ì € ë°›ê¸°) "},{"id":9,"href":"/blog/2023-02-02/","title":"2023-02-02 Log","section":"Posts","content":"ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì‹œë®¬ë ˆì´ì…˜ # ì£¼ë¬¸ì´ ë“¤ì–´ì˜¨ ê²½ìš° ì·¨ì†Œë˜ê¸° ì „ì— ë°œì£¼ í™•ì¸ì„ ëˆŒëŸ¬ì£¼ê¸° \u0026gt; ê³ ê°ì—ê²Œ ë°˜ì†¡ë°°ì†¡ë¹„ ì²­êµ¬\në‹¨, ì´ë¯¸ ë°œì†¡ì´ ê°„ ê²½ìš° ì·¨ì†Œ ê±°ë¶€ ì¬ê³ ê°€ ì—†ì–´ ë°œì†¡ì´ ëŠ¦ì„ ê²½ìš° ë°œì†¡ì§€ì—° ëˆ„ë¥´ê¸° ìƒë‹´ì€ 1ì°¨ë¡œ í†¡í†¡ ìƒë‹´ (ì£¼ë§ì— ë¶€ì¬ì¤‘ ì„¤ì •, ë¬¸ì œê°€ ìˆìœ¼ë©´ ì „í™”ë¡œ ì²˜ë¦¬) ì¿ íŒ¡ ì‹œë®¬ë ˆì´ì…˜ # ë°˜í’ˆ ë°°ì†¡ë¹„ë¥¼ ë†’ì—¬ì„œ ë°˜í’ˆë¥  ë‚®ì¶”ê¸° ë°œì£¼ì„œ ì—‘ì…€ì— ë°°ëŒ€ì§€ ì£¼ì†Œ ì…ë ¥í•˜ê³  ë°œì£¼ì„œ ì—…ë¡œë“œ ìœ ìë³¸ ì°½ì—… ì‹œ ì¼ë°˜ë°°ì†¡ ë³€ê²½ í›„ ë°°ì†¡ë¹„ ë³€ê²½ ë°°ì†¡ ì§€ì—°ì´ ì—†ê¸° ë•Œë¬¸ì— í’ˆì ˆì„ ê±¸ì§€ ë§ê³  ì¶œê³ ì†Œìš”ê¸°ê°„ì„ ëŠ˜ë¦¬ë©´ì„œ ê³„ì† ì£¼ë¬¸ ë°›ê¸° ìƒí’ˆ ë¬¸ì˜ì—ì„œ ë¬¸ì˜ ë°›ê¸° (ì „í™” í†µí•´ ê³ ê° ë§Œì¡±ë„ ì˜¬ë¦¬ê¸°) ìœ„íƒíŒë§¤ # ì œì¡°ì—…ì²´ë¶€í„° ë„ë§¤ì—…ì²´ ë‹¨ê³„ë¥¼ ê³ ë ¤ (ì¤‘êµ­ ì œì¡°ì—…ì²´ \u0026gt; ì¤‘êµ­ ë„ë§¤ì—…ì²´ \u0026gt; êµ­ë‚´ ë„ë§¤ì—…ì²´ \u0026gt; MD ë“±) ì¤‘ì†Œê¸°ì—…í˜„í™©ì •ë³´ì‹œìŠ¤í…œì—ì„œ ì œì¡°ì—…ì²´ íŒŒì•… ì œì¡°ì—…ì²´ì™€ ê°€ê¹Œì´ ìˆëŠ” ê²ƒì´ ì¤‘ìš” 1688 ì‚¬ìš© ì‹œ ì•Œë¦¬ì™•ì™• í†µí•´ ëŒ€í™” (ì¥ë¯¸ ë“± ì´ëª¨í‹°ì½˜ í†µí•´ ìš°í˜¸ì  ê°ì • í‘œì‹œ) ì•Œë¦¬ì™•ì™•ìœ¼ë¡œ ìƒ˜í”Œ ì£¼ë¬¸, ì¶”ê°€ ë™ì˜ìƒ ìš”êµ¬ ë°°ì†¡ëŒ€í–‰ì§€ # ìƒë‹´ ì²« ê°œì‹œ/ë§ˆê° ì‹œê°„ ì „í™”ë¥¼ ë°›ëŠ”ì§€ í™•ì¸ (ì•„ë‹ˆë©´ ê±°ë¦„, ë³´í†µ 2ê°œì˜ ìƒë‹´ ì‹œê°„ ì¡´ì¬) ë„ì°©í•œ ë‹¹ì¼ì— í•œêµ­ìœ¼ë¡œ ì¶œê³ ê°€ ê°€ëŠ¥í•œì§€ ì—¬ë¶€ ì¤‘êµ­ ì„¼í„°ì— í•œêµ­ì¸ ê´€ë¦¬ìê°€ ìˆëŠ”ì§€ ì—¬ë¶€ (ì§€ì ì´ í•œêµ­ì— ìˆëŠ” ê²½ìš° ê±°ë¦„ = 02/032 ë²ˆí˜¸, ë‚´ìš© ì „ë‹¬ ê³¼ì •ì´ ë§ìŒ) ì„¸ê´€ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œ ëŒ€ì²˜í•˜ê¸°\nCopy text ì„¸ê´€ì—ì„œ ë¬¸ì œ ë°œìƒ ì‹œ, ìœ ë‹ˆíŒ¨ìŠ¤ì—ì„œ ìš´ì†¡ì¥ ë²ˆí˜¸ ì…ë ¥ ì´í›„ ë‚˜ì˜¤ëŠ” ì„¸ê´€ì¥/í¬ì›Œë”©ì—…ì²´ì— ì „í™”í•´ì„œ ë¬¸ì œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œëŠ” ë¨¼ì € ì „í™”ê°€ ì˜µë‹ˆë‹¤. ë³´í†µ ë°°ëŒ€ì§€ì— ë¬¼ì–´ë³´ë©´ ê´€ë ¨ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìœ¼ë‚˜, ì§ì ‘ ë¬¸ì œë¥¼ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ í•´ë‹¹ ë°©ë²•ìœ¼ë¡œ ì§„í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì›ì‚°ì§€í‘œê¸°, ìƒì‚° ì •ë³´ í‘œê¸° ë“± í•„ìˆ˜ë¡œ í‘œê¸°í•´ì•¼ í•˜ëŠ” ì‚¬í•­ì„ ìœ„ë°˜í–ˆë‹¤ë©´ ì„¸ê´€ì— ì œí’ˆì´ ë¬¶ì´ê²Œ ë©ë‹ˆë‹¤. ì´ ë•Œ ë³´ìˆ˜ ì‘ì—… ìš”ì²­ì„ ì§„í–‰í•´ì•¼ í•˜ë©°, ë¹„ìš©ì´ ì†Œëª¨ë˜ë©° ë¹„ìš©ì€ ì‘ì—…ëŸ‰ë§ˆë‹¤ ë‹¤ë¦…ë‹ˆë‹¤. í•´ë‹¹ í‘œì‹œ ê¸°ì¤€ì„ ì—¬ëŸ¬ ë²ˆ ì¤€ìˆ˜í•˜ì§€ ì•Šì•˜ì„ ì‹œ ë²Œê¸ˆì´ ë¶€ê³¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„¤ì´ë²„ ìƒí’ˆ ë“±ë¡ # ë„¤ì´ë²„ëŠ” ìƒí’ˆëª…ì— ì¤‘ë³µë˜ëŠ” ë‹¨ì–´ë¥¼ ìµœëŒ€í•œ ì œê±° (2ë²ˆ ë°˜ë³µê¹Œì§€ í—ˆìš©) ë‹¨ì–´ ì¡°í•©ì„ ê°•ì¡°í•˜ê³  ì‹¶ìœ¼ë©´ ë‹¨ì–´ ê°„ ê±°ë¦¬ë¥¼ ê°€ê¹ê²Œ ì§€ì • í• ì¸ìœ¨ì€ 20-30%ë¡œ ë§ì¶°ì„œ íŒë§¤ê°€ ì¡°ì • ë¶€ê°€ì„¸ëŠ” ê³¼ì„¸ìƒí’ˆ ì¬ê³ ìˆ˜ëŸ‰ì€ ë„‰ë„‰í•˜ê²Œ ë„¤ì´ë²„ ì•Œê³ ë¦¬ì¦˜ì€ ì˜µì…˜ëª…ë„ ì¡ê¸° ë•Œë¬¸ì— ì¶”ê°€ë¡œ ì…ë ¥ 1688ì—ì„œ ì¸ë„¤ì¼ì„ ë°”ë¡œ ê°€ì ¸ì˜¤ê¸° ë³´ë‹¤ ìƒì„¸ í˜ì´ì§€ë¥¼ ìº¡ì³í•´ì„œ ê°€ì ¸ì˜¤ê¸° (ì¤‘êµ­ì–´ê°€ ì—†ëŠ” ì‚¬ì§„ ìš”ì²­ ë˜ëŠ” íƒ€ì˜¤ë°”ì˜¤) ì˜ìƒì„ ë„£ìœ¼ë©´ ë™ì˜ìƒ íƒ€ì´í‹€ ì§€ì • ê°€ëŠ¥ ëª¨ë°”ì¼ í™”ë©´ ê¸°ì¤€ìœ¼ë¡œ ìƒì„¸ í˜ì´ì§€ ì‘ì„± ìƒì„¸ í˜ì´ì§€ ë“±ë¡ ì‹œ ì´ë¦„ë„ ì§€ì • (ë…¸ì¶œ í‚¤ì›Œë“œë¥¼ ë‚´ìš©ì— ìì—°ìŠ¤ëŸ½ê²Œ ë‹´ê¸°) ë¸Œëœë“œ, ì œì¡°ì‚¬ëŠ” ë‹¤ë¥¸ ì—…ì²´ë“¤ì´ ë”°ë¼í•  ìˆ˜ ì—†ëŠ” ê²ƒìœ¼ë¡œ (ë¬¸ì œë  ì‹œ ê³µì¥ ì´ë¦„) êµ­ë‚´ ë°°ì†¡ ì‹œ ì˜¤ëŠ˜ ë°°ì†¡ìœ¼ë¡œ ê²½ìŸë ¥ ë†’ì´ê¸° í•´ì™¸ ë°°ì†¡ ì‹œ ë°˜í’ˆë°°ì†¡ë¹„ ë†’ì´ê¸° í¬ì¸íŠ¸ëŠ” 50ì›ì´ë¼ë„ ì§€ì •í•´ì„œ ë¦¬ë·° ìœ ë„ íƒœê·¸ëŠ” í‚¤ì›Œë“œ ê·¸ëŒ€ë¡œ ì§€ì • Page Titleì€ ìƒí’ˆëª… ê·¸ëŒ€ë¡œ ì§€ì • Meta descriptionì€ 20ìì—ì„œ 50ì ë‚´ì™¸ë¡œ ë…¸ì¶œ í‚¤ì›Œë“œë¥¼ í™œìš©í•´ì„œ ì œí’ˆ ì†Œê°œ ì¿ íŒ¡ ìƒí’ˆ ë“±ë¡ # ë§ˆì§€ë§‰ ì¹´í…Œê³ ë¦¬ê¹Œì§€ ì„¤ì • ë¸Œëœë“œ, ì œì¡°ì‚¬ëŠ” ë„¤ì´ë²„ì™€ ë™ì¼ êµ¬ë§¤ëŒ€í–‰ì˜ ê²½ìš° ì¸ë‹¹ìµœëŒ€êµ¬ë§¤ ìˆ˜ëŸ‰ì„ 0ìœ¼ë¡œ ë§ì¶° ë¬´ì œí•œ êµ¬ë§¤ ê°€ëŠ¥í•˜ê²Œ ì¿ íŒ¡ ì˜µì…˜ë„ ìµœëŒ€í•œ ì •í™•í•˜ê²Œ ë°°ì†¡ë°©ë²•ì— êµ¬ë§¤ëŒ€í–‰ ì„ íƒ ì‹œ ì¸ë³´ì´ìŠ¤ ì˜ìˆ˜ì¦ì— í°ë°°ê²½ ì‚¬ì§„ ì˜¬ë ¤ë„ ê°€ëŠ¥ Copy text ìƒí’ˆ ì—…ë¡œë“œ ì „ì— ìƒìœ„ ë…¸ì¶œëœ ìƒí’ˆêµ°ë“¤ ì‚¬ì´ì—ì„œ í‰ê· ì ìœ¼ë¡œ, ê³µí†µì ìœ¼ë¡œ ì–´ë–¤ ìƒí’ˆ ì†ì„±ì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ ìœ ì‹¬íˆ ë³´ì„¸ìš”. ë‚´ ìƒí’ˆì˜ í’ˆì§ˆ ì§€ìˆ˜ ë†’ì´ëŠ”ë°ì— ë„ì›€ì´ ë©ë‹ˆë‹¤. ë¬´ì¡°ê±´ì ìœ¼ë¡œ ì†ì„±ì„ ë§ì´ ë„£ëŠ”ê²Œ ë„ì›€ì´ ë˜ì§„ ì•ŠìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì–´ëŠ ì •ë„ì˜ ê³µí†µì ì„ ìºì¹˜í•˜ê³ , ì´ê±¸ ë°”íƒ•ìœ¼ë¡œ ì†ì„±ì„ ì¶”ê°€í•˜ë©´ ë…¸ì¶œ ì§€ìˆ˜ë¥¼ ë” ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì—…ë¡œë“œ ê³¼ì •ê³¼ í‚¤ì›Œë“œ ìºì¹˜ ê³¼ì •ì€ ë¶„ëª…íˆ ì˜¤ë˜ ê±¸ë¦¬ì§€ë§Œ, ì´ êµ¬ê°„ì—ì„œ ê³„ì†í•´ì„œ ì‹ ê²½ì¨ì•¼ ìœ ì…ì´ ì¼ì–´ë‚˜ê³ , íŒë§¤ë¡œ ì „í™˜ë©ë‹ˆë‹¤. íŒë§¤ëŸ‰ = ì¢‹ì€ ìƒì„¸í˜ì´ì§€ X ì¢‹ì€ í‚¤ì›Œë“œê°€ ê¸°ë°˜ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ ì—…ë¡œë“œ í•  ë•Œ ì‹ ê²½ì¨ì•¼ í•˜ëŠ” í‚¤ì›Œë“œë¥¼ ëŒ€ì¶© ì‘ì—…í•˜ë©´ ì ˆëŒ€ íŒë§¤ê°€ ì¼ì–´ë‚  ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. "},{"id":10,"href":"/blog/2023-01-29/","title":"2023-01-29 Log","section":"Posts","content":"ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì¥ì /íŠ¹ì§• # ë„¤ì´ë²„ ì‚¬ìš©ìê°€ ì ì¬ê³ ê° íŒë§¤ ìˆ˜ìˆ˜ë£Œê°€ êµ‰ì¥íˆ ë‚®ìœ¼ë©°(ì•½ 4%) ì •ì‚°ì´ ë¹ ë¦„(7ì¼ ì´ë‚´)\n(ì¿ íŒ¡ ì•½ 5-10%, ì´ë² ì´ ì•½ 8-12%) ì•ˆì „ê±°ë˜ ë³´ì¦ ê°ì¢… ë§ˆì¼€íŒ… ë°ì´í„° ì œê³µ (í†µê³„ \u0026gt; ë§ˆì¼€íŒ… ë¶„ì„) íŒë§¤ì ì¡´ì¤‘ (ë‹µë³€ ì§€ì—° ë“± ë°°ë ¤) ê¸°íšì „, ëŸ­í‚¤íˆ¬ë°ì´ ë“±ìœ¼ë¡œ ë…¸ì¶œ ì¦ê°€ í†¡í†¡ìœ¼ë¡œ ê°„í¸í•˜ê²Œ CS ì²˜ë¦¬\n(í†¡í†¡ ë¬¸ì˜ëŠ” ì¦‰ì‹œ ë‹µë³€ì´ ì–´ë ¤ìš¸ ê²½ìš° ì—…ë¬´ ì¤‘ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰ëœë‹¤ê³  ì•Œë¦¼) ë¦¬ë·°ì— ì½”ë©˜íŠ¸ë¥¼ ë‹¬ì•„ì„œ ê°ì‚¬,ë°˜ë°• ë“± ì í•©ë„ ì¤‘ìš” (ë¸Œëœë“œ, ì¹´í…Œê³ ë¦¬, ìƒí’ˆëª…, ì´ë¯¸ì§€ ë“±) ì‰½ê¸° ë•Œë¬¸ì— ê²½ìŸ ê°•ë„ê°€ ë†’ìŒ ì¿ íŒ¡ ì¥ì /íŠ¹ì§• # íŠ¸ë˜í”½ì´ ë§ìŒ (í”Œë«í¼ ì‹ ë¢°ë„ë¡œ ì¸í•´ ë¡œì¼“ë°°ì†¡ ì—†ì´ë„ êµ¬ë§¤ìœ¨ ë†’ìŒ) í‚¤ì›Œë“œ ì…‹íŒ…ì´ ììœ ë¡œì›€ (ì¿ íŒ¡ì€ ê²€ìƒ‰ì–´ë¥¼ ì§ì ‘ ì§€ì •, ë„¤ì´ë²„ëŠ” ìƒí’ˆëª…ê³¼ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜) ìƒí’ˆëª…ì€ ë¸Œëœë“œ, ì œí’ˆëª…, ì œì¡°ì‚¬, ë“±ë¡ìƒí’ˆëª… ìˆœìœ¼ë¡œ ì ìš© (ë„¤ì´ë²„ ìƒí’ˆëª… = ì¿ íŒ¡ ë…¸ì¶œìƒí’ˆëª…) ì¿ íŒ¡ì€ êµ¬ë§¤ì í¸ì•  êµ¬ì¡° êµ¬ë§¤ì ì·¨ì†Œ ì‹œ ë°°ì†¡ë¹„ëŠ” íŒë§¤ìê°€ ë¶€ë‹´ ì£¼ë¬¸ ì¦‰ì‹œ ì—…ì²´ì§ì†¡ìœ¼ë¡œ ì²˜ë¦¬í•´ì„œ ë°°ì†¡ ë“±ë¡ êµ¬ë§¤ì íŒŒì† í›„ ë°˜í’ˆí•´ë„ ì†í•´ë°°ìƒ ë¶ˆê°€, ì§ì ‘ ë¶€ë‹´í•´ì•¼ í•¨\n(ìƒí’ˆ í˜ì´ì§€ì—ì„œ ë°˜í’ˆ ì‹œ ì²­êµ¬ ë¹„ìš©ì„ ê³ ê°ì—ê²Œ ëª…ì‹œ) Copy text 2020.07.07 ìµœê·¼ ì¿ íŒ¡ì—ì„œ \u0026#39;ì—…ì²´ ì§ì†¡\u0026#39;ìœ¼ë¡œ ì¸í•œ ê°•ì œ ë°°ì†¡ ì²˜ë¦¬ë¥¼ ì•…ìš©í•˜ëŠ” íŒë§¤ìê°€ ë§ì•„ì ¸, ì¦ì€ ì‚¬ìš© ì‹œ ì–´ë·°ì§•ìœ¼ë¡œ ë¶„ë¥˜í•´ íŒë§¤ ì§€ìˆ˜ë¥¼ ë–¨ì–´ëœ¨ë¦¬ëŠ” ê²ƒìœ¼ë¡œ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë„¤ì´ë²„ì—ì„œ \u0026#39;ì§ì ‘ ì „ë‹¬\u0026#39; ì²˜ë¦¬í•˜ëŠ” ê±´ ë¬¸ì œê°€ ì—†ìœ¼ë‚˜, ì¿ íŒ¡ì˜ ê²½ìš° \u0026#39;ì—…ì²´ ì§ì†¡\u0026#39;ì„ ì´ìš©í•œ ì£¼ë¬¸ ì·¨ì†Œ ë°©ì–´ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì°¸ê³ í•´ ì£¼ì„¸ìš”. ê·¸ëŸ¬ë‚˜ ì•ìœ¼ë¡œ ì£¼ë¬¸ ì·¨ì†Œì— ëŒ€í•œ ì‘ëŒ€ê°€ ë¶ˆê°€ëŠ¥í•œ ê±´ ì•„ë‹™ë‹ˆë‹¤. ë°©ë²•ì„ ì•Œë ¤ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. (1) ì•„ë¬´ë ‡ê²Œë‚˜ ì†¡ì¥ ë²ˆí˜¸ë¥¼ ë½‘ê³  ë‚˜ì„œ, íƒë°°ëŠ” ë³´ë‚´ì§€ ë§ˆì„¸ìš”. (2) ê·¸ëŸ¬ë©´ ê·¸ ì†¡ì¥ ë²ˆí˜¸ëŠ” ì¡´ì¬í•˜ì§€ë§Œ ë°°ì†¡ì´ ë˜ì§€ ì•ŠëŠ”, \u0026#39;ê°€ì†¡ì¥ë²ˆí˜¸\u0026#39;ê°€ ë©ë‹ˆë‹¤. ì´ ë²ˆí˜¸ë¥¼ ë‹¤ë¥¸ ì£¼ë¬¸ ê±´ì— ì†¡ì¥ë²ˆí˜¸ë¡œ ë“±ë¡ì‹œí‚¤ë©´ \u0026#39;ë°°ì†¡ ì§€ì‹œ\u0026#39;í¸ì— ë¨¸ë¬¼ëŸ¬ ìˆê³  ê·¸ ë•Œ ê³ ê°ì€ ì„ì˜ë¡œ ì£¼ë¬¸ ì·¨ì†Œë¥¼ í•  ìˆ˜ ì—†ê²Œ ë©ë‹ˆë‹¤. (3) ì´í›„ì— ì‹¤ì œ ê·¸ ê³ ê°ì— ëŒ€í•œ ì†¡ì¥ ë²ˆí˜¸ë¥¼ ë°œê¸‰ë°›ê²Œ ë˜ë©´ \u0026#39;ë°°ì†¡ ì§€ì‹œ\u0026#39;í¸ì— ë“¤ì–´ê°€ ë‹¤ì‹œ ì†¡ì¥ë²ˆí˜¸ë¥¼ ë“±ë¡ì‹œì¼œ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤. (4) ê·¸ëŸ¬ë©´ í’ˆì§ˆ ì €í•˜/ì–´ë·°ì§• ì—†ì´ ì •ìƒì ìœ¼ë¡œ ì†¡ì¥ë²ˆí˜¸ ë“±ë¡/ì§‘í•˜ ë° ë°°ì†¡ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì •ì‚° ì£¼ê¸°ê°€ ëŠë¦¼ (30ì¼-45ì¼, ì„ ì •ì‚° ì„œë¹„ìŠ¤ ë“± ê¸ˆìœµ ìƒí’ˆ ìˆìŒ) ê²½ìŸì„ ë¶€ì¶”ê¸°ëŠ” í”Œë«í¼ (ì•„ì´í…œ ìœ„ë„ˆ ì‹œìŠ¤í…œ: ë˜‘ê°™ì€ ì œí’ˆì— ê°€ê²©ì´ ì €ë ´í•˜ë©´ 1ìœ„ë¥¼ ëºê¹€) íŠ¸ë˜í”½ ì™¸ì—ëŠ” ëª¨ë“  ê²ƒì´ ë‹¨ì  ìƒì„¸í˜ì´ì§€ ìˆ˜ì • # í•µì‹¬ìš”ì•½ # í¬í† ìƒµ, remove.bg: ëˆ„ë¼ë”°ê¸° ë¼ì´íŠ¸ë£¸: ì‚¬ì§„ ë³´ì • ë§ê³ ë³´ë“œ: ìƒì„¸í˜ì´ì§€ ë§ˆë¬´ë¦¬ ì‘ì—… êµ¬ê¸€ í¬ë¡¬: ì´ë¯¸ì§€ì™€ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì•Œíˆ´ë°”: ì´ë¯¸ì§€ ëŒ€ëŸ‰ ë‹¤ìš´ë¡œë“œ fanyi.baidu.com: ì¤‘êµ­ì–´ ì´ë¯¸ì§€ ë²ˆì—­ ëˆ„ë¼ë”°ê¸° ê´€ë ¨ ê°•ì¢Œ # ğŸ”— [ì´ˆê¸‰] í¬í† ìƒµìœ¼ë¡œ ëˆ„ë¼ë”°ê¸°! - í”„ë””ë©Freelancer Designer LAB\nhttps://www.youtube.com/watch?v=TnLe2TEgGqw ğŸ”— [â˜…10ë¶„íŒâ˜…]í¬í† ìƒµ ì´ë¯¸ì§€ë”°ê¸° 100%ì™„ë²½í•˜ê¸° ë”°ê¸° ê°•ì¢Œ[MaDia] - Madia Designer\nhttps://www.youtube.com/watch?v=j-nL0fPAaME\u0026t=4s ğŸ”— ë„ˆë¬´ ì‰¬-ì›€, í¬í† ìƒµì—ì„œ \u0026lsquo;ë‚˜ë¬´ ëˆ„ë¼ë”°ê¸°\u0026rsquo; - ì»¨íŠ¸ë¡¤ì—ì“°\nhttps://www.youtube.com/watch?v=2L6568VzzR4 ğŸ”— í¬í† ìƒµ ê°•ì¢Œ #46 - íœíˆ´ë¡œ ì‚¬ì§„ ëˆ„ë¼ ì‰½ê²Œ ë”°ê¸° - ë¡¤ìŠ¤í† ë¦¬ë””ìì¸ì—°êµ¬ì†Œ\nhttps://www.youtube.com/watch?v=cpGMMXPiH6M\u0026t=56s ìƒí’ˆ ì†Œì‹± # ì„ ë°œ ì£¼ì: êµ­ë‚´ì— ì—†ëŠ” ìƒí’ˆì„ ë¯¸ë¦¬ ì˜¬ë¦¬ê³  ëŒ€ê¸°, ë˜ëŠ” ë¸”ë¡œê±° ìœ íŠœë²„ë¥¼ í†µí•´ ìƒí’ˆì„ ì•Œë¦¼ í›„ë°œ ì£¼ì: ì„ ë°œ ì£¼ìë¥¼ ë”°ë¼ ìƒí’ˆì„ ì˜¬ë¦¬ê¸° ë•Œë¬¸ì— ì•ˆì •ê° ìˆì§€ë§Œ, ë¨¹ì„ ìˆ˜ ìˆëŠ” íŒŒì´ê°€ ì ìŒ íŒ”ë¦¬ëŠ” ìƒí’ˆì„ ì°¾ê¸° ìœ„í•´ì„œëŠ” ì´í•´í•˜ê³  ê³µê°í•  ìˆ˜ ìˆëŠ” ìƒí’ˆì„ ì„ ì • (ex. ì½”ë¡œë‚˜ ì›¹ìº  ë“±) ë¶ˆí¸í•¨ì„ í•´ê²°í•  ìˆ˜ ìˆëŠ” ìƒí’ˆì„ í‚¤ì›Œë“œí™”í•´ì„œ ìƒí’ˆì„ ì†Œì‹± (ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œ) í•´ì™¸ì§êµ¬ í›„ê¸°, ì•Œë¦¬ìµìŠ¤í”„ë ˆìŠ¤ í›„ê¸°, ì•Œë¦¬ ë‚´ëˆë‚´ì‚°, í•´ì™¸ì§êµ¬ ë‚´ëˆë‚´ì‚°, í•´ì™¸ì§êµ¬ ì§ì ‘ ë“± ìœ„íƒ íŒë§¤ (êµ­ë‚´) # ë‹¤ìŒ, ë°´ë“œì— ë„ë§¤ì—…ì ì°¾ê¸° (ìœ„íƒ ìœ í†µ) ìƒˆìš°ì “ ì˜ˆì‹œ \u0026gt; ê°œì¸ìš© ìš©ëŸ‰ ëŒ€ì‹  ëŒ€ìš©ëŸ‰ ë„ë§¤ìš©, ì—…ì†Œìš© ì œí’ˆ ê²€ìƒ‰ ì‹œ êµ­ë‚´ì‚°ì´ ì—†ëŠ” ê²½ìš° ì´ë¯¸ ì˜¨ë¼ì¸ ì»¤ë¨¸ìŠ¤ì— ì§„ì¶œí•œ ëŒ€ìƒì˜ ê²½ìš° ìš´ì˜ì´ ì˜ ì•ˆë˜ëŠ” ì—…ì²´ë¥¼ ì°¾ì•„ì„œ ë‹¤ë¥¸ ì±„ë„ì„ ê°œí†µ\në°©ë²•ë¡ ì„ ë¬¼ì–´ë³¼ ê²½ìš° ì •ë³´ë¥¼ ê°ì¶°ì„œ ì§€ì†ì ìœ¼ë¡œ í˜‘ë ¥í•  ìˆ˜ ìˆë„ë¡ ì œí’ˆ ë’·ë©´ì˜ ì œì¡°ì‚¬ì— ì§ì ‘ ì—°ë½í•´ ìœ„íƒ ìš”ì²­ ì…€ëŸ¬ ì˜¤ì…˜ í”Œë«í¼ ìœ„íƒ ì œì•ˆì„œ (ê²½ìŸ ì œí•œ ì—…ì²´) Copy text í•œí‰ìƒ ìœ íŠœë¸Œì™€ ì¸í„°ë„·ì— ê´€ì‹¬ë„ ì—†ëŠ” ì‚¬ì¥ë‹˜ì´ ì§‘ ì£¼ë³€ì— ìˆë‹¤ë©´ ë¨¼ì € ì œì•ˆí•´ë³´ì„¸ìš”. ê°–ê³  ìˆëŠ” ì œí’ˆì˜ ë’·ë©´ ë¼ë²¨ì— ì œì¡°ì‚¬ë‚˜ ë„ë§¤ì²˜ì˜ ì •ë³´ê°€ ì í˜€ ìˆìŠµë‹ˆë‹¤. ì „í™”í•´ì„œ ìœ„íƒ ì œì•ˆì„ í•´ë³´ì„¸ìš”. ìœ„íƒ íŒë§¤ (í•´ì™¸) # alibaba, taobao, tmall, 1688 êµ¬ê¸€ í¬ë¡¬, ì•Œë¦¬ì™•ì™•(í†¡í†¡ìƒë‹´), ìœ„ì±—, íŒŒíŒŒê³  ì•Œë¦¬ë°”ë°”: í”„ë¦¬ë¯¸ì—„ì´ ë¶™ê¸° ë•Œë¬¸ì— 1688ì— ì´ë¯¸ì§€ ê²€ìƒ‰ í›„ ê°€ê²© í™•ì¸ íƒ€ì˜¤ë°”ì˜¤: ë‚±ê°œ êµ¬ë§¤ ê°€ëŠ¥, ë„ë§¤ ëŒ€ë¹„ ê°€ê²©ì€ ë†’ì€í¸ 1688: Originìœ¼ë¡œ ë°œì†¡ì§€ í™•ì¸, ìµœì†Œì£¼ë¬¸ëŸ‰(MOQ)ê°€ ì¡´ì¬ 1688ì€ ê²°ì œëŒ€í–‰ ì—…ì²´ í•„ìš” (ë˜ëŠ” íŒë§¤ì í†µí•´ ë§ˆìŠ¤í„° ì¹´ë“œ ê°€ëŠ¥í•œ íƒ€ì˜¤ë°”ì˜¤ ìŠ¤í† ì–´ ê²°ì œë¥¼ ìš”ì²­) íŒë§¤ìì˜ ì‹ ìƒí’ˆì„ íƒìƒ‰ "},{"id":11,"href":"/blog/rich-dad/","title":"ë¶€ì ì•„ë¹  ê°€ë‚œí•œ ì•„ë¹ ","section":"Posts","content":" ìƒˆí•´ì˜ ëª©í‘œë¡œ ë…ì„œë¥¼ ì‚¼ìœ¼ë©´ì„œ ê·¸ë™ì•ˆ ê²½ì œ ì „ë¬¸ê°€ë¡œë¶€í„° ë§ì´ ë“¤ì—ˆë˜ ì´ ì±…ì„ ì½ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nStudy Session 1 # ë¶€ìë“¤ì€ ëˆì„ ìœ„í•´ ì¼í•˜ì§€ ì•ŠëŠ”ë‹¤.\nì±…ì˜ ì´ˆì…ì—ì„œëŠ” ì €ìì˜ ì–´ë¦° ì‹œì ˆ ë‘ ëª…ì˜ ì•„ë²„ì§€ë¡œë¶€í„° ë³´ê³  ë°°ìš´ ê²ƒì„ ì „ë‹¬í•˜ë©´ì„œ\në¶€ìì¸ ì•„ë²„ì§€ë¡œë¶€í„° ëˆì˜ ì‘ìš© ë°©ì‹ì„, ê°€ë‚œí•œ ì•„ë²„ì§€ë¡œë¶€í„° ë°˜ë©´êµì‚¬ë¡œ ì‚¼ì•„ì•¼í•  ë§ˆìŒê°€ì§ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\nì €ìì™€ ê·¸ì˜ ì¹œêµ¬ëŠ” ë¶€ì ì•„ë²„ì§€ë¡œë¶€í„° ê°€ë¥´ì¹¨ì„ ë°›ê¸° ìœ„í•´\n3ì£¼ ë™ì•ˆ ë¬´ê¸‰ìœ¼ë¡œ ì¼í•˜ëŠ” ê²½í—˜ì„ í–ˆëŠ”ë° ì´ë¥¼ í†µí•´ ì„ê¸ˆ ì œì•ˆì˜ ìš•ì‹¬ì— í”ë“¤ë¦¬ì§€ ì•Šê³ \nìì‹ ë§Œì˜ ì‚¬ì—…ì„ ì—´ì–´ ì ì§€ ì•Šì€ ìˆ˜ì…ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nì €ë„ ì‚¬íšŒì´ˆë…„ìƒìœ¼ë¡œì„œ ë‹¤ì†Œ ì ì€ ê¸ˆì•¡ì˜ ì—°ë´‰ìœ¼ë¡œ ì—…ë¬´ì— ì„í•˜ë©´ì„œ ì—°ë´‰ ì¸ìƒì„ ê¾€í•˜ê³  ìˆì—ˆì§€ë§Œ,\nì €ìì˜ ì‚¬ë¡€ë¥¼ ë³´ë©´ì„œ ì‚¬ì†Œí•œ ì„ê¸ˆì˜ ì¦ê°€ë¥¼ ëª©ì ìœ¼ë¡œ ë‚¨ì„ ìœ„í•´ ë”ìš± ì—´ì‹¬íˆ ì¼í•˜ê¸° ë³´ë‹¤ëŠ”\nìì‹ ì´ í–¥í›„ ì‚¬ì—…ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì§€ì‹ì„ ì—…ë¬´ë¡œë¶€í„° ë°°ìš°ëŠ” ê²ƒì´ íš¨ê³¼ì ì„ì´ë¼ ìƒê°í–ˆìŠµë‹ˆë‹¤.\n\u0026ldquo;ëˆì´ ìì‹ ì„ ìœ„í•´ ì¼í•˜ê²Œ í•˜ë¼\u0026rdquo;\në¯¸ë””ì–´ì˜ ë¶€ìë“¤ë¡œë¶€í„° ì–¸ì œë‚˜ ë“¤ì–´ì™”ë˜ ë§ì´ì—ˆì§€ë§Œ,\nì´ë¥¼ ì§ì ‘ ì‹¤ì²œí•œ ì €ìë¥¼ ë³´ë©´ì„œ ì£¼ë³€ì— ëŒ€í•œ ê´€ì‹¬ì„ ê°€ì§ˆ í•„ìš”ì„±ì— ëŒ€í•´ ëŠê¼ˆìŠµë‹ˆë‹¤.\nStudy Session 2 # ì™œ ê¸ˆìœµ ì§€ì‹ì„ ë°°ì›Œì•¼ í•˜ëŠ”ê°€\nì±…ì—ì„œ ì œì‹œëœ ìì‚°ì˜ í˜„ê¸ˆíë¦„ íŒ¨í„´ì— ëŒ€í•œ ê·¸ë¦¼ì€ ë‹¨ìˆœëª…ë£Œí•˜ë©´ì„œë„\nìì‚°ê³¼ ë¶€ì±„ì— ëŒ€í•œ ì´í•´ë¥¼ í™•ì‹¤í•˜ê²Œ ì™€ë‹¿ê²Œ í–ˆìŠµë‹ˆë‹¤.\níŠ¹íˆë‚˜ ì¸ìƒê¹Šì—ˆë˜ ê²ƒì€ ìì‚°ì€ ë¶€ë¥¼ ë§Œë“¤ì–´ë‚´ê³ , ë¶€ì±„ëŠ” ëˆì„ ë¹¼ê°€ëŠ” ê²ƒì´ë¼ëŠ” ì •ì˜ì…ë‹ˆë‹¤.\nê·¸ ì¤‘ì—ì„œë„ ì£¼íƒì— ëŒ€í•œ ì €ìì˜ ì‹œì„ ì€ ë‹¤ì†Œ ì‹ ì„ í–ˆìŠµë‹ˆë‹¤.\nì§€ê¸ˆê¹Œì§€ ì£¼íƒ ê·¸ ìì²´ëŠ” ë¬¼ê°€ ìƒìŠ¹ì— ë”°ë¼ ì¦ê°€í•˜ëŠ” ìì‚°ì´ë¼ê³  ìƒê°í–ˆì§€ë§Œ,\nì„¸ê¸ˆê³¼ ëŒ€ì¶œ ì´ìë¡œë¶€í„° ë°œìƒí•˜ëŠ” ì§€ì¶œê³¼ ëª©ëˆì„ ë¬¶ì´ë©´ì„œ ë‹¤ì–‘í•œ ê¸°íšŒë¥¼ ë†“ì¹˜ê²Œë˜ëŠ” ë¬¸ì œë¥¼ ì§€ì í•˜ë©´ì„œ\níˆ¬ìì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì¼ê¹¨ì›Œì£¼ì—ˆìŠµë‹ˆë‹¤.\në”ìš±ì´ 2023ë…„, ì§‘ê°’ í•˜ë½ê³¼ ê¸ˆë¦¬ ìƒìŠ¹ìœ¼ë¡œ ê³ í†µë°›ëŠ” ì˜ëŒì¡±ë“¤ì˜ ì‚¬ë¡€ë¥¼ ë³´ë©´ì„œ\nì „ì¬ì‚°ê³¼ ë¶€ì±„ë¥¼ ë™ì›í•´ ì˜ëª»ëœ íƒ€ì´ë°ì— íˆ¬ìí•˜ëŠ” ê²ƒì˜ ë¬¸ì œì ì„ ì¸ì‹í–ˆìŠµë‹ˆë‹¤.\në³¸ë¬¸ì—ì„œ ì— íŒŒì´ì–´ìŠ¤í…Œì´íŠ¸ ë¹Œë”©ì„ ê±´ì¶•í•  ë•Œ ê°€ì¥ ë¨¼ì € ê¹Šì€ êµ¬ë©ì´ë¥¼ íŒŒê³  íŠ¼íŠ¼í•œ í† ëŒ€ë¥¼ ìŒ“ì•„ì•¼ í•œë‹¤ê³  ì „í–ˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ, ë§ì€ ì‚¬ëŒë“¤ì€ ë¹¨ë¦¬ ë¶€ìê°€ ë˜ê³  ì‹¶ì€ ë§ˆìŒì— ì–‰ì€ ì½˜í¬ë¦¬íŠ¸ ê¸°ë°˜ ìœ„ì— ì— íŒŒì´ì–´ìŠ¤í…Œì´íŠ¸ ë¹Œë”©ì„ ì§€ìœ¼ë ¤ê³  í•©ë‹ˆë‹¤.\nì €ì—­ì‹œ 1ë…„ì „ ì•„ë¬´ëŸ° íˆ¬ì ì§€ì‹ë„ ì—†ì´ ì£¼ì‹ í•˜ë½ì¥ì— ë›°ì–´ë“¤ì–´ ì ì§€ ì•Šì€ ë§ˆì´ë„ˆìŠ¤ ìˆ˜ìµë¥ ì„ ê¸°ë¡í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ëˆì— ëŒ€í•´ ì œëŒ€ë¡œ ì´í•´í•˜ëŠ” ê²ƒë§Œí¼ ë¦¬ìŠ¤í¬ë¥¼ íšŒí”¼í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ ìˆ˜ë‹¨ì€ ì—†ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\nStudy Session 3 # ë¶€ìë“¤ì€ ìì‹ ì„ ìœ„í•´ ì‚¬ì—…ì„ í•œë‹¤\në§¥ë„ë‚ ë“œ ì°½ì—…ì ë ˆì´ í¬ë¡ì€ ìì‹ ì´ í–„ë²„ê±° ì‚¬ì—…ì´ ì•„ë‹Œ ë¶€ë™ì‚° ì‚¬ì—…ì— ì¢…ì‚¬í•œë‹¤ê³  ë§í–ˆìŠµë‹ˆë‹¤.\nìƒê°í•´ë³´ë©´ ë§¥ë„ë‚ ë“œëŠ” ì „ ì„¸ê³„ì—ì„œ ì²´ì¸ì ì„ ìš´ì˜í•˜ë©´ì„œ ì¢‹ì€ ì…ì§€ì˜ ê±´ë¬¼ì„ ì°¨ì§€í•˜ê³  ìˆì—ˆìŠµë‹ˆë‹¤.\nì§€ê¸ˆê¹Œì§€ ì‚¬ì—…ì´ë€ ëŒ€ë‹¨í•œ ê²ƒì´ë¼ê³  ì—¬ê²¼ê³ , ì§ì¥ì„ ë‹¤ë‹ˆë©´ì„œ ì‚¬ì—…ì„ í•˜ëŠ” ê²ƒì¸ ë§ì´ ì•ˆëœë‹¤ê³  ìƒê°í–ˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ, êµ³ì´ ì°½ì—…ì´ ì•„ë‹ˆë”ë¼ë„ ìì‚°ì„ ë§¤ì…í•˜ê³  ê´€ë¦¬í•˜ëŠ” ê²ƒ ìì²´ê°€ ì‚¬ì—…ì´ë¼ëŠ” ê²ƒì„ ì¸ì‹í–ˆìŠµë‹ˆë‹¤.\nì €ìëŠ” ìì‹ ì´ ì¢‹ì•„í•˜ëŠ” ìì‚°ì„ íšë“í•˜ë¼ê³  ê°•ì¡°í•©ë‹ˆë‹¤.\nì € ì—­ì‹œ ê³¼ê±° í° ì†ì‹¤ì„ ì…ì—ˆì§€ë§Œ ì—¬ì „íˆ ì£¼ì‹ì´ ì¢‹ì•„ ìˆ˜ìµì„ ë‚¼ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ íƒìƒ‰í–ˆê³ ,\nì¥ê¸° íˆ¬ì ëŒ€ì‹  ë‹¨ê¸° ë§¤ë§¤ë¡œ ë°©í–¥ì„ ëŒë¦¬ë©´ì„œ ì†Œì†Œí•˜ê²Œ ìˆ˜ìµì„ ë‚´ê³  ìˆìŠµë‹ˆë‹¤.\nì—…ë¬´ ìƒìœ¼ë¡œë„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì˜ ë§ì€ ë¶€ë¶„ì„ íƒìƒ‰í•˜ë©´ì„œ ìµíˆê³  ìˆëŠ”ë°,\nì´ê²ƒì´ í–¥í›„ ë‚´ê°€ ì—†ì–´ë„ ë˜ëŠ” ì‚¬ì—…ìœ¼ë¡œ ë°œì „í•  ìˆ˜ ìˆì„ì§€ ê¸°ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\nStudy Session 4 # ë¶€ìë“¤ì˜ ê°€ì¥ í° ë¹„ë°€, ì„¸ê¸ˆê³¼ ê¸°ì—…\nê³¼ê±° ë¶€ìë“¤ì€ ìš•ì‹¬ì´ ë§ê³  êµ­ê°€ëŠ” ì´ë“¤ë¡œë¶€í„° ì„¸ê¸ˆì„ ì°©ì·¨í•´ ê°€ë‚œí•œ ì´ë“¤ì—ê²Œ ë‚˜ëˆ ì¤˜ì•¼ í•œë‹¤ê³  ìƒê°í–ˆìŠµë‹ˆë‹¤.\nì´ê²ƒì€ ì „í†µì ì¸ êµìœ¡ê³¼ì •ê³¼ ë¶€ëª¨ë‹˜ìœ¼ë¡œë¶€í„° ë“¤ì–´ì™”ë˜ ê²ƒì¸ë°\nëˆì— ëŒ€í•œ ê³µë¶€ë¥¼ í•˜ê²Œ ë˜ë©´ì„œ ë‹¨ì§€ ëˆ„êµ°ê°€ë¡œë¶€í„° ì„¸ê¸ˆì„ ê±·ì–´ë“¤ì´ê¸¸ ê¸°ë‹¤ë¦¬ëŠ” ê²ƒì´ ì–¼ë§ˆë‚˜ ì–´ë¦¬ì„ì€ì§€ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤.\nì €ìëŠ” ì •ë¶€ê°€ ì„¸ê¸ˆì„ ê±·ì–´ë“¤ì¼ ë•Œ ì‹¤ì§ˆì ìœ¼ë¡œ ì§•ìˆ˜ë‹¹í•˜ëŠ” ëŒ€ìƒì„ ê³ ì†Œë“ ì¤‘ì‚°ì¸µì´ê³ \ní•©ë²•ì ì¸ ê¸°ì—… êµ¬ì¡°ë¥¼ ì´í•´í•˜ëŠ” ë¶€ìë“¤ì€ ë¦¬ìŠ¤í¬ ìƒì‡„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ ì„¸ê¸ˆ íšŒí”¼ë¥¼ ì´ìš©í•˜ê³  ìˆë‹¤ê³  ì „í–ˆìŠµë‹ˆë‹¤.\ní•œêµ­ì˜ ìƒí™©ê³¼ëŠ” ë§ì§€ ì•Šì„ ìˆ˜ ìˆì§€ë§Œ, ë¯¸êµ­ ì„¸ë²• 1031ì¡°í•­ì„ í†µí•´\në¶€ë™ì‚° ê±°ë˜ì— ëŒ€í•œ ì„¸ê¸ˆì„ ìœ ì˜ˆí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ì„¸ê¸ˆì„ ì•Œì•„ì•¼í•  í•„ìš”ì„±ì„ ì¼ê¹¨ì› ìŠµë‹ˆë‹¤.\nëˆì„ ì›€ì§ì´ëŠ”ë° ìˆì–´ì„œ \u0026ldquo;ì•„ëŠ” ê²ƒì´ í˜\u0026quot;ì´ë¼ëŠ” ì‚¬ì‹¤ì€ ë¶€ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\në§ˆì¹˜ë©° # ì´í›„ì˜ ë‚´ìš©ë„ ì™„ë…í•˜ë©´ì„œ ëˆì„ ë§Œë“œëŠ” ìì‚°ì„ ìŒ“ëŠ” ê²ƒì˜ ì¤‘ìš”ì„±ì— ëŒ€í•´ ëŠê¼ˆìŠµë‹ˆë‹¤.\në¹„ë¡ ë¯¸êµ­ì˜ ì‚¬ë¡€ì´ê³  ê°œì¸ì ìœ¼ë¡œëŠ” ìƒì†Œí•œ ë¶€ë™ì‚° íˆ¬ìì— ì§‘ì¤‘í•˜ê¸° ë•Œë¬¸ì—\nëª¨ë“  ì‚¬ë¡€ê°€ ê³µê°ë˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ,\në¦¬ìŠ¤í¬ íšŒí”¼ë¥¼ ìœ„í•´ ë„ˆë¬´ ë§ì€ ë°”êµ¬ë‹ˆì— ë§¤ë¬¼ì„ ë‹´ê¸° ë³´ë‹¤ëŠ” íŠ¹ì • ëª‡ê°œì— ì§‘ì¤‘í•  í•„ìš”ê°€ ìˆë‹¤ëŠ”\nì €ìì˜ ì£¼ì¥ì€ ê·¸ë™ì•ˆ ì „ë¬¸ê°€ë“¤ë¡œë¶€í„° ë“¤ì–´ì˜¨ ë¶„ì‚°íˆ¬ìì˜ ê°œë…ê³¼ ìƒë°˜ë˜ì–´ ìƒˆë¡œì› ìŠµë‹ˆë‹¤.\ní–¥í›„ì—ëŠ” ì£¼ì‹ íˆ¬ìë¥¼ ì§€ì†í•˜ë©´ì„œ ì„¸ë²•ì— ëŒ€í•´ ê³µë¶€í•˜ê³  ë¶€ë™ì‚° íˆ¬ìì—ë„ ê´€ì‹¬ì„ ê°€ì ¸ë³¼ ìƒê°ì…ë‹ˆë‹¤.\nìì‚°ê³¼ ë¶€ì±„ì˜ ì°¨ì´ë¥¼ ì¸ì‹í•˜ê²Œ ëœë°ì„œ ì´ ì±…ì„ ì½ê²Œëœ ê°€ì¹˜ê°€ ìˆì—ˆë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤.\n"},{"id":12,"href":"/blog/2023-01-23/","title":"2022ë…„ 01ì›” 23ì¼ íšŒê³ ","section":"Posts","content":"ì§€ê¸ˆìœ¼ë¡œë¶€í„° ì•½ í•œ ë‹¬ ê°„ ìë™í™” í”„ë¡œê·¸ë¨ ì•ˆì •í™” ì‘ì—…ìœ¼ë¡œ ë‹¤ì†Œ ë°”ìœ ì¼ì •ì„ ë³´ëƒˆì§€ë§Œ,\në‹¤í–‰íˆ í•´ë‹¹ ì‘ì—…ì´ ë§ˆë¬´ë¦¬ë˜ì–´ ì´ë ‡ê²Œ ê¸€ë¡œ ì •ë¦¬í•´ë³¼ ì—¬ìœ ê°€ ìƒê²¼ìŠµë‹ˆë‹¤.\nêµ¬ê¸€ ë¹…ì¿¼ë¦¬ # ì´ì „ íšŒê³ ì—ì„œ ì‚¬ë‚´ ë¹…ì¿¼ë¦¬ ë„ì…ì„ ê³ ë ¤í•˜ê³  ìˆë‹¤ê³  ë‚¨ê¸´ ë°” ìˆì—ˆëŠ”ë°,\nì´ì œëŠ” ë¹…ì¿¼ë¦¬ì— ìµìˆ™í•´ì§€ë©° SQLë„ ì–´ëŠì •ë„ ì›í•˜ëŠ”ëŒ€ë¡œ ë‹¤ë£° ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì— ì´ë¥´ë €ìŠµë‹ˆë‹¤.\nì›ë˜ëŠ” êµ¬ê¸€ ì‹œíŠ¸ APIë¥¼ í†µí•œ ë°ì´í„° ì ì¬ ìë™í™”ì— ìµìˆ™í•´ì§„ í›„ ë¹…ì¿¼ë¦¬ë¡œ ì°¨ì°¨ ë„˜ì–´ê°ˆ ì˜ˆì •ì´ì—ˆì§€ë§Œ,\nìƒê°ë³´ë‹¤ êµ¬ê¸€ APIì˜ ì‚¬ìš©ë²•ì´ ê°„ë‹¨í•˜ì—¬ ì–¼ë§ˆì•ˆê°€ ë¹…ì¿¼ë¦¬ ì‚¬ìš©ì„ ì‹œë„í•´ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nMySQL ê°™ì´ ì˜ ì•Œë ¤ì§„ DB ì¡°ì°¨ ì§ì ‘ ë‹¤ë¤„ë³¸ ê²½í—˜ì´ ì—†ì—ˆê¸°ì—\nìŠ¤í‚¤ë§ˆ êµ¬ì„± ë“±ì˜ í–‰ìœ„ê°€ ë‚¯ì„¤ì—ˆê³ , ëª‡ ë²ˆì´ë‚˜ í…Œì´ë¸”ì˜ êµ¬ì¡°ë¥¼ ê°ˆì•„ ì—ì—ˆìŠµë‹ˆë‹¤.\në¹…ì¿¼ë¦¬ëŠ” ì ì€ ë¹„ìš© ëŒ€ë¹„ ê´€ë¦¬ê°€ í¸í•˜ë‹¤ëŠ” ì¥ì ë„ ìˆì§€ë§Œ,\nì´ˆê¸‰ ê°œë°œì ì…ì¥ì—ì„œ ë¬´ì—‡ë³´ë‹¤ ì¢‹ì•˜ë˜ ê²ƒì€ ì¿¼ë¦¬ ì‹œ ì˜ˆìƒë˜ëŠ” ë¹„ìš©ì„ ì‚°ì •í•´ì£¼ì–´\në”ìš± íš¨ìœ¨ì ì¸ ì¿¼ë¦¬ë¬¸ì„ ì‘ì„±í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤€ë‹¤ëŠ” ì ì…ë‹ˆë‹¤.\nì´ì— ëŒ€í•œ ê²ƒì„ ëª°ëì„ ë„ì…ê¸° ë•ŒëŠ” ì–´ë– í•œ ì¿¼ë¦¬ ìµœì í™” ê¸°ë²•ë„ ì ìš©í•˜ì§€ ì•Šì•„\në‹¹ì‹œ 90MBì˜ í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ë§¤ ì‹œê°„ë§ˆë‹¤ ëŒ€ì‹œë³´ë“œì—ì„œ í˜¸ì¶œí•˜ê²Œ í–ˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ í…Œì´ë¸”ì€ ë§¤ ì‹œê°„ë§ˆë‹¤ ë°ì´í„°ê°€ ìŒ“ì´ëŠ” êµ¬ì¡°ì˜€ê¸° ë•Œë¬¸ì— ìš©ëŸ‰ì˜ ì¦ê°€ê°€ ì ì§€ ì•Šì•˜ëŠ”ë°,\nì¥ê¸°ì ìœ¼ë¡œ ë¹…ì¿¼ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” ì›” 1TBì˜ ë¬´ë£Œ ìš©ëŸ‰ì„ ì´ˆê³¼í•  ìˆ˜ë„ ìˆê² ë‹¤ëŠ” ê±±ì •ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\nì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ DB ìµœì í™”ì— ëŒ€í•´ ê³ ë ¤í•˜ê²Œ ë˜ì—ˆê³ ,\níŒŒí‹°ì…”ë‹ê³¼ ì •ê·œí™” ê¸°ë²•ì„ ì ìš©í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\níŒŒí‹°ì…”ë‹ # ë¹…ì¿¼ë¦¬ëŠ” í…Œì´ë¸” ìƒì„± ì‹œ í•˜ë‚˜ì˜ ìˆ˜ì¹˜í˜• ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ íŒŒí‹°ì…˜ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì €ëŠ” ë³´í†µ ë°ì´í„° ìˆ˜ì§‘ì¼ì‹œì— í•´ë‹¹í•˜ëŠ” ë‚ ì§œ ì—´ì„ íŒŒí‹°ì…˜ì˜ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ëŠ”ë°,\níŒŒí‹°ì…”ë‹ ì‹œì˜ ì¥ì ì€ WHERE ë¬¸ìœ¼ë¡œ íŒŒí‹°ì…˜ì„ íŠ¹ì •í•  ê²½ìš° í•´ë‹¹ íŒŒí‹°ì…˜ì˜ ë°ì´í„°ë§Œì„ í˜¸ì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\nì´ ë•ë¶„ì— ë‹¹ì¼ì˜ ë°ì´í„°ë§Œì´ í•„ìš”í•œ ëŒ€ì‹œë³´ë“œì—ì„œ ë¹…ì¿¼ë¦¬ë¡œ ë°ì´í„°ë¥¼ ìš”ì²­í•  ê²½ìš°\nê¸°ì¡´ì˜ 90MBì—ì„œ 1MB ë¯¸ë§Œìœ¼ë¡œ ì¿¼ë¦¬ ë¹„ìš©ì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nì§€ê¸ˆì€ ì¼ìë³„ë¡œ ë°ì´í„°ê°€ ëˆ„ì ë˜ëŠ” ëª¨ë“  í…Œì´ë¸”ì— íŒŒí‹°ì…”ë‹ì„ ì ìš©í•´\në°ì´í„°ê°€ ì¶•ì ë˜ë©´ì„œ ì¦ê°€í•  ìˆ˜ ìˆì—ˆë˜ ì¿¼ë¦¬ ë¹„ìš©ì— ëŒ€í•œ ê±±ì •ì„ ëœê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nDB ì •ê·œí™” # ë°ì´í„°ê°€ ëˆ„ì ë˜ë©´ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¹„ìš©ì€ ì¿¼ë¦¬ì—ì„œë¿ ì•„ë‹ˆë¼ ë°ì´í„° ìì²´ì˜ ì €ì¥ ë¹„ìš©ì—ì„œë„ ë°œìƒí•©ë‹ˆë‹¤.\nì œê°€ ì—…ë¬´ì—ì„œ í™œìš©í•˜ëŠ” ìƒí’ˆ ìˆœìœ„ ë°ì´í„°ë¥¼ ìŒ“ê¸° ì‹œì‘í•  ë‹¹ì‹œì—ëŠ”\nìƒí’ˆì½”ë“œì™€ ìˆœìœ„ ë¿ ì•„ë‹ˆë¼ í•´ë‹¹ ìƒí’ˆì˜ ìƒí’ˆëª…, íŒë§¤ì²˜ëª… ë“±ì˜ ë¬¸ìì—´ì„ ê°™ì´ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.\nìƒí’ˆëª…ì˜ ê²½ìš° ë¬¸ìì—´ì˜ ê¸¸ì´ê°€ ì‘ì§€ ì•Šì•˜ê¸°ì— ì „ì²´ì ì¸ ë°ì´í„° ìš©ëŸ‰ì˜ ì¦ê°€ë¥¼ ê°€ì†ì‹œì¼°ê³ \nDB ìµœì í™”ë¥¼ ê³ ë ¤í•  ë•Œì¯¤ì— í•´ë‹¹ ìƒí’ˆëª…ê³¼ íŒë§¤ì²˜ëª… ë“±ì˜ ë¬¸ìì—´ ì»¬ëŸ¼ì´ ì „ì²´ í…Œì´ë¸”ì—ì„œ\nì ˆë°˜ ì´ìƒì— í•´ë‹¹í•˜ëŠ” ìš©ëŸ‰ì„ ì°¨ì§€í•˜ê³  ìˆì—ˆë‹¤ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ê¸°ë²•ì„ ì°¾ë˜ ì¤‘ ë°œê²¬í•œ ê²ƒì´ DB ì •ê·œí™” ê¸°ë²•ì´ì—ˆìŠµë‹ˆë‹¤.\nDB ì •ê·œí™” ê¸°ë²•ì€ ë°˜ë³µë˜ëŠ” ë°ì´í„°ë¥¼ ë³„ë„ì˜ í…Œì´ë¸”ë¡œ ë¶„ë¦¬í•˜ëŠ” ê¸°ë²•ì¸ë°,\në¶„ë¦¬ëœ ë°ì´í„°ëŠ” í•„ìš”í•  ë•Œë§Œ JOINì„ í†µí•´ ë¶ˆëŸ¬ì˜¤ë©´ ë˜ê¸° ë•Œë¬¸ì—\në”ìš± íš¨ìœ¨ì ìœ¼ë¡œ ë°ì´í„° ê³µê°„ì„ êµ¬ì„±í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ ìƒê°í–ˆìŠµë‹ˆë‹¤.\nì €ëŠ” ë³„ë„ì˜ ì¸ë±ìŠ¤ DBë¥¼ ìƒì„±í•˜ê³  ê³µí†µëœ ì½”ë“œë¡œ ë¬¶ì„ ìˆ˜ ìˆëŠ” ë¬¸ìì—´ ì»¬ëŸ¼ë“¤ì„\nì—¬ëŸ¬ í…Œì´ë¸”ë¡œë¶€í„° í•˜ë‚˜ì˜ ì¸ë±ìŠ¤ DB ì•„ë˜ í…Œì´ë¸”ë¡œ ë¶„ë¦¬ì‹œì¼°ìŠµë‹ˆë‹¤.\nê·¸ ê²°ê³¼ 300MBì— ë‹¬í•˜ëŠ” í…Œì´ë¸”ë¡œë¶€í„° ë¶„ë¦¬ëœ 210MBì˜ ë°ì´í„°ë¥¼ 3MBë¡œ ì••ì¶•ì‹œí‚¤ë©´ì„œ\ní…Œì´ë¸”ì˜ ìš©ëŸ‰ì„ 2/3 ê°€ëŸ‰ ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤.\nDB ì •ê·œí™”ë¥¼ ê±°ì¹˜ì§€ ì•Šì•˜ë‹¤ë©´ ì§€ê¸ˆì¯¤ 500MB ì •ë„ì˜ ë°ì´í„°ê°€ ìŒ“ì˜€ê² ì§€ë§Œ,\nìµœì í™”ë¥¼ í†µí•´ ì•„ì§ê¹Œì§€ 140MB ì •ë„ì˜ ìš©ëŸ‰ì´ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\npandas-gbq # DB ì„¤ê³„ë„ ì¤‘ìš”í•˜ì§€ë§Œ, ì œ ì—…ë¬´ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ì´ì—ˆê¸° ë•Œë¬¸ì—\nìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¹…ì¿¼ë¦¬ë¡œ ì˜®ê¸°ëŠ” ê³¼ì •ì„ êµ¬í˜„í•´ì•¼ í–ˆìŠµë‹ˆë‹¤.\nêµ¬ê¸€ ì‹œíŠ¸ì˜ ê²½ìš° ë§¤ë²ˆ JSON ì¸ì¦ íŒŒì¼ì„ ê°–ê³  ë‹¤ë‹ˆë©° ì¸ì¦ ìš”ì²­ì„ ìˆ˜í–‰í•´ì•¼ í–ˆê¸°ì—\nì—…ë¡œë“œë¥¼ ìœ„í•´ ë³„ë„ì˜ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³  í˜¸ì¶œí•´ì•¼í•˜ëŠ” ë¶ˆí¸í•¨ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ, ë¹…ì¿¼ë¦¬ëŠ” í‰ì†Œì— ì‚¬ìš©í•˜ëŠ” pandas ëª¨ë“ˆì—ì„œ ì—…ë¡œë“œìš© ëª¨ë“ˆì„ ì§€ì›í•œ ë•ë¶„ì— ì—‘ì…€ì„ ì €ì¥í•˜ë“¯ì´ ë‚´ì¥ëœ to_gbq í•¨ìˆ˜ë¡œ ê°„ë‹¨í•˜ê²Œ ì—…ë¡œë“œë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\në¡œì»¬ì—ì„œ ë¹…ì¿¼ë¦¬ ì—…ë¡œë“œë¥¼ ìœ„í•œ ì¸ì¦ë„ ì´ˆê¸°ì— í•œë²ˆë§Œ êµ¬ê¸€ ë¡œê·¸ì¸ì„ ìˆ˜í–‰í•˜ë©´ ë˜ì—ˆê¸°ì—\nì§€ê¸ˆë„ êµ‰ì¥íˆ ê°„í¸í•˜ê²Œ í™œìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\nêµ¬ê¸€ í´ë¼ìš°ë“œ í‘ì…˜ # ìœˆë„ìš° ìŠ¤ì¼€ì¤„ëŸ¬ì™€ íŒŒì´ì¬ì„ í†µí•œ ë¹…ì¿¼ë¦¬ ì—…ë¡œë“œë¥¼ í†µí•´ ì–´ëŠì •ë„ ìë™í™”ë¥¼ ì´ë£¨ì—ˆë‹¤ê³  ìƒê°í–ˆì„ ë•Œì¯¤\nì˜ˆìƒì¹˜ ëª»í•œ ì‚¬ê±´ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\ní‰ì†Œì— ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆë˜ ë„¤ì´ë²„ì˜ ê²½ìš° í•˜ë‚˜ì˜ IP ì£¼ì†Œë¡œ ë°˜ë³µ ìš”ì²­ ì‹œ\ní¬ë¡¤ë§ì´ ê°ì§€ë˜ì–´ ì°¨ë‹¨ë‹¹í•˜ëŠ” ë¬¸ì œ ë•Œë¬¸ì— ë³„ë„ì˜ ê³µì¸ IPë¥¼ ì œê³µí•˜ëŠ” ì•„ì´í”¼íŒ í”„ë¡œê·¸ë¨ì˜ í™˜ê²½ ì•„ë˜ì„œ\nìë™í™” í”„ë¡œê·¸ë¨ì´ ëŒì•„ê°€ê³  ìˆì—ˆëŠ”ë°, í•´ë‹¹ ì•„ì´í”¼íŒì´ ê³µê²©ì„ ë‹¹í•´ ë¨¹í†µì´ ë˜ëŠ” ê²½ìš°ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì´ ë¬¸ì œê°€ ì¼ì£¼ì¼ ì´ìƒ ì§€ì†ë˜ë©´ì„œ ê²°êµ­ ë¡œì»¬ì—ì„œ í”„ë¡œê·¸ë¨ì„ ëŒë¦¬ëŠ” ê²ƒì´ ì•ˆì „í•˜ì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì¸ì‹í–ˆê³ ,\nêµ³ì´ ì´ê²ƒì´ ì•„ë‹ˆë”ë¼ë„ ìë™í™” í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼\ní•´ë‹¹ PCì— ì ‘ê·¼í•˜ì§€ ì•Šê³ ëŠ” í•´ê²°í•  ìˆ˜ ì—†ì—ˆë˜ë°ì„œ ë¶ˆë§Œì„ ê°–ê³  ìˆê¸°ë„ í–ˆìŠµë‹ˆë‹¤.\nëŒ€ì•ˆì„ ì°¾ê¸° ìœ„í•´ ìš°ì„ ì ìœ¼ë¡œ ìƒê°í•´ë³¸ ê²ƒì€ ê¸°ì¡´ì— ìƒê°í•˜ê³  ìˆì—ˆë˜ Airflow ì˜€ì§€ë§Œ,\në‹¨ê¸°ê°„ì— íŒŒì´ì¬ ì½”ë“œë¥¼ Airflowì— ë§ê²Œ ìˆ˜ì •í•˜ëŠ” ê²ƒì€ ì–´ë ¤ì›€ì´ ìˆë‹¤ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤.\nì´ë•Œ, ì–´ë””ì„ ê°€ ë“¤ì—ˆë˜ AWS ëŒë‹¤ê°€ ë– ì˜¬ëê³  ê´€ë ¨ëœ ì„œë²„ë¦¬ìŠ¤ ì„œë¹„ìŠ¤ì— ëŒ€í•´ ì°¾ì•„ë³´ë‹¤ê°€\në§ˆì¹¨ í˜„ì¬ ì‚¬ìš©í•˜ê³  ìˆëŠ” GCP ì•ˆì—ì„œ êµ¬ê¸€ í‘ì…˜ì´ë¼ëŠ” ì„œë²„ë¦¬ìŠ¤ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ ì•Œê²Œë˜ì—ˆìŠµë‹ˆë‹¤.\nêµ¬ê¸€ í‘ì…˜ì„ í™œìš©í•˜ë©´ HTTP ìš”ì²­ íŠ¸ë¦¬ê±°ë¡œì„œ í˜„ì¬ì˜ íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\në”ìš±ì´ ë§¤ì¼ ì¼ì • ì‹œê°„ì—ë§Œ ì ê¹ ìˆ˜í–‰ë˜ëŠ” ìë™í™” í”„ë¡œê·¸ë¨ì€\nì‹¤ì‹œê°„ìœ¼ë¡œ ëŒì•„ê°€ëŠ” Compute Engineì—ì„œ ëŒë¦¬ëŠ” ê²ƒë³´ë‹¤ êµ¬ê¸€ í‘ì…˜ì´ ë¹„ìš©ì ìœ¼ë¡œ ë”ìš± íš¨ìœ¨ì ì„ì´ ê³„ì‚°ë˜ì—ˆê³ ,\në¬´ì—‡ë³´ë‹¤ HTTP íŠ¸ë¦¬ê±°ê°€ ë§¤ì¼ë³´ë˜ í¬ë¡¤ë§ ì‘ì—…ì—ì„œ ë‹¤ë¤˜ë˜ ê²ƒê³¼ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šì•˜ë‹¤ëŠ”ë°ì„œ ì ì‘í•˜ê¸° ì‰¬ì› ìŠµë‹ˆë‹¤.\në‹¤ë§Œ, í•­ìƒ í´ë¼ì´ì–¸íŠ¸ì˜ ì…ì¥ì—ì„œ ìš”ì²­ë§Œ í•˜ë‹¤ê°€ ì´ëŸ¬í•œ ìš”ì²­ì„ ë°›ì•„ì„œ ì²˜ë¦¬í•˜ëŠ” ë¡œì§ì„ êµ¬í˜„í•˜ê²Œ ë˜ë©´ì„œ,\ní•­ìƒ ë³´ë‚´ë˜ í—¤ë”ì™€ ë°ì´í„°ê°€ ì„œë²„ì—ì„œ ì–´ë–»ê²Œ ë³´ì—¬ì§€ëŠ”ì§€ë¥¼ ì•Œê²Œë˜ëŠ” ë“±ì˜ ìƒˆë¡œìš´ ê´€ì ì˜ ì „í™˜ì„ ëŠê¼ˆìŠµë‹ˆë‹¤.\nêµ¬ê¸€ í‘ì…˜ì˜ ì‚¬ìš©ë²•ì€ ê°„ë‹¨í•˜ì—¬, ê¸°ì¡´ì— ì—‘ì…€ ê¸°ë°˜ì˜ ì„¤ì •ì„ ì½ì–´ì„œ íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë˜ ë™ì‘ì„\nJSON í˜•ì‹ì˜ ì„¤ì •ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ê°™ì€ í•¨ìˆ˜ì— ë™ì¼í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•´ í˜¸ì¶œí•˜ê²Œ í•˜ë©´ ë˜ì—ˆìŠµë‹ˆë‹¤.\në¦¬ë‹¤ì´ë ‰íŠ¸ # êµ¬ê¸€ í‘ì…˜ì„ ë„ì…í•˜ê²Œ ë˜ë©´ì„œ í¬ë¡¤ë§ ê¸°ëŠ¥ì„ ë¹„ì•½ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nì €ëŠ” ì´ ê¸°ë²•ì„ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¼ê³  ë¶€ë¥´ëŠ”ë°, êµ¬ê¸€ í‘ì…˜ì˜ ìŠ¤ì¼€ì¼ ì•„ì›ƒ ê¸°ëŠ¥ì„ í†µí•´\nì—¬ëŸ¬ ê°œì˜ ì¿¼ë¦¬ë¥¼ ë‚˜ëˆ ì„œ êµ¬ê¸€ í‘ì…˜ì— ë™ì‹œì— ìš”ì²­í•˜ë©´ ìš”ì²­ ì°¨ë‹¨ì˜ ìš°ë ¤ ì—†ì´\në¹„ë™ê¸°ì ìœ¼ë¡œ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nê¸°ì¡´ ë¡œì»¬ì—ì„œë„ ë¹„ë™ê¸°ì ìœ¼ë¡œ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•˜ê¸´ í–ˆì§€ë§Œ,\në„¤ì´ë²„ ë“±ì—ì„œ ìš”ì²­ì´ ì°¨ë‹¨ë‹¹í•˜ëŠ” ë¬¸ì œ ë•Œë¬¸ì— ìµœëŒ€ ë™ì‹œ ìš”ì²­ íšŸìˆ˜ë¥¼ 3íšŒë¡œ ì œí•œí•˜ê³ \nìš”ì²­ ê°„ ë”œë ˆì´ë¥¼ ì£¼ì—ˆìŠµë‹ˆë‹¤.\në¬¼ë¡ , ì´ëŸ¬í•œ ë°©ì‹ì´ ìƒëŒ€ë°© ì„œë²„ ì…ì¥ì—ì„œ ì•ˆì „í•˜ê³ \në™ì‹œë‹¤ë°œì ìœ¼ë¡œ ìš”ì²­ì„ ë³´ë‚´ëŠ” ê¸°ë²•ì€ ì„œë²„ì—ê²Œ ê³µê²©ìœ¼ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì¸ì§€í•˜ê¸° ë•Œë¬¸ì—,\në¦¬ë‹¤ì´ë ‰íŠ¸ì˜ ë™ì‹œ ì œí•œ íšŸìˆ˜ë¥¼ ì •í•´ë†“ì•˜ìŠµë‹ˆë‹¤.\nì´ ê¸°ë²•ì„ ë„ì…í•˜ë©´ì„œ ê¸°ì¡´ì— 2ì‹œê°„ë§ˆë‹¤ 40ë¶„ì”© ê±¸ë¦¬ë©´ì„œ ëŒë ¸ë˜ ìë™í™” í”„ë¡œê·¸ë¨ì„\n1ë¶„ ì¡°ê¸ˆ ë„˜ëŠ” ì‹¤í–‰ ì‹œê°„ìœ¼ë¡œ ë‹¨ì¶•ì‹œí‚¬ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nêµ¬ê¸€ í´ë¼ìš°ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ # êµ¬ê¸€ í‘ì…˜ë„ ê²°êµ­ ëˆ„êµ°ê°€ê°€ íŠ¸ë¦¬ê±°ë¥¼ ê±¸ì–´ì¤˜ì•¼ í–ˆê¸° ë•Œë¬¸ì— ì•„ì§ê¹Œì§€ ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ëŠ” ë¬¸ì œë¥¼ ë²—ì–´ë‚˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\nì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë§ˆì°¬ê°€ì§€ë¡œ GCP ì•ˆì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ë¥¼ íƒìƒ‰í–ˆê³ ,\ní´ë¼ìš°ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ë¼ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\ní´ë¼ìš°ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” í¬ë¡ íƒ­ìœ¼ë¡œ ì¼ì • ì£¼ê¸°ë§ˆë‹¤ HTTP ìš”ì²­ì„ ë³´ë‚¼ ìˆ˜ ìˆê²Œ ì„¤ì •í•  ìˆ˜ ìˆê²Œ ì§€ì›í•´ì£¼ëŠ”ë°,\në§ˆì¹¨ HTTP ìš”ì²­ì— ê°™ì´ ë‹´ê²¨ì•¼ë˜ëŠ” ì¸ì¦ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ì²¨ë¶€í•  ìˆ˜ ìˆì–´ì„œ\në¡œì»¬ì—ì„œ ìš”ì²­ì„ ë³´ë‚´ëŠ” ê²ƒë³´ë‹¤ ë”ìš± ê°„í¸í•˜ê²Œ ì „ì†¡í•  ìˆ˜ ìˆëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.\nì‚¬ìš©ë²•ë„ ì£¼ê¸°, ëŒ€ìƒ ì£¼ì†Œ, JSON ë³¸ë¬¸ë§Œ ì§€ì •í•˜ë©´ ë§¤ì¼ íŠ¹ì • ì‹œê°„ë§ˆë‹¤ êµ¬ê¸€ í‘ì…˜ì„ ìˆ˜í–‰í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì´ë¥¼ í†µí•´ ë¡œì»¬ í™˜ê²½ì„ íƒˆí”¼í•´ GCP ì•ˆì—ì„œ ëª¨ë“  ìë™í™”ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\në§ˆë¬´ë¦¬ # ì‚¬ì‹¤ GCP ë‚´ì—ì„œì˜ ì‘ì—…ì€ ë§ì€ ì‹œê°„ì´ ê±¸ë¦¬ì§€ ì•Šì•˜ê³ \nì‹¤ì§ˆì ìœ¼ë¡œ GCPì— ë§ê²Œ ê¸°ì¡´ íŒŒì´ì¬ ì½”ë“œë¥¼ ë¦¬íŒ©í† ë§í•˜ëŠ”ë°ì„œ ë”ìš± ê¹”ë”í•˜ê²Œ ê³ ì¹˜ê³  ì‹¶ì€ ìš•ì‹¬ì´ ë“¤ì–´\ní•œ ë‹¬ ë™ì•ˆ ì „ì²´ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\në³„ë„ì˜ í”„ë ˆì„ì›Œí¬ ì—†ì´ ì œì‘í•œ ì œ í¬ë¡¤ëŸ¬ëŠ” scrapy ëª¨ë“ˆì—ì„œ ì°©ì•ˆí•´ Spider, Parser, Pipelineì˜ êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì ¸ ìˆëŠ”ë°\nê¸°ì¡´ì— ë¹„ë™ê¸°ì™€ ë™ê¸°ì‹ Spiderì˜ ì‚¬ìš©ì—¬ë¶€ë¡œ êµ¬ë¶„ëœ ë³„ë„ì˜ í”„ë¡œì íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹œë‹¤ê±°ë‚˜\ncrawl \u0026gt; gather/redirect \u0026gt; fetchì˜ ë‹¨ê³„ë¡œ ì¶”ìƒ ë©”ì†Œë“œë¥¼ ì •ì˜í•˜ëŠ” ë“±ì˜ ì „ë°˜ì ì¸ ë¦¬íŒ©í„°ë§ ì‘ì—…ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\në§ˆì¹¨ ëª…ì ˆì„ ë§ì•„ ëª¨ë“  ì‘ì—…ì´ ì•ˆì •í™”ë˜ì—ˆê³  ì—¬ìœ ë¥¼ ê°€ì§€ë©° ì‘ì—…ì„ ë˜ëŒì•„ ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nì§€ê¸ˆê¹Œì§€ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê´€ì ì—ì„œ ë¹„ì•½ì ìœ¼ë¡œ ì„±ì¥í–ˆë‹¤ê³  ëŠë¼ë©´ì„œë„,\ní˜¼ìë§Œì˜ ë…¸ë ¥ìœ¼ë¡œ ì´ ì´ìƒ ì„±ì¥í•  ìˆ˜ ìˆì„ì§€ì— ëŒ€í•´ì„œëŠ” ë‹¤ì†Œ ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤.\nì•„ë§ˆ ë‹¹ë¶„ê°„ì€ ê·¸ë™ì•ˆ ë°©ì¹˜í–ˆì—ˆë˜ ë°ì´í„° ë¶„ì„ ìª½ì— ëˆˆê¸¸ì„ ëŒë ¤\nê·¸ë™ì•ˆ ìŒ“ì•„ë‘” ë°ì´í„°ë“¤ì„ ë³´ë©´ì„œ ìƒˆë¡œìš´ ë°œê²¬ì„ í•˜ê²Œ ë ì§€ë„ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\n"},{"id":13,"href":"/blog/smartstore-login-3/","title":"[Python] requestsë¡œ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ êµ¬í˜„í•˜ê¸° (3)","section":"Posts","content":"ì•ì„  ë„¤ì´ë²„ ë¡œê·¸ì¸ êµ¬í˜„ ê³¼ì •ì„ í†µí•´ ë„¤ì´ë²„ ë¡œê·¸ì¸ì— ëŒ€í•´ ì´í•´í•˜ê³ \nìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ ê²°ê³¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ì¿ í‚¤ ê°’ì˜ ì¼ë¶€ë¥¼ íšë“í–ˆìŠµë‹ˆë‹¤.\nCopy python cookies = { \u0026#34;NNB\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;nid_inf\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_AUT\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_JKL\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_CHK\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NSI\u0026#34;: \u0026#34;...\u0026#34;, } í•˜ì§€ë§Œ, ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„°ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ í•„ìš”í•œ ì¿ í‚¤ ê°’ì€\nCBI_SES, CBI_CHK, NSI ì„¸ ê°€ì§€ ê°’ì´ê¸° ë•Œë¬¸ì—\nì§€ê¸ˆê¹Œì§€ëŠ” ì¤€ë¹„ ê³¼ì •ì— ë¶ˆê³¼í–ˆë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì´ë²ˆ ê²Œì‹œê¸€ì—ì„œëŠ” ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ ê³¼ì •ì„ ì´í•´í•˜ê³ \nì§ì ‘ êµ¬í˜„í•´ë³´ë©´ì„œ SmartstoreLogin í´ë˜ìŠ¤ë¥¼ ì™„ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.\nìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ ì´í•´ # ì§€ê¸ˆê¹Œì§€ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„°ì˜ ë‘ ê°€ì§€ ë¡œê·¸ì¸ ë°©ì‹ ì¤‘\në„¤ì´ë²„ ë¡œê·¸ì¸ ë°©ì‹ìœ¼ë¡œ ë¡œê·¸ì¸ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´,\nì‹¤ì œ ë„¤ì´ë²„ ë¡œê·¸ì¸ì— ëŒ€í•œ ì´í•´ ë° êµ¬í˜„ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\nìš”ì²­ ë‚´ì—­ íƒìƒ‰ ì‹œ ì£¼ì˜ì‚¬í•­ # ìƒˆ ì°½ì—ì„œ ë„ì›Œì§€ëŠ” ë„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ëŠ”\në¡œê·¸ì¸ì´ ì™„ë£Œë˜ë©´ ë‹«í˜€ë²„ë¦¬ê¸° ë•Œë¬¸ì— ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë‚´ì—­ì„ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\nì´ ê²½ìš° ê°œë°œì ë„êµ¬ Sources íƒ­ì—ì„œ Event Listener Breakpoints ë©”ë‰´ ì•„ë˜\nWindow \u0026gt; window.close ë¶€ë¶„ì„ ì„ íƒí•˜ë©´ ì°½ì´ ë‹«íˆëŠ” ìˆœê°„ì— ì¤‘ë‹¨ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në„¤ì´ë²„ ë¡œê·¸ì¸ê³¼ì˜ ì°¨ì´ì  # ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ì—ì„œì˜ ë„¤ì´ë²„ ë¡œê·¸ì¸ì€ ê¸°ì¡´ ë°©ì‹ê³¼ ë‹¤ì†Œì˜ ì°¨ì´ì ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\nì•„ë˜ëŠ” ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ POST ìš”ì²­ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì…ë‹ˆë‹¤.\nCopy json { \u0026#34;localechange\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dynamicKey\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;logintp\u0026#34;: \u0026#34;oauth2\u0026#34;, \u0026#34;encpw\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;enctp\u0026#34;: 1, \u0026#34;svctype\u0026#34;: 64, \u0026#34;smart_LEVEL\u0026#34;: 1, \u0026#34;bvsd\u0026#34;: { \u0026#34;uuid\u0026#34;:\u0026#34;...\u0026#34;, \u0026#34;encData\u0026#34;:\u0026#34;...\u0026#34; }, \u0026#34;encnm\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;locale\u0026#34;: \u0026#34;ko_KR\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://nid.naver.com/oauth2.0/authorize?response_type=code\u0026amp;state=...\u0026amp;client_id=...\u0026amp;redirect_uri=https%3A%2F%2Faccounts.commerce.naver.com%2Foauth%2Fcallback\u0026amp;locale=ko_KR\u0026amp;inapp_view=\u0026amp;oauth_os=\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pw\u0026#34;: \u0026#34;\u0026#34; } ê¸°ì¡´ì˜ ë„¤ì´ë²„ ë¡œê·¸ì¸ ë°ì´í„°ì™€ ë¹„êµí–ˆì„ ë•Œ 3ê°œì˜ ê°’ì´ ì¶”ê°€ë˜ì—ˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nlogintpì˜ ê²½ìš° \u0026quot;oauth2\u0026quot;ë¡œ ê³ ì •ëœ ê°’ìœ¼ë¡œ ë³´ì´ì§€ë§Œ,\nurl ë‚´ stateì™€ client_idëŠ” ì§€ê¸ˆê¹Œì§€ì˜ ê³¼ì •ì—ì„œëŠ” ì–»ì„ ìˆ˜ ì—†ì—ˆë˜\nìƒˆë¡œìš´ ê°’ìœ¼ë¡œ ë¡œê·¸ì¸ì„ ìœ„í•´ ì¶”ê°€ì ì¸ ë™ì‘ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤.\nOAuth URL ê°€ì ¸ì˜¤ê¸° # stateì™€ client_idì˜ ê²½ìš° ë„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê³¼ì •ì—ì„œ\nì´ë¯¸ ì „ë‹¬ë˜ëŠ” ê°’ì´ê¸° ë•Œë¬¸ì— í•´ë‹¹ í˜ì´ì§€ ì•ˆì—ì„œëŠ” ì¶œì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.\në”°ë¼ì„œ ë„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™í•˜ê¸° ìœ„í•´ ê±°ì¹˜ëŠ” ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ\në„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ë¥¼ ë„ìš°ëŠ” ê³¼ì •ì— ì§‘ì¤‘í•˜ì—¬ ë‘ ê°’ì´ ë°œìƒí•˜ëŠ” ì§€ì ì„ ì°¾ì•„ë³´ì•˜ê³ ,\ngraphql ì£¼ì†Œë¡œ ë³´ë‚¸ POST ìš”ì²­ì— ëŒ€í•œ ì‘ë‹µìœ¼ë¡œ urlì— í•´ë‹¹í•˜ëŠ” authUrl ê°’ì„ ë°›ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\nì´ë ‡ê²Œ êµ¬í•œ client_id ë° url ê°’ì„ ë¡œê·¸ì¸ ë°ì´í„°ì— ë‹´ì•„ ìš”ì²­ì„ ë³´ë‚¼ ê²½ìš°\nì¼ë°˜ì ì¸ ë„¤ì´ë²„ ë¡œê·¸ì¸ ê²°ê³¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” NID_AUT ë“±ì˜ ì¿ í‚¤ ê°’ì„ íšë“í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nGraphQL ë¡œê·¸ì¸ ë¶„ì„ # ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ì€ ë„¤ì´ë²„ ë¡œê·¸ì¸ì—ì„œ ê·¸ì¹˜ì§€ ì•Šê³ \nCBI_SES, CBI_CHK, NSI ì¿ í‚¤ ê°’ì„ ì¶”ê°€ë¡œ ì–»ì–´ì•¼ í•©ë‹ˆë‹¤.\nì´ ì¤‘ì—ì„œ CBI_SESë¥¼ ì‘ë‹µ íŒŒì¼ ë‚´ì—ì„œ ê²€ìƒ‰í–ˆì„ ë•Œ graphql ì£¼ì†Œì— ëŒ€í•œ ì‘ë‹µìœ¼ë¡œ\nCBI_SESì™€ CBI_CHK ê°’ì„ ë°˜í™˜í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ ì£¼ì†ŒëŠ” ì•ì„œ ì¸ì¦ ì£¼ì†Œë¥¼ ê°€ì ¸ì˜¤ëŠ” ê³¼ì •ì—ì„œ ë³´ì•˜ë˜ ê²ƒì¸ë°\në‹¹ì‹œ snsLoginBeginë¼ëŠ” ëª…ì¹­ì˜ ì¿¼ë¦¬ì™€ëŠ” ë‹¤ë¥¸ snsLoginCallback ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬\nì¶”ê°€ì ì¸ ë¡œê·¸ì¸ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„ì„ ì§ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në³€ìˆ˜ë¡œ ì „ë‹¬ë˜ëŠ” stateì˜ ê²½ìš° ì•ì—ì„œ êµ¬í•œ ê²ƒê³¼ ë™ì¼í•œ ê°’ì´ì§€ë§Œ,\ncodeëŠ” ì•„ì§ê¹Œì§€ ë³¸ ì  ì—†ëŠ” ê°’ì…ë‹ˆë‹¤.\ní•˜ì§€ë§Œ, codeëŠ” ì–´ë– í•œ ì‘ë‹µ íŒŒì¼ ë‚´ì—ì„œë„ ì¶œì²˜ë¥¼ ì°¾ì•„ë³¼ ìˆ˜ ì—†ê³ ,\ncodeì˜ ê°’ ìì²´ë¥¼ ê²€ìƒ‰í–ˆì„ ë•Œ oauth_tokenì´ë¼ëŠ” í‚¤ì™€ ë™ì¼í•œ ê°’ì„ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒ ë§ê³ ëŠ”\në³„ë‹¤ë¥¸ ë‹¨ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.\nì´ ê²½ìš° ë„¤ì´ë²„ ë¡œê·¸ì¸ í›„ì— ì—°ì†ì ìœ¼ë¡œ ì§„í–‰ë˜ëŠ” ë‹¤ë¥¸ ìš”ì²­ ë‚´ì—­ì„ ì§ì ‘ ë“¤ì—¬ë‹¤ë´ì•¼ í–ˆê³ ,\në‹¤í–‰íˆ ë°”ë¡œ ì•„ë˜ì˜ ì£¼ì†Œì— ëŒ€í•œ ì‘ë‹µ ë‚´ì—­ì—ì„œ oauth_token ê°’ì„ ë°›ì•„ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nCopy html \u0026lt;html\u0026gt; \u0026lt;script language=javascript nonce=\u0026#34;4SzeR1mCGzDbnzr3s5rjQ1Li\u0026#34;\u0026gt; location.replace(\u0026#34;https://nid.naver.com/login/noauth/allow_oauth.nhn?oauth_token=...\u0026amp;with_pin\u0026amp;step=agree_term\u0026amp;inapp_view=\u0026amp;oauth_os=\u0026#34;); \u0026lt;/script\u0026gt; \u0026lt;/html\u0026gt; oauth_tokenì˜ ê°’ì„ codeì— ë„£ì–´ì„œ stateì™€ í•¨ê»˜ graphql ì£¼ì†Œì— ìš”ì²­í•  ê²½ìš°\nì‘ë‹µ í—¤ë”ì˜ Set-Cookieì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” CBI_SESì™€ CBI_CHKë¥¼ ë°›ê²Œ ë©ë‹ˆë‹¤.\n2ë‹¨ê³„ ì¸ì¦ ë¶„ì„ # ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„°ëŠ” ìµœì´ˆ ë¡œê·¸ì¸ ì‹œ ë°˜ë“œì‹œ 2ë‹¨ê³„ ì¸ì¦ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤.\në§ˆì§€ë§‰ ë‚¨ì€ NSI ê°’ ë˜í•œ í•´ë‹¹ 2ë‹¨ê³„ ì¸ì¦ì„ ê±°ì³ì•¼ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì´ë¼ ê±±ì •í–ˆì§€ë§Œ,\në‹¤í–‰íˆ 2ë‹¨ê³„ ì¸ì¦ì„ ê±°ì¹˜ì§€ ì•Šì•„ë„ ë„¤íŠ¸ì›Œí¬ ì‘ë‹µ ë‚´ì—­ì—ì„œ NSIë¥¼ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nPOST ìš”ì²­ì´ì§€ë§Œ ì „ë‹¬ë˜ëŠ” ë°ì´í„°ëŠ” ì•„ë˜ì™€ ê°™ì´ ë‹¨ìˆœí–ˆê¸°ì—\nì¶”ê°€ì ì¸ ë¶„ì„ ì—†ì´ ë§ˆì§€ë§‰ NSI ê°’ì„ íšë“í–ˆìŠµë‹ˆë‹¤.\nCopy json {\u0026#34;url\u0026#34;: \u0026#34;https://sell.smartstore.naver.com/#/home/dashboard\u0026#34;} ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ êµ¬í˜„ # ì§€ê¸ˆê¹Œì§€ì˜ ê³¼ì •ì„ í†µí•´ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„°ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ í•„ìš”í•œ CBI_SES, CBI_CHK, NSI ê°’ì„ íšë“í•˜ëŠ” ë°©ë²•ì„ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.\nì´ë¥¼ SmartstoreLogin í´ë˜ìŠ¤ì˜ ë©”ì†Œë“œë¡œ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\në„¤ì´ë²„ ë¡œê·¸ì¸ êµ¬í˜„ # ê¸°ì¡´ì˜ ë„¤ì´ë²„ ë¡œê·¸ì¸ ê¸°ëŠ¥ì— OAuth URLì„ ê°€ì ¸ì˜¤ëŠ” ë¶€ë¶„ì„ ì¶”ê°€ì‹œí‚¨\nnid_login() ë° fetch_oauth_url() ë©”ì†Œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\nCopy python SMARTSTORE_URL = \u0026#34;https://sell.smartstore.naver.com/\u0026#34; SLOGIN_URL = \u0026#34;https://accounts.commerce.naver.com\u0026#34; GRAPHQL_DATA = str({ \u0026#34;operationName\u0026#34;: \u0026#34;snsLoginBegin\u0026#34;, \u0026#34;variables\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;login\u0026#34;, \u0026#34;snsCd\u0026#34;: \u0026#34;naver\u0026#34;, \u0026#34;svcUrl\u0026#34;: \u0026#34;https://sell.smartstore.naver.com/#/login-callback\u0026#34;}, \u0026#34;query\u0026#34;: \u0026#34;mutation snsLoginBegin($mode: String!, $snsCd: String!, $svcUrl: String!, \\ $oneTimeLoginSessionKey: String, $userInfos: [UserInfoEntry!]) {\\n snsBegin(\\n \\ snsLoginBeginRequest: {mode: $mode, snsCd: $snsCd, svcUrl: $svcUrl, oneTimeLoginSessionKey: \\ $oneTimeLoginSessionKey, userInfos: $userInfos}\\n ) {\\n authUrl\\n __typename\\n }\\n}\\n\u0026#34; }).replace(\u0026#39;\\\u0026#39;\u0026#39;,\u0026#39;\\\u0026#34;\u0026#39;) class SmartstoreLogin(NaverLogin): def fetch_oauth_url(self): referer = f\u0026#34;{SLOGIN_URL}/login?url={SMARTSTORE_URL}#/login-callback\u0026#34; headers = self.get_headers(host=SLOGIN_URL, referer=referer) response = self.post(urljoin(SLOGIN_URL, \u0026#34;graphql\u0026#34;), data=GRAPHQL_DATA, headers=headers) self.oauth_url = json.loads(response.text)[\u0026#34;data\u0026#34;][\u0026#34;snsBegin\u0026#34;][\u0026#34;authUrl\u0026#34;] self.oauth_params = {k:v.pop() for k,v in parse_qs(urlparse(self.oauth_url).query).items()} if \u0026#34;auth_type\u0026#34; in self.oauth_params: self.oauth_params.pop(\u0026#34;auth_type\u0026#34;) self.oauth_params = dict(self.oauth_params, **{\u0026#34;locale\u0026#34;:\u0026#34;ko_KR\u0026#34;,\u0026#34;inapp_view\u0026#34;:\u0026#39;\u0026#39;,\u0026#34;oauth_os\u0026#34;:\u0026#39;\u0026#39;}) graphql ì£¼ì†Œì— ëŒ€í•œ ìš”ì²­ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ êµ¬í˜„í•œ ê²ƒì´ GRAPHQL_DATAì´ë©°,\nê·¸ ê²°ê³¼ë¡œ OAuth URLì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nOAuth URLì˜ íŒŒë¼ë¯¸í„°ëŠ” í–¥í›„ GraphQL ì¸ì¦ ê³¼ì •ì—ì„œ ì¬í™œìš©ë˜ê¸° ë•Œë¬¸ì—\noauth_params ë³€ìˆ˜ì— ì €ì¥í•´ë‘¡ë‹ˆë‹¤.\nCopy python LOGIN_URL = \u0026#34;https://nid.naver.com/nidlogin.login\u0026#34; SLOGIN_DATA = lambda dynamicKey, encpw, bvsd, encnm, client_id: \\ dict(LOGIN_DATA(dynamicKey, encpw, bvsd, encnm), **{\u0026#34;logintp\u0026#34;:\u0026#34;oauth2\u0026#34;,\u0026#34;svctype\u0026#34;:\u0026#34;64\u0026#34;,\u0026#34;client_id\u0026#34;:client_id}) class SmartstoreLogin(NaverLogin): def nid_login(self): self.fetch_keys() self.set_encpw() self.set_bvsd() self.fetch_oauth_url() data = SLOGIN_DATA(self.dynamicKey, self.encpw, self.bvsd, self.encnm, self.oauth_params.get(\u0026#34;client_id\u0026#34;)) headers = self.get_headers(LOGIN_URL, referer=self.oauth_url) headers[\u0026#34;Content-Type\u0026#34;] = \u0026#34;application/x-www-form-urlencoded\u0026#34; headers[\u0026#34;Upgrade-Insecure-Requests\u0026#34;] = \u0026#34;1\u0026#34; response = self.post(LOGIN_URL, data=data, headers=headers) ë„¤ì´ë²„ ë¡œê·¸ì¸ ê³¼ì •ì—ì„œëŠ” bvsdë¥¼ ìƒì„±í•œ í›„ OAuth URLì„ ì¶”ê°€ë¡œ ê°€ì ¸ì˜¤ê³ \nclient_idë¥¼ ê¸°ì¡´ì˜ ë¡œê·¸ì¸ ë°ì´í„° ë‚´ì— í¬í•¨ì‹œì¼œ POST ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\ní•´ë‹¹ ë©”ì†Œë“œì˜ ê²°ê³¼ë¡œ NID_AUT, NID_JKL, NID_SESë¥¼ ë¶€ì—¬ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nOAuth ë¡œê·¸ì¸ êµ¬í˜„ # OAuth ë¡œê·¸ì¸ì€ ë„¤ì´ë²„ ë¡œê·¸ì¸ê³¼ GraphQL ì¸ì¦ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\ní˜„ì‹œì ì—ì„œ GraphQL ì¸ì¦ì— í•„ìš”í•œ ê²ƒì€ oauth_token ë¿ì´ê¸° ë•Œë¬¸ì—\nì•ì„  ë„¤ì´ë²„ ë¡œê·¸ì¸ ê³¼ì •ì—ì„œ íšë“í•œ ì£¼ì†Œë¡œë¶€í„° oauth_tokenì„ ê°€ì ¸ì˜¤ëŠ” ë©”ì†Œë“œ fetch_oauth_token()ê³¼\nì „ì²´ì ì¸ OAuth ë¡œê·¸ì¸ ê³¼ì •ì„ êµ¬í˜„í•œ oauth_login() ë©”ì†Œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\nCopy python OAUTH_URL = \u0026#34;https://nid.naver.com/oauth2.0/authorize\u0026#34; class SmartstoreLogin(NaverLogin): def fetch_oauth_token(self): headers = self.get_headers(LOGIN_URL, referer=LOGIN_URL, cookies=self.get_cookies()) response = self.get(OAUTH_URL, headers=headers, params=self.oauth_params) if re.search(\u0026#34;(?\u0026lt;=oauth_token\\=)(.*?)(?=\u0026amp;)\u0026#34;, response.text): self.oauth_token = re.search(\u0026#34;(?\u0026lt;=oauth_token\\=)(.*?)(?=\u0026amp;)\u0026#34;, response.text).group() Copy python OAUTH_DATA = lambda code, state: str({ \u0026#34;operationName\u0026#34;:\u0026#34;snsLoginCallback\u0026#34;, \u0026#34;variables\u0026#34;: { \u0026#34;code\u0026#34;: code, \u0026#34;state\u0026#34;: state}, \u0026#34;query\u0026#34;:\u0026#34;mutation snsLoginCallback($code: String!, $state: String!) \\ {\\n snsCallback(snsLoginCallbackRequest: {code: $code, state: $state}) \\ {\\n statCd\\n loginStatus\\n nextUrl\\n sessionKey\\n snsCd\\n \\ idNo\\n realnm\\n age\\n email\\n __typename\\n }\\n}\\n\u0026#34; }).replace(\u0026#39;\\\u0026#39;\u0026#39;,\u0026#39;\\\u0026#34;\u0026#39;) class SmartstoreLogin(NaverLogin): def oauth_login(self): self.nid_login() self.fetch_oauth_token() code, state = self.oauth_token, self.oauth_params.get(\u0026#34;state\u0026#34;) referer = SLOGIN_URL+f\u0026#34;/oauth/callback?code={code}\u0026amp;state={state}\u0026#34; headers = self.get_headers(host=SLOGIN_URL, referer=referer, cookies=self.get_cookies()) response = self.post(urljoin(SLOGIN_URL, \u0026#34;graphql\u0026#34;), data=OAUTH_DATA(code, state), headers=headers) 2ë‹¨ê³„ ì¸ì¦ êµ¬í˜„ # 2ë‹¨ê³„ ì¸ì¦ì„ ì§ì ‘ ìˆ˜í–‰í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.\nNSI ì¿ í‚¤ ê°’ì„ í• ë‹¹ë°›ì„ ìˆ˜ ìˆëŠ” ì£¼ì†Œë¡œ POST ìš”ì²­ì„ ë³´ë‚´ëŠ”\ntwo_factor_login() ë©”ì†Œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\nCopy python TWOLOGIN_URL = SMARTSTORE_URL+\u0026#34;api/login?url=https%3A%2F%2Fsell.smartstore.naver.com%2F%23%2Fhome%2Fdashboard\u0026#34; TWOLOGIN_DATA = {\u0026#34;url\u0026#34;: \u0026#34;https://sell.smartstore.naver.com/#/home/dashboard\u0026#34;} class SmartstoreLogin(NaverLogin): def two_factor_login(self): headers = self.get_headers(SMARTSTORE_URL, referer=SMARTSTORE_URL, cookies=self.get_cookies()) headers[\u0026#34;Content-Type\u0026#34;] = \u0026#34;application/json;charset=UTF-8\u0026#34; headers[\u0026#34;x-current-state\u0026#34;] = \u0026#34;https://sell.smartstore.naver.com/#/login-callback\u0026#34; headers[\u0026#34;x-current-statename\u0026#34;] = \u0026#34;login-callback\u0026#34; headers[\u0026#34;x-to-statename\u0026#34;] = \u0026#34;login-callback\u0026#34; response = self.post(TWOLOGIN_URL, data=TWOLOGIN_DATA, headers=headers) ë¡œê·¸ì¸ ë©”ì†Œë“œ êµ¬í˜„ # SmartstoreLogin ê°ì²´ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” login() ë©”ì†Œë“œë¥¼ í™œìš©í•©ë‹ˆë‹¤.\nCopy python class SmartstoreLogin(NaverLogin): def login(self): email_pattern = re.compile(\u0026#34;[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\u0026#34;) self.seller_login() if email_pattern.search(self.userid) else self.oauth_login() self.two_factor_login() í–¥í›„ íŒë§¤ì ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸ í•˜ëŠ” ê²½ìš°ë¥¼ ê³ ë ¤í•´\nuseridê°€ ì´ë©”ì¼ì¸ ê²½ìš° seller_login() ì´ë¼ëŠ” ë¯¸êµ¬í˜„ëœ ë©”ì†Œë“œë¥¼ ì‹¤í–‰í•˜ë„ë¡ ì •ì˜í–ˆìŠµë‹ˆë‹¤.\nì¼ë°˜ì ì¸ ë„¤ì´ë²„ ì•„ì´ë””ë¥¼ ì‚¬ìš©í•  ê²½ìš°ì—” OAuth ë¡œê·¸ì¸ê³¼ 2ë‹¨ê³„ ì¸ì¦ì„ ê±°ì³\nì²˜ìŒ ëª©ì ìœ¼ë¡œ í–ˆë˜ ì•„ë˜ì˜ ëª¨ë“  ì¿ í‚¤ ê°’ì„ íšë“í•˜ê²Œ ë©ë‹ˆë‹¤.\nCopy python cookies = { \u0026#34;NNB\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;nid_inf\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_AUT\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_JKL\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_CHK\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NSI\u0026#34;: \u0026#34;...\u0026#34;, } í•´ë‹¹ ì¿ í‚¤ë¥¼ ê°€ì§„ SmartstoreLogin ê°ì²´ë¥¼ ì„¸ì…˜ ê°ì²´ë¡œ í™œìš©í•œë‹¤ë©´\nìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë‚´ ì–´ë–¤ ë°ì´í„°ë¼ë„ íŒŒì´ì¬ requests ëª¨ë“ˆë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n"},{"id":14,"href":"/blog/smartstore-login-2/","title":"[Python] requestsë¡œ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ êµ¬í˜„í•˜ê¸° (2)","section":"Posts","content":"ì´ë²ˆ ê²Œì‹œê¸€ì—ì„œëŠ” ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìë™í™” í”„ë¡œê·¸ë¨ì„ ì œì‘í•˜ê¸° ìœ„í•œ\nì²« ë²ˆì§¸ ê³¼ì •ìœ¼ë¡œ ë„¤ì´ë²„ ë¡œê·¸ì¸ì„ êµ¬í˜„í•  ê²ƒì…ë‹ˆë‹¤.\nì•ì„  ê²Œì‹œê¸€ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë°©ì‹ì— ëŒ€í•´ ì•Œì•„ë³´ë©´ì„œ\në¡œê·¸ì¸ì´ í•„ìš”í•œ í˜ì´ì§€ì— ì ‘ê·¼í•˜ê¸° ë‹¤ìŒê³¼ ê°™ì€ ì¿ í‚¤ ê°’ì´ í•„ìš”í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\nCopy python cookies = { \u0026#34;NNB\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;nid_inf\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_AUT\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_JKL\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_CHK\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NSI\u0026#34;: \u0026#34;...\u0026#34;, } ìœ„ í‚¤ê°’ë“¤ì€ ì•ìœ¼ë¡œ ë¡œê·¸ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ íŒŒì•…í•˜ëŠ” ê³¼ì •ì—ì„œ ì¤‘ìš”í•˜ê²Œ í™œìš©ë©ë‹ˆë‹¤.\në„¤ì´ë²„ ë¡œê·¸ì¸ ì´í•´ # ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ ê³¼ì •ì—ì„œ ì§„í–‰ë˜ëŠ” ë„¤ì´ë²„ ë¡œê·¸ì¸ì€\nì¼ë°˜ì ì¸ ë„¤ì´ë²„ ë¡œê·¸ì¸ê³¼ëŠ” ë‹¤ë¥¸ ê³¼ì •ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\në”°ë¼ì„œ ìš°ì„  ì¼ë°˜ì ì¸ ë„¤ì´ë²„ ë¡œê·¸ì¸ ê³¼ì •ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\ní•´ë‹¹ íŒŒíŠ¸ëŠ” ì•„ë˜ ê²Œì‹œê¸€ì„ ì°¸ê³ í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\níŒŒì´ì¬#76 - íŒŒì´ì¬ í¬ë¡¤ë§ requests ë¡œ ë„¤ì´ë²„ ë¡œê·¸ì¸ í•˜ê¸°\në„¤ì´ë²„ ë¡œê·¸ì¸ ìš”ì²­ ë¶„ì„ # ë„¤ì´ë²„ ë¡œê·¸ì¸ ê³¼ì •ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„  ë„¤ì´ë²„ ë¡œê·¸ì¸ì„ ìš”ì²­ì„ ì‹œë„í•˜ì—¬\nì „ë‹¬ë˜ëŠ” ê°’ì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\në„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ ë¡œê·¸ì¸ì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ\në°œê²¬í•  ìˆ˜ ìˆëŠ” POST ìš”ì²­ì„ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë°ì´í„°ê°€ ì „ë‹¬ë¨ì„ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì•”í˜¸í™”ëœ ê°’ì„ ìƒëµí•˜ê³  í‚¤ë¡œ ì „ë‹¬ë˜ëŠ” ë‚´ìš©ì„ í™•ì¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\nCopy json { \u0026#34;localechange\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dynamicKey\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;encpw\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;enctp\u0026#34;: 1, \u0026#34;svctype\u0026#34;: 1, \u0026#34;smart_LEVEL\u0026#34;: 1, \u0026#34;bvsd\u0026#34;: { \u0026#34;uuid\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;encData\u0026#34;: \u0026#34;...\u0026#34; }, \u0026#34;encnm\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;locale\u0026#34;: \u0026#34;ko_KR\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.naver.com\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pw\u0026#34;: \u0026#34;\u0026#34; } ê³µë°±ì´ë‚˜ ê³ ì •ëœ ê°’ì„ ê°€ì§„ í‚¤ë¥¼ ì œì™¸í•˜ë©´ ê²°ê³¼ì ìœ¼ë¡œ\ndynamicKey, encpw, bvsd, encnmë¥¼ ë°í˜€ë‚´ëŠ” ê²ƒì´ ì¤‘ìš”í•  ê²ƒì´ë¼ íŒë‹¨ë©ë‹ˆë‹¤.\në„¤ì´ë²„ ë¡œê·¸ì¸ í¼ ë¶„ì„ # í‚¤ì˜ ëª…ì¹­ë§Œìœ¼ë¡œëŠ” ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì—\në¡œê·¸ì¸ í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ í‚¤ëª…ì¹­ì„ ê²€ìƒ‰í•˜ì˜€ê³  ë„¤ì´ë²„ ë¡œê·¸ì¸ í¼ì—ì„œ í•˜ë‚˜ì˜ ë‹¨ì„œë¥¼ ì°¾ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\ndynamicKeyì˜ ê²½ìš° ë¡œê·¸ì¸ í¼ì— ë™ì ìœ¼ë¡œ ë¶€ì—¬ë˜ëŠ” ê°’ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ ë‚˜ë¨¸ì§€ encpw, bvsd, encnmì˜ ê°’ì€ ë¹„ì–´ìˆê¸° ë•Œë¬¸ì—\në‹¤ë¥¸ ìë°”ìŠ¤í¬ë¦½íŠ¸ ì‘ë‹µì„ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.\në„¤ì´ë²„ ë¡œê·¸ì¸ RSA ì•”í˜¸í™” # encpw ê°’ì— ëŒ€í•œ ë‹¨ì„œë¥¼ ì°¾ê¸° ìœ„í•´ ì „ì²´ ê²€ìƒ‰ì„ ìˆ˜í–‰í–ˆì„ ë•Œ\ncommon_202201.js ë‚´ë¶€ì—ì„œ RSA ì•”í˜¸í™” ì²˜ë¦¬ë¥¼ í†µí•´ ê°’ì„ ìƒì„±í•¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nê·¸ ì¤‘ì—ì„œ ê°€ì¥ ì²˜ìŒ ë‹¨ê³„ë¡œ ì‹¤í–‰ë  ê²ƒì´ë¼ ì¶”ì¸¡ë˜ëŠ” ê²ƒì´ ì•„ë˜ confirmSubmit() í•¨ìˆ˜ì…ë‹ˆë‹¤.\ní•´ë‹¹ í•¨ìˆ˜ëŠ” ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ì˜ ì—¬ë¶€ë¥¼ ì²´í¬í•˜ê³  encryptIdPw() í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\në°”ë¡œ ë°‘ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” encryptIdPw() í•¨ìˆ˜ì˜ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\nCopy js function encryptIdPw() { var id = $(\u0026#34;id\u0026#34;); var pw = $(\u0026#34;pw\u0026#34;); var encpw = $(\u0026#34;encpw\u0026#34;); var rsa = new RSAKey; if (keySplit(session_keys)) { rsa.setPublic(evalue, nvalue); try{ encpw.value = rsa.encrypt( getLenChar(sessionkey) + sessionkey + getLenChar(id.value) + id.value + getLenChar(pw.value) + pw.value); } catch(e) { return false; } $(\u0026#39;enctp\u0026#39;).value = 1; id.value = \u0026#34;\u0026#34;; pw.value = \u0026#34;\u0026#34;; return true; } else { getKeyByRuntimeInclude(); return false; } return false; } í•´ë‹¹ í•¨ìˆ˜ëŠ” session_keysë¼ëŠ” ê°’ì„ ì²˜ë¦¬í•˜ê³  RSA ì•”í˜¸í™”í•œ ê²°ê³¼ë¥¼\nencpwì˜ ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në§ˆì°¬ê°€ì§€ë¡œ í•´ë‹¹ ëª…ì¹­ì„ ê²€ìƒ‰í–ˆì„ ë•Œ\nsession_keysëŠ” Ajax í†µì‹ ì˜ ì‘ë‹µ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ ë„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ svctype=262144ë¥¼ ì¶”ê°€ì ì¸ íŒŒë¼ë¯¸í„°ë¡œ ì…ë ¥í•  ê²½ìš°\nì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ëª¨ë°”ì¼ ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ í•´ë‹¹ ê°’ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\në‹¤ì‹œ encryptIdPw() í•¨ìˆ˜ë¡œ ëŒì•„ê°€ì„œ session_keysë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´\nkeySplit() í•¨ìˆ˜ë¥¼ ì°¾ì•„ë³´ì•˜ìŠµë‹ˆë‹¤.\nCopy js function keySplit(a) { keys = a.split(\u0026#34;,\u0026#34;); if (!a || !keys[0] || !keys[1] || !keys[2] || !keys[3]) { return false; } sessionkey = keys[0]; keyname = keys[1]; evalue = keys[2]; nvalue = keys[3]; $(\u0026#34;encnm\u0026#34;).value = keyname; return true } ëª¨ë°”ì¼ í˜ì´ì§€ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” session_keys ê°’ì€ ì½¤ë§ˆë¥¼ ê¸°ì¤€ìœ¼ë¡œ\n4ê°œì˜ ê°’ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ ìˆì—ˆëŠ”ë° í•´ë‹¹ í•¨ìˆ˜ì—ì„œëŠ” ê°ê°ì„\nsessionKey, encnm, evalue, nvalueìœ¼ë¡œ ë¶„ë¦¬í–ˆìŠµë‹ˆë‹¤.\nì—¬ê¸°ì„œ encnm ê°’ì„ ìš°ì„ ì ìœ¼ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì—ˆê³ ,\në‹¤ìŒìœ¼ë¡œ encpw ê°’ì„ ì°¾ê¸° ìœ„í•´ RSA ì•”í˜¸í™” ë¶€ë¶„ì„ íƒìƒ‰í•´ë´…ë‹ˆë‹¤.\nCopy js rsa.setPublic(evalue, nvalue); encpw.value = rsa.encrypt( getLenChar(sessionkey) + sessionkey + getLenChar(id.value) + id.value + getLenChar(pw.value) + pw.value); session_keysì—ì„œ ë¶„ë¦¬ëœ evalueì™€ nvalueë¡œ RSA ê³µê°œí‚¤ë¥¼ ìƒì„±í•˜ê³ \në§ˆì°¬ê°€ì§€ë¡œ session_keysì— í¬í•¨ëœ sessionKey ë° ì•„ì´ë””, ë¹„ë°€ë²ˆí˜¸ì˜ ì¡°í•©ì„\nì•”í˜¸í™”í•œ ê²°ê³¼ê°€ encpwì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\níŒŒì´ì¬ì—ì„œëŠ” ê³µê°œí‚¤ ìƒì„±ì„ rsa.PublicKey() í•¨ìˆ˜ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°\nrsa.encrypt() í•¨ìˆ˜ë¡œ RSA ì•”í˜¸í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ ê³¼ì •ì€ ì•„ë˜ì™€ ê°™ì´ êµ¬í˜„ë©ë‹ˆë‹¤.\nCopy python publicKey = rsa.PublicKey(int(nvalue,16), int(evalue,16)) value = \u0026#39;\u0026#39;.join([chr(len(key))+key for key in [sessionKey, id, pw]]) encpw = rsa.encrypt(value.encode(), publicKey).hex() ì—¬ê¸°ê¹Œì§€ì˜ ê³¼ì •ìœ¼ë¡œ dynamicKey, encpw, encnmì˜ ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nbvsd ê°’ ìƒì„±í•˜ê¸° # ë§ˆì§€ë§‰ìœ¼ë¡œ í•„ìš”í•œ bvsd ê°’ì— ëŒ€í•œ ë‹¨ì„œëŠ” ì‘ë‹µ ë¬¸ì„œ ë‚´ì—ì„œ\nbvsd.1.3.8.min.jsë€ ëª…ì¹­ìœ¼ë¡œ ì•Œê¸° ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆì§€ë§Œ\nê·¸ ë‚´ìš©ì€ ê°€ë…ì„± ë©´ì—ì„œ ì‰½ê²Œ í•´ì„í•˜ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤.\në‹¤ë¥¸ ìë£Œë¥¼ ì°¸ê³ í–ˆì„ ë•Œ bvsdëŠ” ë¸Œë¼ìš°ì €ê°€ ì •ìƒì ì¸ì§€ ì—¬ë¶€ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•œ ê°’ìœ¼ë¡œ\ní•´ë‹¹ ê°’ì´ ì—†ì„ ê²½ìš° ë¡œê·¸ì¸ ê³¼ì •ì—ì„œ ìº¡ì°¨ë¥¼ ë°œìƒì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nbvsd.1.3.8.min.jsì—ì„œ ì£¼ëª©í•  ë¶€ë¶„ì€ uuid ë° encDataë¥¼ ìƒì„±í•˜ëŠ” ë¶€ë¶„ì¸ë°\nì•„ë˜ ì½”ë“œì—ì„œ encDataëŠ” oë¼ëŠ” ê°’ì„ ì¸ì½”ë”©í•˜ëŠ” ê²ƒìœ¼ë¡œ ì¶”ì¸¡ë©ë‹ˆë‹¤.\no ê°’ì„ ì½”ë“œ ë‚´ì—ì„œ ì°¾ì•„ë³´ë‹ˆ ì•„ë˜ì™€ ê°™ì´ ë””ë°”ì´ìŠ¤ì˜ ë§ˆìš°ìŠ¤ ìƒíƒœ ë“±ì„\nê¸°ë¡í•œ ê°’ì„ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nCopy js o = { a: n, b: \u0026#34;1.3.8\u0026#34;, c: (0, m[\u0026#34;default\u0026#34;])(), d: r, e: this._deviceOrientation.get(), f: this._deviceMotion.get(), g: this._mouse.get(), j: this._fpDuration || y.NOT_YET, h: this._fpHash || \u0026#34;\u0026#34;, i: this._fpComponent || [] }; í•˜ì§€ë§Œ ê°ê°ì˜ ê°’ì„ í•´ì„í•˜ê³  ìƒì„±í•˜ëŠ” ê²ƒì€ ì‰½ì§€ ì•Šì•˜ê¸°ì—\nì´ë¯¸ ì™„ì„±ëœ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ set_bvsd() ë©”ì†Œë“œë¥¼ ì •ì˜í–ˆìŠµë‹ˆë‹¤.\nencDataì˜ ì¸ì½”ë”©ì—ëŠ” lzstring ëª¨ë“ˆì˜\nLZString.compressToEncodedURIComponent() í•¨ìˆ˜ë¥¼ í™œìš©í–ˆìŠµë‹ˆë‹¤.\nCopy python from lzstring import LZString import uuid ENC_DATA = lambda uuid, userid, passwd: str({ \u0026#34;a\u0026#34;: f\u0026#34;{uuid}-4\u0026#34;, \u0026#34;b\u0026#34;: \u0026#34;1.3.4\u0026#34;, \u0026#34;d\u0026#34;: [{ \u0026#34;i\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;b\u0026#34;: {\u0026#34;a\u0026#34;: [\u0026#34;0\u0026#34;, userid]}, \u0026#34;d\u0026#34;: userid, \u0026#34;e\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;f\u0026#34;: \u0026#34;false\u0026#34; }, { \u0026#34;i\u0026#34;: passwd, \u0026#34;e\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;f\u0026#34;: \u0026#34;false\u0026#34; }], \u0026#34;h\u0026#34;: \u0026#34;1f\u0026#34;, \u0026#34;i\u0026#34;: {\u0026#34;a\u0026#34;: \u0026#34;Mozilla/5.0\u0026#34;} }).replace(\u0026#39;\\\u0026#39;\u0026#39;,\u0026#39;\\\u0026#34;\u0026#39;) class NaverLogin(LoginSpider): def set_bvsd(self): uuid4 = str(uuid.uuid4()) encData = LZString.compressToEncodedURIComponent(ENC_DATA(uuid4, self.userid, self.passwd)) self.bvsd = str({\u0026#34;uuid\u0026#34;:uuid4, \u0026#34;encData\u0026#34;:encData}).replace(\u0026#39;\\\u0026#39;\u0026#39;,\u0026#39;\\\u0026#34;\u0026#39;) ë„¤ì´ë²„ ë¡œê·¸ì¸ êµ¬í˜„ # ì§€ê¸ˆê¹Œì§€ì˜ ê³¼ì •ì„ í†µí•´ ë„¤ì´ë²„ ë¡œê·¸ì¸ì— í•„ìš”í•œ\ndynamicKey, encpw, bvsd, encnm ê°’ì„ ìƒì„±í•˜ëŠ” ë²•ì„ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.\nì´ë¥¼ NaverLogin í´ë˜ìŠ¤ì˜ ë©”ì†Œë“œë¡œ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\nRSA ì•”í˜¸í™” êµ¬í˜„ # ë¨¼ì € dynamicKeyì™€ í•¨ê»˜ encpw, encmn ìƒì„±ì— í•„ìš”í•œ\nsession_keysë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ë©”ì†Œë“œ fetch_keys()ì™€,\nRSA ì•”í˜¸í™”ë¥¼ í†µí•´ encpw ê°’ì„ êµ¬í•˜ëŠ” set_encpw() ë©”ì†Œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\nCopy python from bs4 import BeautifulSoup import rsa LOGIN_URL = \u0026#34;https://nid.naver.com/nidlogin.login\u0026#34; class NaverLogin(LoginSpider): def fetch_keys(self): response = self.get(LOGIN_URL, headers=self.get_headers(host=LOGIN_URL), params={\u0026#34;svctype\u0026#34;:\u0026#34;262144\u0026#34;}) source = BeautifulSoup(response.text, \u0026#39;lxml\u0026#39;) keys = source.find(\u0026#34;input\u0026#34;, {\u0026#34;id\u0026#34;:\u0026#34;session_keys\u0026#34;}).attrs.get(\u0026#34;value\u0026#34;) self.sessionKey, self.encnm, n, e = keys.split(\u0026#34;,\u0026#34;) self.dynamicKey = source.find(\u0026#34;input\u0026#34;, {\u0026#34;id\u0026#34;:\u0026#34;dynamicKey\u0026#34;}).attrs.get(\u0026#34;value\u0026#34;) self.publicKey = rsa.PublicKey(int(n,16), int(e,16)) session_keysì˜ ê²½ìš° ëª¨ë°”ì¼ ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œë§Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—\nsvctype=262144ë¥¼ GET ìš”ì²­ì˜ íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬í•´ ëª¨ë°”ì¼ ë¡œê·¸ì¸ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\nnvalueì™€ evalueëŠ” ë³„ë„ì˜ ë³€ìˆ˜ë¡œ ì €ì¥í•˜ì§€ ì•Šê³ \npublicKeyë¥¼ ìƒì„±í•´ í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\nCopy python class NaverLogin(LoginSpider): def set_encpw(self): value = \u0026#34;\u0026#34;.join([chr(len(key))+key for key in [self.sessionKey, self.userid, self.passwd]]) self.encpw = rsa.encrypt(value.encode(), self.publicKey).hex() ì•ì—ì„œ ê°€ì ¸ì˜¨ sessionKeyì™€ í•¨ê»˜ ë¯¸ë¦¬ ì´ˆê¸°í™”ëœ ë„¤ì´ë²„ ì•„ì´ë”” ë° ë¹„ë°€ë²ˆí˜¸ë¥¼\nì¡°í•© ë° ì•”í˜¸í™”í•˜ì—¬ encpwë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\nPOST ìš”ì²­ êµ¬í˜„ # ë¯¸ë¦¬ ì •ì˜í•œ set_bvsd() ë©”ì†Œë“œë¥¼ í¬í•¨í•´ ëª¨ë“  ì¤€ë¹„ ê³¼ì •ì´ ë§ˆë¬´ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\ní´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥ëœ ì•”í˜¸í™”ëœ ê°’ë“¤ì„ ë°ì´í„°ì— ë‹´ì•„ POST ë¡œê·¸ì¸ ìš”ì²­ì„ ë³´ë‚´ëŠ”\nlogin() ë©”ì†Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy python NAVER_URL = \u0026#34;https://www.naver.com\u0026#34; LOGIN_DATA = lambda dynamicKey, encpw, bvsd, encnm: { \u0026#34;localechange\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dynamicKey\u0026#34;: dynamicKey, \u0026#34;encpw\u0026#34;: encpw, \u0026#34;enctp\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;svctype\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;smart_LEVEL\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;bvsd\u0026#34;: bvsd, \u0026#34;encnm\u0026#34;: encnm, \u0026#34;locale\u0026#34;: \u0026#34;ko_KR\u0026#34;, \u0026#34;url\u0026#34;: quote_plus(NAVER_URL), \u0026#34;id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;pw\u0026#34;: \u0026#34;\u0026#34;, } class NaverLogin(LoginSpider): def login(self): self.fetch_keys() self.set_encpw() self.set_bvsd() data = LOGIN_DATA(self.dynamicKey, self.encpw, self.bvsd, self.encnm) headers = self.get_headers(LOGIN_URL, referer=LOGIN_URL) headers[\u0026#34;Content-Type\u0026#34;] = \u0026#34;application/x-www-form-urlencoded\u0026#34; headers[\u0026#34;Upgrade-Insecure-Requests\u0026#34;] = \u0026#34;1\u0026#34; self.post(LOGIN_URL, data=data, headers=headers) POST ìš”ì²­ ì‹œ ì „ë‹¬ë˜ì—ˆë˜ ë°ì´í„°ì™€ ë™ì¼í•œ ê°’ì„ ë°˜í™˜í•˜ëŠ” LOGIN_DATA í•¨ìˆ˜ë¥¼ ìƒì„±í•˜ê³ \nì•”í˜¸í™”ëœ ê°’ì„ ì „ë‹¬í•´ ìµœì¢…ì ì¸ POST ë°ì´í„°ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ ë°ì´í„°ë¡œ ìš”ì²­ì„ ë³´ë‚¼ ê²½ìš° ì •ìƒì ì¸ ì‘ë‹µì„ ë°›ê²Œ ë˜ê³ \nNaverLogin ì„¸ì…˜ ê°ì²´ì˜ ì¿ í‚¤ ê°’ì„ í™•ì¸í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy python naver = NaverLogin(\u0026#34;userid\u0026#34;, \u0026#34;passwd\u0026#34;) naver.login() naver.get_cookies() ====================================== \u0026#39;NID_AUT=...; NID_JKL=...; NID_SES=...; nid_inf=1228467713\u0026#39; ë˜í•œ í•´ë‹¹ ê²°ê³¼ëŠ” ê°œë°œì ë„êµ¬ì—ì„œë„ ì‘ë‹µ í—¤ë”ì˜ set-cookie ê°’ì—ì„œ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì§€ê¸ˆê¹Œì§€ì˜ ê³¼ì •ìœ¼ë¡œ ë„¤ì´ë²„ ë¡œê·¸ì¸ ê³¼ì •ì„ ê±°ì³¤ì„ ë•Œ,\nê²Œì‹œê¸€ì˜ ì„œë‘ì—ì„œ ì–¸ê¸‰í•œ ì¿ í‚¤ ê°’ì˜ ëª©ë¡ ì¤‘ì—ì„œ ì¼ë¶€ ê°’ì„ íšë“í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy python cookies = { \u0026#34;NNB\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;nid_inf\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_AUT\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_JKL\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_CHK\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NSI\u0026#34;: \u0026#34;...\u0026#34;, } ì´ ì¤‘ì—ì„œ NNBì˜ ê²½ìš° ë„¤ì´ë²„ í˜ì´ì§€ ì ‘ì† ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ë¶€ì—¬ë˜ëŠ” ê°’ì´ê¸° ë•Œë¬¸ì— ë¬´ì‹œí•˜ê³ \nNID_AUT, NID_JKL, NID_SESê°€ ì±„ì›Œì¡ŒìŠµë‹ˆë‹¤.\në‚˜ë¨¸ì§€ ê°’ë“¤ì€ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ ê³¼ì •ì—ì„œ ì–»ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—\në‹¤ìŒ ê²Œì‹œê¸€ì—ì„œ ë‹¤ë¤„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n"},{"id":15,"href":"/blog/smartstore-login-1/","title":"[Python] requestsë¡œ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ êµ¬í˜„í•˜ê¸° (1)","section":"Posts","content":"ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„°ì—ì„œëŠ” ë§¤ì¶œ í–¥ìƒì— ë„ì›€ì„ ì£¼ëŠ” ìœ ìš©í•œ í†µê³„ ë°ì´í„°ë¥¼ ì œê³µí•´ì¤ë‹ˆë‹¤.\nì‡¼í•‘ëª° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì…ì¥ì—ì„œ ë¬´ë£Œë¡œ ì œê³µë˜ëŠ” ì´ëŸ° ë°ì´í„°ëŠ” í° ë„ì›€ì´ ë˜ì§€ë§Œ,\nëŒ€ë¶€ë¶„ì´ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ ì§€ì›í•˜ì§€ ì•Šê³  ë¹ˆë²ˆí•˜ê²Œ ìˆ˜ì¹˜ê°€ ë°”ë€ŒëŠ” ë°ì´í„°ë¥¼ ê°ê°ì˜ ë©”ë‰´ì—ì„œ ë§¤ë²ˆ í™•ì¸í•˜ê¸°ë„ ì–´ë µìŠµë‹ˆë‹¤.\nì´ëŸ° ë°ì´í„°ë¥¼ ìë™í™” í”„ë¡œê·¸ë¨ìœ¼ë¡œ ìˆ˜ì§‘ ë° ì ì¬í•  ìˆ˜ ìˆë‹¤ë©´ ì—…ë¬´ íš¨ìœ¨ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\nì´ë²ˆ ê²Œì‹œê¸€ì—ì„œëŠ” ì‹¤ì œ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë¡œê·¸ì¸ êµ¬í˜„ì— ì•ì„œ\në°ì´í„° ìˆ˜ì§‘ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…ì„ ì§„í–‰í•˜ê³  ë„¤ì´ë²„ ë¡œê·¸ì¸ êµ¬í˜„ì˜ ë°”íƒ•ì´ ë˜ëŠ” í´ë˜ìŠ¤ì™€ ë©”ì†Œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\në°ì´í„° ìˆ˜ì§‘ ê°œìš” # ë„¤ì´ë²„ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ë•Œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì€ 2ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\nì²« ë²ˆì§¸ëŠ” CSS Selector ë˜ëŠ” XPathë¥¼ í™œìš©í•´ ì›¹ì‚¬ì´íŠ¸ íŠ¹ì • ìœ„ì¹˜ì˜ ê°’ì„ ê°€ì ¸ì˜¤ëŠ” ê²ƒ,\në‘ ë²ˆì§¸ëŠ” APIì— ìš”ì²­ì„ ë³´ë‚´ JSON í˜•íƒœì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\níŠ¹ì • ìœ„ì¹˜ì˜ ê°’ì„ ê°€ì ¸ì˜¤ëŠ” ì²« ë²ˆì§¸ ë°©ì‹ì€ UIì— ì˜ì¡´ì ì´ì–´ì„œ ì½”ë“œì˜ ì§€ì†ì„±ì„ ë³´ì¥í•˜ê¸° ì–´ë µê³ \nì›í•˜ëŠ” ë°ì´í„°ì™€ ê´€ë ¨ì—†ëŠ” ì›¹ ì†ŒìŠ¤ ì „ì²´ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ë•Œë¬¸ì— ì†ë„ ë©´ì—ì„œë„ ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.\në”°ë¼ì„œ, APIë¥¼ ì œê³µí•˜ëŠ” ê²½ìš° ë‘ ë²ˆì§¸ ë°©ì‹ì„ ì´ìš©í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.\në°ì´í„° ìˆ˜ì§‘ ì‹œë‚˜ë¦¬ì˜¤ # ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ í‘œì‹œë˜ëŠ” ìƒí’ˆì˜ ìˆœìœ„ëŠ” ê²€ìƒ‰ì¸ê¸°ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²°ì •ë©ë‹ˆë‹¤.\ní‚¤ì›Œë“œë³„ ìƒìœ„ê¶Œ ìƒí’ˆì˜ ê²€ìƒ‰ì¸ê¸°ë„ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒì„ ì˜ˆì‹œë¡œ ë°ì´í„° ìˆ˜ì§‘ì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤.\nìœ„ ì´ë¯¸ì§€ì—ì„œ ì™¼ìª½ ë¶€ë¶„ì€ ì‹¤ì œ UI, ì˜¤ë¥¸ìª½ ë¶€ë¶„ì€ HTML ì†ŒìŠ¤ ì…ë‹ˆë‹¤.\ní•´ë‹¹ ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤ë©´ div.popularity-product \u0026gt; div.box-border ìœ„ì¹˜ì—ì„œ\ndd íƒœê·¸ë¥¼ ìˆœì„œëŒ€ë¡œ ì§€ì •í•´ì„œ ê°ê°ì˜ ì¢…í•©, ì í•©ë„, ì¸ê¸°ë„ ê°’ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ ë°ì´í„°ë¥¼ ë¶„ì„ì— í™œìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ì¸ê¸°ë„ ìˆ˜ì¹˜ë¥¼ êµ¬ì„±í•˜ëŠ” í´ë¦­ìˆ˜, íŒë§¤ì‹¤ì  ë“±ë„ í•„ìš”í•˜ê¸° ë•Œë¬¸ì—\nìƒì„¸ë³´ê¸° í˜ì´ì§€ë¥¼ í™•ì¸í•´ì•¼í•˜ê³  ê²°ê³¼ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ìƒí’ˆì— ëŒ€í•œ ë°ì´í„°ë¥¼ ë³´ê¸° ìœ„í•´ ë‘ ê°œì˜ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•´ì•¼ í•©ë‹ˆë‹¤.\ní•˜ì§€ë§Œ ë„¤ì´ë²„ì˜ ëŒ€ë¶€ë¶„ì˜ ì›¹í˜ì´ì§€ëŠ” APIë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¡œ êµ¬ì„±ë˜ê¸° ë•Œë¬¸ì—\ní•´ë‹¹ APIë¥¼ í™œìš©í•  ìˆ˜ ìˆë‹¤ë©´ ë”ìš± íš¨ìœ¨ì ì¸ ë°ì´í„° ìˆ˜ì§‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\nì„œë²„ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ë°ì´í„°ë¥¼ í™•ì¸í•  ë•ŒëŠ” ì£¼ë¡œ ê°œë°œì ë„êµ¬ì˜ ë„¤íŠ¸ì›Œí¬ íƒ­ì„ í™œìš©í•©ë‹ˆë‹¤.\nì›¹í˜ì´ì§€ ë¡œë“œ ì‹œ ê°€ì ¸ì˜¤ëŠ” ë¬¸ì„œë¥¼ í™•ì¸í•˜ë‹¤ë³´ë©´ ìœ„ ì´ë¯¸ì§€ì™€ ê°™ì´ ëª©í‘œë¡œ í•˜ëŠ” ë°ì´í„°ë¥¼ ë³´ë‚´ì£¼ëŠ” APIë¥¼ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nìƒˆ íƒ­ì—ì„œ í•´ë‹¹ API ì£¼ì†Œë¥¼ ìš”ì²­í•˜ë©´ ìœ„ ì´ë¯¸ì§€ ë‚´ ì˜¤ë¥¸ìª½ ë¶€ë¶„ê³¼ ê°™ì€ JSON í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì‹¤ì œ UIì—ì„œ ê°€ì ¸ì˜¤ê³ ì í•˜ëŠ” ì¢…í•©, ì í•©ë„, ì¸ê¸°ë„ ìˆ˜ì¹˜ë„ í•´ë‹¹ ë°ì´í„°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì—¬ê¸°ì—ëŠ” ì¶”ê°€ë¡œ í´ë¦­ìˆ˜, íŒë§¤ì‹¤ì  ë“±ì— ëŒ€í•œ ìˆ˜ì¹˜ ë°ì´í„°ë„ í¬í•¨ë˜ì–´ ìˆê¸° ë•Œë¬¸ì—\ní•´ë‹¹ APIë¥¼ í™œìš©í•˜ë©´ ë‹¤ìˆ˜ì˜ í˜ì´ì§€ì— ìš”ì²­ì„ ë³´ë‚¼ ìˆ˜ê³ ë„ ì¤„ì–´ë“¤ê²Œ ë©ë‹ˆë‹¤.\në¡œê·¸ì¸ì´ í•„ìš”í•œ í˜ì´ì§€ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° # ì—¬ê¸°ê¹Œì§€ëŠ” ê°„ë‹¨í•´ë³´ì´ì§€ë§Œ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë°ì´í„°ë¥¼ requests ëª¨ë“ˆë¡œ ê°€ì ¸ì˜¤ëŠ”ë°ëŠ”\ní•˜ë‚˜ì˜ ì¶”ê°€ì ì¸ ë¬¸ì œê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\në‹¨ìˆœí•œ GET ìš”ì²­ì¼ì§€ë¼ë„ ë¡œê·¸ì¸ ì •ë³´ë¥¼ ê°–ê³  ìˆì§€ ì•Šë‹¤ë©´ ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„°ì— ë¡œê·¸ì¸í•˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ ìœ„ API ì£¼ì†Œë¡œ ìš”ì²­ì„ ë³´ë‚´ê²Œ ëœë‹¤ë©´\nì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë°›ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy json { \u0026#34;error\u0026#34;: \u0026#34;Full authentication is required to access this resource\u0026#34; } ì´ ë¬¸ì œì— ëŒ€í•œ í•´ê²°ë°©ë²•ì€ í—¤ë”ì— ìˆìŠµë‹ˆë‹¤.\nê°œë°œì ë„êµ¬ ë„¤íŠ¸ì›Œí¬ íƒ­ì—ì„œ í•˜ë‚˜ì˜ ë¬¸ì„œë¥¼ í´ë¦­í•˜ê³  Headers íƒ­ì—ì„œ ìŠ¤í¬ë¡¤ì„ ë‚´ë¦¬ë©´\nì•„ë˜ì™€ ê°™ì€ Request Headers ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ ê°„ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹œ ì„œë²„ëŠ” í´ë¼ì´ì–¸íŠ¸ì˜ ì •ë³´ë¥¼ í™•ì¸í•  ëª©ì ìœ¼ë¡œ\ní´ë¼ì´ì–¸íŠ¸ì— ì¿ í‚¤ë¼ëŠ” ì•”í˜¸í™”ëœ ì¸ì¦ ì •ë³´ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.\ní´ë¼ì´ì–¸íŠ¸ê°€ í•´ë‹¹ ì •ë³´ë¥¼ í—¤ë”ì— ë‹´ì•„ ìš”ì²­ì„ ë³´ë‚´ëŠ” ê²½ìš°ì—ë§Œ ì„œë²„ê°€ ì˜¬ë°”ë¥¸ ì‘ë‹µì„ ì „ë‹¬í•©ë‹ˆë‹¤.\nrequests ëª¨ë“ˆì—ì„œëŠ” ì´ëŸ¬í•œ ê³¼ì •ì„ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy python headers = {\u0026#34;cookie\u0026#34;: \u0026#34;...\u0026#34;} response = requests.get(url, headers=headers) í•˜ì§€ë§Œ ì¼ë°˜ì ì¸ ì¿ í‚¤ ê°’ì€ 30ë¶„ì˜ ìœ í†µê¸°í•œì´ ìˆê¸° ë•Œë¬¸ì—, ë§¤ë²ˆ ì¿ í‚¤ ê°’ì„ ê°±ì‹ í•´ì•¼ í•˜ëŠ”ë°\nìë™í™” í”„ë¡œê·¸ë¨ì„ ëŒë¦¬ê¸° ì „ì— ì§ì ‘ ë¡œê·¸ì¸í•´ì„œ ì¿ í‚¤ ê°’ì„ ê°±ì‹ í•˜ëŠ” ê²ƒì€ ë°”ëŒì§í•˜ì§€ ëª»í•©ë‹ˆë‹¤.\nê²°ê³¼ì ìœ¼ë¡œ ë¡œê·¸ì¸ì´ í•„ìš”í•œ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ í˜ì´ì§€ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ì„œëŠ”\nìë™í™”ëœ ë¡œê·¸ì¸ ê³¼ì •ì„ ê±°ì³ì„œ ì¿ í‚¤ ê°’ì„ ê°±ì‹ í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\nì¿ í‚¤ í™•ì¸í•˜ê¸° # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìš”ì²­í•˜ëŠ” í—¤ë” ë‚´ì—­ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì •ë³´ëŠ” í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\nCopy json { \u0026#34;NNB\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;nid_inf\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_AUT\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NID_JKL\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_SES\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;CBI_CHK\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;NSI\u0026#34;: \u0026#34;...\u0026#34; } ì´ëŠ” ì•ìœ¼ë¡œ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ì„ êµ¬í˜„í•˜ëŠ”ë°ì„œ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼í•  ëª©ë¡ì…ë‹ˆë‹¤.\nì§€ê¸ˆì€ ì´ ê°’ë“¤ì´ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ì–´ë””ì„œ ë°œìƒí•˜ëŠ” ê°’ì¸ì§€ ì•Œ ìˆ˜ëŠ” ì—†ì§€ë§Œ,\nì„œë²„ë¡œë¶€í„° í•´ë‹¹ ê°’ë“¤ì„ ë°›ì•„ì˜¤ëŠ” ê²ƒì— ì§‘ì¤‘í•˜ì—¬ ë¡œê·¸ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ íŒŒì•…í•˜ê³ \në¡œê·¸ì¸ ì§„í–‰ ê³¼ì •ì„ ì¿ í‚¤ ê°’ì„ í†µí•´ ì‹œê°ì ìœ¼ë¡œ ì ê²€í•  ê²ƒì…ë‹ˆë‹¤.\nìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ ê°œìš” # ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ ë¡œê·¸ì¸ í˜ì´ì§€ë¥¼ íƒìƒ‰í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\në©”ì¸ í˜ì´ì§€ì—ì„œ ë¡œê·¸ì¸í•˜ê¸° ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œ ì´ë™í•˜ëŠ” ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ ì‹¤ì œ ë¡œê·¸ì¸ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\nìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ì—ëŠ” íŒë§¤ì ì•„ì´ë””ë¡œ ë¡œê·¸ì¸í•˜ëŠ” ë°©ì‹ê³¼\në„¤ì´ë²„ ì•„ì´ë””ë¡œ ë¡œê·¸ì¸í•˜ëŠ” ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤.\nìš°ì„ ì ìœ¼ë¡œ ë„¤ì´ë²„ ì•„ì´ë””ë¡œ ë¡œê·¸ì¸í•˜ëŠ” ë°©ì‹ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\në„¤ì´ë²„ ë¡œê·¸ì¸ì„ êµ¬í˜„í•˜ëŠ” ê²ƒì— ê´€í•´ì„  ì¢‹ì€ ì„ ë¡€ê°€ ìˆì–´ ë§ì€ ë¶€ë¶„ì„ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ ë‚´ìš©ì€ ì•„ë˜ ë§í¬ë¥¼ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\níŒŒì´ì¬#76 - íŒŒì´ì¬ í¬ë¡¤ë§ requests ë¡œ ë„¤ì´ë²„ ë¡œê·¸ì¸ í•˜ê¸°\ní´ë˜ìŠ¤ ì •ì˜ # ë„¤ì´ë²„ ë¡œê·¸ì¸ ê¸°ëŠ¥ì€ ìë™í™” í”„ë¡œê·¸ë¨ì—ì„œ ì§€ì†ì ìœ¼ë¡œ í™œìš©ë  ê²ƒì´ê¸° ë•Œë¬¸ì—\në³„ë„ì˜ í´ë˜ìŠ¤ì—ì„œ ë©”ì†Œë“œë¡œ êµ¬í˜„í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\në¨¼ì € requests ëª¨ë“ˆì˜ Session í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ëŠ” NaverLogin í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\nNaverLoginì€ ë„¤ì´ë²„ IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ë‹¨ìˆœí•œ ê¸°ëŠ¥ë§Œì„ êµ¬í˜„í–ˆì§€ë§Œ\nrequests.Session í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•˜ê¸° ë•Œë¬¸ì—\nì›¹í˜ì´ì§€ ìš”ì²­ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\nCopy python class NaverLogin(requests.Session): def __init__(self, userid: str, passwd: str, **kwargs): super().__init__(**kwargs) self.userid = userid self.passwd = passwd ê·¸ë¦¬ê³  NaverLoginì„ ìƒì†ë°›ëŠ” SmartstoreLogin í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\nì¼ë°˜ì ì¸ ë„¤ì´ë²„ ë¡œê·¸ì¸ê³¼ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„°ì—ì„œ ì§„í–‰ë˜ëŠ” ë„¤ì´ë²„ ë¡œê·¸ì¸ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—\nNaverLogin ë©”ì†Œë“œì˜ ì¼ë¶€ë¥¼ ë³€ê²½í•  í•„ìš”ê°€ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\nCopy python class SmartstoreLogin(NaverLogin): def __init__(self, userid=str(), passwd=str(), **kwargs): super().__init__(userid, passwd, **kwargs) ì¶”ê°€ì ìœ¼ë¡œ ë¡œê·¸ì¸ í˜ì´ì§€ ìš”ì²­ ê³¼ì •ì—ì„œ ë¹ˆë²ˆí•˜ê²Œ ì •ì˜í•´ì•¼ í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ ìƒì„±ì„\nê°„ë‹¨í•˜ê²Œ í•  ìˆ˜ ìˆëŠ” ë©”ì†Œë“œë¥¼ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤.\ní—¤ë” ìƒì„± ë©”ì†Œë“œ ì •ì˜ # requests ëª¨ë“ˆì€ ê¸°ë³¸ì ìœ¼ë¡œ í—¤ë”ë¥¼ ê°–ê³  ìˆì§€ ì•ŠëŠ”ë°\nì´ ìƒíƒœë¡œ ë‹¤ìˆ˜ì˜ ì›¹í˜ì´ì§€ì— ìš”ì²­ì„ ë³´ë‚¸ë‹¤ë©´ ë¡œë´‡ìœ¼ë¡œ ê°„ì£¼ë‹¹í•´ ì°¨ë‹¨ë‹¹í•  ê²ƒì…ë‹ˆë‹¤.\nì„ì˜ì˜ ì›¹í˜ì´ì§€ì— ìš”ì²­ì„ ë³´ë‚¼ ë•Œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ìš”ì²­ í—¤ë” HEADERSë¥¼ ê¸°ë³¸ ë°”íƒ•ìœ¼ë¡œ,\nì›¹í˜ì´ì§€ ë³„ë¡œ ìµœì í™”ëœ í—¤ë”ë¥¼ ìƒì„±í•˜ëŠ” get_headers() ë©”ì†Œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\nCopy python HEADERS = { \u0026#34;Accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate, br\u0026#34;, \u0026#34;Accept-Language\u0026#34;: \u0026#34;ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\u0026#34;, \u0026#34;Connection\u0026#34;: \u0026#34;keep-alive\u0026#34;, \u0026#34;sec-ch-ua\u0026#34;: \u0026#39;\u0026#34;Chromium\u0026#34;;v=\u0026#34;106\u0026#34;, \u0026#34;Google Chrome\u0026#34;;v=\u0026#34;106\u0026#34;, \u0026#34;Not;A=Brand\u0026#34;;v=\u0026#34;99\u0026#34;\u0026#39;, \u0026#34;sec-ch-ua-mobile\u0026#34;: \u0026#34;?0\u0026#34;, \u0026#34;sec-ch-ua-platform\u0026#34;: \u0026#39;\u0026#34;Windows\u0026#34;\u0026#39;, \u0026#34;Sec-Fetch-Dest\u0026#34;: \u0026#34;empty\u0026#34;, \u0026#34;Sec-Fetch-Mode\u0026#34;: \u0026#34;cors\u0026#34;, \u0026#34;Sec-Fetch-Site\u0026#34;: \u0026#34;same-origin\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\u0026#34;, } Copy python from urllib.parse import urlparse class NaverLogin(requests.Session): def get_headers(self, authority=str(), referer=str(), cookies=str(), host=str(), **kwargs) -\u0026gt; Dict[str,Any]: headers = HEADERS.copy() if authority: headers[\u0026#34;Authority\u0026#34;] = urlparse(authority).hostname if host: headers[\u0026#34;Host\u0026#34;] = urlparse(host).hostname if referer: headers[\u0026#34;Referer\u0026#34;] = referer if cookies: headers[\u0026#34;Cookie\u0026#34;] = cookies return dict(headers, **kwargs) í˜¸ìŠ¤íŠ¸ëª…ì„ ì˜ë¯¸í•˜ëŠ” Authority ë˜ëŠ” Host, ë¦¬ë‹¤ì´ë ‰íŠ¸ ì „ ê²½ë¡œë¥¼ ì˜ë¯¸í•˜ëŠ” Referer,\nê·¸ë¦¬ê³  ì¿ í‚¤ë¥¼ ì˜ë¯¸í•˜ëŠ” Cookie ë“±ì˜ ê°’ì€ ìˆ˜ì‹œë¡œ ë³€í•˜ê¸° ë•Œë¬¸ì— ë³„ë„ì˜ ì…ë ¥ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.\nì¿ í‚¤ ìƒì„± ë©”ì†Œë“œ ì •ì˜ # í—¤ë”ì™€ í•¨ê»˜ í™œìš©ë˜ëŠ” ì¿ í‚¤ëŠ” í—¤ë”ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì›¹í˜ì´ì§€ ìš”ì²­ ì‹œ ë¹ˆë²ˆíˆ í™œìš©ë˜ëŠ”ë°\nrequests ëª¨ë“ˆì˜ ì¿ í‚¤ ìë£Œí˜•ì¸ RequestsCookieJarë¥¼ í—¤ë”ì— ì§ì ‘ í¬í•¨ì‹œí‚¬ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì—,\nì¿ í‚¤ë¥¼ ì ì ˆí•œ í˜•íƒœì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” get_cookies() ë©”ì†Œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\nCopy python from requests.cookies import RequestsCookieJar class NaverLogin(requests.Session): def get_cookies(self, **kwargs) -\u0026gt; str: return self.parse_cookies(dict(self.cookies, **kwargs)) def parse_cookies(self, cookies: RequestsCookieJar) -\u0026gt; str: return \u0026#34;; \u0026#34;.join([str(key)+\u0026#34;=\u0026#34;+str(value) for key,value in cookies.items()]) ë§ˆì¹˜ë©° # ì´ë²ˆ ê²Œì‹œê¸€ì—ì„œëŠ” ë‘ ê°€ì§€ ë°ì´í„° ìˆ˜ì§‘ ë°©ì‹ì„ ì˜ˆì‹œë¥¼ í†µí•´ ì•Œì•„ë³´ì•˜ê³ \nìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° ë¡œê·¸ì¸ì˜ ë°”íƒ•ì´ ë˜ëŠ” í´ë˜ìŠ¤ì™€ ë©”ì†Œë“œë¥¼ ì •ì˜í–ˆìŠµë‹ˆë‹¤.\në‹¤ìŒ ê²Œì‹œê¸€ì—ì„œëŠ” ë„¤ì´ë²„ ë¡œê·¸ì¸ì„ ë³¸ê²©ì ìœ¼ë¡œ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n"},{"id":16,"href":"/blog/2022-11-13/","title":"2022ë…„ 11ì›” 13ì¼ íšŒê³ ","section":"Posts","content":"ë°ì´í„° ë¶„ì„ê°€ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•œì§€ ë‘ ë‹¬ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.\nì‹ ì…ìœ¼ë¡œì„œ ì‚¬ìˆ˜ ì—†ì´ ë‹¤ì–‘í•œ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ë‹¤ë³´ë‹ˆ ë‹¤ì‚¬ë‹¤ë‚œí–ˆë˜ 2ê°œì›”ì´ì—ˆìŠµë‹ˆë‹¤.\nUI # ì´ˆê¸°ì—” Airflowì™€ íƒœë¸”ë¡œë¥¼ ìœ„ì£¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ì„ ê³„íší–ˆì§€ë§Œ,\në„¤ì´ë²„ ë“± ëŒ€ìƒ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ì„ êµ¬í˜„í•˜ëŠ”ë° ì†Œë¹„í•˜ëŠ” ì‹œê°„ì´ í¬ë‹¤ë³´ë‹ˆ\nì„œë²„ë¥¼ í†µí•œ ì²´ê³„ì ì¸ ìë™í™”ë¥¼ êµ¬í˜„í•  ì—¬ìœ ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤.\nëŒ€ì‹ , Streamlitê³¼ PyInstallerë¥¼ í†µí•´ UIë¥¼ êµ¬ì„±í•˜ê³ \nê°ê°ì˜ ë©”ë‰´ì™€ ì—‘ì…€ ì„¤ì • íŒŒì¼ì„ ì •ì˜í•˜ì—¬ ìë™í™” ì„œë¹„ìŠ¤ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.\nê°œë°œ í™˜ê²½ì´ ì§œì—¬ì§ì„ ì „ì œë¡œ í”„ë¡œê·¸ë¨ì„ ì œì‘í–ˆë˜ ì´ì „ê³¼ëŠ” ì •ë°˜ëŒ€ë¡œ\nì•„ë¬´ê²ƒë„ ì—†ëŠ” ìœˆë„ìš° í™˜ê²½ì—ì„œë„ ëŒì•„ê°€ëŠ” í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ë ¤ë‹¤ë³´ë‹ˆ ì ì–ì€ ê³ ë¯¼ì„ í–ˆìŠµë‹ˆë‹¤.\në°‘ë°”ë‹¥ë¶€í„° UIë¥¼ ê°œë°œí•˜ë ¤ í–ˆìœ¼ë©´ ê·¸ ìì²´ë¡œ ë§ì€ ì‹œê°„ì´ ê±¸ë ¸ê² ì§€ë§Œ,\në‹¤í–‰íˆ ì´ì „ êµìœ¡ ê³¼ì •ì—ì„œ í™œìš©í•´ë³¸ Streamlitì„ ë„ì…í•˜ë©´ì„œ\nUIì— ëŒ€í•œ ê±±ì •ì„ ì¼ì²´í•˜ì§€ ì•Šê³  í¬ë¡¤ë§ ê¸°ëŠ¥ë§Œì„ êµ¬í˜„í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ, Streamlitë„ ë§ˆëƒ¥ í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ëŠ” ì—†ì—ˆë˜ ê²ƒì´,\në¬´ë£Œ ë°°í¬ ì„œë¹„ìŠ¤ì˜ ì œí•œëœ ìì› ë•Œë¬¸ì— í¬ë¡¤ë§ì´ ì•ˆì •ì ì´ì§€ ëª»í–ˆê³ \nì—¬ëŸ¬ ì‚¬ëŒì´ í•˜ë‚˜ì˜ ì„œë²„ì— ë¶™ë‹¤ë³´ì–´ í¬ë¡¤ë§ì´ ì§„í–‰ë˜ë‹¤ ë³´ë‹ˆ\nëŒ€ìƒ ì‚¬ì´íŠ¸ë¡œë¶€í„° ì°¨ë‹¨ë‹¹í•˜ëŠ” ê²½ìš°ë„ ìˆì—ˆìŠµë‹ˆë‹¤.\në”ìš±ì´ Streamlitì˜ ë°°í¬ ì„œë²„ê°€ í•´ì™¸ ì†Œì¬ì˜€ê¸° ë•Œë¬¸ì—\nì¿ íŒ¡ í¬ë¡¤ë§ ë˜ëŠ” ê·¸ì™¸ ì‚¬ì´íŠ¸ì˜ ë¡œê·¸ì¸ ë“±ì´ í•´ì™¸ IP ì°¨ë‹¨ì˜ ì´ìœ ë¡œ ì›í™œí•˜ê²Œ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\nê²°êµ­ ë¡œì»¬ í™˜ê²½ì—ì„œ ëŒì•„ê°€ëŠ” ì‹¤í–‰ í”„ë¡œê·¸ë¨ì´ í•„ìš”í–ˆê³ ,\nì´ˆê¸°ì—ëŠ” ê°œì¸ì ìœ¼ë¡œ í™œìš©í•˜ë˜ Bittorrent Web í”„ë¡œê·¸ë¨ì²˜ëŸ¼\nStreamlitì„ ë¡œì»¬ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰ì‹œí‚¤ëŠ” ë°©ì•ˆì„ êµ¬ìƒí–ˆì§€ë§Œ,\nìƒê°ë§Œí¼ ì‰½ì§€ ì•Šì•„ ë‹¨ìˆœíˆ í¬ë¡¤ë§ ê¸°ëŠ¥ì„ ì‹¤í–‰ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒìœ¼ë¡œ íƒ€í˜‘í–ˆìŠµë‹ˆë‹¤.\nì‚¬ìš©ì í¸ì˜ì„±ì„ ê³ ë ¤í–ˆì„ ë•Œ GUIê°€ í¬í•¨ëœ ì‹¤í–‰ í”„ë¡œê·¸ë¨ì´ ì¢‹ì„ ìˆ˜ ìˆì§€ë§Œ,\nìœˆë„ìš° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ëŒì•„ê°€ëŠ” ë°©ì‹ì„ ê³ ë ¤ ì¤‘ì— ìˆì—ˆê¸° ë•Œë¬¸ì—\nìµœëŒ€í•œ ì‚¬ëŒ ì†ì„ ê±°ì¹˜ì§€ ì•Šê²Œ ëª¨ë“  ì„¤ì •ì„ ì—‘ì…€ íŒŒì¼ë¡œ ì œì–´í•˜ê²Œ í•˜ê³ \ní„°ë¯¸ë„ì—ì„œ ì§„í–‰ìƒí™©ë§Œ í‘œì‹œí•˜ë„ë¡ ê°œë°œí–ˆìŠµë‹ˆë‹¤.\ní–¥í›„ Airflowì™€ ê°™ì€ ì›¹ ì„œë²„ ì„¤ê³„ë¥¼ ê¸°ëŒ€í•˜ì§€ë§Œ,\ní˜„ì¬ë¡œì„œëŠ” ìœ„ì™€ ê°™ì€ ì‹¤í–‰ ë°©ì‹ì´ ê°€ì¥ ê°œë°œ íš¨ìœ¨ì ì´ë¼ ìƒê°í•˜ì—¬ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.\ní¬ë¡¤ë§ # ì´ì „ê¹Œì§€ ë°°ìš´ í¬ë¡¤ë§ì€ HTMLì„ íŒŒì‹±í•˜ëŠ” êµ‰ì¥íˆ ë‹¨ìˆœí•œ ìˆ˜ì¤€ì´ì—ˆê³ \níŒŒì´ì¬ ìì²´ë¥¼ ê¹Šì´ ë‹¤ë¤„ë³¼ ì¼ë„ ì—†ì—ˆê¸°ì— requests ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ í¬ë¡¤ë§ì„ ì‹œë„í–ˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ, 1ì£¼ ì •ë„ê°€ í¬ë¡¤ë§ ê¸°ëŠ¥ì„ ê°œë°œí•˜ë©´ì„œ ìœ ì§€ë³´ìˆ˜ ëŒ€ë¹„ ë° ì‹œê°„ ê°œì„ ì˜ í•„ìš”ì„±ì„ ëŠë¼ê³ \në‹¤ë¥¸ ë°©ì•ˆì„ íƒìƒ‰í–ˆìŠµë‹ˆë‹¤.\në‹¹ì‹œë¶€í„° ì§€ê¸ˆê¹Œì§€ ì§‘ì¤‘í•˜ê³  ìˆë˜ ê²ƒì´ ë„¤ì´ë²„ í¬ë¡¤ë§ì´ì—ˆëŠ”ë°,\nìš°ì—°íˆ ë„¤ì´ë²„ ë‚´ ë°ì´í„°ëŠ” Open APIì™€ëŠ” ë³„ê°œì˜ ë‚´ë¶€ APIë¡œ ì „ë‹¬ë˜ëŠ” ê²ƒì„ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.\nì´ë•Œë¶€í„° í¬ë¡¬ ê°œë°œì ë„êµ¬ì˜ ë„¤íŠ¸ì›Œí¬ íƒ­ì—ì„œ ëª¨ë“  ë°ì´í„°ì˜ ì†ŒìŠ¤ë¥¼ íŒŒì•…í–ˆê³ \në„¤ì´ë²„ ì‡¼í•‘ í•œì •í•´ì„œëŠ” ë³´ì´ëŠ” ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ê¸°ë°˜ì„ ë‹¤ì¡ŒìŠµë‹ˆë‹¤.\në˜í•œ, ì‹œê°„ ê°œì„ ì„ ìœ„í•´ ë©€í‹° ì“°ë ˆë”© ë°©ì‹ì„ ì•Œì•„ë³´ì•˜ê³ ,\nì´ì™€ ìœ ì‚¬í•œ ë¹„ë™ê¸° ë°©ì‹ì´ íŒŒì´ì¬ì—ì„œ ê°€ì¥ íš¨ìœ¨ì ì„ì„ ì¸ì‹í•˜ê³ \nrequestsë¡œ ì´ë£¨ì–´ì§„ ì½”ë“œë¥¼ asyncio ë° aiohttpë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\nì´ ê³¼ì •ì—ì„œ Scrapyì˜ Spider ë° Pipeline êµ¬ì¡°ë¥¼ ì°¸ê³ í•´\nê¸°ì¡´ì˜ í•¨ìˆ˜ ìœ„ì£¼ì˜ ì½”ë“œë„ Spider, Parser, Pipelineìœ¼ë¡œ êµ¬ë¶„ëœ í´ë˜ìŠ¤ ìœ„ì£¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.\nì´ˆê¸°ë³´ë‹¤ í›¨ì”¬ ë‹¤ì–‘í•œ í¬ë¡¤ë§ ê¸°ëŠ¥ì´ ìƒê¸´ ì§€ê¸ˆë„ ìœ„ì™€ ê°™ì€ êµ¬ì¡° ë•ë¶„ì—\nì½”ë“œ ê´€ë¦¬ ë° ì¬í™œìš©ì„ í¸ë¦¬í•˜ê²Œ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.\ní•œí¸, ë„¤ì´ë²„ ì™¸ì— ì´ì§€ì–´ë“œë¯¼ì´ë¼ëŠ” ì¢…í•© ì‡¼í•‘ëª° ê´€ë¦¬ ì†”ë£¨ì…˜ ë‚´ì—ì„œ\në°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê³¼ì •ì—ì„œ ë¡œê·¸ì¸ì„ requestsë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë§ì€ ìë£Œë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.\nê·¸ ì¤‘ì—ì„œ ê°€ì¥ ë„ì›€ì´ ë˜ì—ˆë˜ ê²ƒì€ ë„¤ì´ë²„ ë¡œê·¸ì¸ì„ requestsë¡œ êµ¬í˜„í•œ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìë£Œì˜€ëŠ”ë°,\ní•´ë‹¹ ë‚´ìš©ì„ í†µí•´ POST ìš”ì²­ ë° RSA ì•”í˜¸í™”ì— ëŒ€í•´ ì´í•´í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\në•ë¶„ì— ê°œë°œì ë„êµ¬ ë„¤íŠ¸ì›Œí¬ íƒ­ì—ì„œ ë¡œê·¸ì¸ ê³¼ì •ì„ ì—­ì¶”ì í•˜ëŠ” ì‹ìœ¼ë¡œ\nì´ì§€ì–´ë“œë¯¼ê³¼ 11ë²ˆê°€ ì…€ëŸ¬ì˜¤í”¼ìŠ¤ì˜ requests ë¡œê·¸ì¸ì„ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆê³ ,\në„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„°ë¥¼ ìœ„í•œ 2ì°¨ ì¸ì¦ ë˜í•œ ë‹¤ì†Œì˜ ì‹œê°„ì´ ê±¸ë ¸ì§€ë§Œ í•´ê²°í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\níŠ¹íˆ ë„¤ì´ë²„ 2ì°¨ ì¸ì¦ì„ êµ¬í˜„í•˜ë©´ì„œ ì„¸ì…˜ê³¼ ì¿ í‚¤ì— ëŒ€í•œ ê°œë…ì„ ì¡ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nì—…ë¬´ì™€ëŠ” ë³„ê°œë¡œ ê°œì¸ì ìœ¼ë¡œ í¬ë¡¤ë§ì— ê³ ì „í•˜ê³  ìˆëŠ” jQuery ê¸°ë°˜ì˜ ì›¹ì‚¬ì´íŠ¸ê°€ ìˆëŠ”ë°,\nì´ëŸ° íŠ¹ìˆ˜í•œ ê²½ìš°ë¥¼ ì œì™¸í•˜ê³ ëŠ” ëŒ€ë¶€ë¶„ì˜ ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ì— ìì‹ ì´ ë“¤ì—ˆìŠµë‹ˆë‹¤.\në˜í•œ, ì—¬ëŸ¬ ì‚¬ì´íŠ¸ì˜ ì†ŒìŠ¤ë¥¼ ëœ¯ì–´ë³´ë©´ì„œ ìë°”ìŠ¤í¬ë¦½íŠ¸ì— ëŒ€í•œ í¥ë¯¸ê°€ ìƒê²¼ìŠµë‹ˆë‹¤.\nëŒ€ì‹œë³´ë“œ # í•œë‹¬ ì „ì¯¤, ì™¸ë¶€ ì—…ì²´ë¥¼ í†µí•´ ì™¸ì£¼ë¥¼ ë§¡ê¸°ë©´ì„œ êµ¬ê¸€ ë°ì´í„° ìŠ¤íŠœë””ì˜¤ êµìœ¡ì„ ë“¤ì—ˆëŠ”ë°,\nìµœê·¼ë“¤ì–´ì„œëŠ” ì´ë¥¼ í™œìš©í•œ ëŒ€ì‹œë³´ë“œ ì œì‘ì— ê°œë°œí•˜ëŠ” ê²ƒë³´ë‹¤ ë§ì€ ì‹œê°„ì„ ì“°ê³  ìˆìŠµë‹ˆë‹¤.\nëŒ€ì‹œë³´ë“œ ì œì‘ ìì²´ëŠ” ì´ë¯¸ ì˜ˆìƒëœ ì¼ì´ì—ˆê¸° ë•Œë¬¸ì— íƒœë¸”ë¡œë¥¼ ê³µë¶€í•œ ì´ë ¥ì´ ìˆëŠ”ë°,\nì˜ˆìƒê³¼ ë‹¤ë¥¸ BI íˆ´ì„ ì‚¬ìš©í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\níƒœë¸”ë¡œì™€ ë¹„êµí–ˆì„ ë•Œ êµ¬ê¸€ ë°ì´í„° ìŠ¤íŠœë””ì˜¤ëŠ” ë¬´ë£Œë¼ëŠ” ì¥ì ê³¼ í•¨ê»˜\nêµ¬ê¸€ í”Œë«í¼ ë‚´ì—ì„œ ì‰½ê²Œ ì˜¨ë¼ì¸ìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤ëŠ” í¸ì˜ì„±ì´ ìˆì§€ë§Œ,\níƒœë¸”ë¡œ ëŒ€ë¹„ ë§ì´ ë¶€ì¡±í•œ ê¸°ëŠ¥ê³¼ íˆ¬ë°•í•œ ê·¸ë˜í”„ ë””ìì¸ì˜ ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.\níƒœë¸”ë¡œì˜ Fixed LODë‚˜ íˆ´íŒ ì»¤ìŠ¤í„°ë§ˆì´ì§•ê³¼ ê°™ì€ ê¸°ëŠ¥ì´ ì—†ëŠ” ê²ƒì´ ë‹¤ì†Œ ë‹µë‹µí•˜ì§€ë§Œ,\nìµœëŒ€ ì¥ì ì¸ êµ¬ê¸€ í”Œë«í¼ ë‚´ ì—°ë™ì„±ì˜ ì¥ì ì„ ì‚´ë ¤ ìˆœìœ„ ë¹„êµì™€ ê°™ì€ ì„¤ì •ì„\nêµ¬ê¸€ ì‹œíŠ¸ ë‚´ì—ì„œ êµ¬í˜„í•˜ê³  êµ¬ê¸€ ë°ì´í„° ìŠ¤íŠœë””ì˜¤ ë‚´ì— í•„ë“œë¡œ ì—°ë™ì‹œí‚¤ëŠ” ë°©ì‹ì„ í™œìš©í–ˆìŠµë‹ˆë‹¤.\në•ë¶„ì— êµ¬ê¸€ ì‹œíŠ¸ì˜ ARRAYFORMULA ë“±ì˜ í•¨ìˆ˜ì— ìµìˆ™í•´ì§€ê²Œ ë˜ì—ˆê³ ,\nêµ¬ê¸€ ì‹œíŠ¸ì˜ ë§¤í¬ë¡œë¼ê³  í•  ìˆ˜ ìˆëŠ” ì•± ìŠ¤í¬ë¦½íŠ¸ë„ ì¡°ì‘í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\nì•± ìŠ¤í¬ë¦½íŠ¸ì˜ ê²½ìš° ìë°”ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ì´ê¸° ë•Œë¬¸ì— í¬ë¡¤ë§ ê³¼ì •ì—ì„œ ëŠë‚€\nìë°”ìŠ¤í¬ë¦½íŠ¸ì— ëŒ€í•œ í¥ë¯¸ë¥¼ ê°€ì§€ê³  ì¬ë°Œê²Œ í™œìš©í–ˆìŠµë‹ˆë‹¤.\nêµ¬ê¸€ ë°ì´í„° ìŠ¤íŠœë””ì˜¤ë„ 1ì£¼ ì´ìƒ ì‚¬ìš©í•´ë³´ë©´ì„œ ì—…ë¬´í˜„í™©ì„ ê´€ë¦¬í•˜ê±°ë‚˜\në§¤ì¶œ ë“±ì„ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ëŒ€ì‹œë³´ë“œë¥¼ ì œì‘í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nê°„ë‹¨í•œ ê²ƒì€ í…Œì´ë¸” ê³„ì‚°ì‹ìœ¼ë¡œ, ì–´ë ¤ìš´ ê²ƒì€ êµ¬ê¸€ ì‹œíŠ¸ë¡œ ë– ë„˜ê¸°ë‹¤ë³´ë‹ˆ\níƒœë¸”ë¡œ ëŒ€ë¹„ ë¶€ì¡±í•œ ê¸°ëŠ¥ì˜ ë‹¨ì ì„ ì–´ëŠì •ë„ ë³´ì™„í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\níšŒì‚¬ ì°¨ì›ì—ì„œëŠ” í–¥í›„ ëŒ€ì‹œë³´ë“œì™€ ì—°ê³„í•  ë°ì´í„° ì ì¬ë¥¼ ìœ„í•´ ë¹…ì¿¼ë¦¬ ë„ì…ì„ ê³ ë ¤í•˜ê³  ìˆëŠ”ë°,\në‹¹ì¥ì˜ ì €ëŠ” êµ¬ê¸€ ì‹œíŠ¸ APIë¥¼ í†µí•œ ì—…ë¡œë“œë¥¼ í†µí•´ ë‹¤ìŒ ë°œì „ì— ëŒ€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\nì•ìœ¼ë¡œ # ì´ ê¸€ì„ ì‘ì„±í•˜ê³  ìˆëŠ” ì‹œì ì˜ ì €ëŠ” í•œ ì£¼ ê°€ê¹Œì´ ê°ê¸°ì— ê±¸ë¦° ê²ƒê³¼ í•¨ê»˜\ní˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì—…ë¬´ê°€ ëŒ€ë¶€ë¶„ ë§ˆë¬´ë¦¬ë˜ë©´ì„œ ë¬´ë£Œí•œ ìƒíƒœë¥¼ ë³´ë‚´ê³  ìˆìŠµë‹ˆë‹¤.\në°¤ë‚®ì—†ì´ í•˜ë£¨ì¢…ì¼ ì¼ë§Œ í–ˆë˜ ì´ì „ê³¼ ëŒ€ë¹„í•´ì„œ í¸í•´ì§„ ê²ƒì€ ìˆì§€ë§Œ,\nê°‘ì‘ê¸° í• ì¼ì´ ì¤„ì–´ë“  ê²ƒê³¼ í•¨ê»˜ ê°ê¸°ë¡œ ì¸í•œ ì‹¬ê²½ì˜ ë³€í™”ë¡œ ë‹¤ì†Œ ì˜ìš•ì´ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤.\nìŠ¬ëŸ¼í”„ë³´ë‹¤ëŠ” ì•½í•œ ìˆ˜ì¤€ì˜ ì¼ì‹œì ì¸ í˜„ìƒì´ë¼ê³  ìƒê°í•˜ì§€ë§Œ,\ní–¥í›„ í¥ë¯¸ë¥¼ ë‹êµ´ ìƒˆë¡œìš´ ì¼ê±°ë¦¬ë¥¼ ì°¾ì§€ ëª»í•œë‹¤ë©´ ì¢‹ì§€ ëª»í•œ ë°©í–¥ìœ¼ë¡œ ê°ˆ ê²ƒì´ë¼ ìƒê°í•©ë‹ˆë‹¤.\nê°œì¸ì ì¸ ì°¨ì›ì—ì„œ í‰ì†Œ ê¸°íší•˜ê³ ë§Œ ìˆë˜ í¬ë¡¤ë§ì„ ê°œë°œí•˜ê³ ëŠ” ìˆì§€ë§Œ,\nì´ë³´ë‹¤ ë”ìš± ë°œì „í•´ì„œ íŒ€ ë‹¨ìœ„ì˜ ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ë¥¼ ê¸°ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\nì•¼ê·¼ì˜ ë¶ˆí™•ì‹¤ì„±ë„ ë§ì´ ê°œì„ ë˜ì—ˆê¸°ì— ì´ì œëŠ” ê°œë°œìë¼ë¦¬ì˜ ìŠ¤í„°ë””ë¥¼ í†µí•´\nê¸°ìˆ ì  ë°œì „ê³¼ ë„¤íŠ¸ì›Œí‚¹ì„ ê°™ì´ ì±™ê²¨ë³´ë ¤ í•©ë‹ˆë‹¤.\n"},{"id":17,"href":"/blog/datacamp-tableau/","title":"[DataCamp] Tableau Courses","section":"Posts","content":"ê°€ì§œì—°êµ¬ì†Œì—ì„œ ì§€ì›í•˜ëŠ” Data Science Fellowship(DSF) í”„ë¡œê·¸ë¨ì„ í†µí•´\nê°œì¸ ìŠ¤í„°ë”” ë©¤ë²„ì˜ ê¶Œí•œìœ¼ë¡œ 1ë…„ ë™ì•ˆ ì´ìš©ê°€ëŠ¥í•œ DataCamp ë¼ì´ì„¼ìŠ¤ë¥¼ íšë“í•˜ì˜€ìŠµë‹ˆë‹¤.\nDataCampëŠ” ë°ì´í„° ì§êµ°ê³¼ ê´€ë ¨ëœ 300ê°œ ì´ìƒì˜ ê°•ì¢Œë¥¼ ì œê³µí•˜ëŠ” í”Œë«í¼ìœ¼ë¡œ,\nì €ëŠ” ì´ˆê¸°ì— ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê¸°ìˆ ì„ ëª©ì ìœ¼ë¡œ í•´ë‹¹ í”„ë¡œê·¸ë¨ì— ì§€ì›í–ˆì§€ë§Œ\nê°‘ì‘ìŠ¤ëŸ½ê²Œ íƒœë¸”ë¡œë¥¼ í™œìš©í•´ì•¼í•  í•„ìš”ê°€ ìƒê²¨ ê´€ë ¨ëœ íŠ¸ë™ ê³¼ì •ì„ ìˆ˜ê°•í•˜ê³  ìˆìŠµë‹ˆë‹¤.\nì œê°€ í˜„ì¬ ìˆ˜ê°•í•˜ê³  ìˆëŠ” íŠ¸ë™ì€ Tableau Fundamentalsì´ë©°,\nê°ê°ì˜ ê³¼ì •ì„ ìˆ˜ë£Œí•˜ê³  í•™ìŠµ ë‚´ìš©, í›„ê¸° ë“±ì„ ì •ë¦¬í•  ì˜ˆì •ì…ë‹ˆë‹¤.\nì§„ë„ê°€ ì§„í–‰ë¨ì— ë”°ë¼ í•´ë‹¹ ê²Œì‹œê¸€ì„ ì—…ë°ì´íŠ¸í•  ê²ƒì´ë©°,\ní–¥í›„ SQL, ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤, ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ë“±ì˜ íŠ¸ë™ë„ ê³„íší•˜ê³  ìˆìŠµë‹ˆë‹¤.\nì•„ë˜ ì œëª©ê³¼ ì—°ê²°ë˜ëŠ” ë§í¬ì— ì ‘ì†í•˜ê¸° ìœ„í•´ì„  DataCamp íšŒì›ê°€ì… ë° ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\nIntroduction to Tableau # Introduction to Tableau ê³¼ì •ì€ íƒœë¸”ë¡œ ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ êµ¬ì„±ì— ì´ë¥´ëŠ” ì „ë°˜ì ì¸ ê¸°ëŠ¥ì„\nê°„ë‹¨í•˜ê²Œ ì´í•´í•˜ê³  ë‹¤ë¤„ë³´ê¸° ìœ„í•œ ê³¼ì •ìœ¼ë¡œ, ì•„ë˜ 4ê°œì˜ ì±•í„°ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\nGetting Started with Tableau Building and Customizing Visualizations Digging Deeper Presenting Your Data ìœˆë„ìš° ê°€ìƒ í™˜ê²½ ìƒì—ì„œ ë¯¸ë¦¬ ì¤€ë¹„ëœ íƒœë¸”ë¡œ íŒŒì¼ì„ í™œìš©í•´ í•„í„°, í…Œì´ë¸” ê³„ì‚° ë“±ì„ ë”°ë¼í•´ë³´ê³ \nì§€ë„, ì‹œê³„ì—´ ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë°ì´í„°ë¥¼ ë‹¤ë¤„ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\në§ˆì§€ë§‰ ì±•í„°ì—ì„œëŠ” íŠ¹íˆ ê²Œì„ í”Œë«í¼ ë³„ ë§¤ì¶œ ë°ì´í„°ë¥¼ í™œìš©í•´ ëŒ€ì‹œë³´ë“œ ë° ì•¡ì…˜ì„ êµ¬í˜„í•´ë³´ê³ \nì‹œíŠ¸, ëŒ€ì‹œë³´ë“œ, ìŠ¤í† ë¦¬ì˜ ì°¨ì´ì— ëŒ€í•´ ì•Œì•„ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nì§§ì€ ê°•ì˜ë¥¼ ìˆ˜ê°•í•œ í›„ ì‹¤ì œ íƒœë¸”ë¡œ í”„ë¡œê·¸ë¨ ìƒì—ì„œ ë°”ë¡œ ì‹¤ìŠµì„ ìˆ˜í–‰í•´ë³¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—\nì§€ë£¨í•˜ì§€ ì•Šìœ¼ë©´ì„œ ì‰½ê²Œ íƒœë¸”ë¡œì˜ ê¸°ëŠ¥ì„ ìµí ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\në¶ˆíŠ¹ì • ë‹¤ìˆ˜ì—ê²Œ ì œê³µë˜ëŠ” ê°€ìƒ í™˜ê²½ì´ë¼ëŠ” íŠ¹ì„± ìƒ ì¡°ì‘ì— ë‹¤ì†Œ ë”œë ˆì´ë¥¼ ëŠê¼ˆì§€ë§Œ,\nê°•ì˜ë¥¼ ë“£ê³  ì¦‰ê°ì ìœ¼ë¡œ í™œìš©í•´ë³¼ ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²½í—˜ì€ ë§¤ìš° ìƒˆë¡œì› ìŠµë‹ˆë‹¤.\nAnalyzing Data in Tableau # Analyzing Data in Tableau ê³¼ì •ì€ ì „ë¬¸ì ì¸ ìˆ˜ì¤€ì—ì„œ\në°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ê¸°ìˆ ì„ ìµíˆê¸° ìœ„í•œ ê³¼ì •ìœ¼ë¡œ, ì•„ë˜ 4ê°œì˜ ì±•í„°ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\nPreparing for Analysis Exploring Visualizations Mapping Analysis Groups, Sets, and Parameters í•™ìŠµ ì¤‘\n"},{"id":18,"href":"/blog/hugo-blog-3/","title":"Hugo ë¸”ë¡œê·¸ ë§Œë“¤ê¸° (3) - í…Œë§ˆ ì»¤ìŠ¤í„°ë§ˆì´ì§•","section":"Posts","content":"Hugo ë¸”ë¡œê·¸ ë§Œë“¤ê¸° (3) - í…Œë§ˆ ì»¤ìŠ¤í„°ë§ˆì´ì§• # ë¸”ë¡œê·¸ë¥¼ êµ¬ì„±í•  ë•Œ ê¸°ìˆ ì , ì‹œê°„ì  í•œê³„ ë•Œë¬¸ì— ì´ë¯¸ ë§Œë“¤ì–´ì§„ í…Œë§ˆë¥¼ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.\nì œê°€ Hugo ë¸”ë¡œê·¸ë¥¼ ë§Œë“¤ ë•Œë„ ì´ëŸ¬í•œ ë¬¸ì œ ë•Œë¬¸ì— PaperMod í…Œë§ˆë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ,\në¸”ë¡œê·¸ë¥¼ ë³´ë‹¤ë³´ë©´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ëª»í•œ ë¶€ë¶„ì´ ë°œê²¬ë©ë‹ˆë‹¤.\nì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì œê°€ PaperMod í…Œë§ˆë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•œ ê³¼ì •ì„ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\nArchive, Search ì¶”ê°€í•˜ê¸° # PaperMod í…Œë§ˆë¥¼ ê°€ì ¸ì˜¤ë©´ì„œ ê°€ì¥ ì‹ ê²½ì“°ì˜€ë˜ ë¶€ë¶„ì€\në©”ì¸ ë©”ë‰´ê°€ Categories, Tags ë‘ ê°œ ë¿ì´ì—ˆë‹¨ ì ì…ë‹ˆë‹¤.\nArchiveëŠ” ê·¸ë ‡ë‹¤ì³ë„ Search ê¸°ëŠ¥ì€ ë¹¼ë¨¹ì„ ìˆ˜ ì—†ëŠ” ë¶€ë¶„ì´ë¼ ìƒê°í•˜ê¸° ë•Œë¬¸ì—,\nHugo ë° PaperMod ë‚´ ì´ìŠˆë¥¼ ì°¸ê³ í•˜ì—¬ ê´€ë ¨ëœ ë‚´ìš©ì„ íƒìƒ‰í–ˆìŠµë‹ˆë‹¤.\në‹¤í–‰íˆ PaperMod í…Œë§ˆì—ì„œ í•´ë‹¹ ê¸°ëŠ¥ì„ ì—°ê²°í•˜ì§€ ì•Šì•˜ì„ ë¿,\nê¸°ëŠ¥ì— ëŒ€í•œ ë ˆì´ì•„ì›ƒì€ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— content/ ë””ë ‰í† ë¦¬ ì•„ë˜ ë‹¤ìŒê³¼ ê°™ì€ íŒŒì¼ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\nCopy yaml # content/archive.md --- title: \u0026#34;Archive\u0026#34; layout: \u0026#34;archives\u0026#34; url: \u0026#34;/archive\u0026#34; summary: \u0026#34;archive\u0026#34; --- Copy yaml # content/search.md --- title: \u0026#34;Search\u0026#34; layout: \u0026#34;search\u0026#34; url: \u0026#34;/search\u0026#34; summary: \u0026#34;search\u0026#34; --- ì¶”ê°€ë¡œ, ì„¤ì •ì—ì„œë„ í•´ë‹¹ íŒŒì¼ì„ ì¸ì‹í•´ì•¼ë˜ê¸° ë•Œë¬¸ì— ë‹¤ìŒê³¼ ê°™ì€ ì„¤ì •ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\npost/ ì™¸ì— ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ë¥¼ ë“±ë¡í•˜ê³  ì‹¶ì€ ê²½ìš°ì—ë„ í•´ë‹¹ í‚¤ê°’ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy yaml params: mainsections: [\u0026#34;page\u0026#34;, \u0026#34;post\u0026#34;, \u0026#34;archive\u0026#34;, \u0026#34;search\u0026#34;] ë§ˆì§€ë§‰ìœ¼ë¡œ, ë©”ì¸ ë©”ë‰´ì—ì„œ í•´ë‹¹ ë§í¬ë¡œ ì´ë™í•˜ê¸° ìœ„í•œ ë°”ë¡œê°€ê¸°ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\nì—¬ê¸°ì—ëŠ” ì¹´í…Œê³ ë¦¬, íƒœê·¸ ë“±ì´ ìˆì„ê±´ë° weight ê°’ì„ í†µí•´ ì ì ˆí•˜ê²Œ ìœ„ì¹˜ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy yaml menu: main: - identifier: archive name: Archive url: /archive/ weight: 10 - identifier: search name: Search url: /search/ weight: 20 ìœ„ì™€ ê°™ì€ ê³¼ì •ì„ í†µí•´ Archive, Search ê¸°ëŠ¥ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\nê²€ìƒ‰ ì—”ì§„ ë“±ë¡í•˜ê¸° # ê²€ìƒ‰ ì—”ì§„ì— ë“±ë¡í•˜ê¸° ìœ„í•œ ê³¼ì •ì€ í•´ë‹¹ ì˜ìƒì„ ì°¸ê³ í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\nì €ëŠ” ìœ„ ê³¼ì •ì—ì„œ ë¸”ë¡œê·¸ ë‚´ì— ì¶”ê°€í•´ì•¼ í•  Site Verification Tagë¥¼ ì¶”ê°€í•˜ëŠ” ë²•ì„ ì „ë‹¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\nPaperMod í…Œë§ˆì—ì„œëŠ” ì•„ë˜ì²˜ëŸ¼ í•´ë‹¹ ë¶€ë¶„ì´ ë§Œë“¤ì–´ì ¸ ìˆê¸° ë•Œë¬¸ì— í¬ê²Œ ê±±ì •í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.\nì•„ë˜ëŠ” layouts/partials/ ë‚´ì— head.html íŒŒì¼ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\nCopy html {{- if site.Params.analytics.google.SiteVerificationTag }} \u0026lt;meta name=\u0026#34;google-site-verification\u0026#34; content=\u0026#34;{{ site.Params.analytics.google.SiteVerificationTag }}\u0026#34;\u0026gt; {{- end }} {{- if site.Params.analytics.yandex.SiteVerificationTag }} \u0026lt;meta name=\u0026#34;yandex-verification\u0026#34; content=\u0026#34;{{ site.Params.analytics.yandex.SiteVerificationTag }}\u0026#34;\u0026gt; {{- end }} {{- if site.Params.analytics.bing.SiteVerificationTag }} \u0026lt;meta name=\u0026#34;msvalidate.01\u0026#34; content=\u0026#34;{{ site.Params.analytics.bing.SiteVerificationTag }}\u0026#34;\u0026gt; {{- end }} {{- if site.Params.analytics.naver.SiteVerificationTag }} \u0026lt;meta name=\u0026#34;naver-site-verification\u0026#34; content=\u0026#34;{{ site.Params.analytics.naver.SiteVerificationTag }}\u0026#34;\u0026gt; {{- end }} êµ¬ê¸€, ë„¤ì´ë²„ ì™¸ì— Bing, Yandexë¥¼ ì§€ì›í•˜ë©° ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ê¸€ê³¼ ë„¤ì´ë²„ë§Œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\nCopy yaml params: analytics: google: SiteVerificationTag: \u0026lt;YOUR-VERIFICATION-TAG\u0026gt; naver: SiteVerificationTag: \u0026lt;YOUR-VERIFICATION-TAG\u0026gt; ë²ˆì™¸ë¡œ Google Tag ë“± headì— ì¶”ê°€ë¡œ ì…ë ¥í•  ë¶€ë¶„ì´ ìˆë‹¤ë©´,\në™ì¼í•œ ìœ„ì¹˜ì— extend_head.htmlì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì•„ë˜ëŠ” ì œê°€ extend_head.html ë‚´ì— Google Tagë¥¼ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¶”ê°€í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.\nCopy html {{- if site.GoogleAnalytics }} {{- /* Google tag (gtag.js) */}} \u0026lt;script async src=\u0026#34;https://www.googletagmanager.com/gtag/js?id={{ site.GoogleAnalytics }}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\u0026#39;js\u0026#39;, new Date()); gtag(\u0026#39;config\u0026#39;, \u0026#39;{{ site.GoogleAnalytics }}\u0026#39;); \u0026lt;/script\u0026gt; {{- end }} KaTex ì¶”ê°€í•˜ê¸° # KaTexëŠ” ì›¹ì—ì„œ ìˆ˜ì‹ì„ í‘œí˜„í•˜ê¸° ìœ„í•œ ë°©ì‹ì…ë‹ˆë‹¤.\nì œ ê³¼ê±° ê²Œì‹œê¸€ì—” KaTex í‘œê¸°ë²•ì„ ì‚¬ìš©í•œ ê²ƒì´ ì¡´ì¬í•˜ëŠ”ë° ì´ê²ƒì´ ì œëŒ€ë¡œ í‘œì‹œë˜ì§€ ì•ŠëŠ” ë¬¸ì œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\nì €ëŠ” ê³µì‹ ë¬¸ì„œ ëŒ€ì‹  Stack Overflow ë“±ì„ ì°¸ê³ í•´ ì•„ë˜ ì½”ë“œë¥¼ extend_head.htmlì— ì¶”ê°€í–ˆëŠ”ë°,\nì•„ì‰½ê²Œë„ ì¶œì²˜ëŠ” ë‚¨ê²¨ë‘ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\nCopy html \u0026lt;script\u0026gt; MathJax = { tex: { inlineMath: [[\u0026#39;$\u0026#39;, \u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;, \u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\\\[\u0026#39;, \u0026#39;\\\\]\u0026#39;]], processEscapes: true, processEnvironments: true }, options: { skipHtmlTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;] } }; window.addEventListener(\u0026#39;load\u0026#39;, (event) =\u0026gt; { document.querySelectorAll(\u0026#34;mjx-container\u0026#34;).forEach(function(x){ x.parentElement.classList += \u0026#39;has-jax\u0026#39;}) }); \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://polyfill.io/v3/polyfill.min.js?features=es6\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; id=\u0026#34;MathJax-script\u0026#34; async src=\u0026#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Cover ê°„í¸í•˜ê²Œ ì§€ì •í•˜ê¸° # ì €ëŠ” Github ì €ì¥ì†Œ ë‚´ì— ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ ì£¼ì†Œë¥¼ ì†ì„±ê°’ì— ì—°ê²°í•´ ë¸”ë¡œê·¸ ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•˜ëŠ”ë°,\nê²Œì‹œê¸€ì„ ì‘ì„±í•  ë•Œë§ˆë‹¤ ì§€ì •í•˜ê²Œ ë˜ëŠ” Cover ì´ë¯¸ì§€ì˜ ê²½ìš° ë§¤ë²ˆ ì „ì²´ ë§í¬ë¥¼ ì§€ì •í•˜ëŠ”ê²Œ ë¶ˆí¸í–ˆìŠµë‹ˆë‹¤.\nëŒ€í‘œì ìœ¼ë¡œ í•´ë‹¹ ê²Œì‹œê¸€ì˜ Cover ì´ë¯¸ì§€ ì£¼ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\nCopy html https://github.com/minyeamer/til/blob/main/.media/covers/hugo-logo.png?raw=true ì €ëŠ” ì—¬ê¸°ì„œ hugo-logo.pngë¥¼ ì œì™¸í•œ ì•ë’¤ì˜ ìš”ì†Œê°€ ë¶ˆí•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì¸ì‹í–ˆê³ \nì„¤ì • íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ prefix, suffixë¼ëŠ” í‚¤ê°’ìœ¼ë¡œ ì§€ì •í•˜ê²Œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.\nCopy yaml params: cover: prefix: \u0026#34;https://github.com/minyeamer/til/blob/main/.media/covers/\u0026#34; suffix: \u0026#34;?raw=true\u0026#34; ê·¸ë¦¬ê³  í•´ë‹¹ ì„¤ì •ì„ ì ìš©ì‹œí‚¤ê¸° ìœ„í•´ ì‹¤ì§ˆì ìœ¼ë¡œ Cover ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•˜ëŠ” layouts/partials/ ì•„ë˜ cover.html íŒŒì¼ì„ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.\nì£¼ì„ìœ¼ë¡œ ì§€ì •ëœ ë¶€ë¶„ì´ ì›ë³¸ì´ë©°, image í‚¤ê°’ì˜ ì•ë’¤ë¡œ prefixì™€ suffixë¥¼ ë§ë¶™ì˜€ìŠµë‹ˆë‹¤.\nCopy html \u0026lt;!-- {{- if $addLink }}\u0026lt;a href=\u0026#34;{{ (.Params.cover.image) | absURL }}\u0026#34; target=\u0026#34;_blank\u0026#34; rel=\u0026#34;noopener noreferrer\u0026#34;\u0026gt;{{ end -}} \u0026lt;img loading=\u0026#34;lazy\u0026#34; src=\u0026#34;{{ (.Params.cover.image) | absURL }}\u0026#34; alt=\u0026#34;{{ $alt }}\u0026#34;\u0026gt; --\u0026gt; {{- if $addLink }}\u0026lt;a href=\u0026#34;{{ if site.Params.cover.prefix }}{{ site.Params.cover.prefix }}{{ end }}{{ .Params.cover.image }}{{ if site.Params.cover.suffix }}{{ site.Params.cover.suffix }}{{ end }}\u0026#34; target=\u0026#34;_blank\u0026#34; rel=\u0026#34;noopener noreferrer\u0026#34;\u0026gt;{{ end -}} \u0026lt;img loading=\u0026#34;lazy\u0026#34; src=\u0026#34;{{ if site.Params.cover.prefix }}{{ site.Params.cover.prefix }}{{ end }}{{ .Params.cover.image }}{{ if site.Params.cover.suffix }}{{ site.Params.cover.suffix }}{{ end }}\u0026#34; alt=\u0026#34;{{ $alt }}\u0026#34;\u0026gt; ê¸°íƒ€ ì„¤ì • # ë„ˆë¹„ ì„¤ì • # ì´ˆê¸°ì— PaperMod í…Œë§ˆë¥¼ ì‚¬ìš©í•  ë•Œ ë„ˆë¹„ê°€ ì¢ì•„ ë¶ˆí¸í•œ ëŠë‚Œì´ ìˆì—ˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ ì„¤ì •ì€ css íŒŒì¼ë¡œ ì§€ì •í•  ê²ƒì´ë¼ ìƒê°í–ˆê³ ,\nassets/css/core/ ê²½ë¡œì— ìˆëŠ” theme-vars.css íŒŒì¼ì„ ë°œê²¬í•´ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.\nê¸°ì¡´ 720pxì—ì„œ 900pxë¡œ ëŠ˜ì–´ë‚˜ ì¾Œì í•˜ê²Œ ë¸”ë¡œê·¸ë¥¼ ë³¼ ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nCopy css :root { --main-width: 900px; ìƒˆ íƒ­ì—ì„œ ë§í¬ ì—´ê¸° # ë‹¤ìŒìœ¼ë¡œ ê´€ì‹¬ì„ ê°€ì§„ ê±´ ê¹ƒí—ˆë¸Œì—ì„œ ë§¤ë²ˆ ë¶ˆí¸í•˜ê²Œ ìƒê°í–ˆë˜ ë§í¬ ì˜¤í”ˆ ë°©ì‹ì¸ë°,\nê°œì¸ì ìœ¼ë¡œëŠ” í˜„ì¬ íƒ­ì´ ì•„ë‹Œ ìƒˆ íƒ­ì—ì„œ ì—´ë¦¬ëŠ” ë°©ì‹ì„ ì„ í˜¸í•˜ê¸° ë•Œë¬¸ì— í•´ë‹¹ ë¶€ë¶„ì˜ ìˆ˜ì •ì´ í•„ìš”í–ˆìŠµë‹ˆë‹¤.\në‹¤í–‰íˆ Hugo ì´ìŠˆ ë‚´ìš© ì¤‘ ë‹¤ìŒê³¼ ê°™ì€ ë‹µë³€ì„ ì°¸ê³ í•´ íŒŒì¼ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\nì•„ë˜ëŠ” layouts/_default/_markup/ ê²½ë¡œì— ì¶”ê°€í•œ render-link.html íŒŒì¼ì…ë‹ˆë‹¤.\nCopy html \u0026lt;a href=\u0026#34;{{ .Destination | safeURL }}\u0026#34;{{ with .Title}} title=\u0026#34;{{ . }}\u0026#34;{{ end }}{{ if strings.HasPrefix .Destination \u0026#34;http\u0026#34; }} target=\u0026#34;_blank\u0026#34; rel=\u0026#34;noopener\u0026#34;{{ end }}\u0026gt;{{ .Text | safeHTML }}\u0026lt;/a\u0026gt; í¬ìŠ¤íŠ¸ ìˆ˜ì • # ë§ˆì§€ë§‰ìœ¼ë¡œ í¬ìŠ¤íŠ¸ ìˆ˜ì • ë²„íŠ¼ì— ë¬¸ì œë¥¼ ì¸ì‹í–ˆìŠµë‹ˆë‹¤.\në¬¼ë¡ , ëª¨ë“  í¬ìŠ¤íŠ¸ëŠ” ë¡œì»¬ì—ì„œ ì‘ì„±í•˜ê³  ìˆ˜ì •í•˜ì§€ë§Œ, ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ë²„íŠ¼ì„ ê·¸ëƒ¥ ë†”ë‘˜ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤.\nGoì— ëŒ€í•´ ì˜ ì•Œì§€ ëª»í•´ ìµœì„ ì˜ ê¸°ëŠ¥ì´ë¼ê³  ìƒê°í•˜ì§€ëŠ” ì•Šì§€ë§Œ,\nê²€ìƒ‰ì„ í†µí•´ ë°œê²¬í•œ replace í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ê¸°ì¡´ ê²½ë¡œì—ì„œ ì˜¤ë¥˜ë¥¼ ì¼ìœ¼í‚¤ëŠ” ë¶€ë¶„ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.\nCopy html {{- if or .Params.editPost.URL site.Params.editPost.URL -}} {{- $fileUrlPath := path.Join .File.Path }} {{- if or .Params.author site.Params.author (.Param \u0026#34;ShowReadingTime\u0026#34;) (not .Date.IsZero) .IsTranslated }}\u0026amp;nbsp;|\u0026amp;nbsp;{{- end -}} \u0026lt;a href=\u0026#39;{{ .Params.editPost.URL | default site.Params.editPost.URL }}{{ if .Params.editPost.appendFilePath | default ( site.Params.editPost.appendFilePath | default false ) }}/{{ replace $fileUrlPath site.Params.editPost.ignoreFilePath \u0026#34;\u0026#34; 1 }}{{ end }}\u0026#39; rel=\u0026#34;noopener noreferrer\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; {{- .Params.editPost.Text | default (site.Params.editPost.Text | default (i18n \u0026#34;edit_post\u0026#34; | default \u0026#34;Edit\u0026#34;)) -}} \u0026lt;/a\u0026gt; {{- end }} ê°œì„ ì‚¬í•­ # í˜„ì¬ PaperMod í…Œë§ˆì˜ ì¹´í…Œê³ ë¦¬ëŠ” ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ íƒœê·¸ì™€ ë™ì¼í•œ ë¦¬ìŠ¤íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ëŠ”ë°,\nê°œì¸ì ìœ¼ë¡œëŠ” íŠ¸ë¦¬ í˜•íƒœì˜ ê³„ì¸µì‹ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.\nì–¸ì œë‚˜ì²˜ëŸ¼ PaperMod ì´ìŠˆë¥¼ íƒìƒ‰í•˜ë˜ ì¤‘ í•´ë‹¹ ì´ìŠˆë¥¼ ë°œê²¬í–ˆëŠ”ë°,\nì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ ì œê°€ ë¨¸ë¦¿ì†ì— ê·¸ë¦¬ë˜ ë°©ì‹ì„ ê·¸ëŒ€ë¡œ í‘œí˜„í•˜ì—¬ í° ê´€ì‹¬ì„ ê°€ì¡ŒìŠµë‹ˆë‹¤.\ní•´ë‹¹ ê¸°ëŠ¥ì„ êµ¬í˜„í•œ ë¶„ê»˜ ë©”ì¼ì„ ë³´ë‚´ ì°¸ê³  ìë£Œë¥¼ ì–»ì—ˆì§€ë§Œ,\nì•„ì§ê¹Œì§„ ì‹œê°„ì  ì—¬ìœ ê°€ ë¶€ì¡±í•´ í•´ë‹¹ ì‘ì—…ì„ ì²˜ë¦¬í•˜ì§€ ëª»í•œ ìƒíƒœì…ë‹ˆë‹¤.\ní–¥í›„ ê°œì„ ë˜ê¸°ë¥¼ í¬ë§í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.\në§ˆì¹˜ë©° # Hugo ë¸”ë¡œê·¸ ë§Œë“¤ê¸° ì‹œë¦¬ì¦ˆì˜ ë§ˆì§€ë§‰ìœ¼ë¡œ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê³¼ì •ì„ ì†Œê°œí–ˆìŠµë‹ˆë‹¤.\nì»¤ìŠ¤í„°ë§ˆì´ì§•ì€ ê·¸ë•Œê·¸ë•Œ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ë¶€ë¶„ì„ ìˆ˜ì •í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì—\në³¸ì¸ì˜ ì…ë§›ì— ë§›ëŠ” ë¸”ë¡œê·¸ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” í…Œë§ˆì˜ êµ¬ì¡°ë¥¼ ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤.\nì•„ì§ Goì— ëŒ€í•´ì„œë„ ì˜ ëª°ë¼ ê²€ìƒ‰ì„ í†µí•´ ìš”ë ¹ê» ì°¾ì•„ë‚´ëŠ” ìˆ˜ì¤€ì´ì§€ë§Œ,\nGoì— ìµìˆ™í•´ì§€ê²Œ ëœë‹¤ë©´ ë™ì  TOC ë“± ê¸°ëŠ¥ì˜ ê°œì„ ì„ ê¸°ëŒ€í•´ ë³¼ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\ní•´ë‹¹ ê²Œì‹œê¸€ì„ í†µí•´ Hugo ë¸”ë¡œê·¸ ë§Œë“¤ê¸°ì— ë„ì›€ì´ ë˜ì—ˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\nì°¸ê³  ìë£Œ # EP09. êµ¬ê¸€, ë„¤ì´ë²„ ê²€ìƒ‰ì—”ì§„ ë“±ë¡í•˜ê¸° KaTex Simple way to open in a new tab [Feature][Discussion] Tree-style category list page "},{"id":19,"href":"/blog/hugo-blog-2/","title":"Hugo ë¸”ë¡œê·¸ ë§Œë“¤ê¸° (2) - Utterances ëŒ“ê¸€ ì ìš©","section":"Posts","content":"Hugo ë¸”ë¡œê·¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ëŒ“ê¸€ ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.\nì œê°€ ì‚¬ìš©í•˜ëŠ” PaperMod í…Œë§ˆì—ì„œëŠ” ì„œë“œíŒŒí‹° ì„œë¹„ìŠ¤ì¸ Disqusë¥¼ ìœ„í•œ ë ˆì´ì•„ì›ƒì´ ì¡´ì¬í•˜ì§€ë§Œ,\nì €ëŠ” ê¸°ë³¸ì ì¸ ë¸”ë¡œê·¸ ìš´ì˜ì„ Github í”Œë«í¼ ë‚´ì—ì„œ êµ¬ì„±í•˜ê³  ì‹¶ê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ë³´ë ¤ í•©ë‹ˆë‹¤.\nì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” Utterances ëŒ“ê¸€ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\nUtterances ì„¤ì¹˜í•˜ê¸° # UtterancesëŠ” Github issues ê¸°ë°˜ìœ¼ë¡œ ëŒ“ê¸€ì„ ê´€ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\në¬´ë£Œ í”Œëœì—ì„œ ê´‘ê³ ê°€ ë¶™ëŠ” Disqusì™€ ë‹¤ë¥´ê²Œ ë³„ë„ì˜ ìœ ë£Œ í”Œëœì´ ì—†ì–´ ê°„í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nUtterances ì„¤ì¹˜ëŠ” ë‹¨ìˆœíˆ ë ˆì´ì•„ì›ƒ ìƒì—ì„œ ëŒ“ê¸€ì´ ìœ„ì¹˜í•  ê³³ì— ìë°”ìŠ¤í¬ë¦½íŠ¸ ì½”ë“œë¥¼ ì‚½ì…í•˜ë©´ ë©ë‹ˆë‹¤.\ní•˜ì§€ë§Œ, ì„ í–‰ì ìœ¼ë¡œ í•´ë‹¹ ë§í¬ë¥¼ í†µí•´ Utterancesì™€ ì—°ë™ì‹œí‚¬ ì €ì¥ì†Œë¥¼ ë“±ë¡í•´ì•¼ í•©ë‹ˆë‹¤.\në¬´ë£Œ í”Œëœ ì„ íƒ í›„ Utterancesë¥¼ ì ìš©í•  ì €ì¥ì†Œë¥¼ ì„ íƒí•˜ê²Œ ë˜ëŠ”ë°\nëª¨ë“  ì €ì¥ì†Œë¥¼ ì§€ì •í•´ë„ ë˜ì§€ë§Œ, ì €ëŠ” ëŒ“ê¸€ì„ ê´€ë¦¬í•  ì €ì¥ì†Œë§Œ ì§€ì •í•˜ê² ìŠµë‹ˆë‹¤.\nê°„ë‹¨í•˜ê²Œ Utterances ì ìš©ì´ ì™„ë£Œë˜ë©´ ì•„ë˜ ê³µì‹ ë¬¸ì„œ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.\nhttps://utteranc.es/ ê³µì‹ ë¬¸ì„œì—ì„œ ì €ì¥ì†Œ ì´ë¦„, ì´ìŠˆ ë§µí•‘ ë°©ì‹ ë“±ì„ ì§€ì •í•˜ë©´ í•´ë‹¹í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ê°€ ìƒì„±ë©ë‹ˆë‹¤.\nì €ëŠ” í¬ìŠ¤íŠ¸ ì œëª©ì´ ë³€ê²½ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— pathnameì„ ê¸°ì¤€ìœ¼ë¡œ ì´ìŠˆë¥¼ ìƒì„±í•˜ê³ ,\nì‚¬ìš©ì ì‹œìŠ¤í…œ ì„¤ì •ì— í˜¸í™˜ë˜ëŠ” Preferred Color Scheme í…Œë§ˆë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\nCopy html \u0026lt;script src=\u0026#34;https://utteranc.es/client.js\u0026#34; repo=\u0026#34;[ENTER REPO HERE]\u0026#34; issue-term=\u0026#34;pathname\u0026#34; theme=\u0026#34;github-light\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; ìŠ¤í¬ë¦½íŠ¸ ì‚½ì…í•˜ê¸° # PaperMod í…Œë§ˆì—ëŠ” layouts/partials/ ìœ„ì¹˜ì— comments.htmlì´ë¼ëŠ” ë ˆì´ì•„ì›ƒì´ ì¡´ì¬í•©ë‹ˆë‹¤.\ní…Œë§ˆ ë³„ë¡œ ë ˆì´ì•„ì›ƒì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ í…Œë§ˆì˜ ê²½ìš° ì´ìŠˆ ë“±ì„ ì°¸ê³ í•˜ì—¬ êµ¬ì¡°ë¥¼ íŒŒì•…í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\nCopy html {{- /* Comments area start */ -}} {{- /* to add comments read =\u0026gt; https://gohugo.io/content-management/comments/ */ -}} {{- if $.Site.Params.utteranc.enable -}} \u0026lt;script src=\u0026#34;https://utteranc.es/client.js\u0026#34; repo=\u0026#34;{{ .Site.Params.utteranc.repo }}\u0026#34; issue-term=\u0026#34;{{ .Site.Params.utteranc.issueTerm }}\u0026#34; {{- if $.Site.Params.utteranc.label -}}label=\u0026#34;{{ .Site.Params.utteranc.label }}\u0026#34;{{- end }} theme=\u0026#34;{{ .Site.Params.utteranc.theme }}\u0026#34; crossorigin=\u0026#34;{{ .Site.Params.utteranc.crossorigin }}\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; {{- end }} {{- /* Comments area end */ -}} ë‹¨ìˆœí•˜ê²Œ ë ˆì´ì•„ì›ƒì— ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶™ì—¬ë„£ì–´ë„ ë˜ì§€ë§Œ,\ní–¥í›„ ì†ì„±ê°’ì„ ë³€ê²½í•˜ê¸° ìœ„í•´ ë¶ˆí•„ìš”í•˜ê²Œ í…Œë§ˆë¥¼ ìˆ˜ì •í•˜ëŠ” ê²½ìš°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´\nì„¤ì • íŒŒì¼ì„ í†µí•´ ë™ì ìœ¼ë¡œ ì†ì„±ê°’ì„ ì§‘ì–´ë„£ë„ë¡ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\nHugo HTML ì½”ë“œ ë‚´ì— ì´ì¤‘ ì¤‘ê´„í˜¸({{ }})ëŠ” Go í…œí”Œë¦¿ì„ ì½”ë”©í•˜ëŠ” ë¶€ë¶„ìœ¼ë¡œ,\nì•„ë˜ì™€ ê°™ì€ ì„¤ì • íŒŒì¼ì„ ì½ì–´ì„œ ê°ê°ì˜ í‚¤ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ í• ë‹¹í•©ë‹ˆë‹¤.\nì´ì— ëŒ€í•œ ìì„¸í•œ ì‚¬ìš©ë²•ì€ Hugo ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy yaml params: utteranc: enable: true repo: \u0026#34;minyeamer/minyeamer.github.io\u0026#34; issueTerm: \u0026#34;pathname\u0026#34; label: \u0026#34;comments\u0026#34; theme: \u0026#34;preferred-color-scheme\u0026#34; crossorigin: \u0026#34;anonymous\u0026#34; ì •ìƒì ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‚½ì…ë˜ì—ˆë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ ëŒ“ê¸€ì„ ì…ë ¥í•˜ëŠ” ë¶€ë¶„ì´ í‘œì‹œë©ë‹ˆë‹¤.\nëŒ“ê¸€ ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì ìš©ë˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì‹¤í—˜ì ìœ¼ë¡œ ëŒ“ê¸€ì„ ì‘ì„±í•´ë´…ë‹ˆë‹¤.\nì €ë„ ê³¼ê±° ê²Œì‹œê¸€ì— ëŒ“ê¸€ì„ ì‘ì„±í•˜ì—¬ ì•„ë˜ì™€ ê°™ì´ ì˜¬ë¼ì˜¨ ì´ìŠˆë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\në§ˆì¹˜ë©° # Hugo ë¸”ë¡œê·¸ë¥¼ í†µí•œ ì†Œí†µì„ ê¸°ëŒ€í•˜ì—¬ ëŒ“ê¸€ ê¸°ëŠ¥ì„ ì¶”ê°€í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\nìƒê°ë³´ë‹¤ ê°„ë‹¨í•˜ê¸° ë•Œë¬¸ì— ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ë¥¼ ê¾¸ë¯¸ë©´ì„œ ëŒ“ê¸€ ê¸°ëŠ¥ì„ í¬ë§í•˜ì‹œëŠ” ë¶„ë“¤ì´ë¼ë©´\nUtterancesë¥¼ ì ê·¹ í™œìš©í•´ë³´ì‹œê¸°ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\në§ˆì§€ë§‰ í¬ìŠ¤íŠ¸ë¡œëŠ” PaperMod í…Œë§ˆë¥¼ ìˆ˜ì •í•œ ê³¼ì •ì„ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\nHugo í…Œë§ˆë¼ë¦¬ ê³µí†µì ì¸ ë¶€ë¶„ì´ ìˆê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ í…Œë§ˆë¥¼ ì‚¬ìš©í•˜ì‹œë”ë¼ë„ ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.\nì°¸ê³  ìë£Œ # Utterances Documents Introduction to Hugo Templating "},{"id":20,"href":"/blog/hugo-blog-1/","title":"Hugo ë¸”ë¡œê·¸ ë§Œë“¤ê¸° (1) - Hugo ê¸°ë³¸ êµ¬ì„±","section":"Posts","content":"ì–¼ë§ˆ ì „, í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ì—ì„œ Jekyll ë¸”ë¡œê·¸ë¡œ ì´ë™í–ˆëŠ”ë°,\nì²˜ìŒ ê¸°ëŒ€í–ˆë˜ submoduleì„ í™œìš©í•œ íš¨ìœ¨ì ì¸ ì €ì¥ì†Œ ì—°ë™ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªê³  ë‹¤ë¥¸ ëŒ€ì•ˆì„ íƒìƒ‰í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nJekyll ë¸”ë¡œê·¸ë¥¼ ì‚¬ìš©í•¨ì— ìˆì–´ì„œ, Ruby ì–¸ì–´ë¡œ êµ¬ì„±ëœ ë¸”ë¡œê·¸ êµ¬ì¡°ì— ëŒ€í•´ ì´í•´í•˜ê¸° ì–´ë ¤ìš´ë°ë‹¤ê°€\në¡œì»¬ í™˜ê²½ì—ì„œ Jekyll ë¸”ë¡œê·¸ë¥¼ ì‹¤í–‰í•˜ë©´ì„œ ë°œìƒí•˜ëŠ” ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ”ë°ë„ ë‚œí•­ì„ ê²ªì—ˆëŠ”ë°,\nì›¹ìƒì—ì„œ ìë™ ë°°í¬ê°€ ì´ë£¨ì–´ì§€ëŠ” ê³¼ì •ì—ì„œ submoduleì¸ TIL ì €ì¥ì†Œë¥¼ í¬ìŠ¤íŠ¸ë¡œ ì¸ì‹í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.\nJekyll ë¸”ë¡œê·¸ì˜ ëŒ€ì•ˆìœ¼ë¡œ Hexo ë° Hugo í”„ë ˆì„ì›Œí¬ì— ì£¼ëª©í–ˆê³ ,\në‘ ì œí’ˆì˜ ì¥ë‹¨ì ì„ ë¹„êµí•˜ì—¬ ìƒëŒ€ì ìœ¼ë¡œ ë°°í¬ê°€ ë¹ ë¥´ê³  í˜„ì¬ê¹Œì§€ë„ ì—…ë°ì´íŠ¸ê°€ ì´ë£¨ì–´ì§€ëŠ” Hugoë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.\nì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì œê°€ Hugo ë¸”ë¡œê·¸ë¥¼ êµ¬ì„±í•œ ê³¼ì •ì„ ê°„ëµí•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\ní…Œë§ˆ ì„ íƒí•˜ê¸° # ë¸”ë¡œê·¸ì˜ ëª¨ë“  í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ë§Œë“¤ ê³„íšì´ ì•„ë‹ˆë¼ë©´ ë¸”ë¡œê·¸ ì„ íƒì— ìˆì–´ í…Œë§ˆ ì„ ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\nHugoëŠ” ì•„ë˜ í˜ì´ì§€ì—ì„œ ë‹¤ì–‘í•œ í…Œë§ˆë¥¼ ì œê³µí•˜ë©°, íƒœê·¸ë¥¼ í†µí•´ ë¸”ë¡œê·¸ ì™¸ì—ë„ ëª©ì ì— ë§ëŠ” í…Œë§ˆë¥¼ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në¯¸ë¦¬ë³´ê¸°ë§Œìœ¼ë¡œ ì•Œê¸° ì–´ë µë‹¤ë©´ ì œì‘ìê°€ ì œê³µí•˜ëŠ” ë°ëª¨ ì‚¬ì´íŠ¸ë¥¼ ë°©ë¬¸í•´ë³¼ ìˆ˜ ìˆê³ ,\nì•„ë˜ ì•ˆë‚´ë“œë¦´ Hugo ì„¤ì¹˜ë¥¼ í†µí•´ ë¡œì»¬ì—ì„œ exampleSiteë¥¼ í™•ì¸í•´ ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\nhttps://themes.gohugo.io/ Jekyll ë¸”ë¡œê·¸ë¥¼ ì‚¬ìš©í–ˆì„ ë‹¹ì‹œ ì ìš©í–ˆë˜ Chirpy í…Œë§ˆëŠ” ì‚¬ì´ë“œ ë©”ë‰´, ê³„ì¸µì‹ ì¹´í…Œê³ ë¦¬, ë™ì  TOC ë“±\nì œê°€ ì¶”êµ¬í•˜ëŠ” ëª¨ë“  ê¸°ëŠ¥ì„ ê°€ì§€ê³  ìˆì—ˆëŠ”ë°, Hugoì—ëŠ” ì €ì˜ ì·¨í–¥ì„ ì™„ë²½íˆ ë§Œì¡±ì‹œí‚¤ëŠ” í…Œë§ˆê°€ ì—†ì—ˆìŠµë‹ˆë‹¤.\nê·¸ë‚˜ë§ˆ ê´œì°®ì•˜ë˜ LoveIt í…Œë§ˆì˜ ê²½ìš° ì„¤ì • ê³³ê³³ì— ì¤‘êµ­ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì–´ ì´í•´í•˜ê¸° ì–´ë µê² ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆìŠµë‹ˆë‹¤.\nê²°êµ­, ì €ëŠ” ëª¨ë“  í…Œë§ˆë¥¼ ë‘˜ëŸ¬ë³¸ í›„ ë‹¤ë£¨ê¸° ì‰¬ì›Œë³´ì´ë©´ì„œ ì™¸ì ìœ¼ë¡œë„ ê´œì°®ì•˜ë˜ PaperMod í…Œë§ˆë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.\nHugo ë¸”ë¡œê·¸ êµ¬ì„±í•˜ê¸° # ì´ë²ˆ Hugo ë¸”ë¡œê·¸ êµ¬ì„±ì€ Mac í™˜ê²½ì—ì„œ ì§„í–‰ë˜ì—ˆìœ¼ë©°, ë‹¤ë¥¸ í™˜ê²½ì˜ êµ¬ì„± ë°©ì‹ì€ ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\nHugo ì„¤ì¹˜ # Mac ì‚¬ìš©ìë¼ë©´ Homebrewë¥¼ í†µí•´ ì‰½ê²Œ Hugoë¥¼ ì„¤ì¹˜í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní„°ë¯¸ë„ì— ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ ì„¤ì¹˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\nCopy bash brew install hugo ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´, ë²„ì „ ì •ë³´ë¥¼ ì¶œë ¥í•´ì„œ ì •ìƒ ì„¤ì¹˜ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\nCopy bash % hugo version hugo v0.102.2+extended darwin/arm64 BuildDate=unknown Github ì €ì¥ì†Œ ìƒì„± # HugoëŠ” ì›ë³¸ ë°ì´í„° ë° ì„¤ì • íŒŒì¼ì´ í¬í•¨ë  ê³µê°„ê³¼, ë Œë”ë§ëœ í˜ì´ì§€ê°€ ì €ì¥ë  ê³µê°„ì´ í•„ìš”í•©ë‹ˆë‹¤.\nì¼ë°˜ì ìœ¼ë¡œëŠ” ë¶„ë¦¬ëœ ì €ì¥ì†Œë¥¼ í†µí•´ êµ¬í˜„í•˜ì§€ë§Œ, ì•ì„œ Jekyll ë¸”ë¡œê·¸ë¥¼ êµ¬ì„±í•´ë³´ë©´ì„œ\në¸Œëœì¹˜ë¥¼ í†µí•´ í•˜ë‚˜ì˜ ì €ì¥ì†Œì—ì„œ ë‘ ê°œì˜ ê³µê°„ì„ ê´€ë¦¬í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ íŒë‹¨í–ˆìŠµë‹ˆë‹¤.\ní•˜ë‚˜ì˜ ì €ì¥ì†Œë¥¼ mainê³¼ gh-pages, ë‘ ê°œì˜ ë¸Œëœì¹˜ë¡œ ë‚˜ëˆ„ì–´ êµ¬ì„±í•  ê³„íšì´ë©°,\nìš°ì„ ì ìœ¼ë¡œ \u0026lt;USERNAME\u0026gt;.github.io ëª…ì¹­ì˜ ì €ì¥ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\nHugo í”„ë¡œì íŠ¸ ìƒì„± # ì¼ë°˜ì ì¸ ì›¹ í”„ë ˆì„ì›Œí¬ì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ëŠ” ê²ƒì²˜ëŸ¼, Hugoì—ì„œë„ ê¸°ë³¸ í…œí”Œë¦¿ì„ ì œê³µí•©ë‹ˆë‹¤. ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê³ , ì´ë¦„ì€ ììœ ë¡­ê²Œ ì§€ì •í•´ë„ ë©ë‹ˆë‹¤.\nCopy bash % hugo new site \u0026lt;NAME\u0026gt; ë§Œë“¤ì–´ì§„ í”„ë¡œì íŠ¸ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\në§Œë“¤ì–´ì§„ í…Œë§ˆë¥¼ ì‚¬ìš©í•œë‹¤ë©´ ëŒ€ë¶€ë¶„ì˜ êµ¬ì„±ìš”ì†Œë“¤ì´ themes/ ë””ë ‰í† ë¦¬ ë‚´ì— ìœ„ì¹˜í•˜ê²Œ ë˜ë©°,\ní¬ìŠ¤íŠ¸ë¥¼ ìœ„í•œ content/, ì´ë¯¸ì§€ ë“±ì„ ìœ„í•œ static/ ë””ë ‰í† ë¦¬ ì™¸ì—” ê±°ì˜ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\nCopy bash . â”œâ”€â”€ archetypes â”‚Â â””â”€â”€ default.md â”œâ”€â”€ config.toml â”œâ”€â”€ content â”œâ”€â”€ data â”œâ”€â”€ layouts â”œâ”€â”€ public â”œâ”€â”€ static â””â”€â”€ themes ì €ì¥ì†Œ ì—°ë™ # í…Œë§ˆë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°ì— ì•ì„œ git ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\ní”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•œ í›„, ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ì›ê²© ì €ì¥ì†Œì™€ ì—°ë™í•©ë‹ˆë‹¤.\nCopy bash % git init % git add . % git commit -m \u0026#34;feat: new site\u0026#34; % git branch -M main % git remote add origin https://github.com/\u0026lt;USERNAME\u0026gt;/\u0026lt;USERNAME\u0026gt;.github.io.git % git push -u origin main ì¶”ê°€ì ìœ¼ë¡œ, ë Œë”ë§ëœ í˜ì´ì§€ê°€ ì €ì¥ë˜ê³  ì‹¤ì§ˆì ì¸ ë°°í¬ê°€ ì´ë£¨ì–´ì§€ëŠ” ë¸Œëœì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\nCopy bash % git branch gh-pages main % git checkout gh-pages % git push origin gh-pages % git checkout main Hugoì—ì„œ í˜ì´ì§€ë¥¼ ë Œë”ë§í•œ ê²°ê³¼ëŠ” public/ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ë©°, ì´ë¥¼ gh-pages ë¸Œëœì¹˜ì™€ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤.\nê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” ë¹ˆ ë””ë ‰í† ë¦¬ë¥¼ ì œê±°í•˜ê³  gh-pages ë¸Œëœì¹˜ë¥¼ main ë¸Œëœì¹˜ì˜ submoduleë¡œ ì—°ê²°í•©ë‹ˆë‹¤.\nsubmoduleì— ëŒ€í•œ ê°œë…ì€ í•´ë‹¹ ì˜ìƒì„ ì°¸ê³ í•´ì£¼ì‹œê¸° ë°”ë¼ë©°, ë‹¨ìˆœí•˜ê²Œ ì„¤ëª…í•˜ìë©´ ë™ê¸°í™” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\nCopy bash % rm -rf public % git submodule add -b gh-pages https://github.com/\u0026lt;USERNAME\u0026gt;/\u0026lt;USERNAME\u0026gt;.github.io.git public % git add public % git add .gitmodules % git commit -m \u0026#34;feat: add submodule for github pages\u0026#34; % git push í…Œë§ˆ ë¶ˆëŸ¬ì˜¤ê¸° # git ì„¤ì •ì„ ì™„ë£Œí•œ í›„, ë¯¸ë¦¬ ì •í•´ë‘ì—ˆë˜ í…Œë§ˆë¥¼ themes/ ë””ë ‰í† ë¦¬ ë‚´ì— ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.\në§ˆì°¬ê°€ì§€ë¡œ submoduleì„ í™œìš©í•˜ë©°, í…Œë§ˆì˜ ë””ë ‰í† ë¦¬ëª…ì€ ë°˜ë“œì‹œ í…Œë§ˆ ì„¤ì •ì— ëª…ì‹œëœ ê²ƒê³¼ ë™ì¼í•œ ì´ë¦„ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\nì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ ê³ ë ¤í•˜ë©´ ì›ë³¸ ì €ì¥ì†Œê°€ ì•„ë‹Œ ë³„ë„ë¡œ forkí•œ ì €ì¥ì†Œë¥¼ ì—°ê²°ì‹œí‚¤ëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤.\nCopy bash % git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod % git add themes/PaperMod % git add .gitmodules % git commit -m \u0026#34;feat: import hugo theme\u0026#34; ë§Œì•½ fork ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ì›ë³¸ ì €ì¥ì†Œì˜ ë³€ê²½ì‚¬í•­ì„ ì—…ë°ì´íŠ¸í•˜ê³  ì‹¶ë‹¤ë©´,\nì›ë³¸ ì €ì¥ì†Œë¥¼ ìƒˆë¡œìš´ ì›ê²© ì €ì¥ì†Œë¡œ ë“±ë¡í•´ pull ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\nCopy python git remote add upstream https://github.com/adityatelange/hugo-PaperMod git fetch upstream git merge upstream/master git commit -m \u0026#34;update: pull upstream\u0026#34; ì•„ë˜ëŠ” PaperMod í…Œë§ˆì˜ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì…ë‹ˆë‹¤.\ní…Œë§ˆë¥¼ ìˆ˜ì •í•  ì¼ì´ ìˆë‹¤ë©´ ì•„ë˜ êµ¬ì¡°ë¥¼ ì°¸ê³ í•´ í•„ìš”í•œ íŒŒì¼ì— ì ‘ê·¼í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy bash themes/PaperMod â”œâ”€â”€ LICENSE â”œâ”€â”€ README.md â”œâ”€â”€ assets â”‚Â â”œâ”€â”€ css â”‚Â â”‚Â â”œâ”€â”€ common â”‚Â â”‚Â â”œâ”€â”€ core â”‚Â â”‚Â â”œâ”€â”€ extended â”‚Â â”‚Â â”œâ”€â”€ hljs â”‚Â â”‚Â â””â”€â”€ includes â”‚Â â””â”€â”€ js â”œâ”€â”€ go.mod â”œâ”€â”€ i18n â”œâ”€â”€ images â”œâ”€â”€ layouts â”‚Â â”œâ”€â”€ 404.html â”‚Â â”œâ”€â”€ _default â”‚Â â”‚Â â””â”€â”€ _markup â”‚Â â”œâ”€â”€ partials â”‚Â â”œâ”€â”€ robots.txt â”‚Â â””â”€â”€ shortcodes â””â”€â”€ theme.toml Hugo ì„¤ì • # Hugo ë¸”ë¡œê·¸ ì„¤ì •ì€ config íŒŒì¼ì—ì„œ ì§€ì •í•  ìˆ˜ ìˆê³ , toml, yaml, json í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤.\ní…Œë§ˆë¥¼ ì‚¬ìš©í•  ê²½ìš° ì»¤ìŠ¤í…€ í‚¤ê°€ ì¡´ì¬í•  ìˆ˜ ìˆì–´ ë³„ë„ì˜ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤.\nHugo ê³µì‹ ì„¤ì •ì— ê´€í•œ ë¬¸ì„œì™€ PaperMod ì„¤ì •ì— ê´€í•œ ë¬¸ì„œëŠ” ì•„ë˜ë¥¼ ì°¸ê³ í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\nhttps://gohugo.io/getting-started/configuration/ https://github.com/adityatelange/hugo-PaperMod/wiki/Installation ì œ ì„¤ì • íŒŒì¼ì˜ ê²½ìš° ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ í†µí•´ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” í‚¤ê°€ ì¡´ì¬í•  ìˆ˜ ìˆì§€ë§Œ,\në™ì¼í•œ í…Œë§ˆë¥¼ ì‚¬ìš©í•œë‹¤ë©´ ì¼ë¶€ë¶„ì„ ì°¸ê³ í•´ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆì„ê±°ë¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.\nHugo ë°°í¬ # HugoëŠ” hugo -t \u0026lt;THEMES\u0026gt; ëª…ë ¹ì–´ë¥¼ í†µí•´ ë¡œì»¬ì—ì„œ í˜ì´ì§€ ë Œë”ë§ì„ ì§„í–‰í•  ìˆ˜ ìˆê³ ,\nê·¸ ê²°ê³¼ì¸ public/ ë””ë ‰í† ë¦¬ ë‚´ ë‚´ìš©ì„ gh-pagesì— pushí•˜ì—¬ ë°°í¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\në°°í¬ì— ì•ì„œ, ê¹ƒí—ˆë¸Œì—ì„œ ì œê³µí•˜ëŠ” Github Pagesê°€ gh-pages ë¸Œëœì¹˜ë¥¼ ì°¸ê³ í•˜ë„ë¡\nì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ ì €ì¥ì†Œ ì„¤ì •ì—ì„œ ë¹Œë“œ ë° ë°°í¬ ëŒ€ìƒ ë¸Œëœì¹˜ë¥¼ ì§€ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.\nìœ„ì™€ ê°™ì´ ìˆ˜ë™ìœ¼ë¡œ ë°°í¬í•  ê²½ìš° ë‘ ë²ˆì˜ push ê³¼ì •ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤.\në§¤ë²ˆ ì´ ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì€ ë¶ˆí¸í•˜ê¸° ë•Œë¬¸ì— ì‰˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì—¬ ì‘ì—…ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.\ní•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ë¥¸ í¬ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•´ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.\nCopy bash #!/bin/bash echo -e \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026#34; # Build the project. # hugo -t \u0026lt;your theme\u0026gt; hugo -t PaperMod # Go to public folder, submodule commit cd public # Add changes to git. git add . # Commit changes. msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin gh-pages # Come back up to the project root cd .. # Commit and push to main branch git add . msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push origin main ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì— ì‹¤í–‰ ê¶Œí•œì„ ë¶€ì—¬í•˜ê³  ì‹¤í–‰í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy bash % chmod 777 deploy.sh % ./deploy.sh ë°°í¬ê°€ ì™„ë£Œë˜ë©´, https://.github.io ì£¼ì†Œë¡œ ì ‘ì†í•´ ë¸”ë¡œê·¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní¬ìŠ¤íŠ¸ ì‘ì„±í•˜ê¸° # Hugo í¬ìŠ¤íŠ¸ëŠ” ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ìƒì„±í•  ìˆ˜ ìˆê³ ,\në³„ë„ì˜ markdown íŒŒì¼ì„ content/post/ ê²½ë¡œ ë‚´ì— ì¶”ê°€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\nCopy bash % hugo new post/\u0026lt;FILENAME\u0026gt;.md Front Matter # ì œëª©, ì‘ì„±ì¼ì ë“±ì„ ì§€ì •í•˜ê¸° ìœ„í•´ í¬ìŠ¤íŠ¸ ìƒë‹¨ì— Front Matterë¼ê³  í•˜ëŠ” í† í°ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. Front MatterëŠ” ì„¤ì • íŒŒì¼ê³¼ ë™ì¼í•˜ê²Œ toml, yaml, json í˜•ì‹ì„ ì§€ì›í•˜ë©°,\nHugo ê³µì‹ ë¬¸ì„œ ë˜ëŠ” PaperModì—ì„œ ì•ˆë‚´í•˜ëŠ” ì•„ë˜í˜•ì‹ì„ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy yaml --- title: \u0026#34;My 1st post\u0026#34; date: 2020-09-15T11:30:03+00:00 # weight: 1 # aliases: [\u0026#34;/first\u0026#34;] tags: [\u0026#34;first\u0026#34;] author: \u0026#34;Me\u0026#34; # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors showToc: true TocOpen: false draft: false hidemeta: false comments: false description: \u0026#34;Desc Text.\u0026#34; canonicalURL: \u0026#34;https://canonical.url/to/page\u0026#34; disableHLJS: true # to disable highlightjs disableShare: false disableHLJS: false hideSummary: false searchHidden: true ShowReadingTime: true ShowBreadCrumbs: true ShowPostNavLinks: true ShowWordCount: true ShowRssButtonInSectionTermList: true UseHugoToc: true cover: image: \u0026#34;\u0026lt;image path/url\u0026gt;\u0026#34; # image path/url alt: \u0026#34;\u0026lt;alt text\u0026gt;\u0026#34; # alt text caption: \u0026#34;\u0026lt;text\u0026gt;\u0026#34; # display caption under cover relative: false # when using page bundles set this to true hidden: true # only hide on current single page editPost: URL: \u0026#34;https://github.com/\u0026lt;path_to_repo\u0026gt;/content\u0026#34; Text: \u0026#34;Suggest Changes\u0026#34; # edit text appendFilePath: true # to append file path to Edit link --- ê²Œì‹œê¸€ ì €ì¥ì†Œ ì—°ë™ # ì €ëŠ” ê¸°ì¡´ TIL ì €ì¥ì†Œë¥¼ ê²Œì‹œê¸€ë¡œ í™œìš©í•  ì˜ˆì •ì´ì—ˆê¸°ì—,\ncontent/post/ ë””ë ‰í† ë¦¬ë¥¼ TIL ì €ì¥ì†Œì˜ submoduleë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.\nCopy bash % git submodule add https://github.com/minyeamer/til.git content/post/ % git add content/post/ % git add .gitmodules % git commit -m \u0026#34;feat: add til repository as post\u0026#34; ì´ë ‡ê²Œ ì„¤ì •í–ˆì„ ë•Œ ì¥ì ì€ TIL ì €ì¥ì†Œì— ë³€ê²½ì‚¬í•­ì´ ë°œìƒí–ˆì„ ê²½ìš°,\nì•„ë˜ì™€ ê°™ì€ ë‹¨ í•œ ì¤„ì˜ ëª…ë ¹ì–´ë¡œ ë¸”ë¡œê·¸ ì €ì¥ì†Œì—ì„œ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ ëª…ë ¹ì–´ëŠ” ë¬¼ë¡ , í…Œë§ˆì™€ ê°™ì€ ë‹¤ë¥¸ submoduleì—ë„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopy bash % git submodule update --remote ë§ˆì¹˜ë©° # Jekyll ë¸”ë¡œê·¸ì™€ ë©°ì¹ ê°„ ì”¨ë¦„í•˜ë‹¤ Hugoë¡œ ì´ë™í•´ ê¸°ì¡´ì˜ ëª©í‘œë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nChirpy í…Œë§ˆë¥¼ í™œìš©í•˜ì§€ ëª»í•˜ëŠ” ê²ƒì´ ì•„ì‰½ì§€ë§Œ, PaperModì˜ ì½”ë“œëŠ” ì•Œê¸° ì‰½ê²Œ ì‘ì„±ë˜ì–´ ìˆì–´\nì‹œê°„ì  ì—¬ìœ ë§Œ ìˆë‹¤ë©´ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì—ì„œ ì–´ë ¤ì›€ì´ ì—†ì„ ê²ƒì´ë¼ íŒë‹¨í•©ë‹ˆë‹¤.\nì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” Hugo ë¸”ë¡œê·¸ë¥¼ êµ¬ì„±í•˜ê³  í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ê³¼ì •ì„ ì „ë‹¬í–ˆìŠµë‹ˆë‹¤.\në‹¤ìŒì—” Utterances ìœ„ì ¯ì„ í™œìš©í•´ ëŒ“ê¸€ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\nì°¸ê³  ìë£Œ # Hugo Documents PaperMod Documents ë¸”ë¡œê·¸ êµ¬ì¶•ê¸° (1) Hugo + Githubìœ¼ë¡œ ê°œì¸ ë¸”ë¡œê·¸ ë§Œë“¤ê¸° ì €ì¥ì†Œ ì•ˆì— ì €ì¥ì†Œ - git submodule "},{"id":21,"href":"/blog/2022-09-07/","title":"ë°ì´í„° ë¶„ì„ê°€ì˜ ì²« ìŠ¤í…","section":"Posts","content":"ì„œë¡  # 2022ë…„ 3ì›” ì½”ë¡œë‚˜19ë¡œ ì¸í•œ ì¡°ê¸°ì „ì—­ í›„,\në©‹ìŸì´ì‚¬ìì²˜ëŸ¼ì—ì„œ ìš´ì˜í•˜ëŠ” AI SCHOOL êµìœ¡ ê³¼ì •ì— ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\nêµ°ëŒ€ì—ì„œ ë‚˜íƒœí•˜ê²Œ ë³´ë‚´ë©° ê³µë¶€ì—ëŠ” ìµìˆ™í•˜ì§€ ì•Šì•˜ì§€ë§Œ, ëª‡ë‹¬ ë’¤ ì„œë¥˜ìƒìœ¼ë¡œ ì „ì—­í•˜ê²Œ ë˜ë©´\nê²°êµ­ ì¼ìë¦¬ë¥¼ êµ¬í•´ì•¼ í–ˆê¸°ì— í‰ì†Œ ëª©í‘œë¡œ í–ˆë˜ ê°œë°œ ê´€ë ¨ êµìœ¡ì„ ë“¤ì„ í•„ìš”ì„±ì„ ëŠê¼ˆê³ ,\ní”íˆ ë§í•˜ëŠ” êµ­ë¹„ ì§€ì› êµìœ¡ì¸ K-Digital Trainingì„ ìˆ˜ê°•í–ˆìŠµë‹ˆë‹¤.\në¹„ì „ê³µìë„ 3ê°œì›”ì˜ ê³¼ì •ì„ ê±°ì³ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ íƒ‘ì¬ëœ ì›¹ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ”\ní¬ë§ì— ê°€ë“ì°¬ ìƒíƒœë¡œ êµìœ¡ì„ ìˆ˜ë£Œí–ˆì§€ë§Œ,\nê´€ì‹¬ìˆì—ˆë˜ NLP ë¶„ì•¼ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë…í•™í•˜ë©´ì„œ ìŠ¤ìŠ¤ë¡œì˜ ë¶€ì¡±í•¨ì„ í¬ê²Œ ì‹¤ê°í–ˆìŠµë‹ˆë‹¤.\nê·¸ë‚˜ë§ˆ ë‹¤í–‰ì¸ ê²ƒì€ êµìœ¡ ê³¼ì •ì„ í†µí•´, ê·¸ë¦¬ê³  ì´í›„ ìŠ¤í„°ë”” ê·¸ë£¹ì„ í†µí•´ ë§Œë‚œ ì¸ì—°ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\nìì‹ ì˜ ê³µë¶€ ì§„ë„ê°€ ì–´ëŠ ì •ë„ ìˆ˜ì¤€ì¸ì§€ ê°ì´ ì¡íˆì§€ ì•ŠëŠ” ë¶ˆí™•ì‹¤ì„±ì€ ë…í•™ì— ìˆì–´ ê°€ì¥ í° ë¶ˆì•ˆìš”ì†Œì¸ë°,\níƒ€ì¸ì˜ ê³µë¶€ ì§„ë„ ë° ê³µìœ ëœ ì½”ë“œ ë“±ì„ í™•ì¸í•˜ë©´ì„œ ì €ì˜ ìˆ˜ì¤€ì„ ê°€ëŠ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\në‹¤í–‰íˆ í•˜ê³  ì‹¶ì€ ê²ƒë§Œí¼ì€ ëª…í™•í–ˆê¸°ì— ë°©í–¥ì„±ì´ í”ë“¤ë¦´ ì¼ì€ ì—†ì—ˆì§€ë§Œ,\në¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´ë¥¼ ëª©ì ìœ¼ë¡œ ì‹¤ë¬´ì ì¸ ë¶€ë¶„ì— ì§‘ì¤‘í•˜ë‹¤ë³´ë‹ˆ ê¸°ì´ˆ ìˆ˜í•™, ë°ì´í„° ë¶„ì„ ê¸°ë²• ë“±\nê¸°ë°˜ì§€ì‹ì˜ ë¶€ì¡±ìœ¼ë¡œ ì–¸ì  ê°€ëŠ” ë¬´ë„ˆì ¸ ë²„ë¦´ ìˆ˜ ìˆê² ë‹¤ëŠ” ìƒê°ì„ í–ˆìŠµë‹ˆë‹¤.\nêµìœ¡ ê³¼ì • ìˆ˜ë£Œ í›„ ì•½ 3ê°œì›”ì´ ë‹¤ë˜ê°€ëŠ” ì‹œì ì—ì„œ ì €ì—ê²Œ ë‘ ê°€ì§€ ì„ íƒì§€ ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ì•¼ í–ˆìŠµë‹ˆë‹¤.\nì²« ë²ˆì§¸ ì„ íƒì§€ëŠ” í˜„ì¬ì˜ ë°©ì‹ì„ ê³ ìˆ˜í•˜ë©´ì„œ \u0026ldquo;ì†ì•„ì¤„\u0026rdquo; íšŒì‚¬ë¥¼ ì°¾ëŠ” ê²ƒ.\në‘ ë²ˆì§¸ ì„ íƒì§€ëŠ” ë°‘ë°”ë‹¥ë¶€í„°, ì„ í˜•ëŒ€ìˆ˜ì™€ í†µê³„í•™ë¶€í„° ê¸°ë°˜ì„ ìŒ“ì•„ê°€ëŠ” ê²ƒ.\nì´ë•Œ, ìš°ì—°í•œ ê¸°íšŒê°€ ì°¾ì•„ì™”ìŠµë‹ˆë‹¤.\nì²« ë©´ì ‘ # ê¸°ì¡´ì— ì°¸ì—¬í•˜ë˜ ë‹¨í†¡ë°© ì»¤ë®¤ë‹ˆí‹°ì—ì„œ í‰ì†Œ ê´€ì‹¬ì„ ë‘ë˜ íšŒì‚¬ì˜ CSO ë¶„ê»˜ ì—°ë½ì„ ë“œë¦´ ê¸°íšŒë¥¼ ì¡ì•˜ìŠµë‹ˆë‹¤.\në§ì§€ëŠ” ì•Šì§€ë§Œ ì•ì„  íšŒì‚¬ ì§€ì› ê³¼ì •ì—ì„œ ì„œë¥˜ê´‘íƒˆì„ ëŠê¼ˆë˜ ì €ëŠ” ì²« ì„œë¥˜í•©ê²©ì„ ê²½í—˜í–ˆìŠµë‹ˆë‹¤.\ní•´ë‹¹ íšŒì‚¬ëŠ” AI ì‘ê³¡ ìŠ¤íƒ€íŠ¸ì—…ìœ¼ë¡œ ì €ëŠ” NLP ê°œë°œì ì§ë¬´ì— ì§€ì›í–ˆëŠ”ë°,\nì¼ë°˜ì ì¸ NLP ê³¼ì œë¥¼ ê¸°ëŒ€í–ˆë˜ ì œê°€ ë°›ì•„ë³¸ ê³¼ì œëŠ” ë„ë©”ì¸ íŠ¹í™”ëœ ìƒˆë¡œìš´ ê³¼ì œì˜€ìŠµë‹ˆë‹¤.\në‹¤í–‰íˆ ì´í‹€ì˜ ê¸°ê°„ ë™ì•ˆ ë…¼ë¬¸ê³¼ ì½”ë“œë¥¼ ëœ¯ì–´ë³´ë©° ì„±ê³µì ìœ¼ë¡œ ê³¼ì œë¥¼ ë§ˆë¬´ë¦¬í–ˆê³ ,\nì´ëŠ” ì œ ê°œì¸ì ìœ¼ë¡œë„ í¬ê²Œ ì„±ì¥í•  ìˆ˜ ìˆëŠ” ê³„ê¸°ì˜€ìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ, ì²˜ìŒ ë³´ëŠ” ë©´ì ‘ì´ì—ˆê¸°ì— ë„ì €íˆ ê°ì´ ì¡íˆì§€ ì•Šì•˜ê³ ,\nì˜¤ì§ ì œê°€ ê²½í—˜í•œ í”„ë¡œì íŠ¸ ìœ„ì£¼ë¡œë§Œ ì¤€ë¹„í•˜ëŠ” ì‹¤ìˆ˜ë¥¼ ì €ì§ˆë €ìŠµë‹ˆë‹¤.\nì‹¤ì œ ë©´ì ‘ì—ì„œëŠ” ê³¼ì œ 20, í”„ë¡œì íŠ¸ 40, ë”¥ëŸ¬ë‹ ì§€ì‹ 40ìœ¼ë¡œ ì§ˆë¬¸ì„ ë°›ì•˜ì—ˆëŠ”ë°,\nì „í˜€ ì˜ˆìƒí•˜ì§€ ëª»í–ˆë˜ ì§ˆë¬¸ë“¤ì´ì—ˆê¸°ì— ì œëŒ€ë¡œ ë‹µë³€í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.\nì´í›„, ê´€ë ¨ëœ ì§ˆë¬¸ë“¤ì„ ì°¾ì•„ë³´ë‹ˆ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì§ˆë¬¸ ëª¨ìŒì§‘ì—ì„œ ë‚˜ì˜¨ ê²ƒë“¤ì´ì—ˆìŠµë‹ˆë‹¤.\nì‚¬ì‹¤ ê³¼ì œë¥¼ ë°›ì•„ë³¼ ë•Œë¶€í„° ëŠê¼ˆë˜ ê²ƒì´ì§€ë§Œ í•´ë‹¹ íšŒì‚¬ëŠ” ì €ì˜ ìˆ˜ì¤€ì— ë§ì§€ ì•Šì€ ë›°ì–´ë‚œ ê¸°ì—…ì´ì—ˆìŠµë‹ˆë‹¤.\nìš°ì—°í•œ ê¸°íšŒë¥¼ ë†“ì¹˜ì§€ ì•Šê¸° ìœ„í•´ ìì‹ ì˜ ë¶€ì¡±í•¨ì„ ê°ìˆ˜í•˜ê³  ì§€ì›í•œ ê²ƒì´ì—ˆëŠ”ë°,\nì—­ì‹œ ì˜ˆìƒì€ ë¹—ë‚˜ê°€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\në¹„ë¡ ê²°ê³¼ëŠ” ì¢‹ì§€ ì•Šì•˜ì§€ë§Œ, ë‹¹ì‹œ ì €ëŠ” ì˜¤íˆë ¤ \u0026ldquo;ë¶ˆí™•ì‹¤ì„± í•´ì†Œ\u0026quot;ë¥¼ ëŠë¼ê³  ë§Œì¡±í–ˆìŠµë‹ˆë‹¤.\nê·¸ë¦¬ê³ , ì´ ê²½í—˜ì´ ë’·ë°›ì¹¨ ë˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ ë‹¤ìŒ ë©´ì ‘ì—ì„œ í•©ê²©í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nì·¨ì—… # ì²« ë©´ì ‘ ì´í›„ ì œ ìˆ˜ì¤€ì—ì„œëŠ” ì¸í„´ë¶€í„° ì‹œì‘í•˜ëŠ” ê²ƒì´ ë§ë‹¤ê³  íŒë‹¨í•˜ì—¬ ê´€ë ¨ëœ ê³µê³ ì— ì§€ì›í–ˆìŠµë‹ˆë‹¤.\nê·¸ë¦¬ ë§ì€ ê³µê³ ê°€ ì˜¬ë¼ì™€ ìˆì§€ëŠ” ì•Šì•„ì„œ ë‹¹ì²¨ì„ ê¸°ëŒ€í•˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ,\në‹¤í–‰íˆ ìŠ¤í¬ì¸  ë¸Œëœë“œ ì‡¼í•‘ëª°ì„ ìš´ì˜í•˜ëŠ” ê¸°ì—…ì—ì„œ ë°ì´í„° ë¶„ì„ê°€ ì§ë¬´ë¡œ ì—°ë½ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤.\nì—°ë½ í›„ ì£¼ë§ì„ ê±°ì³ ë°”ë¡œ ë³´ê²Œëœ 1ì°¨ ë©´ì ‘ì—ì„œëŠ” ì´ì „ ë©´ì ‘ì—ì„œì˜ ê³¼ì˜¤ë¥¼ ë˜í’€ì´í•˜ì§€ ì•Šê¸° ìœ„í•´\nì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ê³  í•˜ë‚˜í•˜ë‚˜ ë‹µë³€ì„ ê¸°ë¡í•´ê°€ë©´ì„œ ì¤€ë¹„í–ˆëŠ”ë°,\nì‹¤ì œ ë©´ì ‘ì—ì„œëŠ” í•©ê²©ì„ ì „ì œë¡œ ì‹¤ì œ ì§„í–‰ë  ì—…ë¬´ì— ëŒ€í•´ ë§ì”€ì„ ì£¼ì…¨ìŠµë‹ˆë‹¤.\ní•´ë‹¹ ê¸°ì—…ì˜ ê²½ìš° ê°œë°œíŒ€ì´ë€ ê²ƒì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë§ˆì¼€íŒ… ì¤‘ì‹¬ ê¸°ì—…ì´ì—ˆê³ ,\nì‹¤í—˜ì ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ìë™í™” ë° ì‹œê°í™”ë¥¼ ìœ„í•´ ê´€ë ¨ ì „ë¬¸ê°€ë¥¼ ì±„ìš©í•´ë³´ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤.\nì œê°€ ì§€ê¸ˆê¹Œì§€ ì¤€ë¹„í–ˆë˜ ê²ƒê³¼ëŠ” ë‹¤ë¥¸ ì—…ë¬´ì˜€ì§€ë§Œ, í‰ì†Œ ë°ì´í„° ê´€ë ¨í•œ ì „ë°˜ì ì¸ ê¸°ìˆ ì— í¥ë¯¸ë¥¼ ê°€ì§€ê³  ìˆì—ˆê¸°ì—\nì œì•ˆëœ ì‚¬í•­ë“¤ì„ ì–´ë–»ê²Œ êµ¬í˜„í• ì§€ì— ëŒ€í•œ ë°©í–¥ì„±ì€ ê¸ˆë°© ì¡ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\nì˜ˆìƒëŒ€ë¡œ 1ì°¨ ë©´ì ‘ì„ í†µê³¼í•˜ê³  ëŒ€í‘œë‹˜ê³¼ ëŒ€ë©´í•˜ì—¬ 2ì°¨ ë©´ì ‘ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\nì§ˆë¬¸ì„ ë°›ëŠ” ê²ƒë³´ë‹¤ëŠ” ì œê°€ ì§ˆë¬¸ì„ ë“œë¦¬ëŠ” ë°©ì‹ì´ì—ˆê³  ìë¦¬ì—ì„œ í•©ê²© í†µë³´ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\nì•ìœ¼ë¡œ # í•©ê²© í†µë³´ë¥¼ ë“£ê³  í˜„ì¬ëŠ” í–¥í›„ ì£¼ì–´ì§„ ê³¼ì œë¥¼ ì–´ë–»ê²Œ êµ¬í˜„í•  ê²ƒì¸ì§€ì— ëŒ€í•´ ê³ ë¯¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.\ní¬ê²Œ ë°ì´í„° ë¶„ì„ê°€, ë°ì´í„° ì—”ì§€ë‹ˆì–´, DB ê°œë°œìì˜ 3ê°€ì§€ ë¶„ì•¼ì˜ ì—­ëŸ‰ì„ ê°€ì§€ê³ \n3ê°œì›” ë™ì•ˆ í˜¼ìì„œ ì„±ê³¼ë¥¼ ë³´ì—¬ì•¼ í•˜ëŠ”ë° ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´ ì§ë¬´ë¥¼ ì¤€ë¹„í–ˆë˜ ì œê²ŒëŠ” êµ‰ì¥íˆ ë„ì „ì ì¸ ì„ íƒì…ë‹ˆë‹¤.\ní˜„ì¬ ì•ì„  ë¶„ì•¼ ë³„ ì§ë¬´ì™€ ê´€ë ¨í•´ ë„ì…ì„ ê³„íší•˜ê³  ìˆëŠ” ê¸°ìˆ ì€ íƒœë¸”ë¡œ, MongoDB, Airflow ì…ë‹ˆë‹¤.\nì‚¬ì‹¤ ì„¸ ê°€ì§€ ì„œë¹„ìŠ¤ ëª¨ë‘ ì–•ì€ ìˆ˜ì¤€ì—ì„œë§Œ ì‚¬ìš©í•´ë³¸ê²Œ ì „ë¶€ë¼ì„œ ê¸°ìˆ ì„ ì ìš©í•˜ëŠ”ë° ìˆì–´ì„œ ì¤‘ì••ê°ì„ ëŠë¼ì§€ë§Œ,\nìµœì†Œí•œ íƒœë¸”ë¡œ ë§Œí¼ì€ ì²« ì¶œê·¼ê¹Œì§€ ë‚¨ì€ 5ì¼ì˜ ì‹œê°„ ë™ì•ˆ ë§ˆìŠ¤í„°í•  ê°ì˜¤ë¡œ ì¤€ë¹„í•´ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.\n"},{"id":22,"href":"/blog/desktop-settings/","title":"ê°€ë²¼ìš´ ë”¥ëŸ¬ë‹ìš© ì¡°ë¦½PC í›„ê¸°","section":"Posts","content":"êµ¬ë§¤ ê³„ê¸° # ë§¤ë²ˆ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ì‹¤í—˜ì„ í•˜ë©´ì„œ Colabì— ì˜ì¡´í•˜ëŠ” ë°©ì‹ì— ë¶ˆí¸í•¨ì„ ëŠê¼ˆëŠ”ë°,\nê²°êµ­ 190ë°œì„ ì‚¬ìš©í•´ì„œ RTX 3060ì´ í¬í•¨ëœ ì¡°ë¦½ PCë¥¼ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤.\nì´ë²ˆ ê¸°íšŒì— í˜¼ìì„œ ì»´í“¨í„°ë¥¼ ì¡°ë¦½í•´ë´¤ìœ¼ë©´ ì¢‹ì•˜ê² ì§€ë§Œ,\nì—¬ê¸°ì— ë§ì€ ì‹œê°„ì„ ìŸì„ë§Œí•œ ìƒí™©ë„ ì•„ë‹ˆì—ˆê³  ì´ìª½ì´ ê³ ì¥ë‚  ì¼ë„ ì—†ì–´ì„œ ë§¡ê²¼ìŠµë‹ˆë‹¤.\nì»´í“¨í„° ì¡°ë¦½ ì—…ì²´ë¡œ ë‹¤ë‚˜ì™€, í”¼ì”¨íŒ©í† ë¦¬ ë“±ì„ ê³ ë ¤í–ˆëŠ”ë°,\ní˜„ê¸ˆ ê²°ì œë¥¼ ê¶Œì¥í•˜ëŠ” ë¶€ë¶„ì´ ë¯¸ì‹¬ì©ì—ˆê³  ì»´í“¨ì¡´ì˜ í‰ì´ ì¢‹ì•„ ë¯¿ê³  ë§¡ê²¼ìŠµë‹ˆë‹¤.\në¶€í’ˆ ì„ ì • # ê·¸ë˜í”½ ì¹´ë“œ # ì²˜ìŒì—” ì•½ 100ë§Œì›ì„ ì–¹ì–´ì„œ RTX 3090Tiì„ êµ¬ë§¤í•  ìƒê°ì´ì—ˆì§€ë§Œ,\në‹¹ì‹œ ì†Œë“ì´ ì—†ëŠ” ìƒí™©ì´ë¼ ì €ë ´í•œ ê°€ê²©ì˜ RTX 3060ì„ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤.\nColabì—ì„œ RoBERTa ë“±ì˜ ëª¨ë¸ì„ ëŒë¦¬ë©´ì„œ 15GBì˜ VRAMì´ ê³ ê°ˆë˜ì–´ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì¸ ê²½í—˜ì´ ìˆì–´\nìƒëŒ€ì ìœ¼ë¡œ ì ì€ 12GB VRAMì˜ RTX 3060 ì œí’ˆì´ ë¶ˆì•ˆí•˜ê¸´ í–ˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ, ë‹¹ì¥ì—” í° ëª¨ë¸ì„ ëŒë¦´ ì˜ˆì •ì´ ì—†ê³  ê·¸ë˜í”½ ì¹´ë“œë¥¼ êµì²´í•˜ëŠ”ê²Œ ì–´ë µì§€ëŠ” ì•Šê¸° ë•Œë¬¸ì—\ní–¥í›„ í™•ì¥ì„±ì„ ê³ ë ¤í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì €ì‚¬ì–‘ì˜ ì œí’ˆì„ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤.\níŒŒì›Œ # ë‹¤ë§Œ, íŒŒì›Œì˜ ê²½ìš° êµì²´ê°€ ì‰½ì§€ ì•Šê¸° ë•Œë¬¸ì— í–¥í›„ ê·¸ë˜í”½ ì¹´ë“œë¥¼ êµì²´í•  ê²ƒì„ ê³ ë ¤í•´ 850Wë¡œ ì„ íƒí–ˆê³ ,\nWiFi ë³´ë“œ, ê°•í™”ìœ ë¦¬ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤ë¥¼ í•„ìˆ˜ ìš”ê±´ìœ¼ë¡œ ì‚¼ì•„\ní€˜ì´ì‚¬ì¡´ì„ í†µí•´ ë¶€í’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ íƒìƒ‰í–ˆìŠµë‹ˆë‹¤.\në©”ì¸ë³´ë“œ # ë©”ì¸ë³´ë“œë¡œëŠ” ì¸í…”ìš© B660 ë³´ë“œë¥¼ ì„ íƒí–ˆëŠ”ë°,\nêµ¬ë§¤í•˜ê³  ë³´ë‹ˆ ì¬ë”ë³¼íŠ¸ ë…ê³¼ ì—°ê²°í• ë§Œí•œ ê³ ì† í¬íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì•„ì‰¬ì› ìŠµë‹ˆë‹¤.\nì´ì ì€ ì¶©ë¶„íˆ ê³ ë ¤í•˜ì§€ ëª»í•˜ê³  ê²°ì •í•œ ë¬¸ì œì…ë‹ˆë‹¤.\nì¼€ì´ìŠ¤ # ì¼€ì´ìŠ¤ëŠ” í”„ë™íƒˆ ë””ìì¸ ì‚¬ì˜ Torrent Compact ì œí’ˆì„ êµ¬ë§¤í–ˆëŠ”ë°,\nê°•í™”ìœ ë¦¬ê°€ ì•ˆë‹¬ë¦° ì œí’ˆë“¤ì˜ ê°€ê²©ì´ ëŒ€ì²´ë¡œ ë¹„ì‹¼ í¸ì´ì–´ì„œ ì´ì™•ì´ë©´ ì·¨í–¥ì— ë§ëŠ” ì œí’ˆìœ¼ë¡œ ì„ íƒí–ˆìŠµë‹ˆë‹¤.\nê¸°íƒ€ ë¶€í’ˆ # ê²Œì„ì´ ëª©ì ì€ ì•„ë‹ˆì—ˆê¸° ë•Œë¬¸ì— CPUëŠ” ì ë‹¹í•œ ì¸í…” ì‚¬ ì œí’ˆì„ ê³¨ëê³ ,\nê´€ë¦¬ì˜ ë¶ˆí¸í•¨ ë•Œë¬¸ì— CPUìš© ì¿¨ëŸ¬ë¡œ DEEPCOOL ì‚¬ì˜ ê³µë­ ì¿¨ëŸ¬ë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.\në¨, SSD, HDDëŠ” ê°ê° ë§ˆì´í¬ë¡ , í•˜ì´ë‹‰ìŠ¤, WD ì‚¬ì˜ ì œí’ˆì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.\në§ˆì°¬ê°€ì§€ë¡œ í¬ê²Œ ì¤‘ìš”í•œ ë¶€í’ˆì€ ì•„ë‹ˆì—ˆê¸° ë•Œë¬¸ì— ìœ ëª…í•œ ê²ƒìœ¼ë¡œ ê³¨ëìŠµë‹ˆë‹¤.\nì»´í“¨ì¡´ ì¡°ë¦½ # ì»´í“¨ì¡´ì— ê²¬ì  ì‹ ì²­ì„ í•œ í›„ ë‹¹ì¼ë‚  ì¡°ë¦½ì´ ì™„ë£Œë˜ì—ˆë‹¤ëŠ” ë‹µë³€ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.\nìš©ì‚°ì—ì„œ íƒë°°ê°€ ë°œì†¡ë˜ê³  ë‹¤ìŒë‚  ì•„ë˜ì™€ ê°™ì€ ì‚¬ì§„ì„ ì „ë‹¬ë°›ì•˜ìŠµë‹ˆë‹¤.\nì œí’ˆ ë°°ì†¡ë„ ì£¼ë¬¸ í›„ í•˜ë£¨ ë‚´ì§€ ì´í‹€ ì‚¬ì´ì— ë„ì°©í•œ ê²ƒìœ¼ë¡œ ê¸°ì–µí•©ë‹ˆë‹¤.\nì»´í“¨í„° ìì²´ë„ ìŠ¤í‹°ë¡œí¼ì´ë‘ ì™„ì¶©ì¬ë¡œ ë‹¨ë‹¨íˆ ê°ì‹¸ì ¸ ìˆì–´ ë°°ì†¡ ìƒíƒœì— ë§Œì¡±í–ˆìŠµë‹ˆë‹¤.\nì œí’ˆ ìˆ˜ë ¹ ë° í™•ì¸ # ê° ì œí’ˆì˜ ë°•ìŠ¤ëŠ” ì°Œê·¸ëŸ¬ì§ ì—†ì´ ì˜ ë°°ì†¡ë˜ì—ˆëŠ”ë°, ê²‰ë°•ìŠ¤ê°€ ì‚´ì§ ê³¼ëŒ€í¬ì¥ì´ ì•„ë‹Œê°€ ìƒê°í–ˆìŠµë‹ˆë‹¤.\nì»´í“¨í„°ëŠ” ì•„ë˜ ì‚¬ì§„ê³¼ ê°™ì´ ë‚´ë¶€ê¹Œì§€ ì™„ì¶©ì¬ë¡œ ë³´í˜¸ëœ ìƒíƒœë¡œ ë°°ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.\nì™„ì¶©ì¬ë¥¼ ê±·ì–´ë‚´ë‹ˆ ê·¸ë˜í”½ ì¹´ë“œì˜ ì•„ë¦„ë‹¤ìš´ ìíƒœê°€ ëˆˆì— ë“¤ì–´ì™”ìŠµë‹ˆë‹¤.\nê°œì¸ì ìœ¼ë¡œ RGBë¥¼ ì„ í˜¸í•˜ì§€ëŠ” ì•Šê¸° ë•Œë¬¸ì— ì œí’ˆ ê·¸ ìì²´ë¥¼ ë³´ëŠ” ê²ƒë§Œìœ¼ë¡œ í–‰ë³µê°ì„ ëŠê¼ˆìŠµë‹ˆë‹¤.\nì¼€ì´ìŠ¤ë„ ê°œì¸ ì·¨í–¥ì— ì‚´ì§ ë¹„ì‹¼ ì œí’ˆì„ êµ¬ë§¤í–ˆëŠ”ë° ì´ë ‡ê²Œ ë‹¤ì‹œ ë³´ë‹ˆ ì˜ ìƒ€ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\níŠ¹íˆ ì¼€ì´ìŠ¤ ì •ë©´ì˜ Yì í˜•íƒœì˜ ë””ìì¸ì´ ë§¤ë ¥ì ì…ë‹ˆë‹¤.\në³„ë„ì˜ ìˆ˜ì‘ì—… ì—†ì´ ë°”ë¡œ ì»´í“¨í„°ë¥¼ ì‹¤í–‰ì‹œì¼°ëŠ”ë° í•œê°€ì§€ ì•„ì‰¬ì› ë˜ ì ì€ ì¿¨ëŸ¬ ì†Œë¦¬ê°€ ë„ˆë¬´ ì‹œë„ëŸ¬ì› ë˜ ê²ƒì…ë‹ˆë‹¤.\níŠ¹ë³„íˆ ë¶ˆëŸ‰ì´ ìˆëŠ” ê²ƒì€ ì•„ë‹ˆê³  ë‹¨ìˆœíˆ ì¿¨ëŸ¬ì˜ RPMì´ ë†’ê²Œ ëŠê»´ì¡Œë˜ ê±´ë°\në©”ì¸ë³´ë“œì—ì„œ CPU ì¿¨ëŸ¬ì˜ ì†ë„ë¥¼ ì¡°ì ˆí•´ë„ ë³€í™”ê°€ ì—†ì–´ ê°ê°ì˜ ì¿¨ëŸ¬ë¥¼ í™•ì¸í•´ë³´ë‹ˆ\nì¼€ì´ìŠ¤ ì¿¨ëŸ¬ì—ì„œ ì œì–´ê°€ ì´ë£¨ì–´ì§€ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.\nì œê°€ ì¡°ë¦½í•œ ì œí’ˆì´ ì•„ë‹ˆì–´ì„œ ë‹¤ ëœ¯ì–´ë³´ê¸°ë„ ë‚œê°í–ˆëŠ”ë°\në‹¤í–‰íˆ ê°€ì¥ ì˜ì‹¬ì©ì—ˆë˜ íŒ¬ í—ˆë¸Œì™€ ê´€ë ¨í•´ ì°¾ì•„ë³´ë©´ì„œ ë©”ì¸ë³´ë“œì™€ ì—°ê²° ë¬¸ì œê°€ ìˆì„ ê²ƒì´ë¼ ì§ì‘í•˜ê²Œ ë˜ì—ˆê³ ,\níŒ¬ í—ˆë¸Œì˜ PWM í¬íŠ¸ê°€ ë©”ì¸ë³´ë“œê°€ ì•„ë‹Œ, ë™ì¼ í—ˆë¸Œì˜ FAN4 í¬íŠ¸ì— ì—°ê²°ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤.\ní™©ë‹¹í•˜ê¸´ í•˜ì§€ë§Œ ì •ìƒì ìœ¼ë¡œ ì—°ê²° í›„ ì¡°ìš©íˆ ëŒì•„ê°€ëŠ” ëª¨ìŠµì„ ë³´ë‹ˆ ë§Œì¡±í–ˆìŠµë‹ˆë‹¤.\ní˜„ì¬ëŠ” ìš°ë¶„íˆ¬ë¥¼ íƒ‘ì¬í•´ ì¥ë‚¨ê°ìœ¼ë¡œì„œ ì¬ë°Œê²Œ ê°€ì§€ê³  ë†€ê³  ìˆìŠµë‹ˆë‹¤.\nM1 ë§¥ë¶ì„ ìœ ì¼í•œ PCë¡œ ì‚¬ìš©í•˜ë©´ì„œ ê°€ë”ì”© í˜¸í™˜ì„±ì— ë¶ˆí¸í•¨ì„ ëŠê¼ˆì—ˆëŠ”ë°\në¦¬ëˆ…ìŠ¤ ì‹œìŠ¤í…œê³¼ í•¨ê»˜ VMware ìƒì—ì„œ ìœˆë„ìš°ë¥¼ ìš´ì˜í•˜ë©´ì„œ ë”ì´ìƒ ê·¸ëŸ¬í•œ ê±±ì •ì„ í•  í•„ìš”ê°€ ì—†ì–´ì¡ŒìŠµë‹ˆë‹¤.\në¬´ì—‡ë³´ë‹¤ ê°€ì¥ ë§Œì¡±ìŠ¤ëŸ¬ìš´ê±´ í„°ë¯¸ë„ì—ì„œ nvidia-smi ëª…ë ¹ì–´ë¥¼ ì…ë ¥í–ˆì„ ë•Œ\ní‘œì‹œë˜ëŠ” ê·¸ë˜í”½ ì¹´ë“œì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\nì ì§€ì•Šì€ ì§€ì¶œì´ì—ˆì§€ë§Œ ê·¸ ì´ìƒìœ¼ë¡œ ë§Œì¡±í•œ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤.\n"},{"id":23,"href":"/blog/leetcode-problems-236/","title":"[LeetCode 236] Lowest Common Ancestor of a Binary Tree (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree/ ë¬¸ì œ í•´ì„¤ # Idea # rootë¶€í„° ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê¹Šì´ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ ìì‹ ë…¸ë“œë¥¼ íƒìƒ‰í•˜ë©´ì„œ\np ë˜ëŠ” q ë…¸ë“œë¥¼ ë°œê²¬í•œ ê²½ìš° í•´ë‹¹ ë…¸ë“œë¥¼ í˜¸ì¶œí•œ í•¨ìˆ˜ì—ê²Œ ë°˜í™˜ ìµœì¢…ì ìœ¼ë¡œ ì¢Œ,ìš°ì— ê°ê° pì™€ qê°€ ìˆì„ ê²½ìš° ê¹Šì´ê°€ ê°€ì¥ ê¹Šì€ ë¶€ëª¨ ë…¸ë“œë¥¼ ë°˜í™˜í•˜ê³ ,\ní•œìª½ ë°©í–¥ì— pì™€ qê°€ ëª°ë ¤ìˆì„ ê²½ìš° ë‘˜ ì¤‘ ë¶€ëª¨ ê´€ê³„ì— ìˆëŠ” ë…¸ë“œë¥¼ ë°˜í™˜ Time Complexity # O(N) = 10^5 Data Size # nodes: [2, 10^5] val: -10^9 \u0026lt;= int \u0026lt;= 10^9 í•´ì„¤ ì½”ë“œ # Copy python # Definition for a binary tree node. # class TreeNode(object): # def __init__(self, x): # self.val = x # self.left = None # self.right = None class Solution(object): def lowestCommonAncestor(self, root, p, q): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :type p: TreeNode :type q: TreeNode :rtype: TreeNode \u0026#34;\u0026#34;\u0026#34; if root: if root == p or root == q: return root left = self.lowestCommonAncestor(root.left, p, q) right = self.lowestCommonAncestor(root.right, p, q) if left and right: return root return left if left else right "},{"id":24,"href":"/blog/boj-problems-10026/","title":"[ë°±ì¤€ 10026] ì ë¡ìƒ‰ì•½ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/10026 ë¬¸ì œ í•´ì„¤ # Idea # ëª¨ë“  ë°©ë¬¸í•˜ì§€ ì•Šì€ ì¹¸ì— ëŒ€í•´ BFS íƒìƒ‰í•˜ë©´ì„œ ê°™ì€ êµ¬ì—­ì„ ë°©ë¬¸ ì ë¡ìƒ‰ì•½ì˜ ê²½ìš° Rê³¼ Gë¥¼ ê°™ì€ êµ¬ì—­ìœ¼ë¡œ íŒë‹¨í•˜ê³  íƒìƒ‰ ê°ê°ì˜ ê²½ìš°ì— ëŒ€í•œ BFS í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì„œë¡œ ë‹¤ë¥¸ êµ¬ì—­ì˜ ìˆ˜ë¡œ íŒë‹¨í•˜ì—¬ ì¶œë ¥ Time Complexity # BFS: O(N^2) = 10,000 Data Size # N: 1 \u0026lt;= int \u0026lt;= 100 í•´ì„¤ ì½”ë“œ # Copy python from collections import deque import sys input = sys.stdin.readline N = int(input()) grid = [list(input().strip()) for _ in range(N)] visited = [[[False] * N for _ in range(N)] for _ in range(2)] answer = [0, 0] def bfs(start, visited, st): queue = deque([start]) dy = [0,1,0,-1] dx = [-1,0,1,0] while queue: y,x = queue.popleft() for i in range(4): ny, nx = y+dy[i], x+dx[i] if 0\u0026lt;=ny\u0026lt;N and 0\u0026lt;=nx\u0026lt;N and not visited[ny][nx]: if st[grid[y][x]] == st[grid[ny][nx]]: queue.append((ny,nx)) visited[ny][nx] = True return 1 for i in range(N): for j in range(N): if not visited[0][i][j]: answer[0] += bfs((i,j), visited[0], {\u0026#39;R\u0026#39;:0,\u0026#39;G\u0026#39;:1,\u0026#39;B\u0026#39;:2}) if not visited[1][i][j]: answer[1] += bfs((i,j), visited[1], {\u0026#39;R\u0026#39;:0,\u0026#39;G\u0026#39;:0,\u0026#39;B\u0026#39;:2}) print(answer[0], answer[1]) "},{"id":25,"href":"/blog/boj-problems-21758/","title":"[ë°±ì¤€ 21758] ê¿€ ë”°ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/21758 ë¬¸ì œ í•´ì„¤ # Idea # ë²Œì´ ê°™ì€ ë°©í–¥ì„ í–¥í•˜ëŠ” ê²½ìš° ìƒìê¹Œì§€ì˜ ì´í•©ì—ì„œ ë‘ ë²Œì˜ ì‹œì‘ ìœ„ì¹˜ì— ìˆëŠ” ê°’ì„ ì œì™¸ ë²Œì´ ë‹¤ë¥¸ ë°©í–¥ì„ í–¥í•˜ëŠ” ê²½ìš° ìƒìê¹Œì§€ì˜ ì´í•©ì— ì ˆëŒ“ê°’ì„ ì·¨í•´ì„œ ë”í•¨ Data Size # N: 3 \u0026lt;= int \u0026lt;= 100,000 arr[i]: 1 \u0026lt;= int \u0026lt;= 10,000 í•´ì„¤ ì½”ë“œ # Copy python N = int(input()) arr = list(map(int, input().split())) forward, backward = [arr[0]]+[0]*(N-1), [0]*(N-1)+[arr[-1]] for i in range(1,N): forward[i] = forward[i-1] + arr[i] backward[N-i-1] = backward[N-i] + arr[N-i-1] answer = 0 for i in range(1,N-1): answer = max(answer, forward[N-1]*2-forward[0]-forward[i-1]-arr[i]*2) answer = max(answer, backward[0]*2-backward[N-1]-backward[N-i]-arr[N-i-1]*2) answer = max(answer, forward[i]-arr[0]+backward[i]-arr[-1]) print(answer) "},{"id":26,"href":"/blog/boj-problems-5547/","title":"[ë°±ì¤€ 5547] ì¼ë£¨ë¯¸ë„¤ì´ì…˜ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/5547 ë¬¸ì œ í•´ì„¤ # Idea # ì „ì²´ ì¢Œí‘œ í‰ë©´ì˜ ì™¸ê³½ì— 1ë§Œí¼ì˜ ì—¬ë°±ì„ ì¶”ê°€í•˜ê³  x,y ì¢Œí‘œê°€ 0ë¶€í„° ì‹œì‘í•œë‹¤ê³  íŒë‹¨ yê°€ í™€ìˆ˜ ì¼ ë•Œ, ì¸ì ‘í•œ ì¢Œí‘œëŠ” ìƒí•˜ì¢Œìš°ì™€ í•¨ê»˜ ìš°ìƒë‹¨,ìš°í•˜ë‹¨ì„ í¬í•¨ yê°€ ì§ìˆ˜ ì¼ ë•Œ, ì¸ì ‘í•œ ì¢Œí‘œëŠ” ìƒí•˜ì¢Œìš°ì™€ í•¨ê»˜ ì¢Œìƒë‹¨, ì¢Œí•˜ë‹¨ì„ í¬í•¨ ê±´ë¬¼ì´ ì—†ëŠ” ì¢Œí‘œë¥¼ BFS íƒìƒ‰í•˜ë©´ì„œ ê±´ë¬¼ê³¼ ë§Œë‚˜ëŠ” ì§€ì ì„ ì¹´ìš´íŠ¸ Time Complexity # BFS: O(N^2) = 10,000 Data Size # W, H: 1 \u0026lt;= int \u0026lt;= 100 í•´ì„¤ ì½”ë“œ # Copy python from collections import deque import sys input = sys.stdin.readline W, H = map(lambda x: int(x)+2, input().split()) maps = [[0] * W for _ in range(H)] for i in range(1,H-1): maps[i] = [0]+list(map(int, input().split()))+[0] visited = [[False] * W for _ in range(H)] def bfs(start): queue = deque([start]) dy = [0,1,0,-1,1,-1] cnt = 0 while queue: y,x = queue.popleft() dx = [-1,0,1,0,-1,-1] if y%2==0 else [-1,0,1,0,1,1] for i in range(6): ny, nx = y+dy[i], x+dx[i] if 0\u0026lt;=ny\u0026lt;H and 0\u0026lt;=nx\u0026lt;W: if maps[ny][nx] == 0 and not visited[ny][nx]: queue.append((ny,nx)) visited[ny][nx] = True elif maps[ny][nx] == 1: cnt += 1 return cnt visited[0][0] = True print(bfs((0,0))) "},{"id":27,"href":"/blog/jekyll-blog/","title":"ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ ì‹œì‘í•˜ê¸°","section":"Posts","content":"ë¸”ë¡œê·¸ë¥¼ ì²˜ìŒ ì‹œì‘í•¨ì— ìˆì–´ì„œ ëª¨ë“  ê²ƒì´ ì¤€ë¹„ëœ í˜¸ìŠ¤íŒ… ì„œë¹„ìŠ¤ì˜ í¸ì˜ì„±ì€ ë¬´ì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nì €ë„ ì²˜ìŒì—” ì½”ë“œë¥¼ ì§ì ‘ ê±´ë“œë¦¬ëŠ” ììœ ë„ ë†’ì€ ë°©ì‹ì˜ ë¸”ë¡œê·¸ì— ì§„ì… ì¥ë²½ì„ ëŠë¼ê³ \nê°€ë³ê²Œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” í‹°ìŠ¤í† ë¦¬ë¥¼ í†µí•´ ë¸”ë¡œê·¸ì— ì…ë¬¸í–ˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ, ê°œë°œì  ì§€ì‹ì„ í•™ìŠµí•˜ë©´ì„œ ê¹ƒí—ˆë¸Œì— ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¥¼ ì˜¬ë¦¬ëŠ” ë¹ˆë„ê°€ ëŠ˜ì–´ë‚¬ê³ ,\nê¹ƒí—ˆë¸Œì— ì˜¬ë¦° ë¬¸ì„œë¥¼ êµ³ì´ í‹°ìŠ¤í† ë¦¬ë¡œ ë‹¤ì‹œ ì˜®ê²¨ ë‹´ëŠ” ê²ƒì— ë¶ˆí¸í•¨ì„ ëŠë¼ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\në§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¥¼ ìì£¼ ì‘ì„±í•˜ê³  ê¹ƒí—ˆë¸Œ ì €ì¥ì†Œë¥¼ í•™ìŠµ ë…¸íŠ¸ë¡œ í™œìš©í•œë‹¤ë©´,\nê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ë¥¼ êµ¬ì„±í•´ë³´ëŠ” ê²ƒì´ ë¬¸ì„œë¥¼ í†µí•©ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ ë§¤ë ¥ì ì´ë¼ ìƒê°í•©ë‹ˆë‹¤.\ní˜„ì¬ëŠ” ë§‰ ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ë¥¼ ê¾¸ë ¤ì„œ ì ì‘í•´ê°€ëŠ” ë‹¨ê³„ì— ë¶ˆê³¼í•˜ì§€ë§Œ,\nì›¹ì—ì„œ ì •ì  íŒŒì¼ì„ ìˆ˜ì§‘í•˜ëŠ” ê¸°ìˆ ì„ ì ìš©í•  ìˆ˜ ìˆë‹¤ë©´ ì¤‘ë³µëœ ìë£Œë¥¼ ìƒì„±í•  í•„ìš” ì—†ì´\nTIL ì €ì¥ì†Œ ìì²´ë¥¼ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥ì†Œë¡œë„ í™œìš©í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.\në¸”ë¡œê·¸ë¥¼ ê°œì„¤í•˜ê³  ì²˜ìŒ ì‘ì„±í•˜ëŠ” ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ë¥¼ ë§Œë“  ê³¼ì •ì„ ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\ní…Œë§ˆ ì„ íƒ ë° ê°€ì ¸ì˜¤ê¸° # ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ë¥¼ ìƒì„±í•˜ëŠ”ë° ìˆì–´ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ê¸°ìˆ ì´ Jekyllì´ë¼ëŠ” ì‚¬ì´íŠ¸ ìƒì„± ì—”ì§„ ì…ë‹ˆë‹¤.\nJekyllì„ êµ¬ì„±í•˜ëŠ” Rubyì™€ ì‰˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±ì— ëŒ€í•œ ì´í•´ê°€ ìˆë‹¤ë©´ ë”ìš± ììœ ë„ ë†’ì€ ì‘ì—…ì„ í•  ìˆ˜ ìˆì§€ë§Œ,\në‹¤í–‰íˆ ì´ë¥¼ ëª¨ë¥¼ì§€ë¼ë„ ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì´ ë§Œë“  í…Œë§ˆë¥¼ ê°€ì ¸ì™€ ë¸”ë¡œê·¸ë¥¼ êµ¬ì„±í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Jekyll í…Œë§ˆëŠ” ì•„ë˜ì™€ ê°™ì€ ì‚¬ì´íŠ¸ë¥¼ ì°¸ì¡°í•˜ì—¬ ë§ˆìŒì— ë“œëŠ” UIë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nhttps://jekyllthemes.io http://jekyllthemes.org ë¬´ë£Œë¡œ ê°€ì ¸ë‹¤ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ í…Œë§ˆ ì¤‘ ê°œì¸ì ìœ¼ë¡œ ë§ˆìŒì— ë“œëŠ” Chirpy í…Œë§ˆë¥¼ í™œìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤.\ní…Œë§ˆ ë³„ë¡œ ì ìš© ë° í™œìš©í•˜ëŠ” ë°©ì‹ì— ë‹¤ì†Œ ì°¨ì´ê°€ ìˆì§€ë§Œ,\nChirpy ê°™ì€ ê²½ìš° ì•„ë˜ íŠœí† ë¦¬ì–¼ ì‚¬ì´íŠ¸ê°€ ë§Œë“¤ì–´ì ¸ ìˆì–´ ë¹„êµì  ì‰½ê²Œ ë¸”ë¡œê·¸ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nhttps://chirpy.cotes.page ë¸”ë¡œê·¸ ë°°í¬í•˜ê¸° # Chirpy í…Œë§ˆë¥¼ ì„¤ì¹˜í•˜ê³  ë°°í¬í•˜ëŠ” ë°©ë²•ì—” ë‘ ê°€ì§€ ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤.\nChirpy Starterë¥¼ í†µí•´ ê°„ë‹¨í•˜ê²Œ ì„¤ì¹˜í•˜ê¸°\níŠœí† ë¦¬ì–¼ì—ì„œëŠ” Jekyllì„ ì „í˜€ ëª¨ë¥´ëŠ” ì‚¬ìš©ìë„ ì‰½ê²Œ í…Œë§ˆë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ” í”„ë¡œì íŠ¸ íŒŒì¼ì´ ë§ˆë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\nê¹ƒí—ˆë¸Œ ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ë‹¨ìˆœí•œ ë²„íŠ¼ í´ë¦­ë§Œìœ¼ë¡œ ì™„ì„±ëœ ì‚¬ì´íŠ¸ë¥¼ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nGithubì—ì„œ ì†ŒìŠ¤ì½”ë“œë¥¼ fork ë°›ì•„ ì§ì ‘ ì„¤ì¹˜í•˜ê¸°\nìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë“± ë‹¤ì†Œì˜ ì‘ì—…ì´ ì¶”ê°€ë˜ì§€ë§Œ, ë¸”ë¡œê·¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì— ìœ ë¦¬í•œ ë°©ì‹ì…ë‹ˆë‹¤.\nJekyllì„ ë‹¤ë¤„ë³¼ ì¤„ ì•ˆë‹¤ë©´ ì§ì ‘ ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ëŠ” ê²ƒì´ ì·¨í–¥ì— ë§ëŠ” ë°©ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì € ê°™ì€ ê²½ìš° Jekyllì— ì¹œìˆ™í•œ í¸ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— 1ë²ˆì§¸ ë°©ë²•ì„ í†µí•´ ì„¤ì¹˜ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\nì´ë•Œ, ì €ì¥ì†Œ ì´ë¦„ì€ \u0026lt;GH_USERNAME\u0026gt;.github.io í˜•ì‹ìœ¼ë¡œ ì§€ì •í•´ì•¼ í•˜ë©°,\n\u0026lt;GH_USERNAME\u0026gt;ì—ëŠ” ê¹ƒí—ˆë¸Œ ì•„ì´ë””ë¥¼ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤.\nìœ„ ë°©ì‹ìœ¼ë¡œ ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ë©´ ìë™ìœ¼ë¡œ ë°°í¬ê°€ ìˆ˜í–‰ë˜ëŠ”ë°, Actions íƒ­ì„ í†µí•´ ì•„ë˜ì²˜ëŸ¼ ì§„í–‰ì‚¬í•­ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në¹Œë“œ ë° ë°°í¬ê°€ ì™„ë£Œë˜ë©´ https://\u0026lt;ì €ì¥ì†Œ ì´ë¦„\u0026gt; ì£¼ì†Œë¥¼ í†µí•´ ë¸”ë¡œê·¸ í˜ì´ì§€ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ”ë°,\n2022ë…„ 8ì›” ê¸°ì¤€ì—ì„œ í•´ë‹¹ í…Œë§ˆë¥¼ ê°€ì ¸ì˜¨ ì§í›„ì—”\n--- layout: home # Index page --- í…ìŠ¤íŠ¸ë§Œ ì¡´ì¬í•˜ëŠ” í™”ë©´ì„ ë§ˆì£¼í•˜ê²Œ ë©ë‹ˆë‹¤.\nì´ê²ƒì€ í˜„ì¬ Github Pagesê°€ ìŠ¤íƒ€ì¼ì´ ì ìš©ë˜ì§€ ì•ŠëŠ” main ë¸Œëœì¹˜ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ê³  ìˆëŠ” ê²ƒì´ ì›ì¸ìœ¼ë¡œ,\nSettings íƒ­ ì•„ë˜ Pages ë©”ë‰´ë¥¼ í´ë¦­í–ˆì„ ë•Œ ë³´ì´ëŠ” Branch ë¶€ë¶„ì„ gh-pagesë¡œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤.\në¸”ë¡œê·¸ ì„¤ì •í•˜ê¸° # í–¥í›„ ë¸”ë¡œê·¸ í˜¸ìŠ¤íŒ… ë° ì‚¬ì´íŠ¸ ì œëª©ì„ ìˆ˜ì •í•˜ëŠ” ë“±ì˜ ì„¤ì •ì„ ìœ„í•´ _config.yml íŒŒì¼ì„ ìˆ˜ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\nì œê°€ ë¸”ë¡œê·¸ ì„¸íŒ…ì— ë„ì›€ì„ ë°›ì€ ê²Œì‹œê¸€ë¡œë¶€í„° ì¼ë¶€ í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\ní•­ëª© ê°’ ì„¤ëª… timezone Asia/Seoul ì‹œê°„ëŒ€ë¥¼ ì„¤ì •í•˜ëŠ” ë¶€ë¶„ìœ¼ë¡œ ì„œìš¸ í‘œì¤€ì‹œë¡œ ì„¤ì •í•©ë‹ˆë‹¤. title ë¸”ë¡œê·¸ ì œëª© í”„ë¡œí•„ ì‚¬ì§„ ì•„ë˜ í° ê¸€ì”¨ë¡œ ì œëª©ì´ í‘œì‹œë©ë‹ˆë‹¤. tagline í”„ë¡œí•„ ì„¤ëª… ë¸”ë¡œê·¸ ì œëª© ì•„ë˜ì— ì‘ì€ ê¸€ì”¨ë¡œ ë¶€ì—°ì„¤ëª…ì„ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. description SEO êµ¬ê¸€ ê²€ìƒ‰ì— ì–´ë–¤ í‚¤ì›Œë“œë¡œ ë‚´ ë¸”ë¡œê·¸ë¥¼ ê²€ìƒ‰í•˜ê²Œ í•  ê²ƒì¸ê°€ë¥¼ ì •ì˜í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. url https://*.github.io ë¸”ë¡œê·¸ì™€ ì—°ê²°ëœ urlì„ ì…ë ¥í•©ë‹ˆë‹¤. github Github ID ë³¸ì¸ì˜ github ì•„ì´ë””ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. twitter.username Twitter ID íŠ¸ìœ„í„°ë¥¼ ì‚¬ìš©í•œë‹¤ë©´ ì•„ì´ë””ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. social.name ì´ë¦„ í¬ìŠ¤íŠ¸ ë“±ì— ì‘ì„±ìë¡œ í‘œì‹œí•  ë‚˜ì˜ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤. social.email ì´ë©”ì¼ ë‚˜ì˜ ì´ë©”ì¼ ê³„ì •ì„ ì…ë ¥í•©ë‹ˆë‹¤. social.links ì†Œì…œ ë§í¬ë“¤ íŠ¸ìœ„í„°, í˜ì´ìŠ¤ë¶ ë“± ë‚´ê°€ ì‚¬ìš©í•˜ê³  ìˆëŠ” ì†Œì…œ ì„œë¹„ìŠ¤ì˜ ë‚˜ì˜ í™ˆ urlì„ ì…ë ¥í•©ë‹ˆë‹¤. avatar í”„ë¡œí•„ ì‚¬ì§„ ë¸”ë¡œê·¸ ì™¼ìª½ ìƒë‹¨ì— í‘œì‹œë  í”„ë¡œí•„ ì‚¬ì§„ì˜ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. toc true í¬ìŠ¤íŠ¸ ì˜¤ë¥¸ìª½ì— ëª©ì°¨ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤. paginate 10 í•œ ëª©ë¡ì— ëª‡ ê°œì˜ ê¸€ì„ í‘œì‹œí•  ê²ƒì¸ì§€ ì§€ì •í•©ë‹ˆë‹¤. ì´ ë¶€ë¶„ì€ ì €ì˜ ì„¤ì • íŒŒì¼ _config.yml ë˜ëŠ” github ë‚´ ê²€ìƒ‰ì„ í†µí•´ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ”\në‹¤ë¥¸ ì‚¬ìš©ì ë¶„ë“¤ì˜ ì„¤ì • íŒŒì¼ì„ ì°¸ê³ í•˜ë©´ ì›í•˜ëŠ” ë¶€ë¶„ì„ ìˆ˜ì •í•˜ëŠ”ë° ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.\n_config.yml íŒŒì¼ì´ ìˆ˜ì • ë“± ì €ì¥ì†Œì— ë³€í™”ê°€ ë°œìƒí•˜ë©´ ìë™ìœ¼ë¡œ ë¹Œë“œ ë° ë°°í¬ ê³¼ì •ì´ ìˆ˜í–‰ë˜ë©°,\në³€ê²½ì‚¬í•­ì´ ì ìš©ë˜ëŠ”ë° ì•½ê°„ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní¬ìŠ¤íŠ¸ ì‘ì„±í•˜ê¸° # Jekyllì€ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ìœ¼ë¡œ ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì— ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´ í•´ë‹¹ ê²Œì‹œê¸€ì„ ì°¸ê³ í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\nVS Code ë˜ëŠ” ê¸°íƒ€ ì›¹ í¸ì§‘ê¸°ë¥¼ í™œìš©í•˜ë©´ ë§ˆí¬ë‹¤ìš´ ì‘ì„± ë‚´ìš©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë Œë”ë§í•´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nê²Œì‹œê¸€ì— ëŒ€í•œ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì€ _posts ë””ë ‰í† ë¦¬ ë‚´ì— ìœ„ì¹˜ì‹œí‚¤ê³ ,\nyyyy-mm-dd-ì œëª©.mdì˜ í˜•ì‹ìœ¼ë¡œ íŒŒì¼ ì´ë¦„ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.\nì œëª©ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì€ ì‹¤ì œ í¬ìŠ¤íŠ¸ ì œëª©ì´ ì•„ë‹Œ, urlë¡œ í™œìš©ë˜ëŠ” ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì—\nê²Œì‹œê¸€ì˜ ë‚´ìš©ì„ ì§ì‘í•˜ê²Œ í•˜ëŠ” ê°„ë‹¨í•œ ë‹¨ì–´ë‚˜ ë¬¸ì¥ì„ í™œìš©í•˜ëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤.\në§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ìƒë‹¨ì—” Front Matterë¼ê³  í•˜ëŠ” Jekyll ê²Œì‹œê¸€ì—ì„œ í—ˆìš©í•˜ëŠ” ê·œì¹™ì„ í†µí•´\nê²Œì‹œê¸€ ì œëª©, ì‘ì„±ì¼ì, ì¹´í…Œê³ ë¦¬, íƒœê·¸ ë“±ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nìì„¸í•œ ë‚´ìš©ì€ íŠœí† ë¦¬ì–¼ì„ ì°¸ì¡°í•  ìˆ˜ë„ ìˆê³ ,\ní•´ë‹¹ ê²Œì‹œê¸€ì— ëŒ€í•œ raw íŒŒì¼ì„ í™•ì¸í•´ë³´ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤.\në§ˆì¹˜ë©° # ê³¼ê±° ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ë¥¼ ë§Œë“¤ë ¤ê³  í–ˆì„ ë•ŒëŠ” Jekyllì„ ì§ì ‘ ë‹¤ë¤„ì•¼ í•´ì„œ ì‰½ê²Œ ì ‘ê·¼í•˜ì§€ ëª»í–ˆëŠ”ë°,\nì´ì œëŠ” ê·¸ëŸ´ í•„ìš” ì—†ì´ ì™„ì„±ëœ íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ë‹¤ ì“¸ ìˆ˜ ìˆê²Œ ë˜ì–´ì„œ ë§ì´ í¸í•´ì¡Œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\nì°¸ê³  ìë£Œ # Chirpy Documents ê¹ƒí—™(GitHub) ë¸”ë¡œê·¸ 10ë¶„ì•ˆì— ì™„ì„±í•˜ê¸° Jekyll Chirpy í…Œë§ˆ ì‚¬ìš©í•˜ì—¬ ë¸”ë¡œê·¸ ë§Œë“¤ê¸° Github ë¸”ë¡œê·¸ í…Œë§ˆì ìš©í•˜ê¸°(Chirpy) "},{"id":28,"href":"/blog/2022-08-26/","title":"2022-08-26 Log","section":"Posts","content":"NNLM # Word Embedding: ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ê°€ê¹Œìš´ ë²¡í„° ê³µê°„ì— í‘œí˜„ one-hot vector: ë‹¨ì–´ì˜ ê°œìˆ˜ë§Œí¼ì˜ ê³µê°„ì„ í‘œí˜„, ëª¨ë“  ë‹¨ì–´ê°„ ìœ ì‚¬ë„ê°€ 0ì— ê°€ê¹Œì›€ ì–´ë–¤ feature vector í‘œí˜„ì´ ì¢‹ê³ , sequenceë“¤ì˜ probabilityê°€ ë†’ìŒì„ í•™ìŠµ chain ruleì— ê¸°ë°˜í•´ ì´ì „ ë‹¨ì–´ì— ëŒ€í•œ ë‹¤ìŒ ë‹¨ì–´ì˜ í™•ë¥ ì„ ê³„ì‚°,\në‹¨ì–´ì˜ ê°œìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ê³¼ê±°ë¡œ ë´ì•¼í•  ë‹¨ì–´ì˜ ìˆ˜ê°€ ë§ì•„ì§€ê¸° ë•Œë¬¸ì—,\nMarkov assumptionì„ ì ìš©í•´ nê°œì˜ ë‹¨ì–´ë§Œ ì°¸ì¡° (n-grams) inputì´ hidden nodeë¥¼ ê±°ì¹˜ì§€ ì•Šê³  outputìœ¼ë¡œ ì—°ê²°ë˜ëŠ” skip-connectionì´ ì¡´ì¬í•  ìˆ˜ ìˆìŒ (optional) NNLMì˜ ëª©ì ì€ ìœˆë„ìš° ë‚´ì—ì„œ të²ˆì§¸ ë‹¨ì–´ì— ëŒ€í•´ t-1ë²ˆì§¸ ë‹¨ì–´ì˜ í™•ë¥ ì´ ê·¹ëŒ€í™”ë˜ëŠ” ê²ƒì„ í•™ìŠµ Word2Vec # CBOW: ì£¼ë³€ ë‹¨ì–´ë¥¼ ê°€ì§€ê³  ì¤‘ì‹¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡, Skip-gram: ì¤‘ì‹¬ ë‹¨ì–´ë¥¼ ê°€ì§€ê³  ì£¼ë³€ ë‹¨ì–´ ì˜ˆì¸¡ CBOWëŠ” gradientê°€ ê°ê°ì˜ ì£¼ë³€ ë‹¨ì–´ì— ë¶„ì‚°ë˜ì§€ë§Œ,\nSkip-gramì€ ì£¼ë³€ ë‹¨ì–´ì˜ gradientë¥¼ í•©ì‚°í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì„±ëŠ¥ì´ ì¢‹ìŒ activation functionì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” linear êµ¬ì¡° Skip-gramì˜ ëª©ì  í•¨ìˆ˜ëŠ” të²ˆì§¸ ë‹¨ì–´ì— ëŒ€í•´ ì¢Œìš°ë¡œ nê°œì˜ ë‹¨ì–´ì— ëŒ€í•œ í™•ë¥  í•©ì˜ ìµœëŒ€í™” ëŒ€ìƒ ë‹¨ì–´ ë²¡í„°ì™€ íŠ¹ì • ë‹¨ì–´ ë²¡í„° ê°„ ë‚´ì ì„ í•˜ê³  ì´í•©ì— softmaxë¥¼ ì·¨í•¨ ë¹ˆë²ˆí•œ ë‹¨ì–´ëŠ” í•œìŒìœ¼ë¡œ ë¬¶ê³ , ë¹ˆë„ê°€ ë†’ì€ ë‹¨ì–´ì˜ í•™ìŠµì„ ì œê±°í•´ ê³„ì‚°ì„ ê°„ì†Œí™” negative sampling: output ë‹¨ì–´ì— ëŒ€í•œ softmax ê°’ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ ë‚˜ë¨¸ì§€ ëª¨ë“  ê²ƒë“¤ì— ëŒ€í•œ ë‚´ì ê°’ì„ ê³„ì‚°í•´ì•¼ í•˜ëŠ”ë°,\nk ê°œì˜ ì˜ˆì‹œì— ëŒ€í•´ì„œë§Œ samplingí•˜ì—¬ ê³„ì‚°ì˜ íš¨ìœ¨ì„±ì„ ì¶”êµ¬ FastText # í˜•íƒœë¡ ì  feature ì •ë³´ë¥¼ í•œ ë‹¨ì–´ì˜ subwork unit, ë¬¸ì ë‹¨ìœ„ì—ì„œ ì¶”ì¶œí•˜ëŠ” ê¸°ë²• ê¸°ì¡´ ë°©ë²•ë¡ ì€ ëª¨ë“  ë‹¨ì–´ë¥¼ ê°ê°ì˜ vectorë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì— í•œê³„ê°€ ìˆê³  (OOV ë¬¸ì œ),\në‹¨ì–´ì˜ ë‚´ë¶€ì  êµ¬ì¡°ë¥¼ ë¬´ì‹œí•˜ì—¬ ìœ ì‚¬í•œ í˜•íƒœì˜ ë‹¨ì–´ë¥¼ í‘œí˜„í•˜ì§€ ëª»í•¨ skip-gram ê¸°ë°˜ì— ë¬¸ì ë‹¨ìœ„ character n-gramì„ í™œìš© ê¸°ì¡´ ëª¨ë¸ì˜ ê²½ìš° corpus ëŒ€ë¹„ context wordì— ëŒ€í•´ì„œë§Œ í•™ìŠµí•´ ë¹„íš¨ìœ¨ì ì¸ ì—°ì‚°ì´ ë§ì€ë°,\nnegative samplingì„ ì ìš©í•´ ì¼ì •í•œ í™•ë¥ ê°’ìœ¼ë¡œ ë½‘ì¸ wordë¥¼ ì°¸ê³  ê³µí†µëœëŠ í˜•íƒœì†Œë“¤ì— ëŒ€í•´ parameter sharingì„ í•˜ì—¬ embeddingì— ë°˜ì˜ (ì˜ë¯¸ ê³µìœ ) ë‹¨ì–´ì˜ ì‹œì‘ê³¼ ë í‘œí˜„ \u0026lsquo;\u0026lt;\u0026rsquo;, \u0026lsquo;\u0026gt;\u0026lsquo;ì„ ì¶”ê°€í•˜ê³  nê°œ ë¬¸ì ë‹¨ìœ„ì˜ ë²¡í„°ë¥¼ ì‚¬ìš©í•´ ê³„ì‚°í•˜ë©°,\nn-gramì´ ì»¤ì§€ëŠ” ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ hasing functionìœ¼ë¡œ hashê°’ ê³„ì‚° LSTM # RNNì—ì„œ ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ëŠ” ê¸°ì¡´ ê°€ì¤‘ì¹˜ W - lr * Wì— ëŒ€í•œ ë¯¸ë¶„ê°’ì˜ chain ruleì¸ë°,\nhidden stateê°€ ë§ì•„ì§ˆìˆ˜ë¡ ìƒˆë¡œìš´ weightê°€ ê¸°ì¡´ weightì™€ ê±°ì˜ ì°¨ì´ê°€ ì—†ì–´ì§ memory cellì„ ì¶”ê°€í•´ ìƒˆë¡œìš´ inputì— ëŒ€í•´ ê³¼ê±°ì˜ ì •ë³´ì— ëŒ€í•´ ëª‡ í¼ì„¼íŠ¸ë¥¼ ê¸°ì–µí• ì§€ ê²°ì •í•˜ê³  ë‚˜ë¨¸ì§€ ì •ë³´ë¥¼ ì œê±° ì¼ë¶€ê°€ ì œê±°ëœ cell stateëŠ” ìƒˆë¡œìš´ inputì— ëŒ€í•œ hidden stateì™€ ë”í•´ì§€ê³ ,\nì´ê²ƒì´ ë‹¤ì‹œ hidden stateì™€ ê³±í•´ì ¸ ë‹¤ìŒ hidden stateë¥¼ ìƒì„± Seq2Seq # LSTMì„ í™œìš©í•œ íš¨ìœ¨ì ì¸ ê¸°ê³„ ë²ˆì—­ ì•„í‚¤í…ì³ ì „í†µì ì¸ RNN ê¸°ë°˜ì˜ ê¸°ê³„ ë²ˆì—­ì€ ì…ë ¥ê³¼ ì¶œë ¥ì˜ í¬ê¸°ê°€ ê°™ë‹¤ê³  ê°€ì • (ì…ë ¥ í† í°ê³¼ ì¶œë ¥ í† í°ì´ ëŒ€ì‘) ìœ„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¸ì½”ë”ì—ì„œ ê³ ì •ëœ í¬ê¸°ì˜ context vectorë¥¼ ì¶”ì¶œ,\në””ì½”ë”ê°€ ë¬¸ë§¥ ë²¡í„°ë¡œë¶€í„° ë²ˆì—­ ê²°ê³¼ë¥¼ ì¶”ë¡  (ì¸ì½”ë”ì™€ ë””ì½”ë”ëŠ” ì„œë¡œ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§) ì‹œì‘ ì‹œì ì— ëŒ€í•œ í† í° \u0026lt;sos\u0026gt;ì™€ ì¢…ë£Œ ì‹œì ì— ëŒ€í•œ í† í° \u0026lt;eos\u0026gt;ë¥¼ ì¶”ê°€í•˜ì—¬,\nì¢…ë£Œ í† í°ì„ ìƒì„±í• ë•Œê¹Œì§€ ë°˜ë³µë¬¸ì„ ë°˜ë³µ ì…ë ¥ ë¬¸ì¥ì˜ ìˆœì„œë¥¼ ê±°ê¾¸ë¡œ í–ˆì„ ë•Œ ë” ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì„ (ì•ìª½ì— ìœ„ì¹˜í•œ ë‹¨ì–´ë¼ë¦¬ ì—°ê´€ì„±ì´ ë†’ìŒ) Attentionì„ ì ìš©í•œ Seq2Seqì˜ ê²½ìš° ëª¨ë“  hidden statesë¥¼ ë””ì½”ë”ë¡œ ì „ë‹¬í•˜ì—¬,\ní•„ìš”í•œ hidden stateë¥¼ ì„ íƒ ELMo # ELMoì—ì„œì˜ embedding vectorëŠ” bi-directional LSTMì—ì„œ ê°€ì ¸ì˜´ forward ë° backwardì˜ ê° ë‹¨ê³„ë³„ hidden stateë¥¼ concatenateí•˜ê³ ,\nê°ê°ì˜ ë²¡í„°ì— ëŒ€í•œ ê°€ì¤‘í•©ì„ í†µí•´ embeddingì„ ìƒì„± íŠ¹ì • taskì— ëŒ€í•œ ê°€ì¤‘í•© embeddingê³¼ taskì— ëŒ€í•œ scale vectorë¥¼ ê³±í•´ ê³„ì‚° forward LMì˜ ê²½ìš° kë²ˆì§¸ í† í°ì˜ jë²ˆì§¸ hidden stateë¥¼ ì‚¬ìš©í•˜ë©°,\në§ˆì§€ë§‰ hidden stateê°€ t+1 ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ”ë° ì‚¬ìš© backward LMì˜ ê²½ìš° ì—­ë°©í–¥ìœ¼ë¡œ t-1 ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ bi-directional LSTMì€ forwardì™€ backwardì—ì„œì˜ ì •í™•ë„ë¥¼ í•¨ê»˜ ìµœëŒ€í™” 2L+1ê°œì˜ í‘œí˜„ Rì— ê°€ì¤‘í•©ì„ ì·¨í•´ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë§Œë“œëŠ”ë°, íƒœìŠ¤í¬ì— ë§ëŠ” jë²ˆì§¸ layerì— ê°€ì¤‘ì¹ ë¥´ ë‘ê³  ì „ë°˜ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ì„ ì·¨í•¨ ê°€ì¤‘í•©ì„ ì·¨í•˜ëŠ” ë°©ì‹ì— ëŒ€í•´ì„  taskë³„ë¡œ ê°ê° ì·¨í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ê³ ,\n1/(L+1)ë¡œ í†µí•©í•˜ëŠ” ê²ƒì´ ë‹¤ìŒ, ë§ˆì§€ë§‰ hidden stateì˜ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë‹¤ìŒìœ¼ë¡œ ì¢‹ìŒ ELMoì˜ ì¡°í•©ì€ downstream task ëª¨ë¸ì˜ inputê³¼ output ì–‘ìª½ì— ë¶™ì´ëŠ”ê²Œ ê°€ì¥ ì¢‹ê³ ,\ninputì— ë¶™ì´ëŠ” ê²ƒ, outputì— ë¶™ì´ëŠ” ê²ƒ ìˆœìœ¼ë¡œ ì¢‹ìŒ GPT # unlabeled text ë°ì´í„°ê°€ labeled text ë°ì´í„°ë³´ë‹¤ í›¨ì”¬ ë§ê¸° ë•Œë¬¸ì—,\nì‚¬ì „í•™ìŠµì„ ìš°ì„  ìˆ˜í–‰í•˜ê³  labeled ë°ì´í„°ì— ëŒ€í•´ fine-tuningì„ ìˆ˜í–‰í•˜ë©´ ë”ìš± ë„ì›€ì´ ë  ê²ƒ transformerì˜ decoder blockì„ ì‚¬ìš©í•˜ë©°,\nencoder-decoder ê°„ì˜ masked multi-head attention ì—†ì´ ë‹¨ìˆœíˆ ìŒ“ì•„ì˜¬ë¦¼ ELMoëŠ” bi-directional LSTMì„ ì‚¬ìš©í•˜ëŠ” ë°˜ë©´, GPTëŠ” ë§ˆìŠ¤í¬ëœ forwardë¥¼ ì‚¬ìš©í•´ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ ì¼ë°˜ì ì¸ LMì€ ì „ ë‹¨ê³„ê¹Œì§€ì˜ ì‹œí€€ìŠ¤ì— ëŒ€í•´ ië²ˆì§¸ í† í°ì˜ likelihoodë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ ëª©ì  í† í° ì„ë² ë”©ê³¼ í¬ì§€ì…˜ ì„ë² ë”©ì„ ë”í•´ ì²«ë²ˆì§¸ hidden stateë¥¼ ë§Œë“¤ê³ ,\nl-1 ë²ˆì§¸ hidden stateë¥¼ decoder blockì„ í†µê³¼ì‹œì¼œ lë²ˆì§¸ hidden state ìƒì„± GPTëŠ” ì…ë ¥ ë‹¨ì–´ì— ëŒ€í•´ ì •ë°©í–¥ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì— BERTì²˜ëŸ¼ maskingí•  í•„ìš”ê°€ ì—†ìŒ BERTì™€ ë‹¬ë¦¬ ê°ê°ì˜ í† í°ì´ ìƒì„±ë˜ë©´, ê·¸ ë‹¤ìŒ í† í°ì„ ìƒì„±í•˜ê¸° ìœ„í•´ í•´ë‹¹ í† í°ì´ ì‚¬ìš©ë˜ëŠ” auto-regressive ë°©ì‹ì„ ê°€ì§ GPT-3 # transformer ëª¨ë¸ì—ì„œ log lossëŠ” scaleì´ ì»¤ì§ˆìˆ˜ë¡ ê°œì„ ë˜ê³ , contextë„ ë§ˆì°¬ê°€ì§€ë¡œ scaleì´ ì»¤ì§ˆìˆ˜ë¡ ì •ë³´ê°€ í–¥ìƒë¨ exampleì´ ë§ì„ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ”ë° scaleì´ í´ìˆ˜ë¡ ì°¨ì´ê°€ ë„ë“œë¼ì§ ê¸°ì¡´ì—” ê°ê°ì˜ exampleì— ëŒ€í•œ ê²°ê³¼ë¥¼ ë³´ë©´ì„œ gradientë¥¼ updateí•˜ë©´ì„œ fine-tuning í•˜ëŠ”ë°,\nGPT-3ëŠ” zero-shotì¼ ê²½ìš° task descriptionê³¼ promptë¥¼ ì£¼ê³ ,\none-shotì¼ ê²½ìš° í•˜ë‚˜ì˜ example, few-shotì¼ ê²½ìš° ì—¬ëŸ¬ ê°œì˜ exampleì„ ì¤Œ (fine-tuningì„ ë‹¤ì‹œ í•˜ì§€ ì•ŠìŒ) fine-tuningì€ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì´ í•„ìš”í•˜ë©´ì„œ, ì¼ë°˜í™” ì„±ëŠ¥ì´ ë–¨ì–´ì§€ê³  ê³¼ì í•© ë¬¸ì œê°€ ë°œìƒ,\nfew-shot learningì€ task-specific ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ SOTAë³´ë‹¤ëŠ” ì„±ëŠ¥ì´ ë–¨ì–´ì§ ê¸°ì¡´ transformerëŠ” ì´ì „ í† í°ì— ëŒ€í•´ ëª¨ë‘ attentionì´ ê±¸ë¦¬ëŠ”ë°,\nsparse transformerë¥¼ ì‚¬ìš©í•´ ê°œì„  í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°„ overlapì´ ì¡´ì¬í•˜ëŠ”ë°, ë¹„ìš©ì´ ë§ì´ ë“¤ì–´ í•´ê²°í•˜ì§€ ëª»í•¨ ë¬¸ì„œ ë ˆë²¨ì—ì„œ íŠ¹ì • í‘œí˜„ì„ ë°˜ë³µí•˜ëŠ” ê²½ìš°, ë§¤ìš° ê¸´ ë¬¸ì¥ì˜ ê²½ìš° ë“± íŠ¹ì • taskì— ëŒ€í•´ ì„±ëŠ¥ì´ ë–¨ì–´ì§ bidirectionalì´ ì•„ë‹Œ auto-regressiveí•œ êµ¬ì¡°ì  ë‹¨ì  "},{"id":29,"href":"/blog/boj-problems-1308/","title":"[ë°±ì¤€ 1308] D-Day (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1308 ë¬¸ì œ í•´ì„¤ # Idea # ê°ê°ì˜ ë‚ ì§œì— ëŒ€í•œ ë¬¸ìì—´ì„ date íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ê³ , today ê¸°ì¤€ 1000ë…„ í›„ ë‚ ì§œì™€ ddayë¥¼ ë¹„êµ ì¡°ê±´ì´ ë§ì„ ê²½ìš° \u0026lsquo;gg\u0026rsquo;ë¥¼ ì¶œë ¥í•˜ê³ , ì•„ë‹ˆë©´ ë‘ ë‚ ì§œì˜ ì°¨ì´ë¥¼ ì¶œë ¥ Data Size # y,m,d: 1,1,1 \u0026lt;= int*3 \u0026lt;= 9999,12,31 í•´ì„¤ ì½”ë“œ # Copy python from datetime import date strptime = lambda: date(**{k:int(v) for k,v in zip([\u0026#39;year\u0026#39;,\u0026#39;month\u0026#39;,\u0026#39;day\u0026#39;],input().split())}) today, dday = strptime(), strptime() if dday \u0026gt;= today.replace(today.year+1000): print(\u0026#39;gg\u0026#39;) else: print(\u0026#39;D-\u0026#39;+str((dday-today).days)) "},{"id":30,"href":"/blog/boj-problems-7569/","title":"[ë°±ì¤€ 7569] í† ë§ˆí†  (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/7569 ë¬¸ì œ í•´ì„¤ # Idea # BFS 7569ë²ˆ í† ë§ˆí†  ë¬¸ì œì—ì„œ í•˜ë‚˜ì˜ ì°¨ì›ì´ ì¶”ê°€ëœ ë²„ì „ì…ë‹ˆë‹¤. ì°¨ì›ì´ ëŠ˜ì–´ë‚œë§Œí¼ Nì˜ ìµœëŒ€ ê¸¸ì´ê°€ ê°ì†Œí–ˆê¸° ë•Œë¬¸ì— ì—¬ì „íˆ BFSë¡œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìµì€ í† ë§ˆí† ì˜ ê¸°ì¤€ì—ì„œ ì „ì²´ ìƒìë¥¼ BFSë¡œ ì™„ì „íƒìƒ‰í•˜ë©´ì„œ ì•ˆìµì€ í† ë§ˆí† ê¹Œì§€ì˜ ìµœì†Œ ê±°ë¦¬ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤. ìµœì†Œ ê±°ë¦¬ì˜ ìµœëŒ“ê°’ì´ ê³§ í† ë§ˆí† ë“¤ì´ ëª¨ë‘ ìµëŠ” ìµœì†Œ ì¼ìˆ˜ì´ë©°,\nëª¨ë“  í† ë§ˆí† ê°€ ë‹¤ ìµì—ˆì„ ê²½ìš°ì— ìµœì†Œ ì¼ìˆ˜ë¥¼ ì¶œë ¥í•˜ê³ , ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ì—” -1ì„ ì¶œë ¥í•©ë‹ˆë‹¤. Time Complexity # O(N^3) = 1,000,000 Data Size # M,N: 2 \u0026lt;= int \u0026lt;= 100 H: 1 \u0026lt;= int \u0026lt;= 100 t in [1,0,-1] í•´ì„¤ ì½”ë“œ # Copy python from collections import deque import sys input = sys.stdin.readline M, N, H = map(int, input().split()) box = [[list(map(int, input().split())) for _ in range(N)] for _ in range(H)] queue = deque([(h,r,c) for h in range(H) for r in range(N) for c in range(M) if box[h][r][c]==1]) days = 0 dz = [0,0,0,0,1,-1] dy = [0,1,0,-1,0,0] dx = [-1,0,1,0,0,0] while queue: z,y,x = queue.popleft() days = max(days, box[z][y][x]) for i in range(6): nz,ny,nx = z+dz[i],y+dy[i],x+dx[i] if 0\u0026lt;=nz\u0026lt;H and 0\u0026lt;=ny\u0026lt;N and 0\u0026lt;=nx\u0026lt;M and box[nz][ny][nx]==0: box[nz][ny][nx] = box[z][y][x] + 1 queue.append((nz,ny,nx)) if 0 in {cell for layer in box for row in layer for cell in row}: print(-1) else: print(days-1) "},{"id":31,"href":"/blog/boj-problems-7576/","title":"[ë°±ì¤€ 7576] í† ë§ˆí†  (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/7576 ë¬¸ì œ í•´ì„¤ # Idea # BFSë¥¼ í™œìš©í•œ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ ëª¨ë“  í† ë§ˆí† ê°€ ìµì„ ë–„ê¹Œì§€ ê±¸ë¦¬ëŠ” ìµœì†Œ ê¸°ê°„ì„ ê³„ì‚° ì´ˆê¸°ì—” ì•ˆìµì€ í† ë§ˆí† ì˜ ê¸°ì¤€ì—ì„œ ë§¤ë²ˆ ìµì€ í† ë§ˆí† ê¹Œì§€ì˜ ìµœë‹¨ê±°ë¦¬ë¥¼ íƒìƒ‰í•˜ì—¬,\nO(N^4)ì˜ ì‹œê°„ ë³µì¡ë„ë¡œ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒ ì´í›„ ìµì€ í† ë§ˆí† ì˜ ê¸°ì¤€ì—ì„œ ì‹œë®¬ë ˆì´ì…˜ì„ ë‹¨ í•œë²ˆë§Œ ìˆ˜í–‰í•˜ì—¬ ê°ê°ì˜ ì¹¸ì— ë„ë‹¬í•˜ëŠ”ë° ê±¸ë¦¬ëŠ” ê±°ë¦¬ê°’ì„ ê°±ì‹  ëª¨ë‘ ìµì§€ ëª»í•˜ëŠ” ìƒí™©ì— ëŒ€í•´ 1ì•ˆì—ì„  ì—ëŸ¬ë¥¼ ë°œìƒì‹œì¼œ ì²˜ë¦¬í–ˆê³ , 2ì•ˆì—ì„  ì¢…ë£Œ ì½”ë“œë¥¼ ì‹¤í–‰í•´ ì²˜ë¦¬ Time Complexity # O(N^2) = 1,000,000 Data Size # M,N: 2 \u0026lt;= int \u0026lt;= 1,000 t in [1,0,-1] í•´ì„¤ ì½”ë“œ # Copy python from collections import deque import sys input = sys.stdin.readline M, N = map(int, input().split()) box = [list(map(int, input().split())) for _ in range(N)] days = 0 # ============== 1ì•ˆ (ì‹œê°„ì´ˆê³¼) ============= def bfs(graph, start, n, m, vistied): queue = deque([start]) dist = 0 dy = [0,1,0,-1] dx = [-1,0,1,0] while queue: for _ in range(len(queue)): y,x = queue.popleft() if graph[y][x] == 1: return dist for i in range(4): ny,nx = y+dy[i],x+dx[i] if 0\u0026lt;=ny\u0026lt;n and 0\u0026lt;=nx\u0026lt;m and not vistied[ny][nx] and graph[ny][nx]!=-1: queue.append((ny,nx)) vistied[ny][nx] = True dist += 1 raise Exception() try: for i in range(N): for j in range(M): if box[i][j] == 0: vistied = [[False] * M for _ in range(N)] vistied[i][j] = True days = max(days, bfs(box, (i,j), N, M, vistied)) print(days) except Exception: print(-1) # =============== 2ì•ˆ (í†µê³¼) =============== queue = deque() for i in range(N): for j in range(M): if box[i][j] == 1: queue.append((i,j)) def bfs(graph, queue, n, m): dy = [0,1,0,-1] dx = [-1,0,1,0] while queue: y,x = queue.popleft() for i in range(4): ny,nx = y+dy[i],x+dx[i] if 0\u0026lt;=ny\u0026lt;n and 0\u0026lt;=nx\u0026lt;m and graph[ny][nx]==0: graph[ny][nx] = graph[y][x] + 1 queue.append((ny,nx)) bfs(box, queue, N, M) for i in range(N): for j in range(M): if box[i][j] == 0: print(-1) exit(0) days = max(days, box[i][j]) print(days-1) "},{"id":32,"href":"/blog/boj-problems-18870/","title":"[ë°±ì¤€ 18870] ì¢Œí‘œ ì••ì¶• (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/18870 ë¬¸ì œ í•´ì„¤ # Idea # Sort ì§‘í•©ì„ í†µí•´ ì••ì¶•í•œ uniqueí•œ ì¢Œí‘œ ëª©ë¡ì„ ì •ë ¬ì‹œí‚¤ê³ ,\nì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ ë‚´ì—ì„œ ì¢Œí‘œì™€ ì¸ë±ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë§µí•‘ Time Complexity # O(N Log N) = 13,000,000 Data Size # N: 1 \u0026lt;= int \u0026lt;= 1,000,000 X: -10^9 \u0026lt;= int \u0026lt;= 10^9 í•´ì„¤ ì½”ë“œ # Copy python N = int(input()) X = list(map(int, input().split())) xtoi = {x:i for i,x in enumerate(sorted(set(X)))} print(\u0026#39; \u0026#39;.join(map(lambda x: str(xtoi[x]), X))) "},{"id":33,"href":"/blog/boj-problems-1931/","title":"[ë°±ì¤€ 1931] íšŒì˜ì‹¤ ë°°ì • (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1931 ë¬¸ì œ í•´ì„¤ # Idea # Sliding Window ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ì˜ ì „í˜•ì ì¸ ë¬¸ì œë¡œ, ë ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹œê°„ì„ ì •ë ¬í•´ì„œ ê²¹ì¹˜ì§€ ì•ŠëŠ” ìˆ˜ë¥¼ ê³„ì‚° Time Complexity # O(N) = 100,000 Data Size # N: 1 \u0026lt;= int \u0026lt;= 100,000 t1,t2: 0 \u0026lt;= int \u0026lt;= 2^31-1 í•´ì„¤ ì½”ë“œ # Copy python import sys input = sys.stdin.readline N = int(input()) times = sorted([tuple(map(int, input().split())) for _ in range(N)], key=lambda x: [x[1],x[0]]) count, end_time = 0, 0 for t1,t2 in times: if t1 \u0026gt;= end_time: count += 1 end_time = t2 print(count) "},{"id":34,"href":"/blog/boj-problems-15686/","title":"[ë°±ì¤€ 15686] ì¹˜í‚¨ ë°°ë‹¬ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/15686 ë¬¸ì œ í•´ì„¤ # Idea # Combinations ìµœëŒ€ ì§‘ì˜ ê°œìˆ˜ê°€ 100, ìµœëŒ€ ì¹˜í‚¨ì§‘ì˜ ê°œìˆ˜ê°€ 13ìœ¼ë¡œ ë§¤ìš° ì ì€ ê²½ìš°ì˜ ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì—,\nëª¨ë“  ì¡°í•©ì— ëŒ€í•œ ì™„ì „íƒìƒ‰ì„ í†µí•´ ìµœì†Œ ê±°ë¦¬ë¥¼ ê³„ì‚° ì´ˆê¸°ì—ëŠ” ì§‘ì— ëŒ€í•œ ì¹˜í‚¨ ê±°ë¦¬ê°€ ì‘ì€ ì¹˜í‚¨ì§‘ì„ ìš°ì„ ì ìœ¼ë¡œ ì„ ë°œí•´ì„œ,\níì—…í•˜ì§€ ì•Šì€ ì¹˜í‚¨ì§‘ì— ëŒ€í•œ ì¹˜í‚¨ ê±°ë¦¬ì˜ ìµœì†Œ í•©ì„ ê³„ì‚°í–ˆì§€ë§Œ í‹€ë¦¼ ì´í›„ combinations ëª¨ë“ˆì„ í™œìš©í•œ ì™„ì „íƒìƒ‰ì„ í†µí•´ í†µê³¼ Time Complexity # O(N * nCr) ~ 100,000 Data Size # N: 2 \u0026lt;= int \u0026lt;= 50 M: 1 \u0026lt;= int \u0026lt;= 13 cell in (0, 1, 2) count(house): 1 \u0026lt;= int \u0026lt; 2N count(chicken): M \u0026lt;= int \u0026lt;= 13 í•´ì„¤ ì½”ë“œ # Copy python from itertools import combinations import sys input = sys.stdin.readline N, M = map(int, input().split()) city = {\u0026#39;0\u0026#39;:list(),\u0026#39;1\u0026#39;:list(),\u0026#39;2\u0026#39;:list()} for r in range(N): for c,i in enumerate(input().split()): city[i].append((r,c)) houses, chickens = city[\u0026#39;1\u0026#39;], city[\u0026#39;2\u0026#39;] diff = lambda c1,c2: abs(c1[0]-c2[0])+abs(c1[1]-c2[1]) # =============== 1ì•ˆ (í‹€ë¦¼) =============== house_cost = {chicken:0 for chicken in chickens} chicken_cost = {house:house_cost.copy() for house in houses} for house in houses: for chicken in chickens: cost = diff(house,chicken) chicken_cost[house][chicken] = cost house_cost[chicken] += cost city_cost = 0 open = [chicken for chicken,cost in sorted(house_cost.items(), key=lambda x: x[1])[:M]] for house, costs in chicken_cost.items(): city_cost += min([cost for chicken,cost in costs.items() if chicken in open]) # =============== 2ì•ˆ (í†µê³¼) =============== city_cost = sys.maxsize for comb in combinations(chickens, M): cost = 0 for house in houses: cost += min([diff(house,chicken) for chicken in comb]) city_cost = min(city_cost,cost) print(city_cost) "},{"id":35,"href":"/blog/boj-problems-1927/","title":"[ë°±ì¤€ 1927] ìµœì†Œ í™ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1927 ë¬¸ì œ í•´ì„¤ # Idea # Heapq íŒŒì´ì¬ heapq ëª¨ë“ˆ ìì²´ê°€ ìµœì†Œí™ì´ê¸° ë•Œë¬¸ì— í•´ë‹¹í•˜ëŠ” ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ êµ¬í˜„ Time Complexity # O(Log N) = 16 Data Size # N: 1 \u0026lt;= int \u0026lt;= 100,000 x: 0 \u0026lt;= int \u0026lt; 2^31 í•´ì„¤ ì½”ë“œ # Copy python import heapq import sys input = sys.stdin.readline N = int(input()) arr = list() for _ in range(N): x = int(input()) if x \u0026gt; 0: heapq.heappush(arr, x) else: if arr: print(heapq.heappop(arr)) else: print(0) "},{"id":36,"href":"/blog/boj-problems-1780/","title":"[ë°±ì¤€ 1780] ì¢…ì´ì˜ ê°œìˆ˜ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1780 ë¬¸ì œ í•´ì„¤ # Idea # Divide and Conquer 2ì°¨ì› ë°°ì—´ì˜ ìš”ì†Œë¥¼ ì™„ì „íƒìƒ‰í•˜ë©´ì„œ ë™ì¼í•œ ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ì§€ ì•Šì„ ê²½ìš°,\ní–‰ë ¬ì„ 9ë“±ë¶„í•˜ì—¬ ì¬ê·€ì  í˜¸ì¶œ ìˆ˜í–‰ ì²˜ìŒ ì‹œë„ì—ì„œëŠ” í–‰ë ¬ì„ ë§¤ë²ˆ ìŠ¬ë¼ì´ì‹±í•˜ë©´ì„œ ì „ë‹¬í•˜ì—¬ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒ í–‰ë ¬ì˜ ì‹œì‘ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ì „ë‹¬í•˜ê³  ê¸¸ì´ë§Œí¼ ì°¸ì¡°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹œê°„ ë³µì¡ë„ ê°œì„  Data Size # N: 1 \u0026lt;= int \u0026lt;= 3^7 í•´ì„¤ ì½”ë“œ # Copy python import sys input = sys.stdin.readline value2id = {-1:0,0:1,1:2} # ============== 1ì•ˆ (ì‹œê°„ì´ˆê³¼) ============= from itertools import chain mat_slice = lambda mat,r1,r2,c1,c2: list(map(lambda x: x[c1:c2], mat[r1:r2])) def nona_comp(n, arr, answer): values = set(chain.from_iterable(arr)) if len(values) == 1: answer[value2id[values.pop()]] += 1 return div = n//3 for i in range(3): for j in range(3): nona_comp(div, mat_slice(arr,div*i,div*(i+1),div*j,div*(j+1)), answer) # =============== 2ì•ˆ (í†µê³¼) =============== def nona_comp(n, arr, r, c, answer): start = arr[r][c] for row in range(r,r+n): for col in range(c,c+n): if arr[row][col] != start: div = n//3 for i in range(3): for j in range(3): nona_comp(div, arr, r+div*i, c+div*j, answer) return answer[value2id[start]] += 1 N = int(input()) arr = [list(map(int, input().split())) for _ in range(N)] answer = [0, 0, 0] nona_comp(len(arr), arr, 0, 0, answer) for num in answer: print(num) "},{"id":37,"href":"/blog/programmers-problems-77486/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ 77486] ë‹¤ë‹¨ê³„ ì¹«ì†” íŒë§¤ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/77486 ë¬¸ì œ í•´ì„¤ # Idea # Union-Find ì•Œê³ ë¦¬ì¦˜ì˜ Find() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€ëª¨ ë…¸ë“œì— ëŒ€í•´ ì¬ê·€ì ìœ¼ë¡œ ì ‘ê·¼ ìµœì•…ì˜ ê²½ìš° O(NM)=10^10ìœ¼ë¡œ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒí•˜ì§€ë§Œ, ë§¤ íƒìƒ‰ë§ˆë‹¤ ìµœëŒ€ 10,000ì›ì„ 10ì”© ë‚˜ëˆ  0ì´ ë˜ëŠ” ìˆœê°„ì— ì¬ê·€ê°€ ì¢…ë£Œë˜ê¸° ë•Œë¬¸ì— ìµœëŒ€ ê¹Šì´ê°€ 5ë¡œ ì¢í˜€ì§ Time Complexity # O(N) = 100,000 Data Size # enroll, referral: str(10) * 10,000 seller: str(10) * 100,000 amount: int(100) * 100,000 í•´ì„¤ ì½”ë“œ # Copy python def find(parents, cur, income, answer): alloc = income//10 if parents[cur] == cur or alloc == 0: answer[cur] += income-alloc return answer[cur] += income-alloc find(parents, parents[cur], alloc, answer) return def solution(enroll, referral, seller, amount): N = len(enroll) answer = [0] * N name2id = {name:i for i,name in enumerate(enroll)} parents = [i if referral[i]==\u0026#39;-\u0026#39; else name2id[referral[i]] for i in range(N)] for i in range(len(seller)): find(parents, name2id[seller[i]], amount[i]*100, answer) return answer "},{"id":38,"href":"/blog/boj-problems-1182/","title":"[ë°±ì¤€ 1182] ë¶€ë¶„ìˆ˜ì—´ì˜ í•© (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1182 ë¬¸ì œ í•´ì„¤ # Idea # Brute Force ì „ì²´ ë°°ì—´ì—ì„œ 1ë¶€í„° Nê°œì˜ ë¶€ë¶„ ì¡°í•©ì„ ì™„ì „íƒìƒ‰í•˜ë©´ì„œ í•©ì´ Sì™€ ê°™ì€ ê²½ìš°ë¥¼ ì¹´ìš´íŠ¸í•˜ê³  ì¶œë ¥ Data Size # N: 1 \u0026lt;= int \u0026lt;= 20 S: abs(int) \u0026lt;= 1,000,000 arr: int(100,000) * N í•´ì„¤ ì½”ë“œ # Copy python from itertools import combinations N, S = map(int, input().split()) arr = list(map(int, input().split())) count = 0 for i in range(1,N+1): comb = combinations(arr, i) count += sum(map(lambda x: sum(x)==S, comb)) print(count) "},{"id":39,"href":"/blog/boj-problems-11725/","title":"[ë°±ì¤€ 11725] íŠ¸ë¦¬ì˜ ë¶€ëª¨ ì°¾ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/11725 ë¬¸ì œ í•´ì„¤ # Idea # BFS 1ë²ˆ ë…¸ë“œë¶€í„° BFSë¥¼ ìˆ˜í–‰í•˜ë©´ì„œ ë‹¤ìŒ ë…¸ë“œì— ìˆœì°¨ì ìœ¼ë¡œ ì ‘ê·¼ ë‹¤ìŒ ë…¸ë“œê°€ ì´ë¯¸ ë°©ë¬¸í•œ ë…¸ë“œì˜ ê²½ìš° ë¶€ëª¨ ë…¸ë“œë¼ íŒë‹¨í•˜ì—¬ ë°°ì—´ì— ì €ì¥ ë¶€ëª¨ ë…¸ë“œê°€ ì €ì¥ëœ ë°°ì—´ì— ëŒ€í•´ 2ë²ˆ ë…¸ë“œë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ë¶€ëª¨ ë…¸ë“œë¥¼ ì¶œë ¥ Time Complexity # O(N+E) = 200,000 Data Size # N: 2 \u0026lt;= int \u0026lt;= 100,000 í•´ì„¤ ì½”ë“œ # Copy python from collections import deque import sys input = sys.stdin.readline N = int(input()) graph = [[] for _ in range(N+1)] visited = [False] * (N+1) parents = [1] * (N+1) for _ in range(N-1): u, v = map(int, input().split()) graph[u].append(v) graph[v].append(u) queue = deque([1]) visited[1] = True while queue: node = queue.popleft() for next in graph[node]: if not visited[next]: queue.append(next) visited[next] = True else: parents[node] = next for parent in parents[2:]: print(parent) "},{"id":40,"href":"/blog/programmers-problems-68936/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ 68936] ì¿¼ë“œì••ì¶• í›„ ê°œìˆ˜ ì„¸ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/68936 ë¬¸ì œ í•´ì„¤ # Idea # Divide and Conquer 2ì°¨ì› ë°°ì—´ì„ 4ë“±ë¶„ì”© ë‚˜ëˆ  ì¬ê·€í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê³  ë™ì¼í•œ ê°’ìœ¼ë¡œ ì±„ì›Œì ¸ ìˆëŠ”ì§€ íŒë‹¨í•˜ì—¬ ê°’ì˜ ê°œìˆ˜ ì¦ê°€ 2^n í˜•íƒœì˜ ì •ìˆ˜ì— ëŒ€í•´ NumPyë¥¼ í™œìš©í•´ í–‰ë ¬ ì¸ë±ì‹±ì„ ê°„ë‹¨íˆ êµ¬í˜„ Time Complexity # O(N^2 Log N^2) = 20,000,000 Data Size # arr: [[int(1)]], shape(2^n, 2^n) 1 \u0026lt;= 2^n \u0026lt;= 1024 í•´ì„¤ ì½”ë“œ # Copy python import numpy as np def quad_comp(n, arr, answer): values = np.unique(arr) if len(values) == 1: answer[values[0]] += 1 return div = n//2 quad_comp(div, arr[:div, :div], answer) quad_comp(div, arr[:div, div:], answer) quad_comp(div, arr[div:, :div], answer) quad_comp(div, arr[div:, div:], answer) def solution(arr): arr = np.array(arr) answer = [0,0] quad_comp(len(arr), arr, answer) return answer "},{"id":41,"href":"/blog/programmers-problems-87390/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ 87390] n^2 ë°°ì—´ ìë¥´ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/87390 ë¬¸ì œ í•´ì„¤ # Idea # Greedy nì˜ í¬ê¸°ê°€ êµ‰ì¥íˆ í¬ê¸° ë•Œë¬¸ì— 2ì°¨ì› ë°°ì—´ì„ ë§Œë“œëŠ” ê²ƒë§Œìœ¼ë¡œ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒí•  ê²ƒì„ ì˜ˆìƒ rí–‰ cì—´ì˜ ê°’ì€ max(r,c)+1ê³¼ ê°™ê³  1ì°¨ì› ë°°ì—´ì˜ ì¸ë±ìŠ¤ iì— ëŒ€í•´ rì€ i//n, cëŠ” i%nì™€ ë™ì¼ leftë¶€í„° rightê¹Œì§€ì˜ ì¸ë±ìŠ¤ë¥¼ ê·œì¹™ì— ë§ëŠ” ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜ Time Complexity # O(N) = 10^5 Data Size # n: 1 \u0026lt;= int \u0026lt;= 10^7 left, right: 0 \u0026lt;= long \u0026lt;= n^2 right - left \u0026lt; 10^5 í•´ì„¤ ì½”ë“œ # Copy python def solution(n, left, right): return [max(divmod(i,n))+1 for i in range(left,right+1)] "},{"id":42,"href":"/blog/programmers-problems-17687/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 17687] nì§„ìˆ˜ ê²Œì„ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/17687 ë¬¸ì œ í•´ì„¤ # Idea # Math 0ë¶€í„° ì‹œì‘í•´ t*mì˜ ê¸¸ì´ë¥¼ ë§Œì¡±í•˜ëŠ” Nì§„ë²• ë°°ì—´ì„ ìƒì„± ë§¤ ìˆœì„œë§ˆë‹¤ p ìœ„ì¹˜ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ì¶”ì¶œí•´ ë¬¸ìì—´ë¡œ ë°˜í™˜ Data Size # n: 2 \u0026lt;= int \u0026lt;= 16 t: 0 \u0026lt; int \u0026lt;= 1,000 m: 2 \u0026lt;= int \u0026lt;= 100 p: 1 \u0026lt;= int \u0026lt;= m í•´ì„¤ ì½”ë“œ # Copy python alpha = {10:\u0026#39;A\u0026#39;,11:\u0026#39;B\u0026#39;,12:\u0026#39;C\u0026#39;,13:\u0026#39;D\u0026#39;,14:\u0026#39;E\u0026#39;,15:\u0026#39;F\u0026#39;} def n_base(num, base): result = str() while num \u0026gt; 0: num, mod = divmod(num, base) result += str(mod) if mod \u0026lt; 10 else alpha[mod] return result[::-1] def solution(n, t, m, p): arr = \u0026#39;01\u0026#39; total = t*m p = p%m i = 2 while len(arr) \u0026lt; total: arr += n_base(i, n) i += 1 answer = [t for i,t in enumerate(arr[:total]) if (i+1)%m==p] return \u0026#39;\u0026#39;.join(answer) "},{"id":43,"href":"/blog/boj-problems-1676/","title":"[ë°±ì¤€ 1676] íŒ©í† ë¦¬ì–¼ 0ì˜ ê°œìˆ˜ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1676 ë¬¸ì œ í•´ì„¤ # Idea # Math íŒ©í† ë¦¬ì–¼ ìˆ˜ë¥¼ êµ¬í•˜ê³  ë¬¸ìì—´ë¡œ ë³€í™˜í•´ ì—°ì†ë˜ëŠ” 0ì˜ ê°œìˆ˜ë¥¼ ì¶œë ¥ Data Size # N: 0 \u0026lt;= int \u0026lt;= 500 í•´ì„¤ ì½”ë“œ # Copy python from math import factorial import re N = int(input()) zeros = re.findall(\u0026#39;0+\u0026#39;, str(factorial(N))) if zeros: print(len(zeros[-1])) else: print(0) "},{"id":44,"href":"/blog/boj-problems-1541/","title":"[ë°±ì¤€ 1541] ìƒì–´ë²„ë¦° ê´„í˜¸ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1541 ë¬¸ì œ í•´ì„¤ # Idea # Greedy ìµœì†Ÿê°’ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” \u0026lsquo;-\u0026lsquo;ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê´„í˜¸ë¥¼ ì¹˜ëŠ” ê²ƒì´ ìµœì„  \u0026lsquo;-\u0026lsquo;ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹ì„ ë‚˜ëˆ„ê³  êµ¬ë¶„ëœ ì‹ì„ ê³„ì‚°í•˜ì—¬ ê²°ê³¼ë¥¼ ì¶œë ¥ Data Size # arr: str(50) í•´ì„¤ ì½”ë“œ # Copy python arr = input().split(\u0026#39;-\u0026#39;) answer = sum(map(int,arr[0].split(\u0026#39;+\u0026#39;))) for i in arr[1:]: answer -= sum(map(int,i.split(\u0026#39;+\u0026#39;))) print(answer) "},{"id":45,"href":"/blog/boj-problems-1389/","title":"[ë°±ì¤€ 1389] ì¼€ë¹ˆ ë² ì´ì»¨ì˜ 6ë‹¨ê³„ ë²•ì¹™ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1389 ë¬¸ì œ í•´ì„¤ # Idea # BFS 1ë¶€í„° Nê¹Œì§€ì˜ ë²ˆí˜¸ì— ëŒ€í•´ ë§¤ë²ˆ BFSë¥¼ ìˆ˜í–‰í•˜ë©´ì„œ ë‹¤ë¥¸ ëª¨ë“  ë…¸ë“œì™€ì˜ ê±°ë¦¬ë¥¼ íŒŒì•… ê°€ì¥ ì‘ì€ ê±°ë¦¬ì˜ í•©ì„ ê°€ì§„ ë…¸ë“œì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ì¶œë ¥ Time Complexity # O(N^2+NM) = 510,000 Data Size # N: 2 \u0026lt;= int \u0026lt;= 100 M: 1 \u0026lt;= int \u0026lt;= 5,000 í•´ì„¤ ì½”ë“œ # Copy python from collections import deque import sys input = sys.stdin.readline def bfs(target, nodes): num = [0] * (N+1) queue = deque([target]) visited = [False] * (N+1) visited[target] = True while queue: node = queue.popleft() for next in nodes[node]: if not visited[next]: num[next] = num[node]+1 visited[next] = True queue.append(next) return sum(num) N, M = map(int, input().split()) rels = [list() for _ in range(N+1)] kevin = [0] * (N+1) for _ in range(M): A, B = map(int, input().split()) rels[A].append(B) rels[B].append(A) for i in range(1,N+1): kevin[i] = bfs(i, rels) print(kevin.index(min(kevin[1:]))) "},{"id":46,"href":"/blog/boj-problems-5430/","title":"[ë°±ì¤€ 5430] AC (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/5430 ë¬¸ì œ í•´ì„¤ # Idea # Implementation, Deque ë¬¸ì œì—ì„œ ì£¼ì–´ì§„ëŒ€ë¡œ ë§¤ë²ˆ ë°°ì—´ì„ ë’¤ì§‘ìœ¼ë©´ O(N^2)ì˜ ì‹œê°„ ë³µì¡ë„ë¡œ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒ ë°°ì—´ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šìœ¼ë©´ì„œ R í•¨ìˆ˜ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ìƒíƒœ ë³€ìˆ˜ë¥¼ ì •ì˜í•˜ê³ ,\nD í•¨ìˆ˜ê°€ í˜¸ì¶œë  ê²½ìš° ë°°ì—´ì˜ ìƒíƒœì— ë”°ë¼ ì²« ë²ˆì§¸ ìˆ˜ë¥¼ ë²„ë¦´ì§€ ë§ˆì§€ë§‰ ìˆ˜ë¥¼ ë²„ë¦´ì§€ ê²°ì • ë§ˆì§€ë§‰ì— ë°°ì—´ì˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ì •í•´ì§„ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì¶œë ¥ Time Complexity # O(N) = 100,000 Data Size # T: 1 \u0026lt;= int \u0026lt;= 100 p: 1 \u0026lt;= int \u0026lt;= 100,000 n: 1 \u0026lt;= int \u0026lt;= 100,000 arr: int(100) * n (like [x_1,\u0026hellip;,x_n]) í•´ì„¤ ì½”ë“œ # Copy python from collections import deque for _ in range(int(input())): p = input() n = int(input()) arr = deque(eval(input())) forward = True try: for cmd in p: if cmd == \u0026#39;R\u0026#39;: forward = not forward elif cmd == \u0026#39;D\u0026#39;: if forward: arr.popleft() else: arr.pop() arr = map(str,arr) if forward else map(str,reversed(arr)) print(f\u0026#39;[{\u0026#34;,\u0026#34;.join(map(str,arr))}]\u0026#39;) except IndexError: print(\u0026#39;error\u0026#39;) "},{"id":47,"href":"/blog/boj-problems-1463/","title":"[ë°±ì¤€ 1463] 1ë¡œ ë§Œë“¤ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1463 ë¬¸ì œ í•´ì„¤ # Idea # Dynamic Programming Nì— ëŒ€í•´ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê²½ìš°ì—ì„œ 3ìœ¼ë¡œ ë‚˜ëˆ„ê¸°, 2ë¡œ ë‚˜ëˆ„ê¸°, 1ì„ ë¹¼ëŠ” ì—°ì‚°ì„ ë°˜ë³µ ìˆ˜í–‰í•˜ê³ \nê°ê°ì˜ ì—°ì‚°íšŸìˆ˜ ë³„ë¡œ ë„ì¶œí•  ìˆ˜ ìˆëŠ” ê°’ì„ ëª¨ë‘ ì €ì¥ ì•ì„  ê²°ê³¼ë¥¼ ëª¨ë‘ í™œìš©í•´ ë‹¤ìŒ ê²°ê³¼ì— ëŒ€í•œ ëª¨ë“  ê²½ìš°ë¥¼ íƒìƒ‰í•˜ê³  ê²°ê³¼ ì§‘í•©ì— 1ì´ ìˆì„ ì‹œ íƒìƒ‰ì„ ì¢…ë£Œ 1ì´ í¬í•¨ëœ ë§ˆì§€ë§‰ ì§‘í•©ì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ìµœì†Œ ì—°ì‚°íšŸìˆ˜ë¡œ ì¶œë ¥ Data Size # N: 1 \u0026lt;= int \u0026lt;= 10^6 í•´ì„¤ ì½”ë“œ # Copy python N = int(input()) dp = [{N,}] while 1 not in dp[-1]: dp.append(set()) for n in dp[-2]: if n % 3 == 0: dp[-1].add(n//3) if n % 2 == 0: dp[-1].add(n//2) dp[-1].add(n-1) print(len(dp)-1) "},{"id":48,"href":"/blog/boj-problems-1697/","title":"[ë°±ì¤€ 1697] ìˆ¨ë°”ê¼­ì§ˆ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1697 ë¬¸ì œ í•´ì„¤ # Idea # BFS Nì—ì„œ ì‹œì‘í•´ Kì— ë„ë‹¬í•  ë•Œê¹Œì§€ x-1, x+1, x*2ì— ëŒ€í•œ ìµœë‹¨ê±°ë¦¬ë¥¼ íƒìƒ‰ ë‘ ì ì´ ìœ„ì¹˜í•  ìˆ˜ ìˆëŠ” ë²”ìœ„ ë‚´ì—ì„œ ê°€ê¹Œìš´ ê±°ë¦¬ì˜ ì ë¶€í„° íƒìƒ‰ì„ ìˆ˜í–‰ Kì— ëŒ€í•œ ê±°ë¦¬ë¥¼ ì¶œë ¥ Nì´ Kë³´ë‹¤ í´ ê²½ìš° x-1 ì™¸ì—ëŠ” ì´ë™ìˆ˜ë‹¨ì´ ì—†ê¸° ë•Œë¬¸ì— ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ ì˜ˆì™¸ë¡œ ì²˜ë¦¬ Time Complexity # O(N) = 100,000 Data Size # N: 0 \u0026lt;= int \u0026lt;= 100,000 K: 0 \u0026lt;= int \u0026lt;= 100,000 í•´ì„¤ ì½”ë“œ # Copy python from collections import deque def bfs(start, target): MAX = 10**5 count = [0] * (MAX+1) queue = deque([start]) while queue: x = queue.popleft() if x == target: return count[x] for nx in (x-1,x+1,x*2): if 0 \u0026lt;= nx \u0026lt;= MAX and not count[nx]: count[nx] = count[x] + 1 queue.append(nx) N, K = map(int, input().split()) if N \u0026gt;= K: print(N - K) else: print(bfs(N, K)) "},{"id":49,"href":"/blog/boj-problems-20922/","title":"[ë°±ì¤€ 20922] ê²¹ì¹˜ëŠ” ê±´ ì‹«ì–´ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/20922 ë¬¸ì œ í•´ì„¤ # Idea # Two Pointer ìˆ˜ì—´ì˜ ì‹œì‘ê³¼ ë ì§€ì ì— ëŒ€í•œ ë‘ ê°œì˜ í¬ì¸í„° ì§€ì • ë ì§€ì ì— ëŒ€í•œ í¬ì¸í„°ë¥¼ í™•ì¥í•˜ë©´ì„œ íƒìƒ‰ë˜ëŠ” ì›ì†Œì˜ ìˆ˜ë¥¼ ì¹´ìš´íŠ¸ ì›ì†Œì˜ ìˆ˜ê°€ Kê°œì™€ ê°™ì•„ì§€ëŠ” ì‹œì ë¶€í„° ì‹œì‘ ì§€ì ì— ëŒ€í•œ í¬ì¸í„°ë¥¼ í™•ì¥í•˜ì—¬ ë²”ìœ„ ì¶•ì†Œ ìµœì¢…ì ìœ¼ë¡œ ë‘ í¬ì¸í„° ê°„ ê±°ë¦¬ì˜ ìµœëŒ€ì¹˜ë¥¼ ì¶œë ¥ Time Complexity # O(N) = 200,000 Data Size # N: 1 \u0026lt;= int \u0026lt;= 200,000 K: 1 \u0026lt;= int \u0026lt;= 100 a: int(100,000) * N í•´ì„¤ ì½”ë“œ # Copy python N, K = map(int, input().split()) a = list(map(int, input().split())) answer = 0 start, end = 0, 0 counter = [0] * (max(a)+1) while end \u0026lt; N: if counter[a[end]] \u0026lt; K: counter[a[end]] += 1 end += 1 else: counter[a[start]] -= 1 start += 1 answer = max(end-start, answer) print(answer) "},{"id":50,"href":"/blog/boj-problems-22859/","title":"[ë°±ì¤€ 22859] HTML íŒŒì‹± (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/22859 ë¬¸ì œ í•´ì„¤ # Idea # Implementation, String , , íƒœê·¸ ë“±ì„ êµ¬ë¶„ ì˜ attributeì¸ titleì„ ìš°ì„  ì¶œë ¥í•˜ê³  ì•ˆì— ìˆëŠ” ë¥¼ í•œ ì¤„ì”© ì¶œë ¥ ì•ˆì— ìˆëŠ” íƒœê·¸ì™€ ì‹œì‘ê³¼ ëì— ìˆëŠ” ê³µë°±ì„ ì§€ìš°ê³  2ê°œ ì´ìƒì˜ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€ê²½ ì œëª©ì€ ë¬´ì¡°ê±´ ì¡´ì¬í•˜ê³  íƒœê·¸ ì‚¬ì´ì—ëŠ” ê³µë°±ì´ ì—†ìœ¼ë©° íƒœê·¸ëŠ” ì˜¬ë°”ë¥¸ ìŒìœ¼ë¡œë§Œ ì£¼ì–´ì§ì„ ë³´ì¥ ì •ê·œ í‘œí˜„ì‹ì„ í™œìš©í•´ ì¡°ê±´ì— ë§ëŠ” ë¬¸ì¥ì„ íŒŒì‹±í•˜ê³  ë¶ˆí•„ìš”í•œ ë¬¸ìë¥¼ ì œê±°í•´ ì¶œë ¥ Data Size # source: str(1,000,000) í•´ì„¤ ì½”ë“œ # Copy python import re source = input() main = re.findall(\u0026#39;\u0026lt;main\u0026gt;(.*)\u0026lt;/main\u0026gt;\u0026#39;, source)[0] div_list = re.findall(\u0026#39;\u0026lt;div title=\u0026#34;(.*?)\u0026#34;\u0026gt;(.*?)\u0026lt;/div\u0026gt;\u0026#39;, main) for title, paragraph in div_list: print(\u0026#39;title :\u0026#39;, title) p_list = re.findall(\u0026#39;\u0026lt;p\u0026gt;(.*?)\u0026lt;/p\u0026gt;\u0026#39;, paragraph) for p in p_list: p = re.sub(\u0026#39;(\u0026lt;.*?\u0026gt;)\u0026#39;, \u0026#39;\u0026#39;, p) p = re.sub(\u0026#39;\\s+\u0026#39;, \u0026#39; \u0026#39;, p.strip()) print(p) "},{"id":51,"href":"/blog/programmers-problems-43238/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ 43238] ì…êµ­ì‹¬ì‚¬ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/43238 ë¬¸ì œ í•´ì„¤ # Idea # Binary Search answerì— ëŒ€í•œ ì´ì§„íƒìƒ‰ ìˆ˜í–‰ (1 \u0026lt;= answer \u0026lt;= max(times)*n) ë§¤ íƒìƒ‰ë§ˆë‹¤ answer ì‹œê°„ ë™ì•ˆ ì‹¬ì‚¬ê´€ë“¤ì´ ì‹¬ì‚¬í•  ìˆ˜ ìˆëŠ” ì‚¬ëŒì˜ ìˆ˜ë¥¼ ê³„ì‚° ì‹¬ì‚¬í•œ ì‚¬ëŒì˜ ìˆ˜ê°€ nëª… ì´ìƒì¼ ê²½ìš° ìµœëŒ€ ë²”ìœ„ë¥¼ ì¡°ì •í•˜ê³  ì¬íƒìƒ‰ ì‹¬ì‚¬í•œ ì‚¬ëŒì˜ ìˆ˜ê°€ nëª… ë¯¸ë§Œì¼ ê²½ìš° ìµœì†Œ ë²”ìœ„ë¥¼ ì¡°ì •í•˜ê³  ì¬íƒìƒ‰ nëª… ì´ìƒì˜ ì‚¬ëŒì„ ì‹¬ì‚¬í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ answerë¥¼ ë°˜í™˜ Time Complexity # Binary Search: O(M Log N^N) = 6,000,000 Data Size # n: 1 \u0026lt;= int \u0026lt;= 1,000,000,000 times: int(1,000,000,000) * 100,000 í•´ì„¤ ì½”ë“œ # Copy python def solution(n, times): answer = 0 start, end = 1, max(times)*n while start \u0026lt;= end: mid = (start+end)//2 passed = 0 for time in times: passed += mid // time if passed \u0026gt;= n: break if passed \u0026gt;= n: answer = mid end = mid-1 elif passed \u0026lt; n: start = mid+1 return answer "},{"id":52,"href":"/blog/programmers-problems-42895/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ 42895] Nìœ¼ë¡œ í‘œí˜„ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/42895 ë¬¸ì œ í•´ì„¤ # Idea # Dynamic Programming S[1] = {N} S[2] = {NN, N+N, N-N, N*N, N/N} S[3] = {NNN, S[2][x] (+,-,*,/) S[1][y], \u0026hellip;} 2ë¶€í„° 8ê¹Œì§€ì˜ ë²”ìœ„ë¥¼ ê°€ì§„ iì™€ 1ë¶€í„° i-1ê¹Œì§€ì˜ ë²”ìœ„ë¥¼ ê°€ì§„ jì— ëŒ€í•´,\nS[j]ì™€ S[i-j]ì˜ ì‚¬ì¹™ì—°ì‚° ê²°ê³¼ë¥¼ S[i]ì— ì¶”ê°€í•˜ê³  í•´ë‹¹ ì§‘í•©ì´ numberë¥¼ í¬í•¨í•˜ëŠ”ì§€ ê²€ì¦ Time Complexity # DP: O(1) Data Size # N: 1 \u0026lt;= int \u0026lt;= 9 number: 1 \u0026lt;= int \u0026lt;= 32,000 answer: int \u0026lt;= 8 í•´ì„¤ ì½”ë“œ # Copy python from itertools import product def solution(N, number): S = [set() for _ in range(9)] if N == number: return 1 else: S[1].add(N) for i in range(2,9): S[i].add(int(str(N)*i)) for j in range(1,i): for x,y in product(S[j],S[i-j]): S[i].update({x+y,x-y,x*y}) if y != 0: S[i].add(x//y) if number in S[i]: return i return -1 "},{"id":53,"href":"/blog/boj-problems-21318/","title":"[ë°±ì¤€ 21318] í”¼ì•„ë…¸ ì²´ì¡° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/21318 ë¬¸ì œ í•´ì„¤ # Idea # Prefix Sum ì‹¤ìˆ˜í•œ ê³¡ì— ëŒ€í•œ ëˆ„ì í•©ì„ êµ¬í•˜ê³  ì¸ë±ì‹±ì„ í†µí•´ íŠ¹ì • êµ¬ê°„ì— ëŒ€í•œ ëˆ„ì í•© ì¶œë ¥ ë§ˆì§€ë§‰ ê³¡ì€ í•­ìƒ ì„±ê³µí•˜ê¸° ë•Œë¬¸ì— yì— ëŒ€í•œ ëˆ„ì í•©ê³¼ y-1ì— ëŒ€í•œ ëˆ„ì í•©ì´ ë‹¤ë¥´ë©´ 1 ê°ì†Œ Time Complexity # Prefix Sum: O(N) = 100,000 Data Size # N: 1 \u0026lt;= int \u0026lt;= 100,000 scores: int(10^9) * N Q: 1 \u0026lt;= int \u0026lt;= 100,000 í•´ì„¤ ì½”ë“œ # Copy python import sys input = sys.stdin.readline N = int(input()) scores = list(map(int, input().split())) Q = int(input()) fails = [0]*(N+1) for i in range(1,N+1): fails[i] = fails[i-1] + int(scores[i-1] \u0026gt; scores[min(i,N-1)]) for _ in range(Q): x, y = map(int, input().split()) answer = fails[y] - fails[x-1] if fails[y] != fails[y-1]: answer -= 1 print(answer) "},{"id":54,"href":"/blog/boj-problems-16987/","title":"[ë°±ì¤€ 16987] ê³„ë€ìœ¼ë¡œ ê³„ë€ì¹˜ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/16987 ë¬¸ì œ í•´ì„¤ # Idea # Backtracking 0ë²ˆì§¸ ê³„ë€ë¶€í„° ë§ˆì§€ë§‰ ê³„ë€ê¹Œì§€ì˜ ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ë¥¼ íƒìƒ‰ ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ í˜„ì¬ ê³„ë€ì´ ê¹¨ì§„ ê²½ìš° ë˜ëŠ” ë‚˜ë¨¸ì§€ ëª¨ë“  ê³„ë€ì´ ê¹¨ì§„ ê²½ìš°ë¥¼ ì˜ˆì™¸ë¡œ ì²˜ë¦¬ í•œ ë²ˆì— ë‘ ê°œ ì´ìƒì˜ ê³„ë€ì„ ì¹˜ëŠ” ê²½ìš°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ê³„ë€ì„ ì¹œ í›„ ì›ìƒë³µêµ¬ ìˆ˜í–‰ Time Complexity # Backtracking: O(N^N) = 16,777,216 Data Size # N: 1 \u0026lt;= int \u0026lt;= 8 S, W: 1 \u0026lt;= int \u0026lt;= 300 í•´ì„¤ ì½”ë“œ # Copy python N = int(input()) eggs = list() for _ in range(N): eggs.append(list(map(int, input().split()))) answer = 0 def dfs(eggs, idx): global answer if idx == N: answer = max(answer, len([s for s,w in eggs if s \u0026lt; 1])) return if eggs[idx][0] \u0026lt; 1: dfs(eggs, idx+1) return if len([s for s,w in eggs if s \u0026lt; 1]) \u0026gt;= N-1: answer = max(answer, N-1) return for target in range(N): if target != idx and eggs[target][0] \u0026gt; 0: eggs[target][0] -= eggs[idx][1] eggs[idx][0] -= eggs[target][1] dfs(eggs, idx+1) eggs[target][0] += eggs[idx][1] eggs[idx][0] += eggs[target][1] dfs(eggs, 0) print(answer) "},{"id":55,"href":"/blog/boj-problems-16918/","title":"[ë°±ì¤€ 16918] ë´„ë²„ë§¨ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/16918 ë¬¸ì œ í•´ì„¤ # Idea # Simulation (or BFS) ì´ˆê¸°ì— ë¹ˆ ì¹¸(.)ì„ 0, í­íƒ„ì´ ìˆëŠ” ì¹¸(O)ì„ 1ë¡œ ì„¤ì • ì²˜ìŒì— í­íƒ„ì´ ìˆëŠ” ì¹¸ì˜ ìƒíƒœë¥¼ ìš°ì„  1 ì¦ê°€ì‹œí‚¤ê³ , ì´í›„ ëª¨ë“  ì¹¸ì˜ ìƒíƒœë¥¼ 1ì”© ì¦ê°€ì‹œí‚¤ëŠ” ê³¼ì • ë°˜ë³µ ë§¤ë²ˆ ê° ì¹¸ì˜ ìƒíƒœë¥¼ ì ê²€í•˜ë©´ì„œ 3ì„ ì´ˆê³¼í•  ê²½ìš° í•´ë‹¹ ìœ„ì¹˜ ë° ì´ì›ƒ ìœ„ì¹˜ë¥¼ í­ë°œ ëŒ€ìƒì— ì¶”ê°€ í­ë°œ ëŒ€ìƒì´ ì¡´ì¬í•  ê²½ìš° ê²©ìì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ” ë²”ìœ„ ë‚´ì—ì„œ ìƒíƒœë¥¼ 0ìœ¼ë¡œ ë³€í™˜ ìœ„ ê³¼ì •ì„ Nì´ˆ ë™ì•ˆ ë°˜ë³µí•˜ê³ , 0ì€ ë¹ˆì¹¸ìœ¼ë¡œ, ë‚˜ë¨¸ì§€ëŠ” Oë¡œ í‘œì‹œí•˜ì—¬ ì¶œë ¥ Time Complexity # Simulation: O(N^3) = 8,000,000 Data Size # R, C, N: 1 \u0026lt;= int \u0026lt;= 200 í•´ì„¤ ì½”ë“œ # Copy python import sys input = sys.stdin.readline R, C, N = map(int, input().split()) board = list() char2id = lambda x: 0 if x == \u0026#39;.\u0026#39; else 1 id2char = lambda x: \u0026#39;.\u0026#39; if x == 0 else \u0026#39;O\u0026#39; for _ in range(R): board.append(list(map(char2id, input().strip()))) board = [[state+1 if state \u0026gt; 0 else 0 for state in row] for row in board] for s in range(2,N+1): board = [[state+1 for state in row] for row in board] bomb = set() for i in range(R): for j in range(C): if board[i][j] \u0026gt; 3: neighbor = [(0,0),(1,0),(-1,0),(0,1),(0,-1)] [bomb.add((i+dy,j+dx)) for dy,dx in neighbor] for i,j in bomb: if 0 \u0026lt;= i \u0026lt; R and 0 \u0026lt;= j \u0026lt; C: board[i][j] = 0 for row in board: print(\u0026#39;\u0026#39;.join(list(map(id2char, row)))) "},{"id":56,"href":"/blog/boj-problems-2302/","title":"[ë°±ì¤€ 2302] ê·¹ì¥ ì¢Œì„ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/2302 ë¬¸ì œ í•´ì„¤ # Idea # Dynamic Programming ìë¦¬ë¥¼ ì˜®ê¸¸ ìˆ˜ ìˆëŠ” ì—°ì†ë˜ëŠ” ì¢Œì„ì˜ ìˆ˜ëŠ” í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ ë”°ë¦„ (S[i] = F[i+1]) VIP ì¢Œì„ ë²ˆí˜¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—°ì†ë˜ëŠ” ì¢Œì„ì˜ ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ ëª¨ë“  ì—°ì†ë˜ëŠ” ì¢Œì„ ìˆ˜ì— ëŒ€í•œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ë¥¼ ê³±í•˜ê³  ì¶œë ¥ Sequence # S2 (1,2) -\u0026gt; (1,2), (2,1) = 2(F3)\nS3 (1,2,3) -\u0026gt; (1,2,3), (2,1,3), (1,3,2) = 3(F4)\nS4 (1,2,3,4) -\u0026gt; (1,2,3,4), (2,1,3,4), (1,2,4,3), (1,3,2,4), (2,1,4,3) = 5(F5)\nS5 (1,2,3,4,5) -\u0026gt; (1,2,3,4,5), (1,2,4,3,5), (1,2,3,5,4), (2,1,3,4,5), (2,1,4,3,5), (2,1,3,5,4), (1,3,2,4,5), (1,3,2,5,4) = 8(F6)\nS6 (1,2,3,4,5,6) -\u0026gt; (1,2,3,4,5,6), (1,2,4,3,5,6), (1,2,3,5,4,6), (1,2,3,4,6,5), (1,2,4,3,6,5), \u0026hellip;\nTime Complexity # DP: O(N) = 40 Data Size # N: 1 \u0026lt;= int \u0026lt;= 40 M: 0 \u0026lt;= int \u0026lt;= N answer: int \u0026lt; 2^31-1 í•´ì„¤ ì½”ë“œ # Copy python import sys input = sys.stdin.readline N = int(input()) M = int(input()) seats, idx = list(), 0 for _ in range(M): vip = int(input()) seats.append(vip-idx-1) idx = vip seats.append(N-idx) F = {1:1, 2:1} def fibonacci(n): if n in F: return F[n] F[n] = fibonacci(n-1) + fibonacci(n-2) return F[n] answer = 1 for seat in seats: if seat \u0026gt; 1: answer *= fibonacci(seat+1) print(answer) "},{"id":57,"href":"/blog/boj-problems-18352/","title":"[ë°±ì¤€ 18352] íŠ¹ì • ê±°ë¦¬ì˜ ë„ì‹œ ì°¾ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/18352 ë¬¸ì œ í•´ì„¤ # Idea # BFS ì‹œì‘ ë…¸ë“œ Xë¶€í„° ì—°ê²°ëœ ë…¸ë“œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë°©ë¬¸í•˜ë©´ì„œ Xë¡œë¶€í„° ë–¨ì–´ì§„ ê±°ë¦¬ë¥¼ ê¸°ë¡ ê±°ë¦¬ê°€ Kì™€ ê°™ì€ ë…¸ë“œë¥¼ ì¶œë ¥í•˜ê³ , í•´ë‹¹í•˜ëŠ” ë…¸ë“œê°€ ì—†ì„ ê²½ìš° -1ì„ ì¶œë ¥ ê±°ë¦¬ê°€ Kë¥¼ ë„˜ì–´ê°€ì§€ ì•ŠëŠ” ë…¸ë“œì— ëŒ€í•´ì„œë§Œ íƒìƒ‰í•˜ì—¬ ì‹œê°„ ë‹¨ì¶• Time Complexity # BFS: O(N+M) = 1,300,000 Data Size # N: 2 \u0026lt;= int \u0026lt;= 300,000 M: 1 \u0026lt;= int \u0026lt;= 1,000,000 K: 1 \u0026lt;= int \u0026lt;= 300,000 X: 1 \u0026lt;= int \u0026lt;= N A, B: 1 \u0026lt;= int \u0026lt;= N í•´ì„¤ ì½”ë“œ # Copy python from collections import deque import sys input = sys.stdin.readline N, M, K, X = map(int, input().split()) nodes = [[] for _ in range(N+1)] visited = [False] * (N+1) dists = [0] * (N+1) for _ in range(M): A, B = map(int, input().split()) nodes[A].append(B) queue = deque() queue.append(X) visited[X] = True while queue: city = queue.popleft() for next in nodes[city]: if not visited[next] and dists[city] \u0026lt; K: queue.append(next) visited[next] = True dists[next] = dists[city]+1 targets = [i for i,d in enumerate(dists) if d==K] if targets: for target in targets: print(target) else: print(-1) "},{"id":58,"href":"/blog/boj-problems-1495/","title":"[ë°±ì¤€ 1495] ê¸°íƒ€ë¦¬ìŠ¤íŠ¸ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/1495 ë¬¸ì œ í•´ì„¤ # Idea # Dynamic Programming P[i] = max(P[i-1]+V[i-1],P[i-1]-V[i-1]), 0 \u0026lt;= P[i] \u0026lt;= M ëª¨ë“  P[i-1]ê°€ P[i+1]ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë²”ìœ„ ë‚´ ëª¨ë“  ê°’ì„ ì§‘í•©ì— ì €ì¥ ë§ˆì§€ë§‰ ê³¡ì— ëŒ€í•œ Pê°€ ì¡´ì¬í•  ê²½ìš° ìµœëŒ“ê°’ì„ ì¶œë ¥í•˜ê³ , ì—†ì„ ê²½ìš° -1ì„ ì¶œë ¥ Time Complexity # DP: O(NM) = 50,000 Data Size # N: 1 \u0026lt;= int \u0026lt;= 50 M: 1 \u0026lt;= int \u0026lt;= 1,000 S: 0 \u0026lt;= int \u0026lt;= M V: int * N í•´ì„¤ ì½”ë“œ # Copy python N, S, M = map(int, input().split()) V = list(map(int, input().split())) P = [set() for _ in range(N+1)] P[0] = {S,} for i in range(1,N+1): for j in P[i-1]: if j+V[i-1] \u0026lt;= M: P[i].add(j+V[i-1]) if j-V[i-1] \u0026gt;= 0: P[i].add(j-V[i-1]) if P[-1]: print(max(P[-1])) else: print(-1) "},{"id":59,"href":"/blog/programmers-problems-17686/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 17686] íŒŒì¼ëª… ì •ë ¬ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/17686 ë¬¸ì œ í•´ì„¤ # Idea # ì •ê·œí‘œí˜„ì‹ì„ í™œìš©í•´ HEAD, NUMBER, TAILì„ ë¶„ë¦¬ ì „ì²´ íŒŒì¼ëª…ì„ ì™„ì „íƒìƒ‰í•˜ë©´ì„œ ë¦¬ìŠ¤íŠ¸ì— ë¶„ë¦¬ëœ íŒŒì¼ëª…ì„ ì €ì¥ HEADì™€ NUMBERë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ëª…ì„ ì •ë ¬í•˜ê³  ì •ë ¬ëœ ì›ë³¸ íŒŒì¼ëª…ì„ ë°˜í™˜ Time Complexity # Brute-Force + Sort: O(NM+NlogN)) = 110000 Data Size # files: str(100) * 1000 í•´ì„¤ ì½”ë“œ # Copy python import re def solution(files): answer = [] for file in files: head, number, tail = re.findall(\u0026#39;([^0-9]+)([0-9]+)(.*)\u0026#39;, file)[0] answer.append((head.lower(), int(number), tail, file)) answer.sort(key=lambda x: [x[0],x[1]]) return [file for _,_,_,file in answer] "},{"id":60,"href":"/blog/programmers-problems-17684/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 17684] ì••ì¶• (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/17684 ë¬¸ì œ í•´ì„¤ # Idea # LZW ì•Œê³ ë¦¬ì¦˜ (Listë¡œ êµ¬í˜„) ë‹¨ì–´ë¥¼ ë¬¸ì ë‹¨ìœ„ë¡œ íƒìƒ‰í•˜ë©´ì„œ ìºì‹œì— ì¶”ê°€ ìºì‹œê°€ ë¬¸ì ì‚¬ì „ì— ì—†ì„ ê²½ìš° ì´ì „ ë¬¸ìê¹Œì§€ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ê³  ìºì‹œë¥¼ ë¬¸ì ì‚¬ì „ì— ì¶”ê°€ Time Complexity # Brute-Force: O(N^2) = 1000000 Data Size # msg: str(1000) í•´ì„¤ ì½”ë“œ # Copy python def solution(msg): answer = [] chars = [chr(x) for x in range(64,91)] cache = str() for c in msg: cache += c if cache not in chars: answer.append(chars.index(cache[:-1])) chars.append(cache) cache = c answer.append(chars.index(cache)) return answer "},{"id":61,"href":"/blog/programmers-problems-17683/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 17683] ë°©ê¸ˆê·¸ê³¡ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://programmers.co.kr/learn/courses/30/lessons/17683 ë¬¸ì œ í•´ì„¤ # Idea # ì•…ë³´ ì •ë³´ì—ì„œ #ì´ í¬í•¨ëœ ìŒì„ ì†Œë¬¸ìë¡œ ëŒ€ì²´í•˜ê³  ì™„ì „íƒìƒ‰ ì‹œê°„ ê³„ì‚°ì€ timedelta í™œìš© (ì¬ìƒì‹œê°„,ì œëª©)ìœ¼ë¡œ êµ¬ì„±ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬ Time Complexity # Brute-Force: O(NM) = 143,900 Data Size # m: 1 \u0026lt;= int \u0026lt;= 1439 musicinfos: list \u0026lt;= 100 musicinfos[0,1]: HH:MM (00:00 - 23:59) musicinfos[2]: str(64) musicinfos[4]: 1 \u0026lt;= int \u0026lt;= 1439 í•´ì„¤ ì½”ë“œ # Copy python import datetime as dt import re import math def solution(m, musicinfos): answer = list() lower_repl = lambda match: match.group(1)[0].lower() sharp_repl = lambda s: re.sub(\u0026#39;([A-G]#)\u0026#39;, lower_repl, s) m = sharp_repl(m) strptime = lambda x: dt.timedelta(hours=int(x[0]),minutes=int(x[1])) for info in musicinfos: start, end, title, chord = info.split(\u0026#39;,\u0026#39;) plays = (strptime(end.split(\u0026#39;:\u0026#39;))-strptime(start.split(\u0026#39;:\u0026#39;))).seconds//60 chord = sharp_repl(chord) chord = (chord * math.ceil(plays/len(chord)))[:plays] if m in chord: answer.append((plays,title)) return sorted(answer, key=lambda x: x[0], reverse=True)[0][1] if len(answer) else \u0026#39;(None)\u0026#39; "},{"id":62,"href":"/blog/programmers-problems-17680/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 17680] ìºì‹œ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://school.programmers.co.kr/learn/courses/30/lessons/17680 ë¬¸ì œ í’€ì´ # Idea # LRU ì•Œê³ ë¦¬ì¦˜ (Dequeë¡œ êµ¬í˜„) ë„ì‹œì´ë¦„ì´ ìºì‹œì— ì¡´ì¬í•  ê²½ìš° ì‹œê°„ì—ì„œ 1 ì¶”ê°€, ì•„ë‹ ê²½ìš° 5 ì¶”ê°€ ìºì‹œì—ì„œ ì°¸ê³ í•œ ë„ì‹œëŠ” deque ìµœìƒë‹¨ìœ¼ë¡œ ì¬ë°°ì¹˜ ìºì‹œ ì‚¬ì´ì¦ˆë¥¼ ì´ˆê³¼í•  ê²½ìš° ê°€ì¥ ì˜¤ë˜ëœ ë„ì‹œë¥¼ ì œê±° Time Complexity # Deque: O(N) = 100,000 Data Size # cacheSize: 0 \u0026lt;= int \u0026lt;= 30 cities: str(20) * 100,000 í•´ì„¤ ì½”ë“œ # Copy python from collections import deque def solution(cacheSize, cities): answer = 0 cache = deque(maxlen=cacheSize) for city in cities: city = city.lower() if city in cache: answer += 1 cache.remove(city) cache.append(city) else: answer += 5 cache.append(city) return answer "},{"id":63,"href":"/blog/2022-07-21/","title":"2022-07-21 Log","section":"Posts","content":"Task # í†µê³„ ëª¨ë¸: ARIMA, ARIMA í™•ì¥ ëª¨ë¸ ë”¥ëŸ¬ë‹ ëª¨ë¸: DeepAR, MQRNN, N-BEATS, Informer, TFT Data # Stationary: ì‹œê³„ì—´ì˜ íŠ¹ì§•ì´ ê´€ì¸¡ëœ ì‹œê°„ê³¼ ë¬´ê´€ (ë°±ìƒ‰ì¡ìŒ ë“±) Non-stationary: Trend í˜¹ì€ seasonalityê°€ ì¡´ì¬í•˜ëŠ” ë°ì´í„° Analysis # log ì°¨ë¶„ ACF(ìê¸° ìƒê´€ ê·¸ë˜í”„): ë¬´ì‘ìœ„ ì‹ í˜¸ê°€ ë‘ ì‹œì ì—ì„œ ê°–ëŠ” ìƒê´€ê³„ìˆ˜ë¥¼ í‘œí˜„í•˜ëŠ” í•¨ìˆ˜ stationary: ì˜ˆì¸¡ê°’ì´ ë¬´í•œëŒ€ë¡œ ë°œì‚°í•˜ì§€ ì•Šê³ , ì¼ì •í•œ ë²”ìœ„ ë‚´ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ëª©ì  ARIAM: stationary ë°ì´í„° ì˜ˆì¸¡ ì„±ëŠ¥ ìš°ìˆ˜ Deep-Learning # non-stationary: training-validation, validation-test ê°„ mismatching ì•Œê³ ë¦¬ì¦˜ ê±°ë˜ê°€ ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ë³€í™˜ domain adaptation \u0026gt; transfer learning Self-Supervised Learning # unlabeld ë°ì´í„° í™œìš© \u0026gt; labeling ì§€ì • (pretext task) ëª¨ë¸ì´ pretext taskë¥¼ í•™ìŠµí•˜ì—¬ ë°ì´í„° ìì²´ì— ëŒ€í•œ ì´í•´ (pre-training) main taskì— ëŒ€í•˜ì—¬ transfer learning ìˆ˜í–‰ (downstream task) "},{"id":64,"href":"/blog/2022-07-19/","title":"2022-07-19 Log","section":"Posts","content":"Time Series # ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì€ ì‹œê°„ì„ ë…ë¦½ë³€ìˆ˜ë¡œ í™œìš© ì‹œê³„ì—´ ë¶„ì„ì€ ì‹œê³„ì—´ ë°ì´í„°ì˜ í™•ë¥ ì  íŠ¹ì„±ì´ ì‹œê°„ì´ ì§€ë‚˜ë„ ê·¸ëŒ€ë¡œ ìœ ì§€ë  ê²ƒ(ì •ìƒì„±)ì„ ê°€ì • AR Model: ìê¸° íšŒê·€ ëª¨ë¸, ê³¼ê±° ì‹œì ì˜ ìì‹ ì˜ ë°ì´í„°ê°€ í˜„ ì‹œì ì˜ ìì‹ ì—ê²Œ ì˜í–¥ì„ ë¯¸ì¹¨ MA Model: ì´ë™ í‰ê·  ëª¨ë¸, ì´ì „ í•­ì˜ ì—ëŸ¬ë¥¼ í˜„ ì‹œì ì— ë°˜ì˜í•´ ë³€í™”ìœ¨ì— ë§ì¶° ì¶”ì • ARMA Model: ARê³¼ MA ëª¨ë¸ì„ í•©ì¹œ ëª¨ë¸, ê³¼ê±° ì‹œì ì˜ ìì‹ ê³¼ ì¶”ì„¸ê¹Œì§€ ì „ë¶€ ë°˜ì˜ ARIMA Model: í˜„ì¬ ìƒíƒœì—ì„œ ë°”ë¡œ ì´ì „ ìƒíƒœë¥¼ ë¹¼ì£¼ëŠ” ì°¨ë¶„ì„ ì ìš© ARIMA Model # ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ìì‹ ì˜ ì‹œì°¨ë¡œ ì´ë£¨ì–´ì§„ ì„ í˜• ì¡°í•©ê³¼ ì§€ì—°ëœ ì˜ˆì¸¡ ì˜¤ì°¨ì˜ ì„ í˜•ì¡°í•©ì— ê¸°ë°˜ $AR(1):Y_t=\\alpha+\\beta_1Y_{t-1}+\\epsilon_t,where|\\beta_1|\u0026lt;1$ $MA(2):Y_t=\\alpha+\\phi_1\\epsilon_{t-1}+\\phi_2\\epsilon_{t-2}+\\epsilon_t,where|\\phi_1|,|\\phi_2|\u0026lt;1$ AR(1)ì€ Y_tê°€ ì•Œë ¤ì§„ Y_t-1 ê°’ìœ¼ë¡œë¶€í„° ì–»ì–´ì¡Œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸ ìê¸°ìƒê´€í•¨ìˆ˜(ACF)ì™€ ë¶€ë¶„ìê¸°ìƒê´€í•¨ìˆ˜(PACF)ë¥¼ ì‚¬ìš©í•´ ARê³¼ MAí•­ì˜ ì°¨ìˆ˜ë¥¼ ê²°ì • ACF: Lagì— ë”°ë¥¸ ê´€ì¸¡ì¹˜ë“¤ ì‚¬ì´ì˜ ê´€ë ¨ì„±ì„ ì¸¡ì •í•˜ëŠ” í•¨ìˆ˜ PACF: k ì´ì™¸ì˜ ëª¨ë“  ë‹¤ë¥¸ ì‹œì  ê´€ì¸¡ì¹˜ì˜ ì˜í–¥ë ¥ì„ ë°°ì œí•˜ê³  y_tì™€ y_t-k ë‘ ê´€ì¸¡ì¹˜ì˜ ê´€ë ¨ì„±ì„ ì¸¡ì •í•˜ëŠ” í•¨ìˆ˜ "},{"id":65,"href":"/blog/2022-07-17/","title":"2022-07-17 Log","section":"Posts","content":"ê¸°ê³„ë²ˆì—­ ê³¼ì œ # ì¸ì½”ë”: ì…ë ¥ ë¬¸ì¥ì˜ í‘œí˜„ ë°©ë²• í•™ìŠµ ë””ì½”ë”: ì¸ì½”ë”ì—ì„œ í•™ìŠµí•œ í‘œí˜„ ê²°ê³¼ë¥¼ ì…ë ¥ë°›ì•„ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë¬¸ì¥ ìƒì„± Encoder # Self Attention # ì„ë² ë”©: ê°ê°ì˜ ë‹¨ì–´ë¥¼ í‘œí˜„í•˜ëŠ” ë²¡í„°ê°’, [ë¬¸ì¥ ê¸¸ì´ x ì„ë² ë”© ì°¨ì›] ì¿¼ë¦¬(Q), í‚¤(K), ë°¸ë¥˜(V) \u0026gt; ê°ê°ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì…ë ¥ í–‰ë ¬ì— ê³±í•´ Q, K, V í–‰ë ¬ ìƒì„± Q, K, Vì˜ ì°¨ì› [ë¬¸ì¥ ê¸¸ì´ x ë²¡í„°ì˜ ì°¨ì›] 1ë‹¨ê³„: Qì™€ K^T í–‰ë ¬ì˜ ë‚´ì  ì—°ì‚°, ì¿¼ë¦¬ ë²¡í„°(I)ì™€ í‚¤ ë²¡í„°(I, am, good) ì‚¬ì´ì˜ ìœ ì‚¬ë„ ê³„ì‚° 2ë‹¨ê³„: QK^T í–‰ë ¬ì„ í‚¤ ë²¡í„° ì°¨ì›ì˜ ì œê³±ê·¼ê°’($\\sqrt{d_k}$)ìœ¼ë¡œ ë‚˜ëˆˆ ê²ƒ, ì•ˆì •ì ì¸ gradient ì–»ìŒ 3ë‹¨ê³„: ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë¹„ì •ê·œí™”ëœ í˜•íƒœì˜ ìœ ì‚¬ë„ ê°’ì„ ì •ê·œí™” (score í–‰ë ¬) 4ë‹¨ê³„: ìŠ¤ì½”ì–´ í–‰ë ¬ì— V í–‰ë ¬ì„ ê³±í•´ ì–´í…ì…˜(Z) í–‰ë ¬ ê³„ì‚°, ì–´í…ì…˜ í–‰ë ¬ì€ ë¬¸ì¥ì˜ ê° ë‹¨ì–´ì™€ ë²¡í„°ê°’ ê°€ì§\n(ë‹¨ì–´ Iì˜ ì…€í”„ ì–´í…ì…˜ì€ ê° ë°¸ë¥˜ ë²¡í„°ê°’ì˜ ê°€ì¤‘ì¹˜ í•©ìœ¼ë¡œ ê³„ì‚°, ë‹¨ì–´ê°€ ë¬¸ì¥ ë‚´ì— ìˆëŠ” ë‹¤ë¥¸ ë‹¨ì–´ì™€ì˜ ì—°ê´€ì„±) Multi-Head Attention # ë¬¸ì¥ ë‚´ì—ì„œ ëª¨í˜¸í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´(it)ê°€ ìˆì„ ê²½ìš°,\në¬¸ì¥ì˜ ì˜ë¯¸ê°€ ì˜ëª» í•´ì„ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ì‚¬ìš©í•œ í›„ ê·¸ ê²°ê´ê°’ì„ ë”í•¨ ë‹¤ìˆ˜ì˜ ì–´í…ì…˜ í–‰ë ¬ì„ êµ¬í•˜ê¸° ìœ„í•´ ì„œë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì…ë ¥ í–‰ë ¬ì— ê³±í•´ Q, K, V ìƒì„± ë‹¤ìˆ˜ì˜ ì–´í…ì…˜ í–‰ë ¬ì„ concatenateí•˜ê³  ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ê³±í•´ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ê²°ê³¼ ë„ì¶œ\n(concatenate ì‹œ [ì–´í…ì…˜ í—¤ë“œ x h] í¬ê¸°ê°€ ë˜ê¸° ë•Œë¬¸ì— ì›ë˜ í¬ê¸°ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ê°€ì¤‘ì¹˜ í–‰ë ¬ ê³±í•¨) Positional Encoding # íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ë¬¸ì¥ ì•ˆì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ë¥¼ ë³‘ë ¬ í˜•íƒœë¡œ ì…ë ¥ ë‹¨ì–´ì˜ ìˆœì„œ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ì˜ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¸ì½”ë”© ì œê³µ ìœ„ì¹˜ ì¸ì½”ë”©ì€ ì‚¬ì¸íŒŒ í•¨ìˆ˜ë¥¼ ì‚¬ìš© ì…ë ¥ ì„ë² ë”© ê²°ê³¼ì— ìœ„ì¹˜ ì¸ì½”ë”©ì„ í•©í•œ í›„ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì— ì…ë ¥ Feed Forward Network # 2ê°œì˜ ì „ê²°í•©ì¸µ(Dense)ê³¼ ReLU í™œì„±í™” í•¨ìˆ˜ë¡œ êµ¬ì„± addì™€ normì„ ì¶”ê°€í•´ ì„œë¸Œë ˆì´ì–´ì—ì„œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ì…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ì„ ì„œë¡œ ì—°ê²° addì™€ normì€ ë ˆì´ì–´ ì •ê·œí™”(ê° ë ˆì´ì–´ ê°’ì´ í¬ê²Œ ë³€í™”í•˜ëŠ” ê²ƒì„ ë°©ì§€í•´ ëª¨ë¸ í•™ìŠµ ë¹ ë¥´ê²Œ)ì™€ ì”ì°¨ ì—°ê²° ì¸ì½”ë” ìˆœì„œ # ì…ë ¥ê°’ì€ ì…ë ¥ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•œ ë‹¤ìŒ ìœ„ì¹˜ ì¸ì½”ë”© ì¶”ê°€, ê°€ì¥ ì•„ë˜ ìˆëŠ” ì¸ì½”ë” 1ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ê³µê¸‰ ì¸ì½”ë” 1ì€ ì…ë ¥ê°’ì„ ë°›ì•„ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ì„œë¸Œë ˆì´ì–´ì— ê°’ì„ ë³´ëƒ„, ì–´í…ì…˜ í–‰ë ¬ì„ ê²°ê´ê°’ìœ¼ë¡œ ì¶œë ¥ ì–´í…ì…˜ í–‰ë ¬ì˜ ê°’ì„ ë‹¤ìŒ ì„œë¸Œë ˆì´ì–´ì¸ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì— ì…ë ¥, ê²°ê´ê°’ ì¶œë ¥ ì¸ì½”ë” 1ì˜ ì¶œë ¥ê°’ì„ ê·¸ ìœ„ì— ìˆëŠ” ì¸ì½”ë” 2ì— ì…ë ¥ê°’ìœ¼ë¡œ ì œê³µ ì¸ì½”ë” 2ì—ì„œ ì´ì „ê³¼ ë™ì¼í•œ ë°©ë²• ìˆ˜í–‰, ì£¼ì–´ì§„ ë¬¸ì¥ì— ëŒ€í•œ ì¸ì½”ë” í‘œí˜„ ê²°ê³¼ë¥¼ ì¶œë ¥ìœ¼ë¡œ ì œê³µ Decoder # ì´ì „ ë””ì½”ë”ì˜ ì…ë ¥ê°’ê³¼ ì¸ì½”ë”ì˜ í‘œí˜„(ì¸ì½”ë”ì˜ ì¶œë ¥ê°’), 2ê°œë¥¼ ì…ë ¥ ë°ì´í„°ë¡œ ë°›ìŒ t=1ì—ì„œ ë””ì½”ë”ì˜ ì…ë ¥ê°’ì€ ë¬¸ì¥ì˜ ì‹œì‘ì„ ì•Œë¦¬ëŠ” ë¥¼ ì…ë ¥ \u0026gt; íƒ€ê¹ƒ ë¬¸ì¥ì˜ ì²« ë²ˆì§¸ ë‹¨ì–´(Je) ìƒì„± t=2ì—ì„œ t-1 ë””ì½”ë”ì—ì„œ ìƒì„±í•œ ë‹¨ì–´(, Je)ë¥¼ ì¶”ê°€í•´ ë¬¸ì¥ì˜ ë‹¤ìŒ ë‹¨ì–´ ìƒì„± t=3ì—ì„œë„ ë™ì¼í•˜ê²Œ (, Je, vais)ë¥¼ ì…ë ¥ë°›ì•„ ë‹¤ìŒ ë‹¨ì–´ ìƒì„± ë””ì½”ë”ì—ì„œ í† í°ì„ ìƒì„±í•  ë•Œ íƒ€ê¹ƒ ë¬¸ì¥ì˜ ìƒì„±ì´ ì™„ë£Œ ë””ì½”ë”ë„ ì…ë ¥ê°’ì„ ë°”ë¡œ ì…ë ¥í•˜ì§€ ì•Šê³  ìœ„ì¹˜ ì¸ì½”ë”©ì„ ì¶”ê°€í•œ ê°’ì„ ì¶œë ¥ ì„ë² ë”©ì— ë”í•´ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš© Masked Multi-Head Attention # ë””ì½”ë”ì—ì„œ ë¬¸ì¥ì„ ìƒì„±í•  ë•Œ ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±í•œ ë‹¨ì–´ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ë•Œë¬¸ì—,\nì•„ì§ ì˜ˆì¸¡í•˜ì§€ ì•Šì€ ì˜¤ë¥¸ìª½ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•´ í•™ìŠµì„ ì§„í–‰ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•œ ì •ê·œí™” ì‘ì—… ì „ì— ì˜¤ë¥¸ìª½ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ $-{\\infty}$ë¡œ ë§ˆìŠ¤í‚¹ ìˆ˜í–‰\n($-{\\infty}$ëŠ” í•™ìŠµ ë„ì¤‘ ë°œì‚°í•˜ëŠ” ê²½ìš°ê°€ ìˆê¸° ë•Œë¬¸ì— ì‹¤ì œë¡œëŠ” ì‘ì€ ê°’ $e^{-9}$ìœ¼ë¡œ ì§€ì •) Encoder-Decoder Attention Layer # ë””ì½”ë”ì˜ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ì…ë ¥ìœ¼ë¡œ ì¸ì½”ë”ì˜ í‘œí˜„ê°’ Rê³¼ ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ê²°ê³¼ Mì„ ë°›ì„ ë•Œ ìƒí˜¸ì‘ìš© ë°œìƒ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì„ ìƒì„±í•  ë•Œ, Mì„ ì‚¬ìš©í•´ Që¥¼ ìƒì„±, Rì„ í™œìš©í•´ K, Vë¥¼ ìƒì„±\n(ì¿¼ë¦¬ í–‰ë ¬ì€ íƒ€ê¹ƒ ë¬¸ì¥ì˜ í‘œí˜„ì„ í¬í•¨í•˜ê¸° ë•Œë¬¸ì— Mì„ ì°¸ì¡°, í‚¤ì™€ ë°¸ë¥˜ í–‰ë ¬ì€ ì…ë ¥ ë¬¸ì¥ì˜ í‘œí˜„ì„ ì°¸ì¡°) ì¿¼ë¦¬, í‚¤ í–‰ë ¬ ê°„ì˜ ë‚´ì  ì‹œ íƒ€ê¹ƒ ë‹¨ì–´ ê°€ ì…ë ¥ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´(I, am, good)ì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ê³„ì‚°\n(ë‘ ë²ˆì§¸ í–‰ì—ì„œ Jeì— ëŒ€í•´, ë‚˜ë¨¸ì§€ í–‰ì—ì„œë„ ë™ì¼í•œ ë°©ë²•ì„ ì ìš©í•´ ìœ ì‚¬ë„ ê³„ì‚°) Linear and Sofmax Layer # ìµœìƒìœ„ ë””ì½”ë”ì—ì„œ ì–»ì€ ì¶œë ¥ ê°’ì„ ì„ í˜• ë° ì†Œí”„íŠ¸ë§¥ìŠ¤ ë ˆì´ì–´ì— ì „ë‹¬ ì„ í˜• ë ˆì´ì–´ëŠ” vocab í¬ê¸°ì™€ ê°™ì€ logit í˜•íƒœ logit ê°’ì„ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë””ì½”ë”ì—ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ê°’ì„ ê°–ëŠ” ì¸ë±ìŠ¤ì˜ ë‹¨ì–´ë¡œ ì¶œë ¥ ë””ì½”ë” ìˆœì„œ # ë””ì½”ë”ì— ëŒ€í•œ ì…ë ¥ ë¬¸ì¥ì„ ì„ë² ë”© í–‰ë ¬ë¡œ ë³€í™˜í•˜ê³  ìœ„ì¹˜ ì¸ì½”ë”© ì •ë³´ë¥¼ ì¶”ê°€í•´ ë””ì½”ë” 1ì— ì…ë ¥ ì…ë ¥ì„ ê°€ì ¸ì™€ì„œ ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ì— ë³´ë‚´ê³ , ì¶œë ¥ìœ¼ë¡œ ì–´í…ì…˜ í–‰ë ¬ M ë°˜í™˜ ì–´í…ì…˜ í–‰ë ¬ M, ì¸ì½”ë”© í‘œí˜„ Rì„ ì…ë ¥ë°›ì•„ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ì— ê°’ì„ ì…ë ¥, ìƒˆë¡œìš´ ì–´í…ì…˜ í–‰ë ¬ ìƒì„± ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜ ë ˆì´ì–´ì—ì„œ ì¶œë ¥í•œ ì–´í…ì…˜ í–‰ë ¬ì„ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì— ì…ë ¥, ë””ì½”ë”ì˜ í‘œí˜„ìœ¼ë¡œ ê°’ ì¶œë ¥ ë””ì½”ë” 1ì˜ ì¶œë ¥ê°’ì„ ë‹¤ìŒ ë””ì½”ë” 2ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš© ë””ì½”ë” 2ëŠ” ì´ì „ê³¼ ë™ì¼í•œ ë°©ë²• ìˆ˜í–‰, íƒ€ê¹ƒ ë¬¸ì¥ì— ëŒ€í•œ ë””ì½”ë” í‘œí˜„ ë°˜í™˜ íƒ€ê¹ƒ ë¬¸ì¥ì˜ ë””ì½”ë” í‘œí˜„ì„ ì„ í˜• ë° ì†Œí”„íŠ¸ë§¥ìŠ¤ ë ˆì´ì–´ì— ì…ë ¥í•´ ìµœì¢…ìœ¼ë¡œ ì˜ˆì¸¡ëœ ë‹¨ì–´ ì–»ìŒ í•™ìŠµ # ì†ì‹¤ í•¨ìˆ˜ë¡œ cross-entropyë¥¼ ì‚¬ìš©í•´ ë¶„í¬ì˜ ì°¨ì´ë¥¼ í™•ì¸ ì˜µí‹°ë§ˆì´ì €ë¡œ Adam ì‚¬ìš© ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ê° ì„œë¸Œë ˆì´ì–´ ì¶œë ¥ì— dropout ì ìš© (ì„ë² ë”© ë° ìœ„ì¹˜ ì¸ì½”ë”© í•©ì„ êµ¬í•  ë•Œë„ í¬í•¨) BERT # Word2Vec: ë¬¸ë§¥ ë…ë¦½ ì„ë² ë”©, BERT: ë¬¸ë§¥ ê¸°ë°˜ ì„ë² ë”© BERTëŠ” ì¸ì½”ë”-ë””ì½”ë”ê°€ ìˆëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì—ì„œ ì¸ì½”ë”ë§Œ ì‚¬ìš© BERT-base: L(ì¸ì½”ë” ë ˆì´ì–´)=12, A(ì–´í…ì…˜ í—¤ë“œ)=12, H(ì€ë‹‰ ìœ ë‹›)=768 BERT-large: L=24, A=16, H=1024 BERT-tiny(L=2, A=2, H=128), BERT-mini(L=4, A=4, H=256) ë“± ì‚¬ì „ í•™ìŠµ # ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ í™œìš©í•´ ìƒˆë¡œìš´ íƒœìŠ¤í¬ì— ì ìš© (find-tuning) BERTëŠ” MLMê³¼ NSP íƒœìŠ¤í¬ë¥¼ ì´ìš©í•´ ê±°ëŒ€í•œ ë§ë­‰ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµ Token Embedding # ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ì‹œì‘ ë¶€ë¶„ì— [CLS] í† í° ì¶”ê°€ ëª¨ë“  ë¬¸ì¥ ëì— [SEP] í† í° ì¶”ê°€ Segment Embedding # ë‘ ë¬¸ì¥ì„ êµ¬ë³„í•˜ëŠ”ë° ì‚¬ìš© [SEP] í† í°ê³¼ ë³„ë„ë¡œ ë‘ ë¬¸ì¥ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ ì…ë ¥ í† í°($E_A,E_B$) ì œê³µ Position Embedding # ë‹¨ì–´(í† í°)ì˜ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ ì œê³µ ì…ë ¥ ë°ì´í„° # í† í° ì„ë² ë”© + ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© + ìœ„ì¹˜ ì„ë² ë”© ìœ¼ë¡œ í‘œí˜„ WordPiece Tokenizer # í•˜ìœ„ ë‹¨ì–´ í† í°í™” ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ Let us start pretraining the model \u0026gt; [let, us, start, pre, ##train, ##ing, the, model] ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ìˆìœ¼ë©´ í† í°ìœ¼ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ í•˜ìœ„ ë‹¨ì–´ë¡œ ë¶„í• í•´ í•˜ìœ„ ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ìˆëŠ”ì§€ í™•ì¸ (OOV ì²˜ë¦¬ì— íš¨ê³¼ì ) Language Modeling # ì„ì˜ì˜ ë¬¸ì¥ì´ ì£¼ì–´ì§€ê³  ë‹¨ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ë³´ë©´ì„œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ëª¨ë¸ í•™ìŠµ ìë™ íšŒê·€ ì–¸ì–´ ëª¨ë¸ë§: ì „ë°©(ì¢Œ\u0026gt;ìš°) ì˜ˆì¸¡, í›„ë°©(ì¢Œ\u0026lt;ìš°) ì˜ˆì¸¡, ê° ë°©í–¥(ë‹¨ë°©í–¥)ìœ¼ë¡œ ê³µë°±ê¹Œì§€ ëª¨ë“  ë‹¨ì–´ë¥¼ ì½ìŒ ìë™ ì¸ì½”ë”© ì–¸ì–´ ëª¨ë¸ë§: ì˜ˆì¸¡í•˜ë©´ì„œ ì–‘ë°©í–¥ìœ¼ë¡œ ë¬¸ì¥ì„ ì½ìŒ Masked Language Modeling (MLM) # ì£¼ì–´ì§„ ì…ë ¥ ë¬¸ì¥ì—ì„œ ì „ì²´ ë‹¨ì–´ì˜ 15%ë¥¼ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹, ë§ˆìŠ¤í¬ëœ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ (ë¹ˆì¹¸ ì±„ìš°ê¸° íƒœìŠ¤í¬) [MASK] í† í°ì„ ì‚¬ì „ í•™ìŠµì‹œí‚¬ ê²½ìš° íŒŒì¸ íŠœë‹ ì‹œ ì…ë ¥ì— [MASK] í† í°ì´ ì—†ì–´ ë¶ˆì¼ì¹˜ê°€ ë°œìƒ 15% í† í°ì— ëŒ€í•´ 80%ë§Œ [MASK] í† í°ìœ¼ë¡œ êµì²´, 10%ëŠ” ì„ì˜ì˜ í† í°(ë‹¨ì–´)ë¡œ êµì²´, 10%ëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ\n(ì‚¬ì „ í•™ìŠµê³¼ íŒŒì¸ íŠœë‹ íƒœìŠ¤í¬ì˜ ì°¨ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ì¼ì¢…ì˜ ì •ê·œí™” ì‘ì—…) ì—­ì „íŒŒë¥¼ í†µí•œ ë°˜ë³µ í•™ìŠµì„ ê±°ì¹˜ë©° ìµœì ì˜ ê°€ì¤‘ì¹˜ í•™ìŠµ Whole Word Masking (WWM) # WWM ë°©ë²•ì—ì„œëŠ” í•˜ìœ„ ë‹¨ì–´ê°€ ë§ˆìŠ¤í‚¹ë˜ë©´ í•´ë‹¹ í•˜ìœ„ ë‹¨ì–´ì™€ ê´€ë ¨ëœ ëª¨ë“  ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹ í•˜ìœ„ ë‹¨ì–´ì™€ ê´€ë ¨ëœ ëª¨ë“  ë‹¨ì–´ì˜ ë§ˆìŠ¤í¬ ë¹„ìœ¨ì´ 15%ë¥¼ ì´ˆê³¼í•˜ë©´ ë‹¤ë¥¸ ë‹¨ì–´ì˜ ë§ˆìŠ¤í‚¹ì„ ë¬´ì‹œ Next Sentence Prediction (NSP) # BERTì— ë‘ ë¬¸ì¥ì„ ì…ë ¥í•˜ê³  ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ë‹¤ìŒ ë¬¸ì¥ì¸ì§€ ì˜ˆì¸¡ B ë¬¸ì¥ì´ A ë¬¸ì¥ì— ì´ì–´ì§€ë§Œ isNextë¥¼ ë°˜í™˜í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ notNextë¥¼ ë°˜í™˜ ë‘ ë¬¸ì¥ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•´ ì§ˆë¬¸-ì‘ë‹µ ë° ìœ ì‚¬ë¬¸ì¥íƒì§€ì™€ ê°™ì€ downstream íƒœìŠ¤í¬ì—ì„œ ìœ ìš© í•œ ë¬¸ì„œì—ì„œ ì—°ì†ëœ ë‘ ë¬¸ì¥ì„ isNextë¡œ í‘œì‹œí•˜ê³ , ë‘ ë¬¸ì„œì—ì„œ ê°ê° ë¬¸ì¥ì„ ê°€ì ¸ì™€ notNextë¡œ í‘œì‹œ [CLS] í† í° í‘œí˜„ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³  í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì— ì…ë ¥í•´ ë‘ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ ê°’ ë°˜í™˜ [CLS] í† í°ì€ ëª¨ë“  í† í°ì˜ ì§‘ê³„ í‘œí˜„ì„ ë³´ìœ í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ë¬¸ì¥ ì „ì²´ì— ëŒ€í•œ í‘œí˜„ì„ ë‹´ê³  ìˆìŒ ì‚¬ì „ í•™ìŠµ ì ˆì°¨ # lr = 1e-4, b1 = 0.9, b2 = 0.999\nì´ˆê¸° ëª¨ë¸ì˜ í° ë³€í™”ë¥¼ ìœ ë„í•˜ê¸° ìœ„í•´ ì›œì—…ìœ¼ë¡œ 1ë§Œ ìŠ¤í… í•™ìŠµ\n(0ì—ì„œ 1e-4ë¡œ ì„ í˜•ì ìœ¼ë¡œ í•™ìŠµë¥  ì¦ê°€, 1ë§Œ ìŠ¤íƒ­ í›„ ìˆ˜ë ´ì— ê°€ê¹Œì›Œì§ì— ë”°ë¼ í•™ìŠµë¥ ì„ ì„ í˜•ì ìœ¼ë¡œ ê°ì†Œ) dropout 0.1, GELU(ê°€ìš°ì‹œì•ˆ ì˜¤ì°¨ ì„ í˜• ìœ ë‹›) í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš© í•˜ìœ„ ë‹¨ì–´ í† í°í™” ì•Œê³ ë¦¬ì¦˜ # Byte Pair Encoding (BPE) # ëª¨ë“  ë‹¨ì–´ë¥¼ ë¬¸ìë¡œ ë‚˜ëˆ„ê³  ë¬¸ì ì‹œí€€ìŠ¤ë¡œ ë§Œë“¦ ìš°ì„  ë¬¸ì ì‹œí€€ìŠ¤ì— ìˆëŠ” ê³ ìœ  ë¬¸ìë¥¼ ì–´íœ˜ ì‚¬ì „ì— ì¶”ê°€ ì–´íœ˜ ì‚¬ì „ í¬ê¸°ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ê°€ì¥ ë¹ˆë„ìˆ˜ê°€ í° ê¸°í˜¸ ìŒì„ ë°˜ë³µì ìœ¼ë¡œ ë³‘í•©í•´ ì–´íœ˜ ì‚¬ì „ì— ì¶”ê°€ í† í°í™” ì‹œ ì–´íœ˜ ì‚¬ì „ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´ëŠ” í•˜ìœ„ ë‹¨ì–´ë¡œ ë‚˜ëˆ”, ì‚¬ì „ì— ì—†ëŠ” ê°œë³„ ë¬¸ìëŠ” í† í°ìœ¼ë¡œ êµì²´ Byte-Level Byte Pair Encoding (BBPE) # ë¬¸ì ìˆ˜ì¤€ ì‹œí€€ìŠ¤ ëŒ€ì‹  ë°”ì´íŠ¸ ìˆ˜ì¤€ ì‹œí€€ìŠ¤ë¥¼ ì‚¬ìš© ìœ ë‹ˆì½”ë“œ ë¬¸ìê°€ ë°”ì´íŠ¸ë¡œ ë³€í™˜ë˜ì–´ ë‹¨ì¼ ë¬¸ì í¬ê¸°ëŠ” 1~4 ë°”ì´íŠ¸ê°€ ë¨ ë°”ì´íŠ¸ ìˆ˜ì¤€ì—ì„œ ë¹ˆë²ˆí•œ ìŒì„ êµ¬ë¶„í•´ ì–´íœ˜ ì‚¬ì „ì„ êµ¬ì¶• ë‹¤êµ­ì–´ ì„¤ì •ì—ì„œ ìœ ìš©, OOV ë‹¨ì–´ ì²˜ë¦¬ì— íš¨ê³¼ì  WordPiece # BPEë‘ ë‹¤ë¥´ê²Œ ë¹ˆë„ìˆ˜ ëŒ€ì‹  likelihoodë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê¸°í˜¸ ìŒì„ ë³‘í•© ëª¨ë“  ê¸°í˜¸ ìŒì— ëŒ€í•´ ì–¸ì–´ ëª¨ë¸ì˜ ê°€ëŠ¥ë„ë¥¼ í™•ì¸, ê°€ëŠ¥ë„ê°€ ê°€ì¥ ë†’ì€ ê¸°í˜¸ ìŒì„ ë³‘í•© "},{"id":66,"href":"/blog/2022-07-13/","title":"2022-07-13 Log","section":"Posts","content":"PyTorch Basic # PyTorch Packages # torch: ë©”ì¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ torch.autograd: ìë™ ë¯¸ë¶„ì„ ìœ„í•œ í•¨ìˆ˜ torch.nn: ë°ì´í„° êµ¬ì¡°ë‚˜ ë ˆì´ì–´ ë“± ì •ì˜ torch.optim: ê²½ì‚¬ í•˜ê°•ë²• ë“± íŒŒë¼ë¯¸í„° ìµœì í™” ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ torch.utils.data: ë¯¸ë‹ˆ ë°°ì¹˜ìš© ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ torch.onnx: ONNXì˜ í¬ë§·ìœ¼ë¡œ ëª¨ë¸ì„ ì €ì¥í•  ë•Œ ì‚¬ìš© Tensor # 2D Tensor: (batch size, dim) 3D Tensor: (batch size, width, height) 3D Tensor(NLP): (batch size, length, dim) torch.FloatTensor(): í…ì„œ ìƒì„± í–‰ë ¬ ê³±ì…ˆ(.matmul()), ì›ì†Œ ë³„ ê³±ì…ˆ(.mul(), *) dim=0: ì²«ë²ˆì§¸ ì°¨ì›(í–‰) ì œê±° = ê°™ì€ ì—´ë¼ë¦¬ ì—°ì‚°, dim=1: ë‘ë²ˆì§¸ ì°¨ì›(ì—´) ì œê±° = ê°™ì€ í–‰ë¼ë¦¬ ì—°ì‚° view(): reshape, squeeze(): 1ì¸ ì°¨ì› ì œê±°, unsequeeze(): íŠ¹ì • ìœ„ì¹˜ì— 1ì¸ ì°¨ì› ì¶”ê°€ cat(), stack(), ones_like(), zeros_like() Linear Regression # ì„ í˜• íšŒê·€ êµ¬í˜„ # ê¸°ë³¸ ì…‹íŒ… ë° ë³€ìˆ˜ ì„ ì–¸: seed ì„¤ì •, x_train ë° y_train ì„ ì–¸ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì˜ ì´ˆê¸°í™”: W = torch.zeros(1, requires_grad=True) ê°€ì„¤ ì„¸ìš°ê¸°: hypothesis = x_train * W + b ë¹„ìš© í•¨ìˆ˜ ì„ ì–¸: cost = torch.mean((hypothesis - y_train) ** 2) ê²½ì‚¬ í•˜ê°•ë²• êµ¬í˜„: Copy python optimizer = optim.SGD([W, b], lr=0.01) optimizer.zero_grad() # gradientë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™” # íŒŒì´í† ì¹˜ê°€ ë¯¸ë¶„ì„ í†µí•´ ì–»ì€ ê¸°ìš¸ê¸°ë¥¼ ì´ì „ì— ê³„ì‚°ëœ ê¸°ìš¸ê¸° ê°’ì„ ëˆ„ì ì‹œí‚¤ê¸° ë•Œë¬¸ì— ë¯¸ë¶„ê°’ì„ ì´ˆê¸°í™” cost.backword() # ë¹„ìš© í•¨ìˆ˜ë¥¼ ë¯¸ë¶„í•˜ì—¬ gradient ê³„ì‚° optimizer.step() # Wì™€ bë¥¼ ì—…ë°ì´íŠ¸ Autograd # requires_grad=True, backward() ë“± ë‹¤ì¤‘ ì„ í˜• íšŒê·€ # xì˜ ê³„ìˆ˜ë¥¼ í–‰ë ¬ë¡œ ë³€í™˜í•´ Wì™€ ë‚´ì  5x3 í¬ê¸°ì˜ x_trainê³¼ 3x1 í¬ê¸°ì˜ Wë¥¼ ë‚´ì í•´ 5x1 í¬ê¸°ì˜ y_train ê³„ì‚° nn.Module # Copy python from torch import nn import torch.nn.functional as F model = nn.Linear(input_dim, output_dim) cost = F.mse_loss(prediction, y_train) optimizer = torch.optim.SGD(model.parameters(), lr=0.01) Class # Copy python class LinearRegressionModel(nn.Module): def __init__(self): # super().__init__() self.linear = nn.Linear(1, 1) def forward(self, x): return self.linear(x) Custom Dataset # Copy python class CustomDataset(torch.utils.data.Dataset): def __init__(self): # ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” ë¶€ë¶„ def __len__(self): # ë°ì´í„°ì…‹ì˜ ê¸¸ì´. ì¦‰, ì´ ìƒ˜í”Œì˜ ìˆ˜ë¥¼ ì ì–´ì£¼ëŠ” ë¶€ë¶„ def __getitem__(self, idx): # ë°ì´í„°ì…‹ì—ì„œ íŠ¹ì • 1ê°œì˜ ìƒ˜í”Œì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ Logistic Regression # hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b))) cost = F.binary_cross_entropy(hypothesis, y_train) Copy python class BinaryClassifier(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(2, 1) self.sigmoid = nn.Sigmoid() def forward(self, x): return self.sigmoid(self.linear(x)) Softmax Regression # F.softmax(z, dim=1) F.softmax() + torch.log() = F.log_softmax() F.log_softmax() + F.nll_loss() = F.cross_entropy() Copy python # One-Hot Encoding y_one_hot = torch.zeros_like(hypothesis) y_one_hot.scatter_(1, y_train.unsqueeze(1), 1) Artificial Neural Network # Copy python model = nn.Sequential( nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, 10) ) Convolutional Neural Network # Copy python class CNN(torch.nn.Module): def __init__(self): super(CNN, self).__init__() # ì²«ë²ˆì§¸ì¸µ # ImgIn shape=(?, 28, 28, 1) # Conv -\u0026gt; (?, 28, 28, 32) # Pool -\u0026gt; (?, 14, 14, 32) self.layer1 = torch.nn.Sequential( torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), torch.nn.ReLU(), torch.nn.MaxPool2d(kernel_size=2, stride=2)) # ë‘ë²ˆì§¸ì¸µ # ImgIn shape=(?, 14, 14, 32) # Conv -\u0026gt;(?, 14, 14, 64) # Pool -\u0026gt;(?, 7, 7, 64) self.layer2 = torch.nn.Sequential( torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), torch.nn.ReLU(), torch.nn.MaxPool2d(kernel_size=2, stride=2)) # ì „ê²°í•©ì¸µ 7x7x64 inputs -\u0026gt; 10 outputs self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True) # ì „ê²°í•©ì¸µ í•œì •ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” torch.nn.init.xavier_uniform_(self.fc.weight) def forward(self, x): out = self.layer1(x) out = self.layer2(out) out = out.view(out.size(0), -1) # ì „ê²°í•©ì¸µì„ ìœ„í•´ì„œ Flatten out = self.fc(out) return out NLP # Copy python import torch.nn as nn embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=3, padding_idx=1) torchtext Error # cannot import name \u0026rsquo;load_state_dict_from_url'\napply this change in _download_hooks.py Copy python try: from torch.hub import load_state_dict_from_url except ImportError: from torch.utils.model_zoo import load_url as load_state_dict_from_url Make Vocabulary # Copy python from torchtext.vocab import build_vocab_from_iterator vocab = build_vocab_from_iterator(sequences) vocab.get_stoi() # ê° ë‹¨ì–´ì˜ ì •ìˆ˜ ì¸ë±ìŠ¤ê°€ ì €ì¥ëœ ë”•ì…”ë„ˆë¦¬ Recurrent Neural Network # Copy python nn.RNN(input_dim, hidden_size, num_layers, batch_fisrt=True) Copy python nn.LSTM(input_dim, hidden_size, num_layers, batch_fisrt=True) Char RNN # Copy python class Net(nn.Module): def __init__(self, vocab_size, input_size, hidden_size, batch_first=True): super(Net, self).__init__() self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, # ì›Œë“œ ì„ë² ë”© embedding_dim=input_size) self.rnn_layer = nn.RNN(input_size, hidden_size, # ì…ë ¥ ì°¨ì›, ì€ë‹‰ ìƒíƒœì˜ í¬ê¸° ì •ì˜ batch_first=batch_first) self.linear = nn.Linear(hidden_size, vocab_size) # ì¶œë ¥ì€ ì›-í•« ë²¡í„°ì˜ í¬ê¸°ë¥¼ ê°€ì ¸ì•¼í•¨. ë˜ëŠ” ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ë§Œí¼ ê°€ì ¸ì•¼í•¨. def forward(self, x): # 1. ì„ë² ë”© ì¸µ # í¬ê¸°ë³€í™”: (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´) =\u0026gt; (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì„ë² ë”© ì°¨ì›) output = self.embedding_layer(x) # 2. RNN ì¸µ # í¬ê¸°ë³€í™”: (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì„ë² ë”© ì°¨ì›) # =\u0026gt; output (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì€ë‹‰ì¸µ í¬ê¸°), hidden (1, ë°°ì¹˜ í¬ê¸°, ì€ë‹‰ì¸µ í¬ê¸°) output, hidden = self.rnn_layer(output) # 3. ìµœì¢… ì¶œë ¥ì¸µ # í¬ê¸°ë³€í™”: (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì€ë‹‰ì¸µ í¬ê¸°) =\u0026gt; (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ë‹¨ì–´ì¥ í¬ê¸°) output = self.linear(output) # 4. viewë¥¼ í†µí•´ì„œ ë°°ì¹˜ ì°¨ì› ì œê±° # í¬ê¸°ë³€í™”: (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ë‹¨ì–´ì¥ í¬ê¸°) =\u0026gt; (ë°°ì¹˜ í¬ê¸°*ì‹œí€€ìŠ¤ ê¸¸ì´, ë‹¨ì–´ì¥ í¬ê¸°) return output.view(-1, output.size(2)) # ëª¨ë¸ ìƒì„± model = Net(vocab_size, input_size, hidden_size, batch_first=True) # ì†ì‹¤í•¨ìˆ˜ ì •ì˜ loss_function = nn.CrossEntropyLoss() # ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ í¬í•¨ì´ë©° ì‹¤ì œê°’ì€ ì›-í•« ì¸ì½”ë”© ì•ˆ í•´ë„ ë¨. # ì˜µí‹°ë§ˆì´ì € ì •ì˜ optimizer = optim.Adam(params=model.parameters()) Classification with GRU # Copy python class GRU(nn.Module): def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2): super(GRU, self).__init__() self.n_layers = n_layers self.hidden_dim = hidden_dim self.embed = nn.Embedding(n_vocab, embed_dim) self.dropout = nn.Dropout(dropout_p) self.gru = nn.GRU(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True) self.out = nn.Linear(self.hidden_dim, n_classes) def forward(self, x): x = self.embed(x) h_0 = self._init_state(batch_size=x.size(0)) # ì²«ë²ˆì§¸ íˆë“  ìŠ¤í…Œì´íŠ¸ë¥¼ 0ë²¡í„°ë¡œ ì´ˆê¸°í™” x, _ = self.gru(x, h_0) # GRUì˜ ë¦¬í„´ê°’ì€ (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì€ë‹‰ ìƒíƒœì˜ í¬ê¸°) h_t = x[:,-1,:] # (ë°°ì¹˜ í¬ê¸°, ì€ë‹‰ ìƒíƒœì˜ í¬ê¸°)ì˜ í…ì„œë¡œ í¬ê¸°ê°€ ë³€ê²½ë¨. ì¦‰, ë§ˆì§€ë§‰ time-stepì˜ ì€ë‹‰ ìƒíƒœë§Œ ê°€ì ¸ì˜¨ë‹¤. self.dropout(h_t) logit = self.out(h_t) # (ë°°ì¹˜ í¬ê¸°, ì€ë‹‰ ìƒíƒœì˜ í¬ê¸°) -\u0026gt; (ë°°ì¹˜ í¬ê¸°, ì¶œë ¥ì¸µì˜ í¬ê¸°) return logit def _init_state(self, batch_size=1): weight = next(self.parameters()).data return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_() "},{"id":67,"href":"/blog/2022-07-08/","title":"2022-07-08 Log","section":"Posts","content":"Optimization # minimize(ìµœì†Œí™”) f(x) subject to(ì œì•½ì¡°ê±´) h(x)=0 glaobal minimum, local minimum, local maximum ëª©ì í•¨ìˆ˜: ì£¼ì–´ì§„ ì ê³¼ ì„ì˜ì˜ ì„ ì˜ ê°„ê²©(error)ë¥¼ ëª¨ë‘ ë”í•¨ Gradient # ê²½ì‚¬ë„ ë²¡í„°: nê°œì˜ ë³€ìˆ˜ì— ëŒ€í•œ í•¨ìˆ˜ f(x)ì˜ $x^*$ì—ì„œì˜ í¸ë¯¸ë¶„ ê³„ìˆ˜ (ì—´ ë²¡í„°) ê²½ì‚¬ë„ ë²¡í„°ëŠ” $f(x^*)=c$ì¸ í‘œë©´ì˜ ì´ˆì ‘í‰ë©´ì— ìˆ˜ì§, í•¨ìˆ˜ì˜ ìµœëŒ€ ì¦ê°€ ë°©í–¥ Gradient Descent Method # $$x^{(t+1)}=x^{(t)}-\\eta\\frac{dy(x^{(t)})}{dx}$$\nminimize ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•´ gradient ë²¡í„°ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™ (ìµœëŒ€ í•˜ê°• ë°©í–¥) ê°•í•˜ë°©í–¥(descent direction): gradient ë²¡í„°ì™€ì˜ ë‚´ì ì´ 0ë³´ë‹¤ ì‘ì€ ê²½ìš° ($c^{(k)}ã†d^{(k)}\u0026lt;0$) $f(x)$ ì •ì‹í™” ê°€ëŠ¥í•  ê²½ìš° ìµœì ì„± ê¸°ì¤€ë²•, ê°„ì ‘ë²• ë“±, ì •ì‹í™” í•  ìˆ˜ ì—†ëŠ” ê²½ìš° íƒìƒ‰ë²•, ì§ì ‘ë²•(ê²½ì‚¬í•˜ê°•ë²•) ë“± ê²½ì‚¬ë„ ë²¡í„° ê³„ì‚° 2) ê°•í•˜ ë°©í–¥ ì„ íƒ 3) ì´ë™ê±°ë¦¬($\\alpha$) ê²°ì • step size($\\alpha$)ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ ì„ íƒìƒ‰(í™©ê¸ˆë¶„í•  íƒìƒ‰) ì‚¬ìš© ìµœì† ê°•í•˜ë²•: ê²½ì‚¬ë„ ë²¡í„°ì˜ ë°˜ëŒ€ ë°˜í–¥ì„ ê°•í•˜ ë°©í–¥ìœ¼ë¡œ ì„ íƒ ì¼¤ë ˆ ê²½ì‚¬ë²•: ê²½ì‚¬ë„ ë²¡í„°ì˜ ë°˜ëŒ€ ë°©í–¥ì— ì´ì „ì˜ ê°•í•˜ ë°©í–¥ì„ ë”í•¨ ëª©ì  í•¨ìˆ˜ë¡œ booth í•¨ìˆ˜, rosenbrock í•¨ìˆ˜ ì‚¬ìš© "},{"id":68,"href":"/blog/2022-07-07/","title":"2022-07-07 Log","section":"Posts","content":"Function # scalar: ì–‘ë§Œìœ¼ë¡œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” ë¬¼ë¦¬ëŸ‰ vector: ì–‘ê³¼ ë°©í–¥ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ë¬¼ë¦¬ëŸ‰ ì¼ë³€ìˆ˜-ìŠ¤ì¹¼ë¼í•¨ìˆ˜ # ë‹¤í•­í•¨ìˆ˜, ë¶„ìˆ˜í•¨ìˆ˜, ì§€ìˆ˜í•¨ìˆ˜, ë¡œê·¸í•¨ìˆ˜, ì‚¼ê°í•¨ìˆ˜ ë“± ì…ë ¥: ìŠ¤ì¹¼ë¼, ì¶œë ¥: ìŠ¤ì¹¼ë¼ ë…ë¦½ë³€ìˆ˜: í•¨ìˆ˜ì˜ ì¶œë ¥ ê²°ì •, ë§¤ê°œë³€ìˆ˜: í•¨ìˆ˜ì˜ ëª¨ì–‘ ê²°ì • ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜: ëª¨ë“  ì‹¤ìˆ˜ë¥¼ 0~1 ì‚¬ì´ë¡œ ì°Œê·¸ëŸ¬íŠ¸ë¦¼, ì¶œë ¥ì„ í™•ë¥ ë¡œ í•´ì„ ë‹¤ë³€ìˆ˜-ìŠ¤ì¹¼ë¼í•¨ìˆ˜ # ê³¡ë©´ê³¼ ë“±ê³ ì„  ê·¸ë˜í”„ ì…ë ¥: ë²¡í„°, ì¶œë ¥: ìŠ¤ì¹¼ë¼ í‰ë©´: ì´ë³€ìˆ˜ ìŠ¤ì¹¼ë¼ í•¨ìˆ˜, ì§ì„ : ìš°ë³€ì´ 0ìœ¼ë¡œ ê³ ì • í¼ì…‰íŠ¸ë¡ : $\\ f(x,y)=ax+by+c$ ì¼ë³€ìˆ˜-ë²¡í„°í•¨ìˆ˜ # í‰ë©´ ë˜ëŠ” ê³µê°„ì— ì¡´ì¬í•˜ëŠ” ê³¡ì„  ì…ë ¥: ìŠ¤ì¹¼ë¼, ì¶œë ¥: ë²¡í„° ë‹¤ë³€ìˆ˜-ë²¡í„°í•¨ìˆ˜ # ì…ë ¥: ë²¡í„°, ì¶œë ¥: ë²¡í„° ì¸ê³µì‹ ê²½ë§ê³¼ ìœ ì‚¬ Composite Function: í•¨ìˆ˜ì˜ í•©ì„±, $\\ gâˆ˜f=g(f(x))$ ì‹ ê²½ë§ì€ ë§¤ìš° ë§ì€ í•¨ìˆ˜ê°€ ê²¹ê²¹ì´ í•©ì„±ëœ ê²ƒ (ëª©ì í•¨ìˆ˜, ë¹„ìš©í•¨ìˆ˜, ì†ì‹¤í•¨ìˆ˜) ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ ë¬¸ì œ í‰ê°€ í•¨ìˆ˜ë¡œ ì§€ìˆ˜,ë¡œê·¸í•¨ìˆ˜ í™œìš© Matrix # í–‰ë ¬ì˜ ì°¨ì›(í¬ê¸°): í–‰ ê°œìˆ˜ x ì—´ ê°œìˆ˜ (${m}\\times{n}$) í–‰ë ¬ì˜ ì „ì¹˜: $\\ A^T$ í–‰ë ¬ì˜ ë§ì…ˆ: ë‘ í–‰ë ¬ì˜ í¬ê¸°ê°€ ê°™ì„ ë•Œ ê°™ì€ ìœ„ì¹˜ ìš”ì†Œ ë§ì…ˆ í–‰ë ¬ì˜ ê³±ì…ˆ: í–‰ê³¼ ì—´ì˜ ìš”ì†Œë¥¼ ê³±í•´ì„œ ë”í•¨ ë‹¨ìœ„í–‰ë ¬: ëŒ€ê° ì„±ë¶„ì´ ëª¨ë‘ 1, ë‚˜ë¨¸ì§€ëŠ” 0ì¸ ì •ì‚¬ê° í–‰ë ¬ ëŒ€ê°í–‰ë ¬: ëŒ€ê° ì„±ë¶„ì´ ì•„ë‹Œ ëª¨ë“  ì„±ë¶„ì´ 0ì¸ ì •ì‚¬ê° í–‰ë ¬ ëŒ€ì¹­í–‰ë ¬: ì •ì‚¬ê° í–‰ë ¬ì— ëŒ€í•´ì„œ $\\ S^T=S$ ì§êµí–‰ë ¬: ì „ì¹˜ëœ ê²ƒì´ ìì‹ ì¸ ì—­í–‰ë ¬ $\\ A^T=A^{-1}$ ì´ë¯¸ì§€ í‘œí˜„: (C, H, W)=PyTorch ë˜ëŠ” (H, W, C)=TensorFlow ì—´ ê²°í•©: ë’¤ì—ì„œ ê³±í•˜ëŠ” ë²¡í„°ì˜ ìš”ì†Œë¥¼ ê³„ìˆ˜ë¡œ í•œ ëª¨ë“  ì—´ì˜ ì„ í˜•ê²°í•© í–‰ ê²°í•©: ì•ì—ì„œ ê³±í•˜ëŠ” í–‰ë ¬ì˜ í–‰ ìš”ì†Œë¥¼ ê³„ìˆ˜ë¡œ ë’· í–‰ë ¬ì˜ í–‰ì„ ì¡°í•© (ì—´ ê²°í•© ì „ì¹˜) ì™¸ì : í–‰ë ¬ ë°˜í™˜, ë‚´ì : ìŠ¤ì¹¼ë¼ ë°˜í™˜ ì¸ê³µì‹ ê²½ë§ # $a^{(1)}=f(W^{(1)}x+b^{(1)})$ (W=weight, b=bias) í™œì„± í•¨ìˆ˜: Sigmoid, ReLU, Tanh MNIST ë°ì´í„°: (28,28)ì¸ ì†ê¸€ì”¨ ì´ë¯¸ì§€ê°€ (1,781)ì¸ ì–´ë ˆì´ë¡œ ì €ì¥ ë¡œì§€ìŠ¤í‹± í•¨ìˆ˜: ê°ê°ì˜ yì— ëŒ€í•œ í™•ë¥  ê³„ì‚° (ë‹¤ì¤‘ ë¶„ë¥˜ì—ì„œ ì •í™•ë„ê°€ ë‚®ìŒ) softmax: ì‹¤ìˆ˜ kê°œê°€ 0ì—ì„œ 1ì‚¬ì´ì˜ ìˆ«ì kê°œë¡œ ë§µí•‘ íšŒê·€: ì…ë ¥ xì— ëŒ€ì‘í•˜ëŠ” ì‹¤ìˆ˜ yê°’ì„ ì¶œë ¥ Differentiation # ì—ëŸ¬ë¥¼ ì¤„ì´ ìœ„í•œ ëª©ì  (ë¯¸ë¶„ ì •ë³´ë¥¼ ì´ìš©í•´ íƒìƒ‰ ë°©í–¥ ê²°ì •) í‰ê· ë³€í™”ìœ¨: í•¨ìˆ˜ì˜ ë³€í™”ë¥¼ ë³´ëŠ” êµ¬ê°„ì´ ì¤‘ìš”, ìì„¸í•œ ì •ë³´ë¥¼ ìœ„í•´ ê°„ê²©ì„ ì¢í í•„ìš” ìˆœê°„ë³€í™”ìœ¨: í‰ê· ë³€í™”ìœ¨ì˜ ë¶„ëª¨ë¥¼ ìˆœê°„ì— ì´ë¥¼ ì •ë„ë¡œ ì‘ê²Œ ë§Œë“¦, ê·¹í•œê°’ì´ ë¯¸ë¶„ê³„ìˆ˜ ìˆœê°„ë³€í™”ìœ¨ì€ ê·¸ ìœ„ì¹˜ì—ì„œ ì ‘ì„ ì˜ ê¸°ìš¸ê¸° sympy íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ íŒŒì´ì¬ì—ì„œ ê¸°í˜¸ ì—°ì‚° ë¯¸ë¶„ë²• # ìƒìˆ˜ì˜ ë¯¸ë¶„, ë§ì…ˆ/ëº„ì…ˆì˜ ë¯¸ë¶„, ê³±ì…ˆì˜ ë¯¸ë¶„ë²•, ë‚˜ëˆ—ì…ˆì˜ ë¯¸ë¶„ë²• í•¨ì„±í•¨ìˆ˜ ë¯¸ë¶„: ë¼ì´í”„ë‹ˆì¸  ë¯¸ë¶„ë²•, $\\ \\sqrt{ax^2+bx+c}=\\sqrt{y}$ $z=\\sqrt{x^2+3x},\\quad y=x^2+3x,\\quad z=\\sqrt{y}$ ì—°ì‡„ë²•ì¹™(Chain Rule): $\\ \\frac{dz}{dx}=\\frac{dz}{dy}ã†\\frac{dy}{dx}$ ì—°ì‡„ë²•ì¹™ì€ ì¸ê³µì‹ ê²½ë§(í•©ì„±í•¨ìˆ˜) ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜ì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ í¸ë¯¸ë¶„ # ë‹¤ë³€ìˆ˜ í•¨ìˆ˜ì— êµ¬í•  ìˆ˜ ìˆëŠ” ë³€í™”ìœ¨ì€ ë¬´ìˆ˜íˆ ë§ìŒ ë‹¤ë³€ìˆ˜ í•¨ìˆ˜ì—ì„œ ë³€ìˆ˜ ê³ ì •, í•œë²ˆì— ë³€ìˆ˜ í•˜ë‚˜ë§Œ ë³€í™” (ìœ¤ê³½ì„ , 1ì°¨ì› í•¨ìˆ˜) í¸ë„í•¨ìˆ˜: ë‹¤ë³€ìˆ˜ í•¨ìˆ˜ì¼ ë•Œ í•˜ë‚˜ì˜ ë³€ìˆ˜ì— ëŒ€í•´ì„œë§Œ ë¯¸ë¶„í•œ ë„í•¨ìˆ˜, ê¸°í˜¸: $\\partial$ Saliency Map: ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ yì— ëŒ€í•œ ë‹¤ë³€ìˆ˜-ìŠ¤ì¹¼ë¼í•¨ìˆ˜ì˜ í¸ë¯¸ë¶„ ê³„ìˆ˜ë¥¼ ì´ë¯¸ì§€í™” Guided Back Propagation: saliency mapë³´ë‹¤ ë” í™•ì‹¤í•œ íŠ¹ì§•ì„ ë³´ì„ ë‹¤ë³€ìˆ˜ í•¨ìˆ˜ì˜ ì—°ì‡„ë²•ì¹™ì€ ëª¨ë“  ë…¸ë“œì˜ ë¯¸ë¶„ê³„ìˆ˜ë¥¼ ë”í•¨ Jacobian # ì•¼ì½”ë¹„ì•ˆ: $\\ w=f_1(x,y),\\ z=f_2(x,y)$ì¼ ë•Œ í¸ë„í•¨ìˆ˜ 4ê°œë¥¼ ë¸”ë¡ í˜•íƒœë¡œ í‘œì‹œ ë¡œì§€ìŠ¤í‹± í•¨ìˆ˜ì˜ ë¯¸ë¶„: ë‚˜ëˆ—ì…ˆì˜ ë¯¸ë¶„ê³¼ í•¨ì„±í•¨ìˆ˜ì˜ ë¯¸ë¶„ì„ ì‚¬ìš©, $\\ \\frac{d}{dz}\\sigma(z)=\\sigma(z)(1-\\sigma(z))$ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ì˜ ë¯¸ë¶„: ë²¡í„°í•¨ìˆ˜ì˜ í¸ë¯¸ë¶„ (ì¸ë°ìŠ¤ ë³„ë¡œ ë‚˜ëˆ ì„œ), ${K}\\times{K}$ê°œì˜ ë¯¸ë¶„ê³„ìˆ˜ ì¸ë±ìŠ¤ê°€ ê°™ì€ ê²½ìš° $\\ \\frac{\\partial}{\\partial{z_j}}s_i(z)=s_j(z)(1-s_j(z))$ ì¸ë±ìŠ¤ê°€ ë‹¤ë¥¸ ê²½ìš° $\\ \\frac{\\partial}{\\partial{z_j}}s_i(z)=-s_i(z)s_j(z)$ ì§ì ‘ ë¯¸ë¶„ # ì§ì ‘ ë¯¸ë¶„í•˜ì—¬ ê²°ê³¼ë¥¼ ì½”ë”© ì •í™•í•œ ê²°ê³¼, ë¹ ë¥¸ ì†ë„ ì¥ì , ë¯¸ë¶„ì„ ì§ì ‘ í•´ì•¼í•˜ë‚˜ëŠ” ë‹¨ì  ìˆ˜ì¹˜ ë¯¸ë¶„ # ìˆ˜ì¹˜ì  ê³„ì‚°ìœ¼ë¡œ ë¯¸ë¶„ ê³„ìˆ˜ë¥¼ ê·¼ì‚¬ êµ¬í˜„ ê°„ë‹¨, ë³€ìˆ˜ê°€ ë§ìœ¼ë©´ ë§¤ìš° ëŠë¦¬ê³  ìˆ˜ì¹˜ì ìœ¼ë¡œ ë¶ˆì•ˆì • ìë™ ë¯¸ë¶„ ê³„ì‚°ì´ ì •í™•í•œì§€ í™•ì¸í•  ëª©ì ìœ¼ë¡œ ì‚¬ìš© ì „ë°© ì°¨ë¶„ë²• diff = (f(x+h) - f(x)) / h ì¤‘ì•™ ì°¨ë¶„ë²• diff = (f(x+(h/2)) - f(x-(h/2))) / h ì‹ì„ ëª¨ë¥¼ ê²½ìš° brute force \u0026gt; 2ë³€ìˆ˜ ì´ìƒì¼ ë•Œ ì´ë™í•  ìˆ˜ ìˆëŠ” ë°©í–¥ì´ ë¬´í•œëŒ€ê°€ ë˜ëŠ” ë‹¨ì  gradient descent ë°©ì‹ì„ ì‚¬ìš©í•´ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì¤„ì„ "},{"id":69,"href":"/blog/2022-07-06/","title":"2022-07-06 Log","section":"Posts","content":"Regular Expression # regexpal.com [wW]oodchuck = Woodchuck, woodchuck ranges: [A-z], [a-z], [0-9] negations: [^Ss], [^A-Z], a^b disjunction: pipe(|), yours|mine ?,,+,.: colou?r(= color, colour), ooh!=o+h!, beg.n(= begin, began) ^(start), $(end): ^[A-Z], \\.$(\\: escape) subset: ([0-9]+), \\1er (= [fast]er) non-capturing groups: /(?:some|a few) (people|cats) ?= (exact match), ?! (does not match) Tokenization # Type vs Token N = number of tokens V = vocabulary (set of types) NLP task: 1)tokenizing words 2)normalizing word formats 3)segmenting sentences simpe way to tokenize: use space chracters issue: punctuation (like Ph.D), clitic (like we\u0026rsquo;re), multiword (like New York) chinese tokenization: don\u0026rsquo;t use spaces, count as a word is complex, so treat each character as token Byte Pair Encoding # subword tokenization (tokens can be parts of words) BPE, Unigram language modeling tokenization, WordPiece add most frequent pair of adjancent tokens in characters er -\u0026gt; er_ -\u0026gt; ne -\u0026gt; new -\u0026gt; lo -\u0026gt; low -\u0026gt; \u0026hellip; frequent subwords are most morphemes like -est or -er Word Normalization # put tokens in a standard format all letters to lower case (but, US vs us) all words to lemma (he is reading -\u0026gt; he be read) morphemes: the smallest meaningful units (stems, affixes) porter stemmer: ational -\u0026gt; ate, sses -\u0026gt; ss abbreviation dictionary can help "},{"id":70,"href":"/blog/2022-07-04/","title":"2022-07-04 Log","section":"Posts","content":"4. ë­í¬, ì°¨ì› # 4-4. ê³ ìœ  ë²¡í„° # ê³ ìœ³ê°’, ê³ ìœ  ë²¡í„° = íŠ¹ì„± ê°’, íŠ¹ì„± ë²¡í„° = í–‰ë ¬ì˜ íŠ¹ì„± ê³ ìœ  ë²¡í„°(eigenvector): ë²¡í„°ì— ì„ í˜• ë³€í™˜ì„ ì·¨í–ˆì„ ë•Œ, ë°©í–¥ì€ ë³€í•˜ì§€ ì•Šê³  í¬ê¸°ë§Œ ë³€í•˜ëŠ” ë²¡í„° ê³ ìœ³ê°’(eigenvalue): ì„ í˜• ë³€í™˜ ì´í›„ ë³€í•œ í¬ê¸°, ê³ ìœ  ë²¡í„°ê°€ ë³€í™˜ë˜ëŠ” í¬ê¸°ì˜ ì •ë„ 4-5. íŠ¹ì´ê°’ ë¶„í•´ # ë‹®ìŒ(similar): $P^{-1}AP=B$ë¥¼ ë§Œì¡±í•˜ëŠ” ê°€ì—­ í–‰ë ¬ $P$ê°€ ì¡´ì¬ ì‹œ, ì •ì‚¬ê° í–‰ë ¬ $A, B$ëŠ” ì„œë¡œ ë‹®ìŒ ì§êµ ë‹®ìŒ(orthogonally similar): $B=P^{-1}AP$ë¥¼ ë§Œì¡±í•˜ëŠ” ì§êµ í–‰ë ¬ $P$ê°€ ì¡´ì¬ ì‹œ, $B$ëŠ” $A$ì— ì§êµ ë‹®ìŒ ì§êµ ëŒ€ê°í™”(orthogonal diagonalization): ì§êµ ë‹®ìŒì˜ ê²½ìš°ì—ì„œ ì •ì‚¬ê° í–‰ë ¬ $B$ê°€ ëŒ€ê° í–‰ë ¬ $D$ì¼ ê²½ìš° ì§êµ ëŒ€ê°í™”ê°€ ê°€ëŠ¥í•˜ê¸° ìœ„í•´ $A$ëŠ” ë°˜ë“œì‹œ ëŒ€ì¹­ í–‰ë ¬ ($A^T=A$) ì´ì–´ì•¼ í•¨ (ê³µë¶„ì‚° í–‰ë ¬ ë“±) 4-6. ê³ ìœ³ê°’ ë¶„í•´ # í–‰ë ¬ì„ ê³ ìœ  ë²¡í„°, ê³ ìœ³ê°’ì˜ ê³±ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ê²ƒ ì§êµ ë²¡í„° $P$ë¥¼ ê³ ìœ  ë²¡í„°ë¥¼ ì´ìš©í•´ ë§Œë“¤ê³  ëŒ€ê° í–‰ë ¬ì˜ ì›ì†Œì— í•´ë‹¹í•˜ëŠ” ê²ƒì´ ê³ ìœ³ê°’ $A=PDP^T$ 4-7. íŠ¹ì´ê°’ ë¶„í•´ # ì •ì‚¬ê° í–‰ë ¬ì„ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ê³ ìœ³ê°’ ë¶„í•´ì™€ ë‹¬ë¦¬ ëŒ€ìƒ í–‰ë ¬ì„ ${m}\\times{n}$ í–‰ë ¬ë¡œ ì¼ë°˜í™” ì¸ìˆ˜ ë¶„í•´ì²˜ëŸ¼ í–‰ë ¬ì˜ ì°¨ì› ì¶•ì†Œë¥¼ ìœ„í•œ ë„êµ¬ë¡œ ì‚¬ìš© ì°¨ì› ì¶•ì†Œë¥¼ $n$ê°œì˜ ì ì„ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ê¸°ì¡´ $p$ë³´ë‹¤ ì‘ì€ ì°¨ì›ì¸ $d$ ì°¨ì›ì¸ ë¶€ë¶„ ê³µê°„(subspace)ì„ ì°¾ëŠ” ë¬¸ì œ ë°ì´í„°ì™€ ë¶€ë¶„ ê³µê°„ìœ¼ë¡œë¶€í„°ì˜ ìˆ˜ì§ ê±°ë¦¬ë¥¼ ìµœì†Œí™”(ì œê³±í•© $A^TA,AA^T$ ì‚¬ìš©)í•˜ì—¬ ë¶€ë¶„ ê³µê°„ì„ ì°¾ìŒ íŠ¹ì´ê°’(singular value): í–‰ë ¬ $A$ë¥¼ ì œê³±í•œ í–‰ë ¬ì˜ ê³ ìœ³ê°’ì— ë£¨íŠ¸ë¥¼ ì”Œìš´ ê°’, $\\sigma_1=\\sqrt{\\lambda_1}$ $A=U\\Sigma{V^T}$ í–‰ë ¬ Uì˜ ì—´ë²¡í„°ëŠ” $AA^T$ì˜ ê³ ìœ  ë²¡í„°ë¡œ êµ¬ì„±ë˜ëŠ” left singular vector í–‰ë ¬ Vì˜ ì—´ë²¡í„°ëŠ” $A^TA$ì˜ ê³ ìœ  ë²¡í„°ë¡œ êµ¬ì„±ë˜ëŠ” right singular vector $\\Sigma$ì˜ ëŒ€ê° ì›ì†ŒëŠ” í–‰ë ¬ Aì˜ íŠ¹ì´ê°’ 4-8. ì´ì°¨ì‹ í‘œí˜„ # ë‹¤í•­ì‹ì„ ë²¡í„° í˜•íƒœë¡œ ë‚˜íƒ€ë‚¼ ë•Œ ì‚¬ìš©í•˜ëŠ” ë°©ë²• ëŒ€ì¹­ í–‰ë ¬ $W$ì— ëŒ€í•´ $x^TWx$ í˜•íƒœë¡œ í‘œí˜„í•œ ì‹ ì–‘ì •ì¹˜(positive definite): $x^TWx\u0026gt;0, \\text{ for all }x\\neq{0}$ (í–‰ë ¬ Wì˜ ê³ ìœ³ê°’ì´ ëª¨ë‘ 0ë³´ë‹¤ í¼) ìŒì •ì¹˜(negative definite): $x^TWx\u0026lt;0, \\text{ for all }x\\neq{0}$ (í–‰ë ¬ Wì˜ ê³ ìœ³ê°’ì´ ëª¨ë‘ 0ë³´ë‹¤ ì‘ìŒ) 4-9. ë²¡í„°ì˜ ë¯¸ë¶„ # íƒ€ê¹ƒ $y=w^Tx=x^Tw$ë¥¼ ë°ì´í„° ë²¡í„° xì— ëŒ€í•´ ë¯¸ë¶„í•˜ë©´ wê°€ ë‚˜ì˜´ 5. í™•ë¥  ë³€ìˆ˜ì™€ í™•ë¥  ë¶„í¬ # 5-1. í™•ë¥  ë³€ìˆ˜ # í™•ë¥ (probability): ì–´ë–¤ ì‚¬ê±´ì´ ì¼ì–´ë‚  ê°€ëŠ¥ì„±ì„ ìˆ˜ì¹˜í™”ì‹œí‚¨ ê²ƒ ëª¨ë“  í™•ë¥ ì€ 0ì—ì„œ 1 ì‚¬ì´ì— ìˆìœ¼ë©°, ëª¨ë“  ê²½ìš°ì¸ í‘œë³¸ ê³µê°„(sample space)ì˜ $P(S)=1$ ë™ì‹œì— ë°œìƒí•  ìˆ˜ ì—†ëŠ” ì‚¬ê±´ë“¤ì— ëŒ€í•´ ê° ì‚¬ê±´ì˜ í•©ì˜ í™•ë¥ ì€ ê°œë³„ í™•ë¥ ì´ ì¼ì–´ë‚  í™•ë¥ ì˜ í•©ê³¼ ê°™ìŒ í™•ë¥  ë³€ìˆ˜(random variable): í™•ë¥ ì ìœ¼ë¡œ ì •í•´ì§€ëŠ” ë³€ìˆ˜, ë™ì „ ë˜ì§€ê¸°ì—ì„œ í™•ë¥  ë³€ìˆ˜ $X$ëŠ” 0 ë˜ëŠ” 1ì˜ ê°’ì„ ê°€ì§ ìƒìˆ˜(constant): ë³€ìˆ˜ì™€ ë‹¤ë¥´ê²Œ í•­ìƒ ê°’ì´ ê³ ì •ëœ ìˆ˜, $\\pi=3.14$ ë“± í•¨ìˆ˜(function): í•œ ì§‘í•©ì˜ ì„ì˜ì˜ í•œ ì›ì†Œë¥¼ ë‹¤ë¥¸ ì§‘í•©ì˜ í•œ ì›ì†Œì— ëŒ€ì‘ì‹œí‚¤ëŠ” ê´€ê³„ 5-2. í™•ë¥  ë¶„í¬ # í™•ë¥  ë³€ìˆ˜ê°€ íŠ¹ì •ê°’ì„ ê°€ì§ˆ í™•ë¥ ì˜ í•¨ìˆ˜ ì´ì‚° í™•ë¥  ë³€ìˆ˜: í™•ë¥  ë³€ìˆ˜ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê°’ì„ ì…€ ìˆ˜ ìˆìŒ í™•ë¥  ì§ˆëŸ‰ í•¨ìˆ˜: ì´ì‚° í™•ë¥  ë³€ìˆ˜ì—ì„œ íŠ¹ì •ê°’ì— ëŒ€í•œ í™•ë¥ ì„ ë‚˜íƒ€ë‚´ëŠ” í•¨ìˆ˜, $p_X(x)=P(X=x)$ ì—°ì† í™•ë¥  ë³€ìˆ˜: í™•ë¥  ë³€ìˆ˜ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê°’ì˜ ê°œìˆ˜ë¥¼ ì…€ ìˆ˜ ì—†ìŒ í™•ë¥  ë°€ë„ í•¨ìˆ˜: ì—°ì† í™•ë¥  ë³€ìˆ˜ì˜ ë¶„í¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í•¨ìˆ˜, $P(a\\lt{X}\\lt{b})=\\int_a^bf_X(x)dx$ ëˆ„ì  ë¶„í¬ í•¨ìˆ˜: ì£¼ì–´ì§„ í™•ë¥  ë³€ìˆ˜ê°€ íŠ¹ì •ê°’ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì€ í™•ë¥ , $F_X(x)=P(X\\in{-\\infty,x}$ ê²°í•© í™•ë¥  ë°€ë„ í•¨ìˆ˜: í™•ë¥  ë³€ìˆ˜ ì—¬ëŸ¬ ê°œë¥¼ í•¨ê»˜ ê³ ë ¤í•˜ëŠ” í™•ë¥  ë¶„í¬, $P_{X,Y}(x,y)=P(X=x,Y=y)$ ë…ë¦½ í•­ë“± ë¶„í¬: ë‘ ê°œ ì´ìƒì˜ í™•ë¥  ë³€ìˆ˜ë¥¼ ê³ ë ¤í•  ë•Œ, ê° í™•ë¥  ë³€ìˆ˜ê°€ í†µê³„ì ìœ¼ë¡œ ë…ë¦½ì´ê³  ë™ì¼í•œ í™•ë¥  ë¶„í¬(iid)ë¥¼ ë”°ë¦„ 5-3. ëª¨ì§‘ë‹¨ê³¼ í‘œë³¸ # ëª¨ì§‘ë‹¨(population)ì€ ê´€ì‹¬ì´ ìˆëŠ” ëŒ€ìƒ ì „ì²´, í‘œë³¸(sample)ì€ ëª¨ì§‘ë‹¨ì˜ ì¼ë¶€ ëª¨ì§‘ë‹¨ì˜ íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ëŒ€í‘¯ê°’ì„ ëª¨ìˆ˜(population parameter), í‘œë³¸ì˜ ëŒ€í‘¯ê°’(sample statistic)ì„ í‘œë³¸ í†µê³„ëŸ‰ 5-4. í‰ê· ê³¼ ë¶„ì‚° # ì‚°ìˆ  í‰ê· : ëª¨ë“  ë°ì´í„°ê°’ì„ ë§ì…ˆí•œ í›„ ë°ì´í„° ê°œìˆ˜ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒ ëª¨í‰ê· : ëª¨ì§‘ë‹¨ì˜ í‰ê· , $E(X)=\\mu$ í‘œë³¸ í‰ê· : ëª¨í‰ê· ì˜ ì¶”ì •ëŸ‰, $\\bar{X}=\\frac{1}{n}\\Sigma^n_{i=1}{x_i}$ Location parameter: í‰ê· ì˜ ë³€í™”ë¡œ, ê·¸ë˜í”„ì˜ ìœ„ì¹˜ ë³€í™”ë¥¼ ë‚˜íƒ€ëƒ„ ë¶„ì‚°: ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ í¼ì ¸ ìˆëŠ”ì§€ë¥¼ ìˆ˜ì¹˜í™”, í‰ê· ì— ëŒ€í•œ í¸ì°¨ ì œê³±ì˜ í‰ê·  ëª¨ë¶„ì‚°: $Var(X)=E[(X-\\mu)^2]=\\sigma^2=E(X^2)-\\mu^2$ í‘œë³¸ ë¶„ì‚°: $\\sigma^2=s^2=\\frac{1}{n-1}\\Sigma^n_{i=1}(x_i-\\bar{x})^2$ $x_i-\\bar{x}$ëŠ” í‰ê· ì— ëŒ€í•œ í¸ì°¨ë¥¼ ì˜ë¯¸í•˜ë©°, í¸ì°¨ ì œê³±ì˜ í•©ì„ n-1ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì€ ììœ ë„ì™€ ê´€ë ¨ ììœ ë„ëŠ” ë³€ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ììœ ë¡œìš´ì§€ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ,\në¶„ì‚°ì„ êµ¬í•˜ëŠ” ì‹œì ì—ì„œ ì´ë¯¸ í‘œë³¸ í‰ê· ì´ ì •í•´ì ¸ ìˆì–´ ììœ ë¡­ê²Œ ì •í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ n-1ê°œì¸ ê²ƒì„ ì˜ë¯¸ Scale parameter: ë¶„ì‚°ê³¼ ê°™ì´ ë°ì´í„°ì˜ í©ì–´ì§ ì •ë„ë¥¼ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„° í‘œì¤€ í¸ì°¨: ë¶„ì‚°ì˜ ì–‘ì˜ ì œê³±ê·¼ìœ¼ë¡œ ì •ì˜, ë¶„ì‚° ê³„ì‚° ì¤‘ ì œê³±ìœ¼ë¡œ ì»¤ì§„ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì›ë˜ ë‹¨ìœ„ë¡œ ì¡°ì •í•˜ëŠ” ê³¼ì • $$E(\\Sigma^n_{i=1}X_i)=n\\mu_X\\text{, }Var(\\Sigma^n_{i=1}X_i)=n\\sigma^2$$\n5-5. ìƒê´€ê´€ê³„ # ê³µë¶„ì‚°(covariance): ë‘ í™•ë¥  ë³€ìˆ˜ì˜ ìƒê´€ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°’, ê°™ì€ ë°©í–¥ìœ¼ë¡œ ì›€ì§ì´ë©´ ì–‘ìˆ˜, ë°˜ëŒ€ì˜ ê²½ìš° ìŒìˆ˜ ê³µë¶„ì‚°ì€ ë³€ìˆ˜ Xì˜ í¸ì°¨ì™€ ë³€ìˆ˜ Yì˜ í¸ì°¨ë¥¼ ê³±í•œ ê°’ì˜ í‰ê· , $Cov(X,Y)=E[(X-\\mu_X)(Y-\\mu_Y)]$ ê³µë¶„ì‚° í–‰ë ¬: í™•ë¥  ë³€ìˆ˜ ê°„ ë¶„ì‚°, ê³µë¶„ì‚°ì„ í–‰ë ¬ë¡œ í‘œí˜„í•œ ê²ƒ, ì°¨ì› ì¶•ì†Œ ë“±ì—ì„œ ìì£¼ ì‚¬ìš© ìƒê´€ ê³„ìˆ˜: ê³µë¶„ì‚°ì„ ê° ë³€ìˆ˜ì˜ í‘œì¤€ í¸ì°¨ë¡œ ë‚˜ëˆ„ì–´ ê³„ì‚° $$Corr(X,Y)=\\frac{Cov(X,Y)}{\\sqrt{Var(X)}\\sqrt{Var(Y)}}=\\frac{Cov(X,Y)}{\\sigma_X\\sigma_Y}$$\n5-6. ê· ì¼ ë¶„í¬ # íŠ¹ì • ë²”ìœ„ ë‚´ì—ì„œ í™•ë¥  ë¶„í¬ê°€ ê· ì¼í•œ ë¶„í¬ ì´ì‚°í˜• ê· ì¼ ë¶„í¬ë¼ë©´ ëª¨ë“  í™•ë¥  ë³€ìˆ˜ì˜ í™•ë¥ ê°’ì´ ë™ì¼, $X~U(1,N)$ ì—°ì†í˜• ê· ì¼ ë¶„í¬ëŠ” í™•ë¥  ë³€ìˆ˜ì˜ ë²”ìœ„ê°€ ì—°ì†í˜•, $X~U(a,b)$ 5-7. ì •ê·œ ë¶„í¬ # ì •ê·œ ë¶„í¬ ë˜ëŠ” ê°€ìš°ì‹œì•ˆ ë¶„í¬ëŠ” í‰ê· ì„ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€ì¹­ í˜•íƒœë¥¼ ë ëŠ” ì¢… ëª¨ì–‘ ë¶„í¬ $$f_X(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2} \\text{, } E(X)=\\mu \\text{, } Var(X)=\\sigma^2$$\n$\\frac{x-\\mu}{\\sigma}$ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì“°ì´ëŠ” ë°ì´í„° í‘œì¤€í™”ì™€ ì¼ì¹˜ í‘œì¤€ ì •ê·œ ë¶„í¬: í‰ê· ì´ 0, ë¶„ì‚°ì´ 1ì¸ ì •ê·œ ë¶„í¬ 5-8. ì´í•­ ë¶„í¬ # ë² ë¥´ëˆ„ì´ ë¶„í¬, ë² ë¥´ëˆ„ì´ ì‹œí–‰: í•œ ê°€ì§€ ì‹¤í—˜ì—ì„œ ê²°ê³¼ê°€ ì˜¤ì§ 2ê°œì¸ ì‹œí–‰ ë² ë¥´ëˆ„ì´ ì‹œí–‰ì˜ ì„±ê³µ í™•ë¥ ì´ pì¼ ë•Œ, ì‹¤íŒ¨ í™•ë¥ ì€ 1-p ì´í•­ ë¶„í¬: ì„±ê³µ í™•ë¥ ì´ pì¸ ë…ë¦½ì ì¸ ë² ë¥´ëˆ„ì´ ì‹œí–‰ì„ níšŒ í–ˆì„ ë•Œ, ì„±ê³µ íšŸìˆ˜ Xê°€ ë”°ë¥´ëŠ” ì´ì‚°í˜• í™•ë¥  ë¶„í¬ ë‹¤í•­ ë¶„í¬: ì´í•­ ë¶„í¬ë¥¼ ì¼ë°˜í™”í•œ ë¶„í¬, ê° ì‹œí–‰ì—ì„œ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ê²°ê³¼ê°€ mê°œë¡œ í™•ì¥ 5-9. ìµœëŒ€ ê°€ëŠ¥ë„ ì¶”ì • # ê°€ëŠ¥ë„, ìš°ë„(likelihood): íŒŒë¼ë¯¸í„°ê°€ ì£¼ì–´ì§ˆ ë•Œ í•´ë‹¹ í‘œë³¸ì´ ìˆ˜ì§‘ë  í™•ë¥  ê°€ëŠ¥ë„ê°€ ë†’ë‹¤ëŠ” ê²ƒì€ í•´ë‹¹ íŒŒë¼ë¯¸í„°ê°€ ì‹¤ì ¯ê°’ì¼ í™•ë¥ ì´ ë†’ë‹¤ëŠ” ëœ» ê°€ëŠ¥ë„ í•¨ìˆ˜ $L(\\theta|x)=\\Pi^n_{i=1}{f(x_i|\\theta)}$ ë¡œê·¸ í•¨ìˆ˜ê°€ 1ëŒ€1 í•¨ìˆ˜ì´ê¸° ë•Œë¬¸ì— ê°€ëŠ¥ë„ í•¨ìˆ˜ì— ë¡œê·¸ í•¨ìˆ˜ë¥¼ ì·¨í•  ìˆ˜ ìˆìŒ (log-likelihood function) ë§ì€ í™•ë¥ ì„ ê³±í•  ê²½ìš° 0ì— ê°€ê¹Œì›Œì§€ê¸° ë•Œë¬¸ì— ê³„ì‚°ìƒì˜ ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë¡œê·¸ë¥¼ ì·¨í•¨ ìµœëŒ€ ê°€ëŠ¥ë„ ì¶”ì •ëŸ‰(MLE): íŒŒë¼ë¯¸í„°ë³„ ê°€ëŠ¥ë„ë¥¼ êµ¬í•´ ê°€ì¥ ë†’ì€ ê°€ëŠ¥ë„ë¥¼ íŒŒë¼ë¯¸í„° ì¶”ì •ê°’ìœ¼ë¡œ ì‚¬ìš© 5-10. ìµœëŒ€ ì‚¬í›„ ì¶”ì • # ì¡°ê±´ë¶€ í™•ë¥ : ì¡°ê±´ì´ ì£¼ì–´ì§ˆ ë•Œì˜ í™•ë¥ , $P(A|B)=\\frac{P({A}\\bigcap{B})}{P(B)}$ ë‘ ì‚¬ê±´ì´ ë…ë¦½ì¼ ê²½ìš°, ë‘ ì‚¬ê±´ì´ ë™ì‹œì— ë°œìƒí•  í™•ë¥ ($P({A}\\bigcap{B}$)ì€ ê° ì‚¬ê±´ì´ ì¼ì–´ë‚  í™•ë¥ ì˜ ê³±ê³¼ ê°™ìŒ Bayesian: í™•ë¥  ë¶„í¬ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ìƒìˆ˜ë¡œ ë³´ëŠ” ì¼ë°˜ì ì¸ ë¹ˆë„ì£¼ì˜(Frequentist)ì™€ ë‹¬ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ í™•ë¥  ë³€ìˆ˜ë¡œ ë³´ëŠ” ë°©ë²• ë² ì´ì¦ˆ ì¶”ì •: íŒŒë¼ë¯¸í„° $\\theta$ê°€ í™•ë¥  ë³€ìˆ˜ì´ë¯€ë¡œ ì‚¬ì „ í™•ë¥  ë°€ë„ í•¨ìˆ˜ $P(\\theta)$ë¥¼ êµ¬í•  ìˆ˜ ìˆìŒ $P(\\theta,x)=P(x|\\theta)P(\\theta)$ ì‚¬í›„ í™•ë¥  ë°€ë„ í•¨ìˆ˜ $P(\\theta|x)\\propto{P(x|\\theta)P(\\theta)}$ ìµœëŒ€ ì‚¬í›„ ì¶”ì •(MAP): ì‚¬í›„ í™•ë¥  ë°€ë„ í•¨ìˆ˜ $P(\\theta|x)$ë¥¼ ìµœëŒ€í™”í•˜ëŠ” íŒŒë¼ë¯¸í„° $\\theta$ 6. ìµœì í™” # 6-1. ì»¨ë²¡ìŠ¤ ì…‹ # ì§ì„ ì€ ì‹œì‘ê³¼ ëì´ ì¡´ì¬í•˜ì§€ ì•Šì§€ë§Œ, ì„ ë¶„ì€ ì‹œì‘ê³¼ ë ì§€ì ì´ ì¡´ì¬ ì•„í•€ ì…‹(affine set): $wx_1+(1-w)x_2\\in{C}$ë¥¼ ë§Œì¡±í•˜ëŠ” ì§‘í•© C í•¨ìˆ˜ $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m$ê°€ ì¡´ì¬í•  ë•Œ,\nì„ í˜• í•¨ìˆ˜ $f(x)=Wx$,\nì•„í•€ í•¨ìˆ˜ $f(x)=Wx+b$ ì»¨ë²¡ìŠ¤ ì…‹(convex set): ë‘ ì  $x_1,x_2\\in{C}$ì— ëŒ€í•´ ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì§‘í•© C $$wx_1+(1-w)x_2\\in{C}\\text{ }(0\\le{w}\\le{1})$$\nì»¨ë²¡ìŠ¤ ì…‹ì€ ë‘ ì ì„ ì‡ëŠ” ì§ì„ ì„ í¬í•¨í•˜ëŠ” ì•„í•€ ì…‹ê³¼ ë‹¬ë¦¬ ë‘ ì  ì‚¬ì´ì˜ ì„ ë¶„ì„ í¬í•¨ (ì§‘í•©ì˜ ê²½ê³„ê°€ ì¡´ì¬, ì»¨ë²¡ìŠ¤ ì…‹ $\\subset$ ì•„í•€ ì…‹) ì»¨ë²¡ìŠ¤ í—(convex hull): ì„ ë¶„ì´ ì•„ë‹Œ, ì£¼ì–´ì§„ ì ë“¤ì„ í¬í•¨í•˜ëŠ” ì»¨ë²¡ìŠ¤ ì…‹ ì´ˆí‰ë©´(hyperplane): ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ ê°œë…, ${x|w^Tx=b}$ ë‚´ì ê°’ bê°€ 0ì¼ ê²½ìš° ë²¡í„° wì™€ ë²¡í„° $x-x_0$ëŠ” ìˆ˜ì§ ë°˜ê³µê°„(halfspace): ì´ˆí‰ë©´ìœ¼ë¡œ ë‚˜ë‰œ ê³µê°„ì˜ ì¼ë¶€, ${w^Tx\\le{b}}$ 6-2. ì»¨ë²¡ìŠ¤ í•¨ìˆ˜ # ì»¨ë²¡ìŠ¤ í•¨ìˆ˜: $$f(wx_1+(1-w)x_2 \\le wf(x_1)+(1-w)f(x_2)$$ ì»¨ë²¡ìŠ¤ í•¨ìˆ˜ì—ì„œ ë“±í˜¸ê°€ ì—†ê³  $0 \\le w \\le 1$ì´ë©´ strictly ì»¨ë²¡ìŠ¤ë¼ê³  ë§í•¨ ì½˜ì¼€ì´ë¸Œ(concave): ì»¨ë²¡ìŠ¤ì˜ ë°˜ëŒ€ë˜ëŠ” ê°œë… (-fê°€ ì»¨ë²¡ìŠ¤í•  ê²½ìš°ì˜ f) ì»¨ë²¡ìŠ¤ í•¨ìˆ˜ì˜ ì˜ˆë¡œ ì§€ìˆ˜ í•¨ìˆ˜, ì ˆëŒ“ê°’ í•¨ìˆ˜, ë©±í•¨ìˆ˜, ì§€ì‹œ í•¨ìˆ˜, ìµœëŒ€ í•¨ìˆ˜ ë“±ì´ ìˆìŒ ë¯¸ë¶„ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ë§ì€ ê·¸ë˜ë””ì–¸íŠ¸(gradient) $\\nabla f$ê°€ ì¡´ì¬í•œë‹¤ëŠ” ëœ» 1ì°¨ ë¯¸ë¶„ ì¡°ê±´: ìµœì ê°’ íƒìƒ‰ì— ì‚¬ìš©, $f(x_2) \\ge f(x_1)+\\nabla{f(x_1)^T}(x_2-x_1)$ ê·¸ë˜ë””ì–¸íŠ¸ ê°’ì´ 0ì¼ ë•Œ, $x_1$ì€ í•¨ìˆ˜ fì— ëŒ€í•œ ì „ì—­ ìµœì†Ÿê°’(global minimizer) 2ì°¨ ë¯¸ë¶„ ì¡°ê±´: í•¨ìˆ˜ fê°€ ë‘ ë²ˆ ë¯¸ë¶„ ê°€ëŠ¥í•  ê²½ìš°, $\\nabla^2f(x) \\ge 0$ ì–€ì„¼ì˜ ë¶€ë“±ì‹: $f(wx_1+(1-w)x_2) \\le wf(x_1)+(1-w)f(x_2)$ "},{"id":71,"href":"/blog/2022-06-30/","title":"2022-06-30 Log","section":"Posts","content":"15-01. Attention Mechanism # seq2seq ëª¨ë¸ì€ í•˜ë‚˜ì˜ ê³ ì •ëœ í¬ê¸°ì˜ ë²¡í„°ì— ëª¨ë“  ì •ë³´ë¥¼ ì••ì¶•í•˜ë ¤ê³  í•´ì„œ ì •ë³´ ì†ì‹¤ì´ ë°œìƒí•˜ë©°,\nRNNì˜ ê³ ì§ˆì ì¸ ë¬¸ì œì¸ ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œë„ ì¡´ì¬ ê¸°ê³„ ë²ˆì—­ ë¶„ì•¼ì—ì„œ ì…ë ¥ ë¬¸ì¥ì´ ê¸¸ë©´ ë²ˆì—­ í’ˆì§ˆì´ ë–¨ì–´ì§€ëŠ” ê²ƒì„ ë³´ì •í•˜ê¸° ìœ„í•´ ì–´í…ì…˜ ê¸°ë²• í™œìš© ì–´í…ì…˜ì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” ë””ì½”ë”ì—ì„œ ì¶œë ¥ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë§¤ ì‹œì ‘ë§ˆë‹¤,\nì¸ì½”ë”ì—ì„œ ì „ì²´ ì…ë ¥ ë¬¸ì¥ì„ ë‹¤ì‹œ í•œ ë²ˆ ì°¸ê³ í•œë‹¤ëŠ” ì  Attention Function # Attention(Q, K, V) = Attention Value ì–´í…ì…˜ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ Queryì— ëŒ€í•´ì„œ ëª¨ë“  Keyì™€ì˜ ìœ ì‚¬ë„ë¥¼ ê°ê° êµ¬í•˜ê³ ,\nìœ ì‚¬ë„ë¥¼ í‚¤ì™€ ë§µí•‘ë˜ì–´ìˆëŠ” ê°ê°ì˜ Valueì— ë°˜ì˜, ì´í›„ ìœ ì‚¬ë„ê°€ ë°˜ì˜ëœ Valueë¥¼ ëª¨ë‘ ë”í•´ ë¦¬í„´ Q(Query): t ì‹œì ì˜ ë””ì½”ë” ì…€ì—ì„œì˜ ì€ë‹‰ ìƒíƒœ\nK(Keys): ëª¨ë“  ì‹œì ì˜ ì¸ì½”ë” ì…€ì˜ ì€ë‹‰ ìƒíƒœë“¤\nV(Values): ëª¨ë“  ì‹œì ì˜ ì¸ì½”ë” ì…€ì˜ ì€ë‹‰ ìƒíƒœë“¤\nDot-Product Attention # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì—ì„œ ì¶œë ¥ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ë””ì½”ë” ì…€ì€\nt-1ì˜ hidden state, t-1ì— ë‚˜ì˜¨ ì¶œë ¥ ë‹¨ì–´, Attention Value $a_t$ë¥¼ í•„ìš” ì œì•ˆìì˜ ì´ë¦„ì„ ë”°ì„œ ë£¨ì˜¹(Luong) ì–´í…ì…˜ì´ë¼ê³ ë„ í•¨ 1. Attention Score # $a_t$ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œëŠ” Attention Scoreë¥¼ êµ¬í•´ì•¼ í•¨\n(ì¸ì½”ë”ì˜ ëª¨ë“  ì€ë‹‰ ìƒíƒœ ê°ê°ì˜ ë””ì½”ë”ì˜ í˜„ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœ $s_t$ì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ íŒë‹¨í•˜ëŠ” ìŠ¤ì½”ì–´) Dot-Product Attentionì—ì„œëŠ” ìŠ¤ì½”ì–´ ê°’ì„ êµ¬í•˜ê¸° ìœ„í•´ $s_t$ë¥¼ ì „ì¹˜í•˜ê³  ê° ì€ë‹‰ ìƒíƒœì™€ ë‚´ì ì„ ìˆ˜í–‰ ìŠ¤ì½”ì–´ í•¨ìˆ˜ $score(s_t,h_i)={s^T_t}{h_i}$ $s_t$ì™€ ì¸ì½”ë”ì˜ ëª¨ë“  ì€ë‹‰ ìƒíƒœì˜ ì–´í…ì…˜ ìŠ¤ì½”ì–´ ëª¨ìŒê°’ $e^t=[{s^T_t}{h_1},\u0026hellip;,{s^T_t}{h_N}]$ ìŠ¤ì½”ì–´ í•¨ìˆ˜ì— ë”°ë¼ scaled dot, general, concat, location-base ì–´í…ì…˜ ë“±ì´ ì¡´ì¬ 2. Attention Distribution # $e^t$ì— softmax í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ëª¨ë“  ê°’ì„ í•©í•˜ë©´ 1ì´ ë˜ëŠ” í™•ë¥  ë¶„í¬,\nAttention Distributionì„ ì–»ìœ¼ë©°, ë¶„í¬ ê°ê°ì˜ ê°’ì„ Attention Weightë¼ í•¨ ì–´í…ì…˜ ë¶„í¬ $\\alpha^t=softmax(e^t)$ 3. Attention Value # ì–´í…ì…˜ì˜ ìµœì¢… ê²°ê³¼ê°’ì„ ì–»ê¸° ìœ„í•´ì„œ ê° ì¸ì½”ë”ì˜ ì€ë‹‰ ìƒíƒœì™€ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë“¤ì„ ê³±í•˜ê³ ,\nìµœì¢…ì ìœ¼ë¡œ ëª¨ë‘ ë”í•˜ëŠ” Weighted Sumì„ ì§„í–‰ ì–´í…ì…˜ ê°’ì´ êµ¬í•´ì§€ë©´ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì€ $a_t$ë¥¼ $s_t$ì™€ ê²°í•©(concatenate)í•˜ì—¬ í•˜ë‚˜ì˜ ë²¡í„° $v_t$ë¥¼ ìƒì„± $v_t\\text{ë¥¼ }\\hat{y}$ ì˜ˆì¸¡ ì—°ì‚°ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•´ ì¸ì½”ë”ë¡œë¶€í„° ì–»ì€ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ $\\hat{y}$ë¥¼ ì˜ˆì¸¡ $$a_t=\\Sigma^N_{i=1}{\\alpha^t_i}{h_i}$$\n15-02. Bahdanau Attention # ë°”ë‹¤ë‚˜ìš° ì–´í…ì…˜ í•¨ìˆ˜ì˜ QueryëŠ” t ì‹œì ì˜ ì€ë‹‰ ìƒíƒœê°€ ì•„ë‹ˆë¼ t-1 ì‹œì ì˜ ì€ë‹‰ ìƒíƒœë¥¼ ì‚¬ìš© $score(s_{t-1},h_i)={W^T_\\alpha}\\tanh{({W_b}{s_{t-1}}+{W_c}{h_i})}$ $W_a,W_b,W_c$ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì˜ë¯¸í•˜ë©°, $s_{t-1}$ì™€ $h_1,h_2,h_3,h_4$ì˜ ì–´í…ì…˜ ìŠ¤ì½”ì–´ë¥¼\nê°ê° êµ¬í•˜ëŠ” ë³‘ë ¬ ì—°ì‚°ì„ ìœ„í•´ $h_1,h_2,h_3,h_4$ë¥¼ í•˜ë‚˜ì˜ í–‰ë ¬ $H$ë¡œ ë³€í™˜ $e^t={W^T_\\alpha}\\tanh{({W_b}{s_{t-1}}+{W_c}H)}$ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ êµ¬í•˜ë©´, í˜„ì¬ ì‹œì ì˜ ì…ë ¥ì¸ ë‹¨ì–´ì˜ ì„ë² ë”© ë²¡í„°ì™€ ì—°ê²°(concatenate)í•˜ê³ ,\ní˜„ì¬ ì‹œì ì˜ ìƒˆë¡œìš´ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš© 16-01. Transformer # ì–´í…ì…˜ì„ RNNì˜ ë³´ì •ì„ ìœ„í•œ ìš©ë„ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì–´í…ì…˜ë§Œìœ¼ë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ìƒì„± Transformer Hyperparameter # $d_{model}=152$\níŠ¸ëœìŠ¤ í¬ë¨¸ì˜ ì¸ì½”ë”ì™€ ë””ì½”ë”ì—ì„œì˜ ì •í•´ì§„ ì…ë ¥ê³¼ ì¶œë ¥ì˜ í¬ê¸°, ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›\n$num_{layers}=6$\níŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì—ì„œ ì¸ì½”ë”ì™€ ë””ì½”ë”ê°€ ì´ ëª‡ ì¸µìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€\n$num_{heads}=8$\nì–´í…ì…˜ì„ ì—¬ëŸ¬ ê°œë¡œ ë¶„í• í•´ì„œ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ê°’ì„ ë‹¤ì‹œ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ”ë°, ì´ë•Œ ì´ ë³‘ë ¬ì˜ ê°œìˆ˜\n$d_{ff}=2048$\ní”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§ì˜ ì€ë‹‰ì¸µì˜ í¬ê¸°, ì…ë ¥ì¸µê³¼ ì¶œë ¥ì¸µì˜ í¬ê¸°ëŠ” $d_{model}$\nPositional Encoding # RNNì€ ë‹¨ì–´ì˜ ìœ„ì¹˜ì— ë”°ë¼ ë‹¨ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ë°›ì•„ ì²˜ë¦¬í•˜ëŠ” íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ê° ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ê°€ì§ íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ë‹¨ì–´ ì…ë ¥ì„ ìˆœì°¨ì ìœ¼ë¡œ ë°›ëŠ” ë°©ì‹ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—\në‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ê° ë‹¨ì–´ì˜ ì„ë² ë”© ë²¡í„°ì— ìœ„ì¹˜ ì •ë³´ë“¤ì„ ë”í•´ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©(í¬ì§€ì…”ë„ ì¸ì½”ë”©) íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìœ„ì¹˜ ì •ë³´ë¥¼ ê°€ì§„ ê°’ì„ ë§Œë“¤ê¸° ìœ„í•´ ì•„ë˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš© $$PE_{(pos,2i)}=\\sin{(pos/10000^{2i/d_{model}})}$$ $$PE_{(pos,2i+1)}=\\cos{(pos/10000^{2i/d_{model}})}$$\nì‚¬ì¸ í•¨ìˆ˜ì™€ ì½”ì‚¬ì¸ í•¨ìˆ˜ì˜ ê°’ì„ ì„ë² ë”© ë²¡í„°ì— ë”í•´ ë‹¨ì–´ì— ìˆœì„œ ì •ë³´ë¥¼ ë¶€ì—¬ $pos$ëŠ” ì…ë ¥ ë¬¸ì¥ì—ì„œì˜ ì„ë² ë”© ë²¡í„°ì˜ ìœ„ì¹˜, $i$ëŠ” ì„ë°ë¹™ ë²¡í„° ë‚´ì˜ ì°¨ì›ì˜ ì¸ë±ìŠ¤ ì˜ë¯¸ $d_{model}$ì€ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ëª¨ë“  ì¸µì˜ ì¶œë ¥ ì°¨ì›ì„ ì˜ë¯¸í•˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° Self-Attention # ì–´í…ì…˜ì„ ìê¸° ìì‹ ì—ê²Œ ìˆ˜í–‰í•˜ëŠ” ê²ƒ Q, K, VëŠ” ëª¨ë‘ ì…ë ¥ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ ë²¡í„°ë“¤ì„ ì˜ë¯¸ ì…€í”„ ì–´í…ì…˜ì€ ì…ë ¥ ë¬¸ì¥ ë‚´ì˜ ë‹¨ì–´ë“¤ë¼ë¦¬ ìœ ì‚¬ë„ë¥¼ êµ¬í•´ itì´ ì–´ë–¤ ë‹¨ì–´ì™€ ì—°ê´€ë˜ì—ˆëŠ”ì§€ í™•ë¥ ì„ ì°¾ì•„ëƒ„ ì…€í”„ ì–´í…ì…˜ì€ ì¸ì½”ë”ì˜ ì´ˆê¸° ì…ë ¥ì¸ $d_{model}$ì˜ ì°¨ì›ì„ ê°€ì§€ëŠ” ë‹¨ì–´ ë²¡í„°ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰í•˜ì§€ ì•Šê³ ,\nê° ë‹¨ì–´ ë²¡í„°ë“¤ë¡œë¶€í„° Që²¡í„°, Kë²¡í„°, Vë²¡í„°ë¥¼ ì–»ëŠ” ì‘ì—…ì„ ê±°ì¹¨ $d_{model}=512$ì˜ ì°¨ì›ì„ ê°€ì¡Œë˜ ê° ë‹¨ì–´ ë²¡í„°ë“¤ì€ Që²¡í„°, Kë²¡í„°, Vë²¡í„°ë¡œ ë³€í™˜ë˜ë©´ì„œ\n$d_{model}$ì„ $num_{heads}$ë¡œ ë‚˜ëˆˆ ê°’ 64ë¥¼ ì°¨ì›ìœ¼ë¡œ ê°–ê²Œ ë¨ Scaled dot-product Attention # íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œëŠ” ìŠ¤ì¼€ì¼ë“œ ë‹·-í”„ë¡œì íŠ¸ ì–´í…ì…˜ì„ ì‚¬ìš© ë²¡í„°ë§ˆë‹¤ ì¼ì¼íˆ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ êµ¬í•˜ëŠ” ë²¡í„° ì—°ì‚°ì„ í•˜ì§€ ì•Šê³ ,\në¬¸ì¥ í–‰ë ¬ì— ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ê³±í•˜ì—¬ êµ¬í•œ Qí–‰ë ¬, Kí–‰ë ¬, Ví–‰ë ¬ì— í–‰ë ¬ ì—°ì‚°ì„ ìˆ˜í–‰ í–‰ë ¬ ì—°ì‚°ì—ì„œ ì–´í…ì…˜ ìŠ¤ì½”ì–´ëŠ” í–‰ë ¬ì˜ ê°’ì— ì „ì²´ì ìœ¼ë¡œ $\\sqrt{d_k}$ë¥¼ ë‚˜ëˆ„ì–´ ìŠ¤ì½”ì–´ ê°’ì„ ê°€ì§€ëŠ” í–‰ë ¬ì„ êµ¬í•¨ $$Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$\nMulti-head Attention # í•œ ë²ˆì˜ ì–´í…ì…˜ì„ í•˜ëŠ” ê²ƒë³´ë‹¤ ì—¬ëŸ¬ë²ˆì˜ ì–´í…ì…˜ì„ ë³‘ë ¬ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” íš¨ê³¼ì ì´ê¸° ë•Œë¬¸ì—\n$d_{model}$ì˜ ì°¨ì›ì„ $num_{heads}$ê°œë¡œ ë‚˜ëˆ„ì–´ Q, K, Vì— ëŒ€í•´ì„œ $num_{heads}$ê°œì˜ ë³‘ë ¬ ì–´í…ì…˜ì„ ìˆ˜í–‰ ê°ê°ì˜ ì–´í…ì…˜ ê°’ í–‰ë ¬ì„ ì–´í…ì…˜ í—¤ë“œë¼ê³  ë¶ˆëŠ”ë°, ì´ë•Œ ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^Q, W^K, W^V$ì˜ ê°’ì€ ì–´í…ì…˜ í—¤ë“œë§ˆë‹¤ ì „ë¶€ ë‹¤ë¦„ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì€ ì–´í…ì…˜ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•˜ì—¬ ë‹¤ë¥¸ ì‹œê°ìœ¼ë¡œ ì •ë³´ë“¤ì„ ìˆ˜ì§‘ ë²™ë ¬ ì–´í…ì…˜ ìˆ˜í–‰ í›„ ëª¨ë“  ì–´í…ì…˜ í—¤ë“œë¥¼ ì—°ê²°(concatenate)í•˜ì—¬ $(seq_{len}, d_{model})$ í¬ê¸°ì˜ í–‰ë ¬ ìƒì„± ì—°ê²°í•œ í–‰ë ¬ì— ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^O$ë¥¼ ê³±í•œ ê²ƒì´ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ìµœì¢… ê²°ê³¼ë¬¼ì´ë©°, ì¸ì½”ë”ì˜ ì…ë ¥ì´ì—ˆë˜ ë¬¸ì¥ í–‰ë ¬ê³¼ ë™ì¼\n(ì¸ì½”ë”ì—ì„œì˜ ì…ë ¥ì˜ í‚‰ê°€ ì¶œë ¥ì—ì„œë„ ë™ì¼ í¬ê¸°ë¡œ ê³„ì™ ìœ ì§€ë˜ì–´ì•¼ë§Œ ë‹¤ìŒ ì¸ì½”ë”ì—ì„œë„ ë‹¤ì‹œ ì…ë ¥ì´ ë  ìˆ˜ ìˆìŒ) Padding Mask # ì…ë ¥ ë¬¸ì¥ì— í† í°ì´ ìˆì„ ê²½ìš° ì–´í…ì…˜ì—ì„œ ì œì™¸í•˜ê¸° ìœ„í•´ -1e9ë¼ëŠ” ì•„ì£¼ ì‘ì€ ìŒìˆ˜ ê°’ì„ ê³±í•¨ Masking: ì–´í…ì…˜ì—ì„œ ì œì™¸í•˜ê¸° ìœ„í•´ ê°’ì„ ê°€ë¦¬ëŠ” ê²ƒ ì–´í…ì…˜ ìŠ¤ì½”ì–´ í–‰ë ¬ì—ì„œ í–‰ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì¥ì€ Query, ì—´ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì¥ì€ Keyì´ë©°,\nKeyì— ê°€ ìˆëŠ” ê²½ìš° í•´ë‹¹ ì—´ ì „ì²´ë¥¼ ë§ˆìŠ¤í‚¹ Position-wise FFNN # í¬ì§€ì…˜ ì™€ì´ì¦ˆ FFNNì€ ì¸ì½”ë”ì™€ ë””ì½”ë”ì—ì„œ ê³µí†µì ìœ¼ë¡œ ê°€ì§€ê³  ìˆëŠ” ì„œë¸Œì¸µìœ¼ë¡œ, ì™„ì „ ì—°ê²° FFNNì„ ì˜ë¯¸ $FFNN(x)=MAX(0,x{W_1}+b_1){W_2}+{b_2}$ $x$ëŠ” ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ê²°ê³¼ë¡œ ë‚˜ì˜¨ $(seq_{len}, d_{model})$ í¬ê¸°ì˜ í–‰ë ¬ì„ ì˜ë¯¸,\nê°€ì¤‘ì¹˜ í–‰ë ¬ $W_1\\text{ì€ }(d_{model},d_{ff})\\text{, }W_2\\text{ì€ }(d_{ff},d_{model})$ì˜ í¬ê¸°ë¥¼ ê°€ì§ ì„œë¸Œì¸µì„ ì§€ë‚œ ì¸ì½”ë”ì˜ ìµœì¢… ì¶œë ¥ì€ ì—¬ì „íˆ ì¸ì½”ë”ì˜ ì…ë ¥ì˜ í¬ê¸°ì˜€ë˜ $(seq_{len}, d_{model})$ì˜ í¬ê¸°ê°€ ë³´ì¡´ Residual Connection # íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ ë‘ ê°œì˜ ì„œë¸Œì¸µì„ ê°€ì§„ ì¸ì½”ë”ì— ì¶”ê°€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” Add \u0026amp; Norm ê¸°ë²• ì¤‘ Addì— í•´ë‹¹ ì”ì°¨ ì—°ê²°ì€ ì„œë¸Œì¸µì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ë”í•˜ëŠ” ê²ƒìœ¼ë¡œ, ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ì˜ í•™ìŠµì„ ë•ëŠ” ê¸°ë²• $x+Sublayer(x)$ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìœ¼ë©°, ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì´ë¼ë©´ $H(x)=x+Multi\\text{-}head\\ Attention(x)$ê³¼ ê°™ìŒ Layer Normalization # ì”ì°¨ ì—°ê²°ì˜ ì…ë ¥ì„ $x$, ì”ì°¨ ì—°ê²°ê³¼ ì¸µ ì •ê·œí™” ë‘ ê°€ì§€ ì—°ì‚°ì„ ëª¨ë‘ ìˆ˜í–‰í•œ í›„ì˜ ê²°ê³¼ í–‰ë ¬ì„ $LN$ì´ë¼ í•  ë•Œ,\nì”ì°¨ ì—°ê²° í›„ ì •ê·œí™” ì—°ì‚°ì„ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ $LN=LayerNorm(x+Sublayer(x))$ì™€ ê°™ìŒ ì´ ì •ê·œí™”ëŠ” í…ì„œì˜ ë§ˆì§€ë§‰ ì°¨ì›ì— ëŒ€í•´ì„œ í‰ê· ê³¼ ë¶„ì‚°ì„ êµ¬í•˜ê³ , ì´ë¥¼ ê°€ì§€ê³  ì–´ë–¤ ìˆ˜ì‹ì„ í†µí•´ ê°’ì„ ì •ê·œí™”í•˜ì—¬ í•™ìŠµì„ ë„ì›€ ì´ ì •ê·œí™”ë¥¼ í‰ê· ê³¼ ë¶„ì‚°ì„ í†µí•œ ì •ê·œí™”, ê°ë§ˆì™€ ë² íƒ€ë¥¼ ë„ì…í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜ëˆ„ì—ˆì„ ë•Œ,\nìš°ì„ , í‰ê· ê³¼ ë¶„ì‚°ì„ í†µí•´ ë²¡í„° $x_i$ë¥¼ ì •ê·œí™” $x_i$ëŠ” ë²¡í„°ì¸ ë°˜ë©´, í‰ê·  $\\mu_i\\text{ê³¼ ë¶„ì‚° }\\sigma^2_i$ì€ ìŠ¤ì¹¼ë¼ì´ê¸° ë•Œë¬¸ì—,\në²¡í„° $x_i$ì˜ ê° $k$ì°¨ì›ì˜ ê°’ì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ê·œí™” ($\\epsilon$ì€ ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” ê°’) $$\\hat{x_{i,k}}=\\frac{x_{i,k}-\\mu_i}{\\sqrt{\\sigma^2_i+\\epsilon}}$$\nLook-ahead Mask # ì…ë ¥ ë‹¨ì–´ë¥¼ ë§¤ ì‹œì ë§ˆë‹¤ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ë°›ëŠ” RNN ê³„ì—´ì˜ ì‹ ê²½ë§ì— ë°˜í•´,\níŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ë¬¸ì¥ í–‰ë ¬ì„ í•œ ë²ˆì— ë°›ê¸° ë•Œë¬¸ì— ë¯¸ë˜ ì‹œì ì˜ ë‹¨ì–´ê¹Œì§€ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” í˜„ìƒ ë°œìƒ ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í¬ëŠ” ë””ì½”ë”ì˜ ì²«ë²ˆì§¸ ì„œë¸Œì¸µì—ì„œ ì´ë£¨ì–´ì§€ë©°,\nìê¸° ìì‹ ë³´ë‹¤ ë¯¸ë˜ì— ìˆëŠ” ë‹¨ì–´ë“¤ì€ ì°¸ê³ í•˜ì§€ ëª»í•˜ë„ë¡ ë§ˆìŠ¤í‚¹í•¨ ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í¬ë¥¼ í•œë‹¤ê³ í•´ì„œ íŒ¨ë”© ë§ˆìŠ¤í¬ê°€ ë¶ˆí•„ìš”í•œ ê²ƒì´ ì•„ë‹ˆë¯€ë¡œ íŒ¨ë”© ë§ˆìŠ¤í¬ë¥¼ í¬í•¨í•˜ë„ë¡ êµ¬í˜„ Endocer-Decoder Attention # ë””ì½”ë”ì˜ ë‘ë²ˆì§¸ ì„œë¸Œì¸µì€ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•œë‹¤ëŠ” ì ì—ì„œ ì´ì „ì˜ ì–´í…ì…˜ë“¤ê³¼ ê³µí†µì ì´ ìˆì§€ë§Œ,\nQueryì™€ Key, Valueê°€ ë‹¬ë¼ ì…€í”„ ì–´í…ì…˜ì´ ì•„ë‹˜ ì¸ì½”ë”ì˜ ì²«ë²ˆì§¸ ì„œë¸Œì¸µ Query = Key = Value\në””ì½”ë”ì˜ ì²«ë²ˆì§¸ ì„œë¸Œì¸µ Query = Key = Value\në””ì½”ë”ì˜ ë‘ë²ˆì§¸ ì„œë¸Œì¸µ Query: ë””ì½”ë” í–‰ë ¬ / Key = Value: ì¸ì½”ë” í–‰ë ¬\n16-02. Transformer Chatbot # íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì´ìš©í•œ í•œêµ­ì–´ ì±—ë´‡ ì°¸ê³  ì±—ë³¸ ë°ì´í„° ì‚¬ìš© 17-01. Pre-training # ì‚¬ì „ í›ˆë ¨ëœ ì›Œë“œ ì„ë² ë”© # Word2Vecë‚˜ GloVe ë“±ì˜ ì›Œë“œ ì„ë² ë”©ì€ í•˜ë‚˜ì˜ ë‹¨ì–´ê°€ í•˜ë‚˜ì˜ ë²¡í„°ê°’ìœ¼ë¡œ ë§µí•‘ë˜ë¯€ë¡œ,\në¬¸ë§¥ì„ ê³ ë ¤í•˜ì§€ ëª»í•˜ì—¬ ë‹¤ì˜ì–´ë‚˜ ë™ìŒì´ì˜ì–´ë¥¼ êµ¬ë¶„í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œ ì‚¬ì „ í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸ # ì–¸ì–´ ëª¨ë¸ì€ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¡œë¶€í„° ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí•˜ì—¬ ë³„ë„ì˜ ë¼ë²¨ ì—†ì´ í•™ìŠµ ê°€ëŠ¥ ë‹¤ì˜ì–´ë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ì—ˆë˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê³ , RNN ê³„ì—´ì˜ ì‹ ê²½ë§ì—ì„œ íƒˆí”¼í•˜ê¸° ìœ„í•´ íŠ¸ëœìŠ¤í¬ë¨¸ë¡œ í•™ìŠµ ì‹œë„ íŠ¸ëœìŠ¤í¬ë¨¸ë¡œ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¨ ì–¸ì–´ ëª¨ë¸ GPT-1 ë“±ì€ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ì–»ìŒ ì´ì „ ë‹¨ì–´ë“¤ë¡œë¶€í„° ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ì˜ íŠ¹ì„±ìœ¼ë¡œëŠ” ì–‘ë°©í–¥ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,\nELMoì—ì„œëŠ” ë‘ ê°œì˜ ë‹¨ë°©í–¥ ì–¸ì–´ ëª¨ë¸ì„ ë”°ë¡œ ì¤€ë¹„í•´ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í–ˆëŠ”ë° ì—¬ê¸°ì„œ ë°œì „ëœ ë§ˆìŠ¤í¬ë“œ ì–¸ì–´ ëª¨ë¸ì´ ë“±ì¥ Masked Language Model # ë§ˆìŠ¤í¬ë“œ ì–¸ì–´ ëª¨ë¸ì€ ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ë‹¨ì–´ ì§‘í•©ì˜ 15%ì˜ ë‹¨ì–´ë¥¼ ëœë¤ìœ¼ë¡œ Masking ë¹ˆì¹¸ ì±„ìš°ê¸° í˜•ì‹ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœ ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡í•˜ê²Œ í•¨ 17-02. BERT # êµ¬ê¸€ì´ ê³µê°œí•œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ë¡œ ìˆ˜ë§ì€ NLP íƒœìŠ¤í¬ì—ì„œ ìµœê³  ì„±ëŠ¥ì„ ë³´ì„ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì´ìš©í•˜ì—¬ êµ¬í˜„ë˜ì—ˆìœ¼ë©°, ìœ„í‚¤í”¼ë””ì•„ì™€ BooksCorpus ê°™ì´ ë¼ë²¨ì´ ì—†ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „ í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¼ë²¨ì´ ìˆëŠ” ë‹¤ë¥¸ ì‘ì—…ì—ì„œ ì¶”ê°€ í›ˆë ¨ê³¼ í•¨ê»˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¬ì¡°ì •,\në‹¤ë¥¸ ì‘ì—…ì— ëŒ€í•´ì„œ íŒŒë¼ë¯¸í„° ì¬ì¡°ì •ì„ ìœ„í•œ ì¶”ê°€ í›ˆë ¨ ê³¼ì •ì„ Fine-tuningì´ë¼ê³  í•¨ BERT-Base: L=12, D=768, A=12: 110Mê°œì˜ íŒŒë¼ë¯¸í„° BERT-Large: L=24, D=1024, A=16: 340Mê°œì˜ íŒŒë¼ë¯¸í„° Contextual Embedding # BERTì˜ ì…ë ¥ì€ ê¸°ì¡´ ëª¨ë¸ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì„ë² ë”© ì¸µì„ ì§€ë‚œ ì„ë² ë”© ë²¡í„° BERTì˜ ì—°ì‚°ì„ ê±°ì¹œ í›„ì˜ ì¶œë ¥ ì„ë² ë”©ì€ ë¬¸ì¥ì˜ ë¬¸ë§¥ì„ ëª¨ë‘ ì°¸ê³ í•œ ë¬¸ë§¥ì„ ë°˜ì˜í•œ ì„ë² ë”©ì´ ë¨ BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ë¥¼ 12ë²ˆ ìŒ“ì€ êµ¬ì¡°ë¡œ, ì…€í”„ ì–´í…ì…˜ì„ í†µí•´ ë¬¸ë§¥ì„ ë°˜ì˜ Subword Tokenizer # BERTëŠ” ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì €ë¡œ WordPiece í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš© ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ëŠ” ê·¸ëŒ€ë¡œ ë‹¨ì–´ ì§‘í•©ì— ì¶”ê°€í•˜ì§€ë§Œ, ìì£¼ ë“±ì¥í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´ëŠ” ì„œë¸Œì›Œë“œë¡œ ë¶„ë¦¬í•´ ì§‘í•©ì— ì¶”ê°€í•˜ë©°,\nì§‘í•©ì´ ë§Œë“¤ì–´ì§€ê³  ë‚˜ë©´ ë‹¨ì–´ ì§‘í•©ì„ ê¸°ë°˜ìœ¼ë¡œ í† í°í™” ìˆ˜í–‰ BERTì—ì„œ í† í°ì´ ë‹¨ì–´ ì§‘í•©ì— ì¡´ì¬í•  ê²½ìš° í•´ë‹¹ í† í°ì„ ë¶„ë¦¬í•˜ì§€ ì•Šì§€ë§Œ,\nì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ í† í°ì„ ì„œë¸Œì›Œë“œë¡œ ë¶„ë¦¬í•˜ê³ , ì²«ë²ˆì§¸ ì„œë¸Œì›Œë“œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì„œë¸Œì›Œë“œë“¤ì€ ì•ì— #ë¥¼ ë¶™ì¸ ê²ƒì„ í† í°ìœ¼ë¡œ í•¨ #ì€ ì„œë¸Œì›Œë“œë“¤ì´ ë‹¨ì–´ì˜ ì¤‘ê°„ë¶€í„° ë“±ì¥í•˜ëŠ” ê²ƒì„ ì•Œë ¤ì£¼ê¸° ìœ„í•´ í‘œì‹œí•´ë‘” ê¸°í˜¸ Copy python from transformers import BertTokenizer tokenizer = BertTokenizer.from_pretrained(\u0026#34;bert-base-uncased\u0026#34;) # BERT-Baseì˜ í† í¬ë‚˜ì´ì € Position Embedding # í¬ì§€ì…”ë„ ì¸ì½”ë”©ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, ìœ„ì¹˜ ì •ë³´ë¥¼ ì‚¬ì¸ í•¨ìˆ˜ì™€ ì½”ì‚¬ì¸ í•¨ìˆ˜ê°€ ì•„ë‹Œ í•™ìŠµì„ í†µí•´ì„œ ì–»ëŠ” ë°©ë²• ìœ„ì¹˜ ì •ë³´ë¥¼ ìœ„í•œ ì„ë² ë”© ì¸µì„ í•˜ë‚˜ ë” ì‚¬ìš©í•˜ê³ , ì…ë ¥ë§ˆë‹¤ í¬ì§€ì…˜ ì„ë² ë”© ë²¡í„°ë¥¼ ë”í•´ì¤Œ MLM (Pre-training) # BERTëŠ” ì‚¬ì „ í›ˆë ¨ì„ ìœ„í•´ì„œ ì…ë ¥ í…ìŠ¤íŠ¸ì˜ 15%ì˜ ë‹¨ì–´ë¥¼ ëœë¤ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ [MASK] í† í°ì´ íŒŒì¸ íŠœë‹ ë‹¨ê³„ì—ì„œ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•„ ì‚¬ì „ í•™ìŠµ ë‹¨ê³„ì™€ íŒŒì¸ íŠœë‹ ë‹¨ê³„ì—ì„œì˜ ë¶ˆì¼ì¹˜ ë¬¸ì œê°€ ìƒê¸°ëŠ”ë°,\nì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ë§ˆìŠ¤í‚¹ ë‹¨ì–´ ì¤‘ 80%ëŠ” [MASK]ë¡œ ë³€ê²½, 10%ëŠ” ëœë¤ìœ¼ë¡œ ë‹¨ì–´ê°€ ë³€ê²½, 10%ëŠ” ë™ì¼í•˜ê²Œ ë‘  NSP (Pre-training) # BERTëŠ” ë‘ ê°œì˜ ë¬¸ì¥ì„ ì¤€ í›„ì— ì´ì–´ì§€ëŠ” ë¬¸ì¥ì¸ì§€ ì•„ë‹Œì§€ë¥¼ ë§ì¶”ëŠ” ë°©ì‹ìœ¼ë¡œ í›ˆë ¨ BERTì˜ ì…ë ¥ì—ì„œ [SEP]ë¼ëŠ” íŠ¹ë³„ í† í°ì„ ì‚¬ìš©í•´ì„œ ë¬¸ì¥ì„ êµ¬ë¶„ ë‘ ë¬¸ì¥ì´ ì‹¤ì œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì¸ì§€ ì•„ë‹Œì§€ì— ëŒ€í•œ ì´ì§„ ë¶„ë¥˜ ë¬¸ì œë¥¼ [CLS] í† í°ì˜ ìœ„ì¹˜ë¡œ ê²°ì • Segment Embedding # WordPiece Embedding, Position Embeddingê³¼ í•¨ê»˜ ë‘ ê°œì˜ ë¬¸ì¥ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© ì¸µ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©ìœ¼ë¡œ êµ¬ë¶„ë˜ëŠ” BERTì˜ ì…ë ¥ì—ì„œ ë‘ ê°œì˜ ë¬¸ì¥ì€ ë‘ ì¢…ë¥˜ì˜ í…ìŠ¤íŠ¸, ë‘ ê°œì˜ ë¬¸ì„œì¼ ìˆ˜ ìˆìŒ Find-tuning # ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ë¥˜, ë¡œì´í„° ë‰´ìŠ¤ ë¶„ë¥˜ ë“± Single Text Classificationì„ ìœ„í•´,\në¬¸ì„œì˜ ì‹œì‘ì— [CLS] í† í°ì„ ì…ë ¥í•´ ë¶„ë¥˜ì— ëŒ€í•´ ì˜ˆì¸¡ íƒœê¹… ì‘ì—…ì„ ìœ„í•´ ê° í† í°ì˜ ìœ„ì¹˜ì— ë°€ì§‘ì¸µì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ì— ëŒ€í•´ ì˜ˆì¸¡ ìì—°ì–´ ì¶”ë¡  ë“±ì˜ Text Pair Classificationì„ ìœ„í•´,\ní…ìŠ¤íŠ¸ ì‚¬ì´ì— [SEP] í† í°ì„ ì§‘ì–´ë„£ê³  ë‘ ì¢…ë¥˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©ì„ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ êµ¬ë¶„ QA(Question Answering)ë¥¼ í’€ê¸° ìœ„í•´ ì§ˆë¬¸ê³¼ ë³¸ë¬¸ì´ë¼ëŠ” ë‘ ê°œì˜ í…ìŠ¤íŠ¸ì˜ ìŒì„ ì…ë ¥ (SQuAD v1.1) Attention Mask # BERTê°€ ì–´í…ì…˜ ì—°ì‚°ì„ í•  ë•Œ, ë¶ˆí•„ìš”í•˜ê²Œ íŒ¨ë”© í† í°ì— ëŒ€í•´ì„œ ì–´í…ì…˜ì„ í•˜ì§€ ì•Šë„ë¡ ì‹¤ì œ ë‹¨ì–´ì™€ íŒ¨ë”© í† í°ì„ êµ¬ë¶„í•˜ëŠ” ì…ë ¥ ìˆ«ì 1ì€ ì‹¤ì œ ë‹¨ì–´ë¡œ ë§ˆìŠ¤í‚¹ì„ í•˜ì§€ ì•Šê³ , ìˆ«ì 0ì€ íŒ¨ë”© í† í°ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ì„ í•¨ 17-03. Pre-training ì‹¤ìŠµ # êµ¬ê¸€ BERTì˜ ë§ˆìŠ¤í¬ë“œ ì–¸ì–´ ëª¨ë¸ ì‹¤ìŠµ ì°¸ê³  í•œêµ­ì–´ BERTì˜ ë§ˆìŠ¤í¬ë“œ ì–¸ì–´ ëª¨ë¸ ì‹¤ìŠµ ì°¸ê³  êµ¬ê¸€ BERTì˜ ë‹¤ìŒ ë¬¸ì¥ ì˜ˆì¸¡ ì°¸ê³  í•œêµ­ì–´ BERTì˜ ë‹¤ìŒ ë¬¸ì¥ ì˜ˆì¸¡ ì°¸ê³  17-07. Sentence BERT(SBERT) # BERTì˜ ë¬¸ì¥ ì„ë² ë”©ì˜ ì„±ëŠ¥ì„ ìš°ìˆ˜í•˜ê²Œ ê°œì„ ì‹œí‚¨ ëª¨ë¸ ë¬¸ì¥ ìŒ ë¶„ë¥˜ íƒœìŠ¤í¬ ë˜ëŠ” ë¬¸ì¥ ìŒ íšŒê·€ íƒœìŠ¤í¬ë¡œ íŒŒì¸ íŠœë‹ Sentence Embedding # [CLS] í† í°ì€ ì…ë ¥ëœ ë¬¸ì¥ì— ëŒ€í•œ ì´ì²´ì  í‘œí˜„ìœ¼ë¡œ, [CLS] í† í° ìì²´ë¥¼ ì…ë ¥ ë¬¸ì¥ì˜ ë²¡í„°ë¡œ ê°„ì£¼ ë¬¸ì¥ ë²¡í„°ë¥¼ ì–»ê¸° ìœ„í•´ [CLS] í† í°ë¿ ì•„ë‹ˆë¼, BERTì˜ ëª¨ë“  ì¶œë ¥ ë²¡í„°ë“¤ì„ í‰ê· ëƒ„ ì¶œë ¥ ë²¡í„°ë“¤ì˜ í‰ê· ì„ poolingì´ë¼ í•˜ë©°, mean pooling, max pooling ë“±ì´ ìˆìŒ 18. BERT ì‹¤ìŠµ # Colabì—ì„œ TPU ì‚¬ìš©í•˜ê¸° Transformersì˜ ëª¨ë¸ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° KoBERTë¥¼ ì´ìš©í•œ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë¶„ë¥˜í•˜ê¸° TFBertForSequenceClassification KoBERTë¥¼ ì´ìš©í•œ KorNLI í’€ì–´ë³´ê¸° (ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜) KoBERTë¥¼ ì´ìš©í•œ ê°œì²´ëª… ì¸ì‹ KoBERTë¥¼ ì´ìš©í•œ ê¸°ê³„ ë…í•´ BERTì˜ ë¬¸ì¥ ì„ë² ë”©(SBERT)ì„ ì´ìš©í•œ í•œêµ­ì–´ ì±—ë´‡ Faissì™€ SBERTë¥¼ ì´ìš©í•œ ì‹œë§¨í‹± ê²€ìƒ‰ê¸° 19. Topic Modelling # í† í”½ì´ë¼ëŠ” ë¬¸ì„œ ì§‘í•©ì˜ ì¶”ìƒì ì¸ ì£¼ì œë¥¼ ë°œê²¬í•˜ê¸° ìœ„í•œ í†µê³„ì  ëª¨ë¸ ì¤‘ í•˜ë‚˜ í…ìŠ¤íŠ¸ ë³¸ë¬¸ì˜ ìˆ¨ê²¨ì§„ ì˜ë¯¸ êµ¬ì¡°ë¥¼ ë°œê²¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” í…ìŠ¤íŠ¸ ë§ˆì´ë‹ ê¸°ë²• 19-01. LSA # SVD # íŠ¹ì´ê°’ ë¶„í•´(Singular Value Decomposition)ëŠ” $A$ê°€ ${m}\\times{m}$ í–‰ë ¬ì¼ ë•Œ,\në‹¤ìŒê³¼ ê°™ì´ 3ê°œì˜ í–‰ë ¬ì˜ ê³±ìœ¼ë¡œ ë¶„í•´(decomposition)í•˜ëŠ” ê²ƒ $$A={U}\\Sigma{V^T}$$\nê° 3ê°œ í–‰ë ¬ì€ ë‹¤ìŒê³¼ ê°™ì€ ì¡°ê±´ì„ ë§Œì¡±\n${U}\\text{: }{m}\\times{m}\\text{ ì§êµí–‰ë ¬ }(AA^T=U(\\Sigma\\Sigma^T)U^T)$\n$V\\text{: }{n}\\times{n}\\text{ ì§êµí–‰ë ¬ }(A^TA=U(\\Sigma^T\\Sigma)V^T)$\n$\\Sigma\\text{: }{m}\\times{n}\\text{ ì§ì‚¬ê° ëŒ€ê°í–‰ë ¬}$ Truncated SVD # Full SVDì—ì„œ ë‚˜ì˜¨ 3ê°œì˜ í–‰ë ¬ì—ì„œ ì¼ë¶€ ë²¡í„°ë“¤ì„ ì‚­ì œì‹œí‚¨ ì ˆë‹¨ëœ SVD ëŒ€ê° í–‰ë ¬ $\\Sigma$ì˜ ëŒ€ê° ì›ì†Œì˜ ê°’ ì¤‘ì—ì„œ ìƒìœ„ê°’ tê°œë§Œ ë‚¨ê¸°ê³ ,\nUí–‰ë ¬ê³¼ Ví–‰ë ¬ì˜ tì—´ê¹Œì§€ë§Œ ë‚¨ê¹€ ì¼ë¶€ ë²¡í„°ë“¤ì„ ì‚­ì œí•´ ë°ì´í„°ì˜ ì°¨ì›ì„ ì¤„ì´ëŠ” ê²ƒìœ¼ë¡œ ê³„ì‚° ë¹„ìš©ì´ ë‚®ì•„ì§€ëŠ” íš¨ê³¼ë¥¼ ì–»ìŒ ë˜í•œ ìƒëŒ€ì ìœ¼ë¡œ ì¤‘ìš”í•˜ì§€ ì•Šì€ ì •ë³´(ë…¸ì´ì¦ˆ)ë¥¼ ì‚­ì œí•´ ê¸°ì¡´ì˜ í–‰ë ¬ì—ì„œ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ë˜ ì‹¬ì¸µì ì¸ ì˜ë¯¸ í™•ì¸ Latent Semantic Analysis(LSA) # BoWì— ê¸°ë°˜í•œ DTMì´ë‚˜ TF-IDFëŠ” ë‹¨ì–´ì˜ ë¹ˆë„ ìˆ˜ë¥¼ ì´ìš©í•œ ìˆ˜ì¹˜í™” ë°©ë²•ìœ¼ë¡œ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ê³ ë ¤í•˜ì§€ ëª»í•¨ LSAëŠ” DTMì´ë‚˜ TF-IDF í–‰ë ¬ì— ì ˆë‹¨ëœ SVDë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¨ì›ì„ ì¶•ì†Œì‹œí‚¤ê³ , ë‹¨ì–´ë“¤ì˜ ì ì¬ì ì¸ ì˜ë¯¸ë¥¼ ëŒì–´ëƒ„ ë¬¸ì„œì˜ ìœ ì‚¬ë„ ê³„ì‚° ë“±ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œ SVDì˜ íŠ¹ì„±ìƒ ì´ë¯¸ ê³„ì‚°ëœ LSAì— ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ë ¤ë©´ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ê³„ì‚°í•´ì•¼í•´ ì—…ë°ì´íŠ¸ê°€ ì–´ë ¤ì›€ 19-02. LDA # Latent Dirichlet Allocation(LDA) # ë¬¸ì„œì˜ ì§‘í•©ìœ¼ë¡œë¶€í„° ì–´ë–¤ í† í”½ì´ ì¡´ì¬í•˜ëŠ”ì§€ë¥¼ ì•Œì•„ë‚´ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ ë¬¸ì„œë“¤ì€ í† í”½ë“¤ì˜ í˜¼í•©ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì ¸ ìˆìœ¼ë©°, í† í”½ë“¤ì€ í™•ë¥  ë¶„í¬ì— ê¸°ë°˜í•˜ì—¬ ë‹¨ì–´ë“¤ì„ ìƒì„±í•œë‹¤ ê°€ì • ë¬¸ì„œê°€ ì‘ì„±ë˜ì—ˆë‹¤ëŠ” ê°€ì • í•˜ì— í† í”½ì„ ë½‘ì•„ë‚´ê¸° ìœ„í•´ ì•„ë˜ ê³¼ì •ì„ ì—­ìœ¼ë¡œ ì¶”ì í•˜ëŠ” ì—­ê³µí•™ì„ ìˆ˜í–‰ LDAì˜ ê°€ì • # ë¬¸ì„œì— ì‚¬ìš©í•  ë‹¨ì–´ì˜ ê°œìˆ˜ Nì„ ì •í•© ë¬¸ì„œì— ì‚¬ìš©í•  í† í”½ì˜ í˜¼í•©ì„ í™•ë¥  ë¶„í¬ì— ê¸°ë°˜í•˜ì—¬ ê²°ì • ë¬¸ì„œì— ì‚¬ìš©í•  ê° ë‹¨ì–´ë¥¼ (ì•„ë˜ì™€ ê°™ì´) ì •í•¨\n3-1. í† í”½ ë¶„í¬ì—ì„œ í† í”½ Të¥¼ í™•ë¥ ì ìœ¼ë¡œ ê³ ë¦„\n3-2. ì„ íƒí•œ í† í”½ Tì—ì„œ ë‹¨ì–´ì˜ ì¶œí˜„ í™•ë¥  ë¶„í¬ì— ê¸°ë°˜í•´ ë¬¸ì„œì— ì‚¬ìš©í•  ë‹¨ì–´ë¥¼ ê³ ë¦„ LDA ìˆ˜í–‰ # ì‚¬ìš©ìëŠ” ì•Œê³ ë¦¬ì¦˜ì—ê²Œ í† í”½ì˜ ê°œìˆ˜ kë¥¼ ì•Œë ¤ì¤Œ ëª¨ë“  ë‹¨ì–´ë¥¼ kê°œ ì¤‘ í•˜ë‚˜ì˜ í† í”½ì— í• ë‹¹ ëª¨ë“  ë¬¸ì„œì˜ ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•´ì„œ ì•„ë˜ì˜ ì‚¬í•­ì„ ë°˜ë³µ ì§„í–‰\n3-1. ì–´ë–¤ ë¬¸ì„œì˜ ë‹¨ì–´ wëŠ” ìì‹ ì˜ ì˜ëª»ëœ í† í”½ì— í• ë‹¹ë˜ì–´ ìˆì§€ë§Œ,\në‹¤ë¥¸ ë‹¨ì–´ë“¤ì€ ì˜¬ë°”ë¥¸ í† í”½ì— í• ë‹¹ë˜ì–´ ìˆë‹¤ëŠ” ê°€ì • í•˜ì— ë‹¨ì–´ wì˜ í† í”½ì„ ì¬í• ë‹¹ LSA DTMì„ ì°¨ì› ì¶•ì†Œí•˜ì—¬ ì¶•ì†Œ ì°¨ì›ì—ì„œ ê·¼ì ‘ ë‹¨ì–´ë“¤ì„ í† í”½ìœ¼ë¡œ ë¬¶ìŒ LDA ë‹¨ì–´ê°€ íŠ¹ì • í† í”½ì— ì¡´ì¬í•  í™•ë¥ ê³¼ ë¬¸ì„œì— íŠ¹ì • í† í”½ì´ ì¡´ì¬í•  í™•ë¥ ì„ ê²°í•©í™•ë¥ ë¡œ ì¶”ì •í•˜ì—¬ í† í”½ ì¶”ì¶œ 19-08. BERTopic # BERT embeddingsê³¼ í´ë˜ìŠ¤ ê¸°ë°˜ TF-IDFë¥¼ í™œìš©í•˜ì—¬\nì£¼ì œ ì„¤ëª…ì—ì„œ ì¤‘ìš”í•œ ë‹¨ì–´ë¥¼ ìœ ì§€í•˜ë©´ì„œë„ ì‰½ê²Œ í•´ì„í•  ìˆ˜ ìˆëŠ” ì¡°ë°€í•œ í´ëŸ¬ìŠ¤í„°ë¥¼ ë§Œë“œëŠ” í† í”½ ëª¨ë¸ë§ ê¸°ìˆ  í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ SBERTë¡œ ì„ë² ë”© ë¬¸ì„œë¥¼ êµ°ì§‘í™” (UMAPì„ ì‚¬ìš©í•´ ì„ë² ë”©ì˜ ì°¨ì›ì„ ì¤„ì´ê³  HDBSCAN ê¸°ìˆ ì„ ì‚¬ìš©í•´ í´ëŸ¬ìŠ¤í„°ë§) í† í”½ í‘œí˜„ì„ ìƒì„± (í´ë˜ìŠ¤ ê¸°ë°˜ TF-IDF í† í”½ ì¶”ì¶œ) 20. Text Summarization # Extractive Summarization # ì›ë¬¸ì—ì„œ ì¤‘ìš”í•œ í•µì‹¬ ë¬¸ì¥ ë˜ëŠ” ë‹¨ì–´êµ¬ ëª‡ ê°œë¥¼ ë½‘ì•„ì„œ ì´ë“¤ë¡œ êµ¬ì„±ëœ ìš”ì•½ë¬¸ì„ ë§Œë“œëŠ” ë°©ë²• ì¶”ì¶œì  ìš”ì•½ì˜ ê²°ê³¼ë¡œ ë‚˜ì˜¨ ìš”ì•½ë¬¸ì˜ ë¬¸ì¥ì´ë‚˜ ë‹¨ì–´êµ¬ë“¤ì€ ì „ë¶€ ì›ë¬¸ì— ìˆëŠ” ë¬¸ì¥ë“¤ ëŒ€í‘œì ì¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¨¸ì‹  ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ TextRankê°€ ìˆìŒ Abstractive Summarization # ì›ë¬¸ì— ì—†ë˜ ë¬¸ì¥ì´ë¼ë„ í•µì‹¬ ë¬¸ë§¥ì„ ë°˜ì˜í•œ ìƒˆë¡œìš´ ë¬¸ì¥ì„ ìƒì„±í•´ì„œ ì›ë¬¸ì„ ìš”ì•½í•˜ëŠ” ë°©ë²• ì£¼ë¡œ seq2seq ê°™ì€ ì¸ê³µ ì‹ ê²½ë§ì„ ì´ìš©í•˜ì§€ë§Œ, ì§€ë„ í•™ìŠµì´ê¸° ë•Œë¬¸ì— ë¼ë²¨ ë°ì´í„°ê°€ ìˆì–´ì•¼í•¨ ì¶”ìƒì  ìš”ì•½ êµ¬í˜„ # ì•„ë§ˆì¡´ ë¦¬ë·° ë°ì´í„° ì‚¬ìš© TextRank # í˜ì´ì§€ë­í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í…ìŠ¤íŠ¸ ìš”ì•½ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ,\ní…ìŠ¤íŠ¸ë­í¬ì—ì„œ ê·¸ë˜í”„ì˜ ë…¸ë“œë“¤ì€ ë¬¸ì¥ë“¤ì´ë©° ê° ê°„ì„ ì˜ ê°€ì¤‘ì¹˜ëŠ” ë¬¸ì¥ë“¤ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì˜ë¯¸ ì‚¬ì „ í›ˆë ¨ëœ GloVe ë° í…Œë‹ˆìŠ¤ ê´€ë ¨ ê¸°ì‚¬ ë°ì´í„° ì‚¬ìš© 21. Question Answering(QA) # Babi ë°ì´í„°ì…‹ # IDëŠ” ê° ë¬¸ì¥ì˜ ë²ˆí˜¸ë¥¼ ì˜ë¯¸, ìŠ¤í† ë¦¬ê°€ ì‹œì‘ë  ë•ŒëŠ” 1ë²ˆìœ¼ë¡œ ì‹œì‘ ë¼ë²¨ì˜ supporting factëŠ” ì‹¤ì œ ì •ë‹µì´ ì£¼ì–´ì§„ ìŠ¤í† ë¦¬ì—ì„œ ëª‡ ë²ˆ ID ë¬¸ì¥ì— ìˆì—ˆëŠ”ì§€ë¥¼ ì•Œë ¤ì¤Œ ë©”ëª¨ë¦¬ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° # ë‘ ê°œì˜ ë¬¸ì¥, ìŠ¤í† ë¦¬ ë¬¸ì¥ê³¼ ì§ˆë¬¸ ë¬¸ì¥ì´ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¤ë©°, ë‘ ë¬¸ì¥ì€ ê°ê° ì„ë² ë”© ê³¼ì •ì„ ê±°ì¹¨ Embedding Cë¥¼ í†µí•´ì„œ ì„ë² ë”© ëœ ìŠ¤í† ë¦¬ ë¬¸ì¥ê³¼ Embedding Bë¥¼ í†µí•´ì„œ ì„ë² ë”© ëœ ì§ˆë¬¸ ë¬¸ì¥ì€\në‚´ì ì„ í†µí•´ ê° ë‹¨ì–´ ê°„ ìœ ì‚¬ë„ë¥¼ êµ¬í•˜ê³ , ê·¸ ê²°ê³¼ê°€ softmax í•¨ìˆ˜ë¥¼ ì§€ë‚˜ì„œ\nEmbedding Aë¡œ ì„ë² ë”©ì´ ëœ ìŠ¤í† ë¦¬ ë¬¸ì¥ì— ë”í•´ì§\n(Embedding A, B, CëŠ” ê°ê° ë³„ê°œì˜ ì„ë² ë”© ì¸µ) Query(ì§ˆë¬¸ ë¬¸ì¥)ì™€ Key(ìŠ¤í† ë¦¬ ë¬¸ì¥)ì˜ ìœ ì‚¬ë„ë¥¼ êµ¬í•˜ê³  softmax í•¨ìˆ˜ë¥¼ í†µí•´ ì •ê·œí™”í•´\nValue(ìŠ¤í† ë¦¬ ë¬¸ì¥)ì— ë”í•˜ëŠ” ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ê³¼ ìœ ì‚¬ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ì„œ ì§ˆë¬¸ ë¬¸ì¥ê³¼ì˜ ìœ ì‚¬ë„ë¥¼ ë°˜ì˜í•œ ìŠ¤í† ë¦¬ ë¬¸ì¥ í‘œí˜„ì„ ì–»ê³ ,\nì´ë¥¼ ì§ˆë¬¸ í‘œí˜„ê³¼ ì—°ê²°(concatenate)í•˜ì—¬ LSTMê³¼ ë°€ì§‘ì¸µì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš© QA íƒœìŠ¤í¬ í’€ê¸° # Babi ë°ì´í„°ì…‹ ì‚¬ìš© MeaNìœ¼ë¡œ í•œêµ­ì–´ QA # í•œêµ­ì–´ Babi ë°ì´í„°ì…‹ ì‚¬ìš© (í›ˆë ¨ ë°ì´í„°, í…ŒìŠ¤íŠ¸ ë°ì´í„°) 22. GPT # Generative Pre-trained Transformer(GPT) # GPT ì„¤ëª… ì°¸ê³  GPT ì‹¤ìŠµ # KoGPT-2ë¥¼ ì´ìš©í•œ ë¬¸ì¥ ìƒì„± KoGPT-2 í…ìŠ¤íŠ¸ ìƒì„±ì„ ì´ìš©í•œ í•œêµ­ì–´ ì±—ë´‡ KoGPT-2ë¥¼ ì´ìš©í•œ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë¶„ë¥˜ KoGPT-2ë¥¼ ì´ìš©í•œ KorNLI ë¶„ë¥˜ "},{"id":72,"href":"/blog/2022-06-29/","title":"2022-06-29 Log","section":"Posts","content":"09-01. Word Embedding # Sparse Representation # ë²¡í„° ë˜ëŠ” í–‰ë ¬ì˜ ê°’ì´ ëŒ€ë¶€ë¶„ 0ìœ¼ë¡œ í‘œí˜„ë˜ëŠ” ë°©ë²•, one-hot vector ë“± ë‹¨ì–´ì˜ ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë©´ ë²¡í„°ì˜ ì°¨ì›ì´ í•œì—†ì´ ì»¤ì§€ëŠ” ë¬¸ì œ, ê³µê°„ì  ë‚­ë¹„ ë°œìƒ Dense Representation # ì‚¬ìš©ìê°€ ì„¤ì •í•œ ê°’ìœ¼ë¡œ ëª¨ë“  ë‹¨ì–´ì˜ ë²¡í„° í‘œí˜„ì˜ ì°¨ì›ì„ ë§ì¶¤ (0ê³¼ 1ë¿ ì•„ë‹ˆë¼ ì‹¤ìˆ˜ í¬í•¨) Word Embedding # ë‹¨ì–´ë¥¼ ë°€ì§‘ ë²¡í„°ì˜ í˜•íƒœë¡œ í‘œí˜„í•˜ëŠ” ë°©ë²• Embedding Vector: ì›Œë“œ ì„ë² ë”© ê³¼ì •ì„ í†µí•´ ë‚˜ì˜¨ ê²°ê³¼ LSA, Word2Vec, FastText, Glove ë“± 09-02. Word2Vec # Distributed Representation # í¬ì†Œ í‘œí˜„ì„ ë‹¤ì°¨ì› ê³µê°„ì— ë²¡í„°í™”í•˜ëŠ” ë°©ë²• ë¶„ì‚° í‘œí˜„ ë°©ë²•ì€ ë¶„í¬ ê°€ì„¤ì´ë¼ëŠ” ê°€ì • í•˜ì— ë§Œë“¤ì–´ì§„ í‘œí˜„ ë°©ë²• ë¶„í¬ ê°€ì„¤: ë¹„ìŠ·í•œ ë¬¸ë§¥ì—ì„œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë“¤ì€ ë¹„ìŠ·í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ë‹¤ (ê·€ì—½ë‹¤, ì˜ˆì˜ë‹¤, ì• êµ ë“±ì˜ ë‹¨ì–´ê°€ ì£¼ë¡œ í•¨ê»˜ ë“±ì¥í•  ê²½ìš° ë²¡í„°í™” ì‹œ ìœ ì‚¬í•œ ë²¡í„°ê°’ì„ ê°€ì§) ì €ì°¨ì›ì— ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì—¬ëŸ¬ ì°¨ì›ì—ë‹¤ê°€ ë¶„ì‚°í•˜ì—¬ í‘œí˜„í•˜ê¸° ëŒ€ë¬¸ì— ë‹¨ì–´ ë²¡í„° ê°„ ìœ ì˜ë¯¸í•œ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥ Word2Vecì˜ í•™ìŠµ ë°©ì‹ìœ¼ë¡œ CBOW(Continuous Bag of Words)ì™€ Skip-Gramì´ ì¡´ì¬ CBOW # ì£¼ë³€ì— ìˆëŠ” ë‹¨ì–´ë“¤ì„ ì…ë ¥ìœ¼ë¡œ ì¤‘ê°„ì— ìˆëŠ” ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²• ì¤‘ì‹¬ ë‹¨ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ window sizeë§Œí¼ ì•ë’¤ë¡œ ë‹¨ì–´ë¥¼ í™•ì¸ (2nê°œì˜ ë‹¨ì–´ í™•ì¸) Sliding Window: windowë¥¼ ì˜†ìœ¼ë¡œ ì›€ì§ì—¬ì„œ ì£¼ë³€ ë‹¨ì–´ì™€ ì¤‘ì‹¬ ë‹¨ì–´ì˜ ì„ íƒì„ ë³€ê²½í•´ê°€ë©° í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± CBOWì˜ ì¸ê³µ ì‹ ê²½ë§ì€ ì£¼ë³€ ë‹¨ì–´ë“¤ì˜ one-hot vectorë¥¼ ì…ë ¥ìœ¼ë¡œ ì¤‘ê°„ ë‹¨ì–´ì˜ one-hot vectorë¥¼ ì˜ˆì¸¡ Word2Vecì€ ì€ë‹‰ì¸µì´ 1ê°œì´ë©°, í™œì„±í™” í•¨ìˆ˜ ì—†ì´ ë£©ì—… í…Œì´ë¸”ì´ë¼ëŠ” ì—°ì‚°ì„ ë‹´ë‹¹í•˜ëŠ” projection layerë¡œ ë¶ˆë¦¼ ì…ë ¥ì¸µê³¼ íˆ¬ì‚¬ì¸µ ì‚¬ì´ì˜ ê°€ì¤‘ì¹˜ WëŠ” ${V}\\times{M}$ í–‰ë ¬, íˆ¬ì‚¬ì¸µì—ì„œ ì¶œë ¥ì¸µ ì‚¬ì´ì˜ ê°€ì¤‘ì¹˜ W\u0026rsquo;ëŠ” ${M}\\times{V}$ í–‰ë ¬ Wì™€ W\u0026rsquo;ëŠ” ë™ì¼í•œ í–‰ë ¬ì˜ ì „ì¹˜ê°€ ì•„ë‹ˆë¼ ì„œë¡œ ë‹¤ë¥¸ í–‰ë ¬ì´ê¸° ëŒ€ë¬¸ì— CBOWëŠ” Wì™€ W\u0026rsquo;ë¥¼ í•™ìŠµí•´ê°€ëŠ” êµ¬ì¡°ë¥¼ ê°€ì§ ì…ë ¥ ë²¡í„°ì™€ ê°€ì¤‘ì¹˜ W í–‰ë ¬ì˜ ê³±ì€ W í–‰ë ¬ì˜ ië²ˆì§¸ í–‰ì„ ê·¸ëŒ€ë¡œ ì½ì–´ì˜¤ëŠ” ê²ƒ(lookup)ê³¼ ë™ì¼ ì£¼ë³€ ë‹¨ì–´ì˜ one-hot vectorì™€ ê°€ì¤‘ì¹˜ Wë¥¼ ê³±í•œ ê²°ê³¼ ë²¡í„°ë“¤ì€ íˆ¬ì‚¬ì¸µì—ì„œ ë§Œë‚˜ í‰ê· ì¸ ë²¡í„°ë¥¼ êµ¬í•¨ í‰ê·  ë²¡í„°ëŠ” ë‘ ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ W\u0026rsquo;ì™€ ê³±í•´ì ¸ì„œ one-hot vectorë“¤ê³¼ ì°¨ì›ì´ Vë¡œ ë™ì¼í•œ ë²¡í„°ê°€ ë‚˜ì˜´ í•´ë‹¹ ë²¡í„°ì— softmax í•¨ìˆ˜ë¥¼ ê±°ì³ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œë¥¼ ìœ„í•œ score vectorë¥¼ ìƒì„± score vectorì˜ jë²ˆì§¸ ì¸ë±ìŠ¤ê°€ ê°€ì§„ ê°’ì€ jë²ˆì§¸ ë‹¨ì–´ê°€ ì¤‘ì‹¬ ë‹¨ì–´ì¼ í™•ë¥ ë¡œ,\nscore vector $\\hat{y}$ì™€ ì¤‘ì‹¬ ë‹¨ì–´ì˜ one-hot vector $y$ì˜ ì˜¤ì°¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ cross-entropy í•¨ìˆ˜ ì‚¬ìš© Skip-gram # CBOWì™€ ë°˜ëŒ€ë¡œ ì¤‘ì‹¬ ë‹¨ì–´ì—ì„œ ì£¼ë³€ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ ì¤‘ì‹¬ ë‹¨ì–´ë§Œì„ ì…ë ¥ìœ¼ë¡œ ë°›ê¸° ë•Œë¬¸ì— íˆ¬ì‚¬ì¸µì—ì„œ ë²¡í„°ë“¤ì˜ í‰ê· ì„ êµ¬í•˜ëŠ” ê³¼ì •ì€ ì—†ìŒ ì „ë°˜ì ìœ¼ë¡œ Skip-gramì´ CBOWë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ë‹¤ê³  ì•Œë ¤ì§ NNLM vs Word2Vec # NNLMì€ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª©ì ì´ì§€ë§Œ, Word2Vec(CBOW)ì€ ì¤‘ì‹¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª©ì , ë•Œë¬¸ì— NNLMì´ ì´ì „ ë‹¨ì–´ë“¤ë§Œ ì°¸ê³ í•œë‹¤ë©´, Word2Vecì€ ì˜ˆì¸¡ ë‹¨ì–´ì˜ ì „í›„ ë‹¨ì–´ë“¤ì„ ëª¨ë‘ ì°¸ê³  Word2Vecì€ NNLMì— ì¡´ì¬í•˜ë˜ í™œì„±í™” í•¨ìˆ˜ê°€ ìˆëŠ” ì€ë‹‰ì¸µì„ ì œê±°í•˜ì—¬ í•™ìŠµ ì†ë„ì—ì„œ ê°•ì ì„ ê°€ì§ 09-03. Word2Vec ì‹¤ìŠµ # ìœ„í‚¤í”¼ë””ì•„ ì‹¤ìŠµ Copy python from gensim.models import Word2Vec from gensim.models import KeyedVectors model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0) size: ì›Œë“œ ë²¡í„°ì˜ íŠ¹ì§• ê°’, ì„ë² ë”©ëœ ë²¡í„°ì˜ ì°¨ì› window: context window size min_count: ë‹¨ì–´ ìµœì†Œ ë¹ˆë„ ìˆ˜ ì œí•œ (ë¹ˆë„ê°€ ì ì€ ë‹¨ì–´ë“¤ì€ ë¬´ì‹œ) workers: í•™ìŠµì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ìˆ˜ sg: 0ì€ CBOW, 1ì€ Skip-gram Copy python # ì…ë ¥í•œ ë‹¨ì–´ì— ëŒ€í•´ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ì„ ì¶œë ¥ model_result = model.wv.most_similar(\u0026#34;man\u0026#34;) print(model_result) [(\u0026#39;woman\u0026#39;, 0.842622697353363), (\u0026#39;guy\u0026#39;, 0.8178728818893433), (\u0026#39;boy\u0026#39;, 0.7774451375007629), (\u0026#39;lady\u0026#39;, 0.7767927646636963), (\u0026#39;girl\u0026#39;, 0.7583760023117065), (\u0026#39;gentleman\u0026#39;, 0.7437191009521484), (\u0026#39;soldier\u0026#39;, 0.7413754463195801), (\u0026#39;poet\u0026#39;, 0.7060446739196777), (\u0026#39;kid\u0026#39;, 0.6925194263458252), (\u0026#39;friend\u0026#39;, 0.6572611331939697)] Copy python model.wv.save_word2vec_format(\u0026#39;eng_w2v\u0026#39;) # ëª¨ë¸ ì €ì¥ loaded_model = KeyedVectors.load_word2vec_format(\u0026#34;eng_w2v\u0026#34;) # ëª¨ë¸ ë¡œë“œ Copy python # ì‚¬ì „ í›ˆë ¨ëœ Word2Vec ì„ë² ë”© urllib.request.urlretrieve(\u0026#34;https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\u0026#34;, filename=\u0026#34;GoogleNews-vectors-negative300.bin.gz\u0026#34;) word2vec_model = KeyedVectors.load_word2vec_format(\u0026#39;GoogleNews-vectors-negative300.bin.gz\u0026#39;, binary=True) # shape(3000000, 300) Copy python # ë‘ ë‹¨ì–´ì˜ ìœ ì‚¬ë„ ê³„ì‚° print(word2vec_model.similarity(\u0026#39;this\u0026#39;, \u0026#39;is\u0026#39;)) # 0.407970363878 09-04. Negative Sampling # Word2Vecì´ í•™ìŠµ ê³¼ì •ì—ì„œ ì „ì²´ ë‹¨ì–´ ì§‘í•©ì´ ì•„ë‹ˆë¼ ì¼ë¶€ ë‹¨ì–´ ì§‘í•©ì—ë§Œ ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²• ì¤‘ì‹¬ ë‹¨ì–´ì— ëŒ€í•´ ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì¼ë¶€ ë‹¨ì–´ ì§‘í•©ì— ëŒ€í•´ ê¸ì • ë˜ëŠ” ë¶€ì •ì„ ì˜ˆì¸¡í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ìˆ˜í–‰ ì „ì²´ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ë§Œí¼ ì„ íƒì§€ë¥¼ ë‘ê³  ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œë¥¼ í‘¸ëŠ” Word2Vecë³´ë‹¤ íš¨ìœ¨ì ì¸ ì—°ì‚° SGNS # ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§ì„ ì‚¬ìš©í•˜ëŠ” Skip-gramì€ ì¤‘ì‹¬ ë‹¨ì–´ì™€ ì£¼ë³€ ë‹¨ì–´ê°€ ëª¨ë‘ ì…ë ¥ì´ ë˜ê³ ,\në‘ ë‹¨ì–´ê°€ ì‹¤ì œë¡œ ìœˆë„ìš° í¬ê°œ ë‚´ì— ì¡´ì¬í•˜ëŠ” ì´ì›ƒ ê´€ê³„ì¸ì§€ í™•ë¥ ì„ ì˜ˆì¸¡ ì¤‘ì‹¬ ë‹¨ì–´ì— ëŒ€í•œ ë¼ë²¨ë¡œ ì£¼ë³€ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ ,\nì¤‘ì‹¬ ë‹¨ì–´ì™€ ì£¼ë³€ ë‹¨ì–´ì— ëŒ€í•œ ì´ì›ƒ ê´€ê³„ë¥¼ í‘œì‹œí•˜ê¸° ìœ„í•œ ë¼ë²¨ë¡œ 1 ë˜ëŠ” 0ì„ ì‚¬ìš© SGNS êµ¬í˜„ # 20newsgroups ë°ì´í„° ì‚¬ìš© Copy python # ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§ ë°ì´í„°ì…‹ ìƒì„± from tensorflow.keras.preprocessing.sequence import skipgrams skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded] # (commited (7837), badar (34572)) -\u0026gt; 0 # (whole (217), realize (1036)) -\u0026gt; 1 # (reason (149), commited (7837)) -\u0026gt; 1 Copy python from tensorflow.keras.models import Sequential, Model from tensorflow.keras.layers import Embedding, Reshape, Activation, Input from tensorflow.keras.layers import Dot Copy python embedding_dim = 100 # ì¤‘ì‹¬ ë‹¨ì–´ë¥¼ ìœ„í•œ ì„ë² ë”© í…Œì´ë¸” w_inputs = Input(shape=(1, ), dtype=\u0026#39;int32\u0026#39;) word_embedding = Embedding(vocab_size, embedding_dim)(w_inputs) # ì£¼ë³€ ë‹¨ì–´ë¥¼ ìœ„í•œ ì„ë² ë”© í…Œì´ë¸” c_inputs = Input(shape=(1, ), dtype=\u0026#39;int32\u0026#39;) context_embedding = Embedding(vocab_size, embedding_dim)(c_inputs) Copy python # ë‘ ì„ë² ë”© í…Œì´ë¸”ì— ëŒ€í•œ ë‚´ì ì˜ ê²°ê³¼ë¡œ 1 ë˜ëŠ” 0ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ì‚¬ìš© dot_product = Dot(axes=2)([word_embedding, context_embedding]) dot_product = Reshape((1,), input_shape=(1, 1))(dot_product) output = Activation(\u0026#39;sigmoid\u0026#39;)(dot_product) model = Model(inputs=[w_inputs, c_inputs], outputs=output) model.summary() model.compile(loss=\u0026#39;binary_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;) Copy python # 5epochs í•™ìŠµ for epoch in range(1, 6): loss = 0 for _, elem in enumerate(skip_grams): first_elem = np.array(list(zip(*elem[0]))[0], dtype=\u0026#39;int32\u0026#39;) second_elem = np.array(list(zip(*elem[0]))[1], dtype=\u0026#39;int32\u0026#39;) labels = np.array(elem[1], dtype=\u0026#39;int32\u0026#39;) X = [first_elem, second_elem] Y = labels loss += model.train_on_batch(X,Y) print(\u0026#39;Epoch :\u0026#39;,epoch, \u0026#39;Loss :\u0026#39;,loss) 09-05. GloVe # ì¹´ìš´íŠ¸ ê¸°ë°˜ê³¼ ì˜ˆì¸¡ ê¸°ë°˜ì„ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ë¡ ìœ¼ë¡œ, LSAì™€ Word2Vecì˜ ë‹¨ì  ë³´ì™„ LSAëŠ” ë‹¨ì–´ì˜ ë¹ˆë„ìˆ˜ë¥¼ ì°¨ì› ì¶•ì†Œí•˜ì—¬ ì ì¬ëœ ì˜ë¯¸ë¥¼ ëŒì–´ë‚´ì§€ë§Œ, ê°™ì€ ë‹¨ì–´ ì˜ë¯¸ì˜ ìœ ì¶” ì‘ì—… ì„±ëŠ¥ì€ ë–¨ì–´ì§ Word2VecëŠ” ì˜ˆì¸¡ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ì–´ ê°„ ìœ ì¶” ì‘ì—…ì—ëŠ” LSAë³´ë‹¤ ë›°ì–´ë‚˜ì§€ë§Œ,\nwindow size ë‚´ ì£¼ë³€ ë‹¨ì–´ë§Œì„ ê³ ë ¤í•˜ì—¬ ì „ì²´ì ì¸ í†µê³„ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì§€ ëª»í•¨ ì„ë² ë”© ëœ ì¤‘ì‹¬ ë‹¨ì–´ì™€ ì£¼ë³€ ë‹¨ì–´ ë²¡í„°ì˜ ë‚´ì ì´ ì „ì²´ ì½”í¼ìŠ¤ì—ì„œì˜ ë™ì‹œ ë“±ì¥ í™•ë¥ ì´ ë˜ë„ë¡ ë§Œë“œëŠ” ê²ƒì´ ëª©ì  Window based Co-occurrence Matrix # í–‰ê³¼ ì—´ì„ ì „ì²´ ë‹¨ì–´ ì§‘í•©ì˜ ë‹¨ì–´ë“¤ë¡œ êµ¬ì„±í•˜ê³ ,\ni ë‹¨ì–´ì˜ window size ë‚´ì—ì„œ k ë‹¨ì–´ê°€ ë“±ì¥í•œ íšŸìˆ˜ë¥¼ ií–‰ kì—´ì— ê¸°ì¬í•œ í–‰ë ¬ Co-occurence Probability # ë™ì‹œ ë“±ì¥ í™•ë¥  $P(k|i)$ëŠ” ë™ì‹œ ë“±ì¥ í–‰ë ¬ë¡œë¶€í„° íŠ¹ì • ë‹¨ì–´ iì˜ ì „ì²´ ë“±ì¥ íšŸìˆ˜ë¥¼ ì¹´ìš´íŠ¸í•˜ê³ ,\níŠ¹ì • ë‹¨ì–´ iê°€ ë“±ì¥í–ˆì„ ë•Œ ì–´ë–¤ ë‹¨ì–´ kê°€ ë“±ì¥í•œ íšŸìˆ˜ë¥¼ ì¹´ìš´íŠ¸í•˜ì—¬ ê³„ì‚°í•œ ì¡°ê±´ë¶€ í™•ë¥  Copy python # pip install glove_python_binary from glove import Corpus, Glove corpus = Corpus() # í›ˆë ¨ ë°ì´í„°ë¡œë¶€í„° GloVeì—ì„œ ì‚¬ìš©í•  ë™ì‹œ ë“±ì¥ í–‰ë ¬ ìƒì„± corpus.fit(result, window=5) glove = Glove(no_components=100, learning_rate=0.05) glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True) glove.add_dictionary(corpus.dictionary) print(glove.most_similar(\u0026#34;man\u0026#34;)) [(\u0026#39;woman\u0026#39;, 0.9621753707315267), (\u0026#39;guy\u0026#39;, 0.8860281455579162), (\u0026#39;girl\u0026#39;, 0.8609057388487154), (\u0026#39;kid\u0026#39;, 0.8383640509911114)] 09-06. FastText # Word2Vecê°€ ë‹¨ì–´ë¥¼ ìª¼ê°œì§ˆ ìˆ˜ ì—†ëŠ” ë‹¨ìœ„ë¡œ ìƒê°í•œë‹¤ë©´,\nFastTextëŠ” í•˜ë‚˜ì˜ ë‹¨ì–´ ì•ˆì—ë„ ì—¬ëŸ¬ ë‹¨ì–´ë“¤ì´ ì¡´ì¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼ ê° ë‹¨ì–´ë¥¼ ê¸€ì ë‹¨ìœ„ n-gramì˜ êµ¬ì„±ìœ¼ë¡œ ì·¨ê¸‰í•˜ì—¬ nì— ë”°ë¼ ë‹¨ì–´ë“¤ì´ ì–¼ë§ˆë‚˜ ë¶„ë¦¬ë˜ëŠ”ì§€ ê²°ì • tri-gramì˜ ê²½ìš° appleì— ëŒ€í•´ì„œ [\u0026lt;ap, app, ppl, ple, le\u0026gt;]ë¡œ ë¶„ë¦¬ëœ ë²¡í„° ìƒì„±\n(\u0026lt;, \u0026gt;ëŠ” ì‹œì‘ê³¼ ëì„ ì˜ë¯¸) ë‚´ë¶€ ë‹¨ì–´ë“¤ì„ Word2Vecë¡œ ë²¡í„°í™”í•˜ê³  appleì˜ ë²¡í„°ê°’ì€ ë‚´ë¶€ ë‹¨ì–´ì˜ ë²¡í„°ê°’ë“¤ì˜ ì´ í•©ìœ¼ë¡œ êµ¬ì„± Out Of Vocabulary # FastTextëŠ” ë°ì´í„°ì…‹ë§Œ ì¶©ë¶„í•˜ë‹¤ë©´ ë‚´ë¶€ ë‹¨ì–´ë¥¼ í†µí•´ ëª¨ë¥´ëŠ” ë‹¨ì–´ì— ëŒ€í•´ì„œë„ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥ birthplaceë¥¼ í•™ìŠµí•˜ì§€ ì•Šì€ ìƒíƒœë¼ë„, birthì™€ placeë¼ëŠ” ë‚´ë¶€ ë‹¨ì–´ê°€ ìˆë‹¤ë©´ ë²¡í„°ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ Rare Word # Word2VecëŠ” ë“±ì¥ ë¹ˆë„ ìˆ˜ê°€ ì ì€ ë‹¨ì–´ì— ëŒ€í•´ì„œ ì„ë² ë”©ì˜ ì •í™•ë„ê°€ ë†’ì§€ ì•Šì€ ë‹¨ì  FastTextëŠ” í¬ê·€ ë‹¨ì–´ë¼ë„ n-gramì´ ë‹¤ë¥¸ ë‹¨ì–´ì˜ n-gramê³¼ ê²¹ì¹˜ëŠ” ê²½ìš°ë¼ë©´,\nWord2Vecë³´ë‹¤ ë¹„êµì  ë†’ì€ ì„ë² ë”© ë²¡í„°ê°’ì„ ì–»ìŒ ì˜¤íƒ€ì™€ ê°™ì€ ë…¸ì´ì¦ˆê°€ ë§ì€ ì½”í¼ìŠ¤ì—ì„œë„ ì¼ì • ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë³´ì„ (apple, appple) Copy python from gensim.models import FastText model = FastText(result, size=100, window=5, min_count=5, workers=4, sg=1) 09-08. Pre-trained Word Embedding # ì‚¬ì „ í›ˆë ¨ëœ ì›Œë“œ ì„ë² ë”© ì°¸ê³  09-09. ELMo # ì–¸ì–´ ëª¨ë¸ë¡œ í•˜ëŠ” ì„ë² ë”©ì´ë¼ëŠ” ëœ»ìœ¼ë¡œ, ì‚¬ì „ í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš© Word2VecëŠ” Bank Accountì™€ River Bankì—ì„œ Bankì˜ ì°¨ì´ë¥¼ êµ¬ë¶„í•˜ì§€ ëª»í•˜ì§€ë§Œ,\nELMoëŠ” ë¬¸ë§¥ì„ ë°˜ì˜í•œ ì›Œë“œ ì„ë² ë”©ì„ ìˆ˜í–‰ ELMo í‘œí˜„ì„ ê¸°ì¡´ ì„ë² ë”© ë²¡í„°ì™€ ì—°ê²°(concatenate)í•´ì„œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥ biLM # RNN ì–¸ì–´ ëª¨ë¸ì—ì„œ $h_t$ëŠ” ì‹œì ì´ ì§€ë‚ ìˆ˜ë¡ ì—…ë°ì´íŠ¸ë˜ê¸° ë•Œë¬¸ì—,\në¬¸ì¥ì˜ ë¬¸ë§¥ ì •ë³´ë¥¼ ì ì°¨ì ìœ¼ë¡œ ë°˜ì˜í•¨ ELMoëŠ” ì–‘ìª½ ë°©í–¥ì˜ ì–¸ì–´ ëª¨ë¸(biLM)ì„ í•™ìŠµí•˜ì—¬ í™œìš© biLMì€ ì€ë‹‰ì¸µì´ ìµœì†Œ 2ê°œ ì´ìƒì¸ ë‹¤ì¸µ êµ¬ì¡°ë¥¼ ì „ì œë¡œ í•¨ ì–‘ë°©í–¥ RNNì€ ìˆœë°©í–¥ RNNì˜ hidden stateì™€ ì—­ë°©í–¥ RNNì˜ hidden stateë¥¼ ì—°ê²°í•˜ëŠ” ê²ƒì´ì§€ë§Œ,\nbiLMì€ ìˆœë°©í–¥ ì–¸ì–´ ëª¨ë¸ê³¼ ì—­ë°©í–¥ ì–¸ì–´ ëª¨ë¸ì´ë¼ëŠ” ë‘ ê°œì˜ ì–¸ì–´ ëª¨ë¸ì„ ë³„ê°œì˜ ëª¨ë¸ë¡œ ë³´ê³  í•™ìŠµ ê° ì¸µ(embedding, hidden state)ì˜ ì¶œë ¥ê°’ì´ ê°€ì§„ ì •ë³´ê°€ ì„œë¡œ ë‹¤ë¥¸ ê²ƒì´ë¯€ë¡œ,\nì´ë¥¼ ëª¨ë‘ í™œìš©í•˜ì—¬ ìˆœë°©í–¥ ì–¸ì–´ ëª¨ë¸ê³¼ ì—­ë°©í–¥ ì–¸ì–´ ëª¨ë¸ì˜ ê° ì¸µì˜ ì¶œë ¥ê°’ì„ ì—°ê²° ELMo Representation # ê° ì¸µì˜ ì¶œë ¥ê°’ì„ ì—°ê²°(concatenate) ê° ì¸µì˜ ì¶œë ¥ê°’ ë³„ë¡œ ê°€ì¤‘ì¹˜($s_1, s_2, s_3$) ë¶€ì—¬ ê° ì¸µì˜ ì¶œë ¥ê°’ì„ ëª¨ë‘ ë”í•¨ (2ë²ˆê³¼ 3ë²ˆì„ ìš”ì•½í•˜ì—¬ ê°€ì¤‘í•©ì´ë¼ í‘œí˜„) ë²¡í„°ì˜ í¬ê¸°ë¥¼ ê²°ì •í•˜ëŠ” ìŠ¤ì¹¼ë¼ ë§¤ê°œë³€ìˆ˜($\\gamma$)ë¥¼ ê³±í•¨ ELMo í™œìš© # ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜í•˜ê¸° ë°ì´í„° ì‚¬ìš© Copy python # í…ì„œí”Œë¡œìš° 1ë²„ì „ì—ì„œ ì‚¬ìš© ê°€ëŠ¥ %tensorflow_version 1.x pip install tensorflow-hub import tensorflow_hub as hub Copy python # í…ì„œí”Œë¡œìš° í—ˆë¸Œë¡œë¶€í„° ELMoë¥¼ ë‹¤ìš´ë¡œë“œ elmo = hub.Module(\u0026#34;https://tfhub.dev/google/elmo/1\u0026#34;, trainable=True) sess = tf.Session() K.set_session(sess) sess.run(tf.global_variables_initializer()) sess.run(tf.tables_initializer()) Copy python # ë°ì´í„°ì˜ ì´ë™ì´ ì¼€ë¼ìŠ¤ â†’ í…ì„œí”Œë¡œìš° â†’ ì¼€ë¼ìŠ¤ê°€ ë˜ë„ë¡ í•˜ëŠ” í•¨ìˆ˜ def ELMoEmbedding(x): return elmo(tf.squeeze(tf.cast(x, tf.string)), as_dict=True, signature=\u0026#34;default\u0026#34;) Copy python from keras.models import Model from keras.layers import Dense, Lambda, Input input_text = Input(shape=(1,), dtype=tf.string) embedding_layer = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text) hidden_layer = Dense(256, activation=\u0026#39;relu\u0026#39;)(embedding_layer) output_layer = Dense(1, activation=\u0026#39;sigmoid\u0026#39;)(hidden_layer) model = Model(inputs=[input_text], outputs=output_layer) model.compile(loss=\u0026#39;binary_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 09-10. Embedding Visualization # êµ¬ê¸€ embedding projector ì‹œê°í™” ë„êµ¬ (ë…¼ë¬¸ ì°¸ê³ ) Copy python # !python -m gensim.scripts.word2vec2tensor --input ëª¨ë¸ì´ë¦„ --output ëª¨ë¸ì´ë¦„ !python -m gensim.scripts.word2vec2tensor --input eng_w2v --output eng_w2v # ì„ë² ë”© í”„ë¡œì íŠ¸ì— ì‚¬ìš©í•  metadata.tsvì™€ tensor.tsv íŒŒì¼ ìƒì„± 09-11. Document Embedding # ë¬¸ì„œ ë²¡í„°ë¥¼ ì´ìš©í•œ ì¶”ì²œ ì‹œìŠ¤í…œ ì°¸ê³  ë¬¸ì„œ ì„ë² ë”© : ì›Œë“œ ì„ë² ë”©ì˜ í‰ê·  ì°¸ê³  Doc2Vecìœ¼ë¡œ ê³µì‹œ ì‚¬ì—…ë³´ê³ ì„œ ìœ ì‚¬ë„ ê³„ì‚°í•˜ê¸° ì°¸ê³  10. RNN Text Classification # ì¼€ë¼ìŠ¤ë¥¼ ì´ìš©í•œ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ê°œìš” ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜í•˜ê¸° (RNN) ë¡œì´í„° ë‰´ìŠ¤ ë¶„ë¥˜í•˜ê¸° (LSTM) IMDB ë¦¬ë·° ê°ì„± ë¶„ë¥˜í•˜ê¸° (GRU) ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸° ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ë¥˜í•˜ê¸°(LSTM) ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° ê°ì„± ë¶„ë¥˜í•˜ê¸°(GRU) BiLSTMìœ¼ë¡œ í•œêµ­ì–´ ìŠ¤íŒ€ ë¦¬ë·° ê°ì„± ë¶„ë¥˜í•˜ê¸° Bayes\u0026rsquo; Theorem # $$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$$\nNaive Bayes Classifier # ë² ì´ì¦ˆ ì •ë¦¬ë¥¼ ì´ìš©í•œ ìŠ¤íŒ¸ ë©”ì¼ í™•ë¥  í‘œí˜„\nP(ì •ìƒ ë©”ì¼ | ì…ë ¥ í…ìŠ¤íŠ¸) = (P(ì…ë ¥ í…ìŠ¤íŠ¸ | ì •ìƒ ë©”ì¼) x P(ì •ìƒ ë©”ì¼)) / P(ì…ë ¥ í…ìŠ¤íŠ¸)\nP(ìŠ¤íŒ¸ ë©”ì¼ | ì…ë ¥ í…ìŠ¤íŠ¸) = (P(ì…ë ¥ í…ìŠ¤íŠ¸ | ìŠ¤íŒ¸ ë©”ì¼) x P(ìŠ¤íŒ¸ ë©”ì¼)) / P(ì…ë ¥ í…ìŠ¤íŠ¸) ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸°ì—ì„œ í† í°í™” ì´ì „ì˜ ë‹¨ì–´ì˜ ìˆœì„œëŠ” ì¤‘ìš”í•˜ì§€ ì•ŠìŒ\n(BoWì™€ ê°™ì´ ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ë¬´ì‹œí•˜ê³  ë¹ˆë„ìˆ˜ë§Œ ê³ ë ¤) ì •ìƒ ë©”ì¼ì— ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ì—†ì–´ í™•ë¥ ì´ 0%ê°€ ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´\nê° ë‹¨ì–´ì— ëŒ€í•œ í™•ë¥ ì˜ ë¶„ëª¨, ë¶„ìì— ì „ë¶€ ìˆ«ìë¥¼ ë”í•´ì„œ ë¶„ìê°€ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” ë¼í”Œë¼ìŠ¤ ìŠ¤ë¬´ë”© ì‚¬ìš© Copy python from sklearn.feature_extraction.text import TfidfTransformer from sklearn.naive_bayes import MultinomialNB # ë‹¤í•­ë¶„í¬ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ # alpha=1.0: ë¼í”Œë¼ìŠ¤ ìŠ¤ë¬´ë”© ì ìš© model = MultinomialNB() # MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) model.fit(tfidfv, newsdata.target) 11-01. Convolutional Neural Network # ì´ë¯¸ì§€ ì²˜ë¦¬ì— íƒì›”í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ì‹ ê²½ë§ í•©ì„±ê³± ì‹ ê²½ë§ì€ convolutional layerì™€ pooling layerë¡œ êµ¬ì„± í•©ì„±ê³± ì—°ì‚°(CONV)ì˜ ê²°ê³¼ê°€ ReLUë¥¼ ê±°ì³ì„œ POOL êµ¬ê°„ì„ ì§€ë‚˜ëŠ” ê³¼ì • Channel: ì´ë¯¸ì§€ëŠ” (ë†’ì´, ë„ˆë¹„, ì±„ë„)ì´ë¼ëŠ” 3ì°¨ì› í…ì„œë¡œ êµ¬ì„±, ì±„ë„ì€ ìƒ‰ ì„±ë¶„ì„ ì˜ë¯¸ í•©ì„±ê³± ì‹ ê²½ë§ì€ ì´ë¯¸ì§€ì˜ ëª¨ë“  í”½ì…€ì´ ì•„ë‹Œ, ì»¤ë„ê³¼ ë§µí•‘ë˜ëŠ” í”½ì…€ë§Œì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬\në‹¤ì¸µ í¼ì…‰íŠ¸ë¡ ë³´ë‹¤ í›¨ì”¬ ì ì€ ìˆ˜ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µê°„ì  êµ¬ì¡° ì •ë³´ë¥¼ ë³´ì¡´ í¸í–¥ì„ ì¶”ê°€í•  ê²½ìš° ì»¤ë„ì„ ì ìš©í•œ ë’¤ì— ë”í•´ì§€ë©°, ë‹¨ í•˜ë‚˜ì˜ í¸í–¥ì´ ì»¤ë„ì´ ì ìš©ëœ ê²°ê³¼ì˜ ëª¨ë“  ì›ì†Œì— ë”í•´ì§ ë‹¤ìˆ˜ì˜ ì±„ë„ì„ ê°€ì§„ ì…ë ¥ ë°ì´í„°ì¼ ê²½ìš° ì»¤ë„ì˜ ì±„ë„ ìˆ˜ë„ ì…ë ¥ì˜ ì±„ë„ ìˆ˜ë§Œí¼ ì¡´ì¬,\nê° ì±„ë„ ê°„ í•©ì„±ê³± ì—°ì‚°ì„ ë§ˆì¹˜ê³  ê·¸ ê²°ê³¼ë¥¼ ëª¨ë‘ ë”í•´ì„œ í•˜ë‚˜ì˜ ì±„ë„ì„ ê°€ì§€ëŠ” íŠ¹ì„± ë§µ ìƒì„± Convolution Operation # ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œ Kernel(filter)ë¼ëŠ” ${n}\\times{m}$ í¬ê¸°ì˜ í–‰ë ¬ë¡œ ê° ì´ë¯¸ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í›‘ìŒ Feature map: í•©ì„±ê³± ì—°ì‚°ì„ í†µí•´ ë‚˜ì˜¨ ê²°ê³¼ Stride: ì»¤ë„ì˜ ì´ë™ ë²”ìœ„, íŠ¹ì„± ë§µì˜ í¬ê¸° Padding: í•©ì„±ê³± ì—°ì‚° ì´í›„ì—ë„ íŠ¹ì„± ë§µì˜ í¬ê¸°ê°€ ì…ë ¥ê³¼ ë™ì¼í•˜ë„ë¡ í–‰ê³¼ ì—´ ì¶”ê°€ 11-02. 1D CNN # 1D Convolutions # LSTMê³¼ ë™ì¼í•˜ê²Œ ê° ë‹¨ì–´ê°€ ë²¡í„°ë¡œ ë³€í™˜ëœ ë¬¸ì¥ í–‰ë ¬ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ ì»¤ë„ì˜ ë„ˆë¹„ëŠ” ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ê³¼ ë™ì¼, ì»¤ë„ì˜ ë†’ì´ë§Œìœ¼ë¡œ í•´ë‹¹ ì»¤ë„ì˜ í¬ê¸°ë¼ ê°„ì£¼ ì»¤ë„ì˜ ë„ˆë¹„ê°€ ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ì´ê¸° ë•Œë¬¸ì— ë„ˆë¹„ ë°©í–¥ìœ¼ë¡œ ì›€ì§ì´ì§€ ëª»í•˜ê³  ë†’ì´ ë°©í–¥ìœ¼ë¡œë§Œ ì›€ì§ì„ Max-pooling # 1D CNNì—ì„œì˜ í´ë§ ì¸µ ê° í•©ì„±ê³± ì—°ì‚°ìœ¼ë¡œë¶€í„° ì–»ì€ ê²°ê³¼ ë²¡í„°ì—ì„œ ê°€ì¥ í° ê°’ì„ ê°€ì§„ ìŠ¤ì¹¼ë¼ ê°’ì„ ë¹¼ë‚´ëŠ” ì—°ì‚°ì„ ìˆ˜í–‰ 1D CNN êµ¬í˜„ # Copy python from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint embedding_dim = 256 # ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› dropout_ratio = 0.3 # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ num_filters = 256 # ì»¤ë„ì˜ ìˆ˜ kernel_size = 3 # ì»¤ë„ì˜ í¬ê¸° hidden_units = 128 # ë‰´ëŸ°ì˜ ìˆ˜ model = Sequential() model.add(Embedding(vocab_size, embedding_dim)) model.add(Dropout(dropout_ratio)) model.add(Conv1D(num_filters, kernel_size, padding=\u0026#39;valid\u0026#39;, activation=\u0026#39;relu\u0026#39;)) model.add(GlobalMaxPooling1D()) model.add(Dense(hidden_units, activation=\u0026#39;relu\u0026#39;)) model.add(Dropout(dropout_ratio)) model.add(Dense(1, activation=\u0026#39;sigmoid\u0026#39;)) es = EarlyStopping(monitor=\u0026#39;val_loss\u0026#39;, mode=\u0026#39;min\u0026#39;, verbose=1, patience=3) mc = ModelCheckpoint(\u0026#39;best_model.h5\u0026#39;, monitor=\u0026#39;val_acc\u0026#39;, mode=\u0026#39;max\u0026#39;, verbose=1, save_best_only=True) model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;acc\u0026#39;]) history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[es, mc]) 11-06. Intent Classification # ì‚¬ì „ í›ˆë ¨ëœ ì›Œë“œ ì„ë² ë”©ì„ ì´ìš©í•œ ì˜ë„ ë¶„ë¥˜ ì°¸ê³  11-07. Character Embedding # \u0026lsquo;misunderstand\u0026rsquo;ì˜ ì˜ë¯¸ë¥¼ \u0026lsquo;mis-\u0026lsquo;ë¼ëŠ” ì ‘ë‘ì‚¬ì™€ \u0026lsquo;understand\u0026rsquo;ë¥¼ í†µí•´ ì¶”ì¸¡í•˜ëŠ” ê²ƒê³¼ ê°™ì´,\nì‚¬ëŒì˜ ì´í•´ ëŠ¥ë ¥ì„ í‰ë‚´ë‚´ëŠ” ì•Œê³ ë¦¬ì¦˜ 1D CNNì—ì„œëŠ” ë‹¨ì–´ë¥¼ ë¬¸ì ë‹¨ìœ„ë¡œ ìª¼ê°œê¸°ë§Œí•˜ë©´ ë˜ê¸° ë•Œë¬¸ì— OOVë¼ë„ ë²¡í„°ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ BiLSTMì—ì„œë„ ë¬¸ìì— ëŒ€í•œ ì„ë² ë”©ì„ í†µí•´ ì–»ì€ ë²¡í„°ë¥¼ ë‹¨ì–´ì— ëŒ€í•œ ë²¡í„°ë¡œ ì‚¬ìš© 12. Tagging Task # ì–‘ë°©í–¥ LSTMë¥¼ ì´ìš©í•œ í’ˆì‚¬ íƒœê¹… ê°œì²´ëª… ì¸ì‹ ê°œì²´ëª… ì¸ì‹ì˜ BIO í‘œí˜„ ì´í•´í•˜ê¸° BiLSTMì„ ì´ìš©í•œ ê°œì²´ëª… ì¸ì‹ BiLSTM-CRFë¥¼ ì´ìš©í•œ ê°œì²´ëª… ì¸ì‹ ë¬¸ì ì„ë² ë”© í™œìš©í•˜ê¸° BIO í‘œí˜„ # ê°œì²´ëª…ì´ ì‹œì‘ë˜ëŠ” ë¶€ë¶„ì— B(Begin), ê°œì²´ëª…ì˜ ë‚´ë¶€ì— I(Inside), ë‚˜ë¨¸ì§€ë¡œ O(Outside) íƒœê¹… ê°œì²´ëª… íƒœê¹…ì—” LOC(location), ORG(organization), PER(person), MISC(miscellaneous)\níƒœê·¸ê°€ ì¶”ê°€ë¡œ ë¶™ìŒ (B-ORG ë“±) CRF(Conditional Random Field) # LSTM ìœ„ì— CRF ì¸µì„ ì¶”ê°€í•˜ë©´ ëª¨ë¸ì€ ì˜ˆì¸¡ ê°œì²´ëª…(ë ˆì´ë¸” ê°„ ì˜ì¡´ì„±)ì„ ê³ ë ¤ ê¸°ì¡´ ì–‘ë°©í–¥ LSTM ëª¨ë¸ì€ í™œì„±í™” í•¨ìˆ˜ë¥¼ ì§€ë‚œ ì‹œì ì—ì„œ ê°œì²´ëª…ì„ ê²°ì •í–ˆì§€ë§Œ,\nCRF ì¸µì„ ì¶”ê°€í•œ ëª¨ë¸ì—ì„œëŠ” í™œì„±í™” í•¨ìˆ˜ì˜ ê²°ê³¼ë“¤ì´ CRF ì¸µì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ CRF ì¸µì€ [ë¬¸ì¥ì˜ ì²«ë²ˆì¨° ë‹¨ì–´ì—ì„œëŠ” Iê°€ ë‚˜ì˜¤ì§€ ì•ŠëŠ”ë‹¤, O-I íŒ¨í„´ì€ ë‚˜ì˜¤ì§€ ì•ŠëŠ”ë‹¤] ë“±ì˜ ì œì•½ì‚¬í•­ì„ í•™ìŠµ ì–‘ë°©í–¥ LSTMì€ ì…ë ¥ ë‹¨ì–´ì— ëŒ€í•œ ì–‘ë°©í–¥ ë¬¸ë§¥ì„ ë°˜ì˜í•˜ë©°, CRFëŠ” ì¶œë ¥ ë ˆì´ë¸”ì— ëŒ€í•œ ì–‘ë°©í–¥ ë¬¸ë§¥ì„ ë°˜ì˜ CRF ì¸µì€ one-hot encodingëœ ë¼ë²¨ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ 13-01. Byte Pair Encoding # UNK(Unknown Token) ë“±ì˜ OOV ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì„œë¸Œì›Œë“œ ë¶„ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰ BPE ì•Œê³ ë¦¬ì¦˜ì€ ì—°ì†ì ìœ¼ë¡œ ê°€ì¥ ë§ì´ ë“±ì¥í•œ ê¸€ìì˜ ìŒì„ ì°¾ì•„ì„œ í•˜ë‚˜ì˜ ê¸€ìë¡œ ë³‘í•© BPEëŠ” ê¸€ì ë‹¨ìœ„ì—ì„œ ì ì°¨ì ìœ¼ë¡œ ë‹¨ì–´ ì§‘í•©ì„ ë§Œë“¤ì–´ë‚´ëŠ” Bottom up ë°©ì‹ì˜ ì ‘ê·¼ ì‚¬ìš© WordPiece Tokenizer # BPEì˜ ë³€í˜• ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ì½”í¼ìŠ¤ì˜ likelihoodë¥¼ ê°€ì¥ ë†’ì´ëŠ” ìŒì„ ë³‘í•© ëª¨ë“  ë‹¨ì–´ì˜ ë§¨ ì•ì— _ë¥¼ ë¶™ì´ê³ , ë‹¨ì–´ëŠ” subwordë¡œ í†µê³„ì— ê¸°ë°˜í•˜ì—¬ ë„ì–´ì“°ê¸°ë¡œ ë¶„ë¦¬ WordPiece TOkenizer ê²¨ë¡œê°€ë¥¼ ë˜ëŒë¦¬ê¸° ìœ„í•´ì„œëŠ” ëª¨ë“  ë„ì–´ì“°ê¸°ë¥¼ ì œê±°í•˜ê³  ì–¸ë”ë°”ë¥¼ ë„ì–´ì“°ê¸°ë¡œ ë°”ê¿ˆ Unigram Language Model Tokenizer # ê°ê°ì˜ ì„œë¸Œì›Œë“œë“¤ì— ëŒ€í•´ì„œ ì†ì‹¤(loss)ì„ ê³„ì‚° ì„œë¸Œ ë‹¨ì–´ì˜ ì†ì‹¤ì€ í•´ë‹¹ ì„œë¸Œì›Œë“œê°€ ë‹¨ì–´ ì§‘í•©ì—ì„œ ì œê±°ë˜ì—ˆì„ ê²½ìš°, ì½”í¼ìŠ¤ì˜ likelihoodê°€ ê°ì†Œí•˜ëŠ” ì •ë„ ì„œë¸Œì›Œë“œë“¤ì˜ ì†ì‹¤ì˜ ì •ë„ë¥¼ ì •ë ¬í•˜ì—¬, ìµœì•…ì˜ ì˜í–¥ì„ ì£¼ëŠ” 10~20%ì˜ í† í°ì„ ì œê±° 13-02. SentencePiece # ë‚´ë¶€ ë‹¨ì–´ ë¶„ë¦¬ë¥¼ ìœ„í•œ êµ¬ê¸€ì˜ íŒ¨í‚¤ì§€ ì‚¬ì „ í† í°í™” ì‘ì—…ì—†ì´ ë‹¨ì–´ ë¶„ë¦¬ í† í°í™”ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì–¸ì–´ì— ì¢…ì†ì ì´ì§€ ì•ŠìŒ Copy python import sentencepiece as spm # IMDB ë¦¬ë·° ë°ì´í„° ì‚¬ìš© spm.SentencePieceTrainer.Train(\u0026#39;--input=imdb_review.txt --model_prefix=imdb --vocab_size=5000 --model_type=bpe --max_sentence_length=9999\u0026#39;) input: í•™ìŠµì‹œí‚¬ íŒŒì¼ model_prefix: ë§Œë“¤ì–´ì§ˆ ëª¨ë¸ ì´ë¦„ vocab_size: ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° model_type: ì‚¬ìš©í•  ëª¨ë¸ (unigram(default), bpe, char, word) max_sentence_length: ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ 13-03. SubwordTextEncoder # Wordpiece ëª¨ë¸ì„ ì±„íƒí•œ í…ì„œí”Œë¡œìš°ì˜ ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì € Copy python import tensorflow_datasets as tfds tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus( train_df[\u0026#39;review\u0026#39;], target_vocab_size=2**13) 13-04. Huggingface Tokenizer # BertWordPieceTokenizer: BERTì—ì„œ ì‚¬ìš©ëœ ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €(WordPiece Tokenizer) CharBPETokenizer: ì˜¤ë¦¬ì§€ë„ BPE ByteLevelBPETokenizer: BPEì˜ ë°”ì´íŠ¸ ë ˆë²¨ ë²„ì „ SentencePieceBPETokenizer: ì•ì„œ ë³¸ íŒ¨í‚¤ì§€ ì„¼í…ìŠ¤í”¼ìŠ¤(SentencePiece)ì™€ í˜¸í™˜ë˜ëŠ” BPE êµ¬í˜„ì²´ BertWordPieceTokenizer # Copy python from tokenizers import BertWordPieceTokenizer tokenizer = BertWordPieceTokenizer(lowercase=False, trip_accents=False) Copy python data_file = \u0026#39;naver_review.txt\u0026#39; vocab_size = 30000 limit_alphabet = 6000 min_frequency = 5 tokenizer.train(files=data_file, vocab_size=vocab_size, limit_alphabet=limit_alphabet, min_frequency=min_frequency) 14-01. Sequence-to-Sequence(seq2seq) # seq2seqëŠ” ì…ë ¥ëœ ì‹œí€€ìŠ¤ë¡œë¶€í„° ë‹¤ë¥¸ ë„ë©”ì¸ì˜ ì‹œí€€ìŠ¤ë¥¼ ì¶œë ¥í•˜ëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ ì±—ë´‡, ê¸°ê³„ ë²ˆì—­, ë‚´ìš© ìš”ì•½, STT(Speech to Text) ë“±ì—ì„œ ì£¼ë¡œ ì‚¬ìš© seq2seqëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë”ë¡œ ë‚˜ëˆ ì§€ë©°, ë‘˜ ë‹¤ LSTM ì…€ ë˜ëŠ” GRU ì…€ì„ ì‚¬ìš©í•˜ëŠ” RNN ì•„í‚¤í…ì²˜ë¡œ êµ¬ì„± softmax í•¨ìˆ˜ë¥¼ í†µí•´ ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê° ë‹¨ì–´ë³„ í™•ë¥ ê°’ì„ ë°˜í™˜í•˜ê³ , ë””ì½”ë”ëŠ” ì¶œë ¥ ë‹¨ì–´ë¥¼ ê²°ì • Encoder # ì…ë ¥ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ë°›ê³  ëª¨ë“  ë‹¨ì–´ ì •ë³´ë“¤ì„ ì••ì¶•í•´ì„œ í•˜ë‚˜ì˜ ë²¡í„° ìƒì„± ì¸ì½”ë” RNN ì…€ì˜ ë§ˆì§€ë§‰ hidden stateë¥¼ context vectorë¡œ ë””ì½”ë”ì— ë„˜ê²¨ì¤Œ Decoder # ì••ì¶•ëœ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ë°›ì•„ì„œ ë²ˆì—­ëœ ë‹¨ì–´ë¥¼ í•œ ê°œì”© ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥ ê¸°ë³¸ì ìœ¼ë¡œ RNNLMìœ¼ë¡œ, ì´ˆê¸° ì…ë ¥ìœ¼ë¡œ ë¬¸ì¥ì˜ ì‹œì‘ì„ ì˜ë¯¸í•˜ëŠ” ì‹¬ë³¼ ê°€ ë“¤ì–´ê° ì²«ë²ˆì§¸ ì‹œì ì˜ ë””ì½”ë” RNN ì…€ì€ ì˜ˆì¸¡ëœ ë‹¨ì–´ë¥¼ ë‹¤ìŒ ì‹œì ì˜ RNN ì…€ ì…ë ¥ìœ¼ë¡œ ë„£ìœ¼ë©°,\në¬¸ì¥ì˜ ëì„ ì˜ë¯¸í•˜ëŠ” ì‹¬ë³¼ì¸ ê°€ ë‹¤ìŒ ë‹¨ì–´ë¡œ ì˜ˆì¸¡ë  ë•Œê¹Œì§€ ë°˜ë³µí•´ì„œ ì˜ˆì¸¡ í›ˆë ¨ ê³¼ì •ì—ì„œëŠ” ì‹¤ì œ ì •ë‹µ ìƒí™©ì—ì„œ ê°€ ë‚˜ì™€ì•¼ ëœë‹¤ê³  ì •ë‹µì„ ì•Œë ¤ì¤Œ\n(êµì‚¬ ê°•ìš”: ì´ì „ ì‹œì ì˜ ë””ì½”ë” ì…€ì˜ ì˜ˆì¸¡ì´ í‹€ë¦´ ê²½ìš° ì—°ì‡„ ì‘ìš©ì„ ë°©ì§€) seq2seq êµ¬í˜„ # í”„ë‘ìŠ¤-ì˜ì–´ ë³‘ë ¬ ì½”í¼ìŠ¤ ë°ì´í„° ì‚¬ìš© ë³‘ë ¬ ì½”í¼ìŠ¤ ë°ì´í„°ì—ì„œ ìŒì´ ë˜ëŠ” ë°ì´í„°ì˜ ê¸¸ì´ê°€ ê°™ì§€ ì•ŠìŒì— ì£¼ì˜ Copy python # Encoder encoder_inputs = Input(shape=(None, src_vocab_size)) encoder_lstm = LSTM(units=256, return_state=True) # encoder_outputsì€ ì—¬ê¸°ì„œëŠ” ë¶ˆí•„ìš” encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs) # LSTMì€ ë°”ë‹ë¼ RNNê³¼ëŠ” ë‹¬ë¦¬ ìƒíƒœê°€ ë‘ ê°œ, ì€ë‹‰ ìƒíƒœì™€ ì…€ ìƒíƒœ encoder_states = [state_h, state_c] Copy python # Decoder decoder_inputs = Input(shape=(None, tar_vocab_size)) decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True) # ë””ì½”ë”ì—ê²Œ ì¸ì½”ë”ì˜ ì€ë‹‰ ìƒíƒœ, ì…€ ìƒíƒœë¥¼ ì „ë‹¬ decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states) decoder_softmax_layer = Dense(tar_vocab_size, activation=\u0026#39;softmax\u0026#39;) decoder_outputs = decoder_softmax_layer(decoder_outputs) model = Model([encoder_inputs, decoder_inputs], decoder_outputs) model.compile(optimizer=\u0026#34;rmsprop\u0026#34;, loss=\u0026#34;categorical_crossentropy\u0026#34;) Copy python model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2) seq2seq ë™ì‘ # ë²ˆì—­í•˜ê³ ì í•˜ëŠ” ì…ë ¥ ë¬¸ì¥ì´ ì¸ì½”ë”ì— ë“¤ì–´ê°€ì„œ ì€ë‹‰ ìƒíƒœì™€ ì…€ ìƒíƒœë¥¼ ì–»ìŒ ìƒíƒœì™€ ì— í•´ë‹¹í•˜ëŠ” \u0026lsquo;\\t\u0026rsquo;ë¥¼ ë””ì½”ë”ë¡œ ë³´ëƒ„ ë””ì½”ë”ê°€ ì— í•´ë‹¹í•˜ëŠ” \u0026lsquo;\\n\u0026rsquo;ì´ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë‹¤ìŒ ë¬¸ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” í–‰ë™ì„ ë°˜ë³µ 14-02. BLEU Score # Bilingual Evaluation Understudy(BLEU) # ê¸°ê³„ ë²ˆì—­ ê²°ê³¼ì™€ ì‚¬ëŒì´ ì§ì ‘ ë²ˆì—­í•œ ê²°ê³¼ê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ë¹„êµí•˜ì—¬ ë²ˆì—­ì— ëŒ€í•œ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë°©ë²• ì¸¡ì • ê¸°ì¤€ì€ n-gramì— ê¸°ë°˜ ì–¸ì–´ì— êµ¬ì• ë°›ì§€ ì•Šê³  ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ê³„ì‚° ì†ë„ê°€ ë¹ ë¥¸ ì´ì  PPLê³¼ ë‹¬ë¦¬ ë†’ì„ ìˆ˜ë¡ ì„±ëŠ¥ì´ ë” ì¢‹ìŒì„ ì˜ë¯¸ Unigram Precision # ì‚¬ëŒì´ ë²ˆì—­í•œ ë¬¸ì¥ ì¤‘ ì–´ëŠ í•œ ë¬¸ì¥ì´ë¼ë„ ë“±ì¥í•œ ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ ì¹´ìš´íŠ¸í•˜ëŠ” ì¸¡ì • ë°©ë²• ê¸°ê³„ ë²ˆì—­ê¸°ê°€ ë²ˆì—­í•œ ë¬¸ì¥ì„ Ca, ì‚¬ëŒì´ ë²ˆì—­í•œ ë¬¸ì¥ì„ Refë¼ í‘œí˜„ $$\\text{Unigram Precision}=\\frac{\\text{Refë“¤ ì¤‘ì—ì„œ ì¡´ì¬í•˜ëŠ” Caì˜ ë‹¨ì–´ì˜ ìˆ˜}}{\\text{Caì˜ ì´ ë‹¨ì–´ ìˆ˜}}$$\nModified Unigram Precision # í•˜ë‚˜ì˜ ë‹¨ì–´ê°€ ì—¬ëŸ¬ë²ˆ ë°˜ë³µë˜ëŠ” ê²½ìš°ì—ì„œ ì •ë°€ë„ê°€ 1ì´ ë‚˜ì˜¤ëŠ” ë¬¸ì œë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´\nìœ ë‹ˆê·¸ë¨ì´ ì´ë¯¸ ë§¤ì¹­ëœ ì ì´ ìˆëŠ”ì§€ë¥¼ ê³ ë ¤ $Max_Ref_Count$: ìœ ë‹ˆê·¸ë¨ì´ í•˜ë‚˜ì˜ Refì—ì„œ ìµœëŒ€ ëª‡ ë²ˆ ë“±ì¥í–ˆëŠ”ì§€ ì¹´ìš´íŠ¸ $Count_{dip}=min(Count,Max_Ref_Count)$ $$\\text{Modified Unigram Precision}=\\frac{\\text{Caì˜ ê° ìœ ë‹ˆê·¸ë¨ì— ëŒ€í•´ }Count_{dip}\\text{ì„ ìˆ˜í–‰í•œ ê°’ì˜ ì´ í•©}}{\\text{Caì˜ ì´ ìœ ë‹ˆê·¸ë¨ ìˆ˜}}$$\nBLEU Score # ìœ ë‹ˆê·¸ë¨ ì •ë°€ë„ëŠ” ë‹¨ì–´ì˜ ë¹ˆë„ìˆ˜ë¡œ ì ‘ê·¼í•˜ê¸° ë•Œë¬¸ì— ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ê³ ë ¤í•˜ê¸° ìœ„í•´ n-gram ì´ìš© BLEU ìµœì¢… ì‹ì€ ë³´ì •ëœ ì •ë°€ë„ $p_1,p_2,\u0026hellip;,p_n$ì„ ëª¨ë‘ ì¡°í•© í•´ë‹¹ BLEU ì‹ì˜ ê²½ìš° ë¬¸ì¥ì˜ ê¸¸ì´ê°€ ì§§ì„ ë•Œ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ëŠ” ë¬¸ì œê°€ ìˆê¸° ë•Œë¬¸ì—,\nê¸¸ì´ê°€ ì§§ì€ ë¬¸ì¥ì—ê²Œ Brevity Penaltyë¥¼ ì¤„ í•„ìš”ê°€ ìˆìŒ $BP$ëŠ” Caì™€ ê°€ì¥ ê¸¸ì´ ì°¨ì´ê°€ ì‘ì€ Refì˜ ê¸¸ì´ $r$ì„ ê¸°ì¤€ìœ¼ë¡œ $e^{(1-r/c)}$ ê°’ì„ ê³±í•˜ë©°,\në¬¸ì¥ì´ $r$ë³´ë‹¤ ê¸¸ì–´ íŒ¨ë„í‹°ë¥¼ ì¤„ í•„ìš”ê°€ ì—†ëŠ” ê²½ìš° 1ì´ì–´ì•¼ í•¨ $$\\text{ë³´ì •ëœ ì •ë°€ë„ } p_1=\\frac{\\Sigma_{{unigram}\\in{Candidate}}Count_{dip}(unigram)}{\\Sigma_{{unigram}\\in{Candidate}}Count(unigram)}$$ $$\\text{n-gram ì¼ë°˜í™” } p_n=\\frac{\\Sigma_{{n\\text{-}gram}\\in{Candidate}}Count_{dip}(n\\text{-}gram)}{\\Sigma_{{n\\text{-}gram}\\in{Candidate}}Count(n\\text{-}gram)}$$ $$BLEU={BP}\\times{exp(\\Sigma^N_{n=1}{w_n}{\\log{p_n}})}$$\nCopy python import nltk.translate.bleu_score bleu_score(candidate.split(),list(map(lambda ref: ref.split(), references))) "},{"id":73,"href":"/blog/2022-06-28/","title":"2022-06-28 Log","section":"Posts","content":"02-01. Tokenization # Corpusì—ì„œ tokenì´ë¼ ë¶ˆë¦¬ëŠ” ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—… ë‹¨ì–´ í† í°í™”ì—ì„œ ë‹¨ìˆœíˆ êµ¬ë‘ì ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ëŠ” ê²ƒì€ ì˜ë¯¸ì˜ ì†ì‹¤ì„ ë°œìƒì‹œí‚¬ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—,\nì‚¬ìš©ìì˜ ëª©ì ê³¼ ì¼ì¹˜í•˜ëŠ” í† í°í™” ë„êµ¬ë¥¼ ì‚¬ìš©í•  í•„ìš”ê°€ ìˆìŒ êµ¬ë‘ì ì´ë‚˜ íŠ¹ìˆ˜ ë¬¸ìê°€ í•„ìš”í•œ ê²½ìš°: Ph.D, AT\u0026amp;T, $45.55, 01/02/06 ë“± ì¤„ì„ë§ê³¼ ë‹¨ì–´ ë‚´ì— ë„ì–´ì“°ê¸°ê°€ ìˆëŠ” ê²½ìš°: what\u0026rsquo;re/what are, New York, rock \u0026rsquo;n\u0026rsquo; roll ë“± ë¬¸ì¥ í† í°í™”ì—ì„œ ë‹¨ìˆœíˆ ë§ˆì¹¨í‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ì„ ì˜ë¼ë‚´ëŠ” ê²ƒì€ 192.168.56.31, gmail.comê³¼ ê°™ì€ ê²½ìš°ë¥¼ ê³ ë ¤í–ˆì„ ë•Œ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ í•œêµ­ì–´ í† í°í™” # í•œêµ­ì–´ì˜ ê²½ìš° ë„ì–´ì“°ê¸°ê°€ ê°€ëŠ¥í•œ ë‹¨ìœ„ê°€ ì–´ì ˆì¸ë°,\n\u0026lsquo;ê·¸ê°€\u0026rsquo;, \u0026lsquo;ê·¸ì—ê²Œ\u0026rsquo;, \u0026lsquo;ê·¸ë¥¼\u0026rsquo;ê³¼ ê°™ì´ ì–´ì ˆì´ ë…ë¦½ì ì¸ ë‹¨ì–´ë¡œ êµ¬ì„±ë˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼\nì¡°ì‚¬ ë“±ì˜ ë¬´ì–¸ê°€ê°€ ë¶™ì–´ìˆëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì— ì´ë¥¼ ì „ë¶€ í˜•íƒœì†Œ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•´ì¤˜ì•¼ í•¨ ìë¦½ í˜•íƒœì†Œ: ì ‘ì‚¬, ì–´ë¯¸, ì¡°ì‚¬ì™€ ìƒê´€ì—…ì‹± ìë¦½í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœì†Œ, [ì²´ì–¸, ìˆ˜ì‹ì–¸, ê°íƒ„ì‚¬] ë“± ì˜ì¡´ í˜•íƒœì†Œ: ë‹¤ë¥¸ í˜•íƒœì†Œì™€ ê²°í•©í•˜ì—¬ ì‚¬ìš©ë˜ëŠ” í˜•íƒœì†Œ, [ì ‘ì‚¬, ì–´ë¯¸, ì¡°ì‚¬, ì–´ê°„] í•œêµ­ì–´ì˜ ê²½ìš° ë„ì–´ì“°ê¸°ê°€ ì§€ì¼œì§€ì§€ ì•Šì•„ë„ ê¸€ì„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆì–´ ë„ì–´ì“°ê¸°ê°€ ì˜ ì§€ì¼œì§€ì§€ ì•ŠìŒ í’ˆì‚¬ íƒœê¹…: ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì œëŒ€ë¡œ íŒŒì•…í•˜ê¸° ìœ„í•´ì„œëŠ” í•´ë‹¹ ë‹¨ì–´ê°€ ì–´ë–¤ í’ˆì‚¬ë¡œ ì“°ì˜€ëŠ”ì§€ êµ¬ë¶„í•  í•„ìš” NLTK, KoNLPy # Copy python from nltk.tokenize import word_tokenize # ë‹¨ì–´ í† í°í™” from nltk.tag import pos_tag # í’ˆì‚¬ íƒœê¹… Copy python from konlpy.tag import Okt okt = Okt() okt.porphs(sentence) # í˜•íƒœì†Œ ì¶”ì¶œ okt.pos(sentence) # í’ˆì‚¬ íƒœê¹… 02-02. Cleaning and Normalization # Cleaning(ì •ì œ): ê°–ê³  ìˆëŠ” corpusë¡œë¶€í„° ë…¸ì´ì¦ˆ ë°ì´í„°ë¥¼ ì œê±° Normalization(ì •ê·œí™”): í‘œí˜„ ë°©ë²•ì´ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì„ í†µí•©ì‹œì¼œì„œ ê°™ì€ ë‹¨ì–´ë¡œ ë§Œë“¦ ì˜ì–´ê¶Œ ì–¸ì–´ì—ì„œ ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì´ëŠ” ì •ê·œí™” ë°©ë²•ìœ¼ë¡œ ëŒ€,ì†Œë¬¸ì í†µí•©ì„ í™œìš© ë…¸ì´ì¦ˆ ë°ì´í„°: ì•„ë¬´ ì˜ë¯¸ ì—†ëŠ” íŠ¹ìˆ˜ ë¬¸ì ë“±, ë¶„ì„í•˜ê³ ì í•˜ëŠ” ëª©ì ì— ë§ì§€ ì•ŠëŠ” ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë“¤ ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ ë¶ˆìš©ì–´, ë“±ì¥ ë¹ˆë„ê°€ ì ì€ ë‹¨ì–´, ê¸¸ì´ê°€ ì§§ì€ ë‹¨ì–´ ë“±ì„ ì œê±° ë…¸ì´ì¦ˆ ë°ì´í„°ì˜ íŠ¹ì§•ì„ ì¡ì•„ë‚¼ ìˆ˜ ìˆë‹¤ë©´, ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•´ì„œ ì œê±° 02-03. Stemming and Lemmatization # Lemmatization # Lemma(í‘œì œì–´): ê¸°ë³¸ ì‚¬ì „í˜• ë‹¨ì–´, [am, are, is]ì˜ ë¿Œë¦¬ ë‹¨ì–´ be ë“± Stem(ì–´ê°„): ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ë‹´ê³  ìˆëŠ” ë‹¨ì–´ì˜ í•µì‹¬ ë¶€ë¶„, \u0026lsquo;cats\u0026rsquo;ì—ì„œ \u0026lsquo;cat\u0026rsquo; Affix(ì ‘ì‚¬): ë‹¨ì–´ì— ì¶”ê°€ì ì¸ ì˜ë¯¸ë¥¼ ì£¼ëŠ” ë¶€ë¶„, \u0026lsquo;cats\u0026rsquo;ì—ì„œ \u0026rsquo;s\u0026rsquo; Copy python from nltk.stem import WordNetLemmatizer lemmatizer = WordNetLemmatizer() lemmatizer.lemmatize(word) # am -\u0026gt; be, having -\u0026gt; have Stemming # Copy python from nltk.stem import PorterStemmer stemmer = PorterStemmer() stemmer.stem(word) # am -\u0026gt; am, having -\u0026gt; hav í•œêµ­ì–´ì—ì„œì˜ ì–´ê°„ ì¶”ì¶œ # 5ì–¸ 9í’ˆì‚¬ì˜ êµ¬ì¡°ì—ì„œ ìš©ì–¸ì— í•´ë‹¹ë˜ëŠ” ë™ì‚¬ì™€ í˜•ìš©ì‚¬ëŠ” ì–´ê°„ê³¼ ì–´ë¯¸ì˜ ê²°í•©ìœ¼ë¡œ êµ¬ì„± í™œìš©: ìš©ì–¸ì˜ ì–´ê°„ì´ ì–´ë¯¸ë¥¼ ê°€ì§€ëŠ” ì¼ ê·œì¹™ í™œìš©: ì–´ê°„ì´ ì–´ë¯¸ë¥¼ ì·¨í•  ë•Œ ì–´ê°„ì˜ ëª¨ìŠµì´ ì¼ì •, ì¡/ì–´ê°„ + ë‹¤/ì–´ë¯¸ ë¶ˆê·œì¹™ í™œìš©: ì–´ê°„ì´ ì–´ë¯¸ë¥¼ ì·¨í•  ë•Œ ì–´ê°„ì˜ ëª¨ìŠµì´ ë°”ë€Œê±°ë‚˜ íŠ¹ìˆ˜í•œ ì–´ë¯¸ì¼ ê²½ìš°, \u0026lsquo;ì˜¤ë¥´+ì•„/ì–´-\u0026gt;ì˜¬ë¼\u0026rsquo; ë“± 02-04. Stopword # Stopword(ë¶ˆìš©ì–´): ë¬¸ì¥ì—ì„œëŠ” ìì£¼ ë“±ì¥í•˜ì§€ë§Œ ì‹¤ì œ ì˜ë¯¸ ë¶„ì„ì„ í•˜ëŠ”ë°ëŠ” ê¸°ì—¬í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´, [ì¡°ì‚¬, ì ‘ë¯¸ì‚¬] ë“± Copy python from nltk.corpus import stopwords stop_words_list = stopwords.words(\u0026#39;english\u0026#39;) Copy python okt = Okt() okt.morphs(sentence) # ì¡°ì‚¬, ì ‘ì†ì‚¬ ë“± ì œê±° # ë˜ëŠ” ë¶ˆìš©ì–´ ì‚¬ì „ì„ ë§Œë“¤ì–´ì„œ ì œê±° 02-05. Regular Expression # ì •ê·œ í‘œí˜„ì‹ ì°¸ê³  02-06. Integer Encoding # ì»´í“¨í„°ëŠ” í…ìŠ¤íŠ¸ë³´ë‹¤ ìˆ«ìë¥¼ ë” ì˜ ì²˜ë¦¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€ê²½ ë‹¨ì–´ë¥¼ ë¹ˆë„ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìˆœì„œëŒ€ë¡œ ë‚®ì€ ìˆ«ìë¶€í„° ì •ìˆ˜ë¥¼ ë¶€ì—¬ dictionary, Counter, nltk.FreqDist, keras.Tokenizer ë“± í™œìš© Copy python from nltk import FreqDist FreqDist(np.hstack(preprocessed_sentences)) # np.hastackìœ¼ë¡œ ë¬¸ì¥ êµ¬ë¶„ì„ ì œê±° Copy python from tensorflow.keras.preprocessing.text import Tokenizer tokenizer = Tokenizer() # num_words íŒŒë¼ë¯¸í„°ë¡œ ì‚¬ìš©í•  ë‹¨ì–´ ê°œìˆ˜ ì§€ì • tokenizer.fit_on_texts(preprocessed_sentences) # ë¹ˆë„ìˆ˜ ê¸°ë¶„ìœ¼ë¡œ ë‹¨ì–´ ì§‘í•© ìƒì„± print(tokenizer.word_intex) # ì •ìˆ˜ ì¸ë±ìŠ¤ í™•ì¸ print(tokenizer.word_counts) # ë‹¨ì–´ ë¹ˆë„ìˆ˜ í™•ì¸ print(tokenizer.texts_to_sequences(preprocessed_sentences)) # corpusë¥¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜ 02-07. Padding # ë³‘ë ¬ ì—°ì‚°ì„ ìœ„í•´ ì—¬ëŸ¬ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ì„ì˜ë¡œ ë™ì¼í•˜ê²Œ ë§ì¶°ì£¼ëŠ” ì‘ì—…ì´ í•„ìš” Copy python from tensorflow.keras.preprocessing.sequence import pad_sequences encoded = tokenizer.texts_to_sequences(preprocessed_sentences) padded = pad_seqences(encoded) # padding=\u0026#39;post\u0026#39;ë¥¼ ì…ë ¥í•´ì•¼ ë’¤ì—ì„œ ë¶€í„° 0ì„ ì±„ì›€ # maxlenìœ¼ë¡œ ë¬¸ì¥ ê¸¸ì´ ì¡°ì ˆ # truncating=\u0026#39;post\u0026#39;ë¥¼ í†µí•´ ë¬¸ì¥ ê¸¸ì´ ì´ˆê³¼ ì‹œ ë’¤ì˜ ë‹¨ì–´ê°€ ì‚­ì œë˜ë„ë¡ ì„¤ì • 02-08. One-Hot Encoding # Vocabulary(ë‹¨ì–´ ì§‘í•©): ì„œë¡œ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì˜ ì§‘í•©, bookê³¼ booksê³¼ ê°™ì€ ë³€í˜• í˜•íƒœë„ ë‹¤ë¥¸ ë‹¨ì–´ë¡œ ê°„ì£¼ One-Hot Encoding: ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ë¥¼ ë²¡í„°ì˜ ì°¨ì›ìœ¼ë¡œ í•˜ê³ ,\ní‘œí˜„í•˜ê³  ì‹¶ì€ ë‹¨ì–´ì— 1, ë‹¤ë¥¸ ì¸í…ìŠ¤ì— 0ì„ ë¶€ì—¬í•˜ëŠ” ë‹¨ì–´ì˜ ë²¡í„° í‘œí˜„ ë°©ì‹ ë‹¨ì–´ì˜ ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚  ìˆ˜ë¡ ë²¡í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê³µê°„ì´ ê³„ì† ëŠ˜ì–´ë‚˜ëŠ” ë‹¨ì  ë‹¨ì–´ì˜ ìœ ì‚¬ë„ë¥¼ í‘œí˜„í•˜ì§€ ëª»í•˜ëŠ” ë‹¨ì  (ê°•ì•„ì§€, ê°œ, ëƒ‰ì¥ê³  ë“±) Copy python from tensorflow.keras.utils import to_categorical encoded = tokenizer.texts_to_sequences(preprocessed_sentences)[0] one_hot = to_categorical(encoded) 03-01. Language Model # ë‹¨ì–´ ì‹œí€€ìŠ¤(ë¬¸ì¥)ì— í™•ë¥ ì„ í• ë‹¹í•˜ëŠ” ëª¨ë¸, ì´ì „ ë‹¨ì–´ë“¤ì´ ì£¼ì–´ì¡Œì„ ë•Œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ ë‹¨ì–´ ì‹œí€€ìŠ¤ Wì˜ í™•ë¥  $P(W)=P(w_1,w_2,w_3,w_4,w_5,\u0026hellip;,w_n)$ ë‹¤ìŒ ë‹¨ì–´ ë“±ì¥ í™•ë¥  $P(w_n|w_1,\u0026hellip;,w_{n-1})$ 03-02. Statistical Language Model # ì¡°ê±´ë¶€ í™•ë¥  # ë‚¨í•™ìƒ(A) ì—¬í•™ìƒ(B) ê³„ ì¤‘í•™ìƒ(C) 100 60 160 ê³ ë“±í•™ìƒ(D) 80 120 200 ê³„ 180 180 360 í•™ìƒì„ ë½‘ì•˜ì„ ë•Œ, ê³ ë“±í•™ìƒì´ë©´ì„œ ë‚¨í•™ìƒì¼ í™•ë¥  $P(A \\bigcap B)=80/360$ ê³ ë“±í•™ìƒ ì¤‘ í•œëª…ì„ ë½‘ì•˜ì„ ë•Œ, ë‚¨í•™ìƒì¼ í™•ë¥  $P(A|D)=P(A \\bigcap D)/P(D)=(80/360)/(200/360)$ ë¬¸ì¥ì— ëŒ€í•œ í™•ë¥  # \u0026lsquo;An adorable little boy is spreading smiles\u0026rsquo;ì˜ í™•ë¥ \n$P(\\text{An adorable little boy is spreading smiles})=\\ P(\\text{An}) \\times P(\\text{adorable}|\\text{An}) \\times \u0026hellip; \\times P(\\text{smiles}|\\text{An adorable little boy is spreading})$ ì¹´ìš´íŠ¸ ê¸°ë°˜ ì ‘ê·¼ # An adorable little boyê°€ 100ë²ˆ ë“±ì¥í–ˆì„ ë•Œ ê·¸ ë‹¤ìŒì— isê°€ ë“±ì¥í•œ ê²½ìš°ê°€ 30ë²ˆì´ë¼ë©´,\n$P(\\text{is}|\\text{An adorable little boy})$ëŠ” 30% ì¹´ìš´íŠ¸ ê¸°ë°˜ìœ¼ë¡œ í›ˆë ¨í•  ê²½ìš° ë‹¨ì–´ ì‹œí€€ìŠ¤ê°€ ì—†ì–´ í™•ë¥ ì´ 0ì´ ë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë°©ëŒ€í•œ ì–‘ì˜ í›ˆë ¨ ë°ì´í„°ê°€ í•„ìš” íšŒì†Œ ë¬¸ì œ: ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ ê´€ì¸¡í•˜ì§€ ëª»í•˜ì—¬ ì–¸ì–´ë¥¼ ì •í™•íˆ ëª¨ë¸ë§í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œ $$P(\\text{is}|\\text{An adorable little boy})= \\frac{count(\\text{An adorable little boy is})}{count(\\text{An adorable little boy})}$$\n03-03. N-gram Language Model # í†µê³„ì  ì–¸ì–´ ëª¨ë¸ì˜ ì¼ì¢…ì´ì§€ë§Œ, ëª¨ë“  ë‹¨ì–´ê°€ ì•„ë‹Œ ì¼ë¶€ ë‹¨ì–´ë§Œ ê³ ë ¤í•˜ëŠ” ì ‘ê·¼ ë°©ë²• ì‚¬ìš© An adorable little boyì—ì„œ isê°€ ë‚˜ì˜¬ í™•ë¥ ì„ boyê°€ ë‚˜ì™”ì„ ë•Œ isê°€ ë‚˜ì˜¬ í™•ë¥ ë¡œ ëŒ€ì²´\n$P(\\text{is}|\\text{An adorable little boy}) \\approx P(\\text{is}|\\text{boy})$ ë’¤ì˜ ë‹¨ì–´ ëª‡ ê°œë§Œ ë³´ë‹¤ ë³´ë‹ˆ ì˜ë„í•˜ê³  ì‹¶ì€ ëŒ€ë¡œ ë¬¸ì¥ì„ ëë§ºìŒí•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë°œìƒ ì „ì²´ ë¬¸ì¥ì„ ê³ ë ¤í•œ ì–¸ì–´ ëª¨ë¸ë³´ë‹¤ëŠ” ì •í™•ë„ê°€ ë–¨ì–´ì§ ëª‡ ê°œì˜ ë‹¨ì–´ë¥¼ ë³¼ì§€ nì„ ì •í•˜ëŠ” ê²ƒì€ trade-off ë¬¸ì œë¥¼ ë°œìƒì‹œí‚´, nì€ ìµœëŒ€ 5ë¥¼ ë„˜ê²Œ ì¡ì•„ì„œëŠ” ì•ˆëœë‹¤ê³  ê¶Œì¥ N-gram # nê°œì˜ ì—°ì†ì ì¸ ë‹¨ì–´ ë‚˜ì—´ An adorable little boyì— ëŒ€í•´\nunigrams: an, adorable, little, boy\nbigrams: an adorable, adorable little, little boy 03-05. Perplexity # Perplexity(PPL): í—·ê°ˆë¦¬ëŠ” ì •ë„, ë‚®ì„ìˆ˜ë¡ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ìŒ $$PPL(W)=P(w_1,w_2,w_3,\u0026hellip;,w_N)^{-\\frac{1}{N}}=\\sqrt[N]{\\frac{1}{P(w_1,w_2,w_3,\u0026hellip;,w_N)}}$$\nBranching Factor # Branching factor(ë¶„ê¸°ê³„ìˆ˜): PPLì´ ì„ íƒí•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥í•œ ê²½ìš°ì˜ ìˆ˜ ëŒ€í•´ PPLì´ 10ì´ ë‚˜ì™”ì„ ë•Œ, ì–¸ì–´ ëª¨ë¸ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ë•Œ í‰ê·  10ê°œì˜ ë‹¨ì–´ë¥¼ ê³ ë ¤ PPLì˜ ê°’ì´ ë‚®ë‹¤ëŠ” ê²ƒì€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì—ì„œ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì´ëŠ” ê²ƒì¼ë¿, ë°˜ë“œì‹œ ì‚¬ëŒì´ ì§ì ‘ ëŠë¼ê¸°ì— ì¢‹ì€ ëª¨ë¸ì¸ ê²ƒì€ ì•„ë‹˜ $$PPL(W)=P(w_1,w_2,w_3,\u0026hellip;,w_N)^{-\\frac{1}{N}}=(\\frac{1}{10}^N)^{-\\frac{1}{N}}=\\frac{1}{10}^{-1}=10$$\n04-01. ë‹¨ì–´ì˜ í‘œí˜„ ë°©ë²• # êµ­ì†Œ í‘œí˜„(ì´ì‚° í‘œí˜„): í•´ë‹¹ ë‹¨ì–´ ê·¸ ìì²´ë§Œ ë³´ê³ , íŠ¹ì •ê°’ì„ ë§µí•‘í•˜ì—¬ ë‹¨ì–´ë¥¼ í‘œí˜„í•˜ëŠ” ë°©ë²• ë¶„ì‚° í‘œí˜„(ì—°ì† í‘œí˜„): ê·¸ ë‹¨ì–´ë¥¼ í‘œí˜„í•˜ê³ ì ì£¼ë³€ì„ ì°¸ê³ í•˜ì—¬ ë‹¨ì–´ë¥¼ í‘œí˜„í•˜ëŠ” ë°©ë²• 04-02. Bag of Words(BoW) # ë‹¨ì–´ë“¤ì˜ ìˆœì„œëŠ” ê³ ë ¤í•˜ì§€ ì•Šê³ , ë‹¨ì–´ë“¤ì˜ ì¶œí˜„ ë¹ˆë„ì—ë§Œ ì§‘ì¤‘í•˜ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì¹˜í™” í‘œí˜„ ë°©ë²• Copy python doc1 = \u0026#39;ì •ë¶€ê°€ ë°œí‘œí•˜ëŠ” ë¬¼ê°€ìƒìŠ¹ë¥ ê³¼ ì†Œë¹„ìê°€ ëŠë¼ëŠ” ë¬¼ê°€ìƒìŠ¹ë¥ ì€ ë‹¤ë¥´ë‹¤.\u0026#39; vocabulary : {\u0026#39;ì •ë¶€\u0026#39;: 0, \u0026#39;ê°€\u0026#39;: 1, \u0026#39;ë°œí‘œ\u0026#39;: 2, \u0026#39;í•˜ëŠ”\u0026#39;: 3, \u0026#39;ë¬¼ê°€ìƒìŠ¹ë¥ \u0026#39;: 4, \u0026#39;ê³¼\u0026#39;: 5, \u0026#39;ì†Œë¹„ì\u0026#39;: 6, \u0026#39;ëŠë¼ëŠ”\u0026#39;: 7, \u0026#39;ì€\u0026#39;: 8, \u0026#39;ë‹¤ë¥´ë‹¤\u0026#39;: 9} bag of words vector : [1, 2, 1, 1, 2, 1, 1, 1, 1, 1] Copy python from sklearn.feature_extraction.text import CounteVectorizer vector = CounterVectorizer() # stop_words íŒŒë¼ë¯¸í„°ë¡œ ë¶ˆìš©ì–´ ì œê±°(\u0026#39;english\u0026#39; ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ ë“±) print(\u0026#39;bag of words vector:\u0026#39;, vector.fit_transform(corpus).toarray()) print(\u0026#39;vocabulary:\u0026#39;, vector.vocabulary_) 04-03. Document-Term Matrix(DTM) # ë‹¤ìˆ˜ì˜ ë¬¸ì„œì—ì„œ ë“±ì¥í•˜ëŠ” ê° ë‹¨ì–´ë“¤ì˜ ë¹ˆë„ë¥¼ í–‰ë ¬ë¡œ í‘œí˜„í•œ ê²ƒ One-hot vectorì™€ ë§ˆì°¬ê°€ì§€ë¡œ ëŒ€ë¶€ë¶„ì˜ ê°’ì´ 0ì¸ í¬ì†Œ í‘œí˜„ì˜ ë¬¸ì œ ë°œìƒ ë¶ˆìš©ì–´ì™€ ì¤‘ìš”í•œ ë‹¨ì–´ì— ëŒ€í•´ì„œ ê°€ì¤‘ì¹˜ë¥¼ ì£¼ê¸° ìœ„í•´ TF-IDFë¥¼ ì‚¬ìš© 04-04. TF-IDF # ë‹¨ì–´ì˜ ë¹ˆë„ì™€ ì—­ ë¬¸ì„œ ë¹ˆë„ë¥¼ ì‚¬ìš©í•˜ì—¬ DTM ë‚´ì˜ ê° ë‹¨ì–´ë“¤ë§ˆë‹¤ ì¤‘ìš”ë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ë¶€ì—¬í•˜ëŠ” ë°©ë²• $tf(d,t)$: íŠ¹ì • ë¬¸ì„œ $d$ì—ì„œì˜ íŠ¹ì • ë‹¨ì–´ $t$ì˜ ë“±ì¥ íšŸìˆ˜, DTMì—ì„œì˜ ê° ë‹¨ì–´ë“¤ì˜ ê°€ì§„ ê°’ $df(t)$: íŠ¹ì • ë‹¨ì–´ $t$ê°€ ë“±ì¥í•œ ë¬¸ì„œì˜ ìˆ˜, íŠ¹ì • ë‹¨ì–´ê°€ ê° ë¬¸ì„œì—ì„œ ë“±ì¥í•œ íšŸìˆ˜ëŠ” ë¬´ì‹œ $idf(d,t)$: $df(t)$ì— ë°˜ë¹„ë¡€í•˜ëŠ” ìˆ˜,\nì´ ë¬¸ì„œì˜ ìˆ˜ nì´ ì»¤ì§ˆìˆ˜ë¡ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ $log$(ì¼ë°˜ì ìœ¼ë¡œ ìì—° ë¡œê·¸) ì ìš© $$idf(d,t)=log(\\frac{n}{1+df(t)})$$\nCopy python from sklearn.feature_extraction.text import TfidfVectorizer print(vector.fit_transform(corpus).toarray()) print(ve) 05. Vector Similarity # Cosine Similarity # ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ê°ë„ë¥¼ ì´ìš©í•˜ì—¬ êµ¬í•  ìˆ˜ ìˆëŠ” ë‘ ë²¡í„°ì˜ ìœ ì‚¬ë„ ë‘ ë²¡í„°ì˜ ë°©í–¥ì´ ë™ì¼í•˜ë©´ 1ì˜ ê°’ì„ ê°€ì§€ë©°, ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ìŒ ë¬¸ì„œì˜ ê¸¸ì´ê°€ ë‹¤ë¥¸ ìƒí™©ì—ì„œ ë¹„êµì  ê³µì •í•œ ë¹„êµë¥¼ í•  ìˆ˜ ìˆìŒ Euclidean Distance # ë‹¤ì°¨ì› ê³µê°„ì—ì„œ ë‘ ê°œì˜ ì  $p$ì™€ $q$ê°€ ê°ê° $p=(p_1,p_2,p_3,\u0026hellip;,p_n)$ê³¼ $q=(q_1,q_2,q_3,\u0026hellip;,q_n)$ì˜ ì¢Œí‘œë¥¼ ê°€ì§ˆ ë•Œ\në‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ” ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³µì‹ $$\\sqrt{(q_1-p_1)^2+(q_2-p_2)^2+\u0026hellip;+(q_n-p_n)^2}=\\sqrt{\\Sigma^n_{i=1}(q_i-p_i)^2}$$\nJaccard Similarity # í•©ì§‘í•©ì—ì„œ êµì§‘í•©ì˜ ë¹„ìœ¨ì„ êµ¬í•œë‹¤ë©´ ë‘ ì§‘í•© Aì™€ Bì˜ ìœ ì‚¬ë„ë¥¼ êµ¬í•  ìˆ˜ ìˆìŒ ìì¹´ë“œ ìœ ì‚¬ë„ JëŠ” 0ê³¼ 1ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, ë‘ ì§‘í•©ì´ ë™ì¼í•˜ë©´ 1, ê³µí†µ ì›ì†Œê°€ ì—†ìœ¼ë©´ 0ì˜ ê°’ì„ ê°€ì§ $$J(A,B)=\\frac{|A \\bigcap B|}{|A \\bigcup B|}=\\frac{|A \\bigcap B|}{|A|+|B|-|A \\bigcap B|}$$\n06. Machine Learning # Classification and Regression # Bianry Classification: ë‘ ê°œì˜ ì„ íƒì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹µì„ ì„ íƒ Multi-class Classification: ì„¸ ê°œ ì´ìƒì˜ ì„ íƒì§€ ì¤‘ì—ì„œ ë‹µì„ ì„ íƒ Regression: ì—°ì†ì ì¸ ê°’ì˜ ë²”ìœ„ ë‚´ì—ì„œ ì˜ˆì¸¡ê°’ì„ ë„ì¶œ Learning # Supervised Learning: ì •ë‹µ ë ˆì´ë¸”ê³¼ í•¨ê»˜ í•¨ìŠµ Unsupervised Learning: ë°ì´í„°ì— ë³„ë„ì˜ ë ˆì´ë¸”ì´ ì—†ì´ í•™ìŠµ Self-Supervised Learning: ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ê°€ ì£¼ì–´ì§€ë©´, ëª¨ë¸ì´ í•™ìŠµì„ ìœ„í•´ ìŠ¤ìŠ¤ë¡œ ë ˆì´ë¸”ì„ ìƒì„± Confusion Matrix # ì˜ˆì¸¡ ì°¸ ì˜ˆì¸¡ ê±°ì§“ ì‹¤ì œ ì°¸ TP(ì •ë‹µ) FN(ì˜¤ë‹µ) ì‹¤ì œ ê±°ì§“ FP(ì˜¤ë‹µ) TN(ì •ë‹µ) Precision(ì •ë°€ë„): Trueë¼ê³  ë¶„ë¥˜í•œ ê²ƒ ì¤‘ ì‹¤ì œ Trueì˜ ë¹„ìœ¨, $Precision=\\frac{TP}{TP+FP}$ Recall(ì¬í˜„ìœ¨): ì‹¤ì œ Trueì¸ ê²ƒ ì¤‘ì—ì„œ ëª¨ë¸ì´ Trueë¼ê³  ì˜ˆì¸¡í•œ ê²ƒì˜ ë¹„ìœ¨, $Recall=\\frac{TP}{TP+FN}$ Accuracy(ì •í™•ë„): ì „ì²´ ì˜ˆì¸¡í•œ ë°ì´í„° ì¤‘ ì •ë‹µì„ ë§ì¶˜ ê²ƒì— ëŒ€í•œ ë¹„ìœ¨, $Accuracy=\\frac{TP+TN}{TP+FN+FP+TN}$ Overfitting and Underfitting # Overfitting: í›ˆë ¨ ë°ì´í„°ë¥¼ ê³¼í•˜ê²Œ í•™ìŠµ, í›ˆë ¨ ë°ì´í„°ì— ë¹„í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì˜¤ì°¨ê°€ ì»¤ì§ Underfitting: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì„±ëŠ¥ì´ ì˜¬ë¼ê°ˆ ì—¬ì§€ê°€ ìˆìŒì—ë„ í›ˆë ¨ì„ ëœ í•œ ìƒíƒœ, í›ˆë ¨ ë°ì´í„°ì—ì„œë„ ì •í™•ë„ê°€ ë‚®ìŒ 07. Deep Learning # Perceptron # ì…ë ¥ê°’ $x$, ê°€ì¤‘ì¹˜ $w$, ì¶œë ¥ê°’ $y$ ê°€ì¤‘ì¹˜ì˜ ê°’ì´ í¬ë©´ í´ìˆ˜ë¡ í•´ë‹¹ ì…ë ¥ ê°’ì´ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸ ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ : ê°’ì„ ë³´ë‚´ëŠ” input layerì™€ ê°’ì„ ë°›ì•„ì„œ ì¶œë ¥í•˜ëŠ” output layerë¡œ êµ¬ì„± ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (MLP): ì…ë ¥ì¸µê³¼ ì¶œë ¥ì¸µ ì‚¬ì´ì— hidden layerë¥¼ ì¶”ê°€ FFNN # FFNN(í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§): ì˜¤ì§ ì…ë ¥ì¸µì—ì„œ ì¶œë ¥ì¸µ ë°©í–¥ìœ¼ë¡œ ì—°ì‚°ì´ ì „ê°œë˜ëŠ” ì‹ ê²½ë§ RNN(ìˆœí™˜ ì‹ ê²½ë§): ì€ë‹‰ì¸µì˜ ì¶œë ¥ê°’ì´ ë‹¤ì‹œ ì€ë‹‰ì¸µìœ¼ë¡œ ì…ë ¥ë˜ëŠ” ì‹ ê²½ë§ Activision Function # ì€ë‹‰ì¸µê³¼ ì¶œë ¥ì¸µì˜ ë‰´ëŸ°ì—ì„œ ì¶œë ¥ê°’ì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ Step function, Sigmoid function, ReLU ë“± ë¹„ì„ í˜• í•¨ìˆ˜ì˜ íŠ¹ì„± Loss Function # MSE: ì—°ì†í˜• ë³€ìˆ˜ ì˜ˆì¸¡ Binary Cross-Entropy: ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ì¶œë ¥ Categorical Cross-Entropy: ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì¶œë ¥ Optimizer # Momentum: ê²½ì‚¬ í•˜ê°•ë²•ì— ëª¨ë©˜í…€ì„ ë”í•´ Local Minimumì— ë¹ ì§€ë”ë¼ë„ ë¹ ì ¸ë‚˜ê°ˆ ìˆ˜ ìˆê²Œ í•¨ Adagrad: ê° ë§¤ê°œë³€ìˆ˜ì— ì„œë¡œ ë‹¤ë¥¸ í•™ìŠµë¥ ì„ ì ìš© RMSprop: Adagradê°€ í•™ìŠµì„ ì§„í–‰í• ìˆ˜ë¡ í•™ìŠµë¥ ì´ ì§€ë‚˜ì¹˜ê²Œ ë–¨ì–´ì§€ëŠ” ë‹¨ì ì„ ê°œì„  Adam: RMSpropê³¼ Momentumì„ í•©ì¹œ ë“¯í•œ ë°©ë²•, ë°©í–¥ê³¼ í•™ìŠµë¥  ë‘ ê°€ì§€ë¥¼ ëª¨ë‘ ì¡ê¸° ìœ„í•œ ë°©ë²• Overfitting ë°©ì§€ # ë°ì´í„°ì˜ ì–‘ì„ ëŠ˜ë¦¬ê¸°\në°ì´í„°ì˜ ì–‘ì´ ì ìœ¼ë©´ ë°ì´í„°ì˜ íŠ¹ì • íŒ¨í„´ì´ë‚˜ ë…¸ì´ì¦ˆê¹Œì§€ ì‰½ê²Œ ì•”ê¸°í•´ë²„ë¦¼, Data Augmentation í™œìš© ëª¨ë¸ì˜ ë³µì¡ë„ ì¤„ì´ê¸°\nì¸ê³µ ì‹ ê²½ë§ì˜ ë³µì¡ë„ëŠ” ì€ë‹‰ì¸µì˜ ìˆ˜ë‚˜ ë§¤ê°œë³€ìˆ˜ì˜ ìˆ˜ ë“±ìœ¼ë¡œ ê²°ì • ê°€ì¶©ì¹˜ ê·œì œ ì ìš©í•˜ê¸°\nL1 ê·œì œ(ê°€ì¤‘ì¹˜ì˜ ì ˆëŒ“ê°’ í•©ê³„ë¥¼ ë¹„ìš© í•¨ìˆ˜ì— ì¶”ê°€), L2 ê·œì œ(ëª¨ë“  ê°€ì¤‘ì¹˜ë“¤ì˜ ì œê³±í•©ì„ ë¹„ìš© í•¨ìˆ˜ì— ì¶”ê°€) Dropout\ní•™ìŠµ ì‹œì— ì¸ê³µ ì‹ ê²½ë§ì´ íŠ¹ì • ë‰´ëŸ° ë˜ëŠ” íŠ¹ì • ì¡°í•©ì— ë„ˆë¬´ ì˜ì¡´ì ì´ê²Œ ë˜ëŠ” ê²ƒì„ ë°©ì§€ ê¸°ìš¸ê¸° ì†Œì‹¤ # ê¸°ìš¸ê¸° ì†Œì‹¤: ì—­ì „íŒŒ ê³¼ì •ì—ì„œ ì…ë ¥ì¸µìœ¼ë¡œ ê°ˆ ìˆ˜ë¡ ê¸°ìš¸ê¸°ê°€ ì ì°¨ì ìœ¼ë¡œ ì‘ì•„ì§€ëŠ” í˜„ìƒ ê¸°ìš¸ê¸° í­ì£¼: ê¸°ìš¸ê¸°ê°€ ì ì°¨ ì»¤ì§€ë‹¤ê°€ ê°€ì¤‘ì¹˜ë“¤ì´ ë¹„ì •ìƒì ìœ¼ë¡œ í° ê°’ì´ ë˜ë©´ì„œ ë°œì‚°ë˜ëŠ” ê²½ìš° Gradient Clipping: ê¸°ìš¸ê¸° í­ì£¼ë¥¼ ë§‰ê¸° ìœ„í•´ ì„ê³„ê°’ì„ ë„˜ì§€ ì•Šë„ë¡ ê°’ì˜ í¬ê¸°ë¥¼ ê°ì†Œ Weight Initialization # Xavier Initialization: ê· ë“± ë¶„í¬ ë˜ëŠ” ì •ê·œ ë¶„í¬ë¡œ ì´ˆê¸°í™” í•  ë•Œ ë‘ ê°€ì§€ ê²½ìš°ë¡œ ë‚˜ë‰¨ He Initialization: Xavier ì´ˆê¸°í™”ì™€ ë‹¤ë¥´ê²Œ ë‹¤ìŒ ì¸µì˜ ë‰´ëŸ°ì˜ ìˆ˜ë¥¼ ë°˜ì˜í•˜ì§€ ì•ŠìŒ Batch Normalization # ë‚´ë¶€ ê³µë³€ëŸ‰ ë³€í™”: í•™ìŠµ ê³¼ì •ì—ì„œ ì¸µ ë³„ë¡œ ì…ë ¥ ë°ì´í„° ë¶„í¬ê°€ ë‹¬ë¼ì§€ëŠ” í˜„ìƒ ë°°ì¹˜ ì •ê·œí™”: í•œ ë²ˆì— ë“¤ì–´ì˜¤ëŠ” ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì •ê·œí™”í•˜ëŠ” ê²ƒ ë°°ì¹˜ ì •ê·œí™”ëŠ” ì¶”ê°€ ê³„ì‚°ì„ ë°œìƒì‹œì¼œ ëª¨ë¸ì„ ë³µì¡í•˜ê²Œ í•˜ê¸° ë•Œë¬¸ì— ì˜ˆì¸¡ ì‹œ ì‹¤í–‰ ì‹œê°„ì´ ëŠë ¤ì§€ëŠ” ë‹¨ì  ë„ˆë¬´ ì‘ì€ ë°°ì¹˜ í¬ê¸°ì—ì„œëŠ” ì˜ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë¯¸ë‹ˆ ë°°ì¹˜ í¬ê¸°ì— ì˜ì¡´ì ì„ RNNì€ ê° ì‹œì ë§ˆë‹¤ ë‹¤ë¥¸ í†µê³„ì¹˜ë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì— RNNì— ì ìš©í•˜ê¸° ì–´ë ¤ì›€ Keras API # Sequential API: ë‹¨ìˆœí•˜ê²Œ ì¸µì„ ìŒ“ëŠ” ë°©ì‹, ë‹¤ìˆ˜ì˜ ì…ì¶œë ¥ ë° ì¸µ ê°„ ì—°ì‚°ì„ êµ¬í˜„í•˜ê¸° ì–´ë ¤ì›€ Functional API: ì…ë ¥ì˜ í¬ê¸°(shape)ë¥¼ ëª…ì‹œí•œ ì…ë ¥ì¸µì„ ëª¨ë¸ì˜ ì•ë‹¨ì— ì •ì˜ Subclassing API: Functional APIë¡œë„ êµ¬í˜„í•  ìˆ˜ ì—†ëŠ” ëª¨ë¸ë“¤ë„ êµ¬í˜„ ê°€ëŠ¥ texts_to_matrix() # tokenizer.texts_to_matrix(texts, mode='count'): DTM ìƒì„± tokenizer.texts_to_matrix(texts, mode='binary'): DTMê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ë‹¨ì–´ì˜ ê°œìˆ˜ëŠ” ë¬´ì‹œ tokenizer.texts_to_matrix(texts, mode='tfidf'): TF-IDF í–‰ë ¬ ìƒì„± tokenizer.texts_to_matrix(texts, mode='freq'):\nê° ë¬¸ì„œì—ì„œì˜ ë‹¨ì–´ ë“±ì¥ íšŸìˆ˜ë¥¼ ë¶„ìë¡œ, ë¬¸ì„œì˜ í¬ê¸°ë¥¼ ë¶„ëª¨ë¡œ í•˜ëŠ” í‘œí˜„í•˜ëŠ” ë°©ë²• NNLM # í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§ ì–¸ì–´ ëª¨ë¸, ì‹ ê²½ë§ ì–¸ì–´ ëª¨ë¸ì˜ ì‹œì´ˆë¡œ, RNNLM, BiLM ë“±ìœ¼ë¡œ ë°œì „ ê¸°ì¡´ N-gram ì–¸ì–´ ëª¨ë¸ì€ ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ ê´€ì¸¡í•˜ì§€ ëª»í•˜ë©´ ì–¸ì–´ë¥¼ ì •í™•íˆ ëª¨ë¸ë§í•˜ì§€ ëª»í•˜ëŠ” í¬ì†Œ ë¬¸ì œë¥¼ ê°€ì§ NNLMì€ N-gram ì–¸ì–´ ëª¨ë¸ì²˜ëŸ¼ ì •í•´ì§„ ê°œìˆ˜(window size)ì˜ ë‹¨ì–´ë§Œì„ ì°¸ê³  NNLMì€ Nê°œì˜ input layerì™€ projection layer, hidden layer, output layerë¡œ êµ¬ì„± Projection layerì˜ í¬ê¸°ê°€ Mì¼ ë•Œ, ê° ì…ë ¥ ë‹¨ì–´ë“¤ì€ V x M í¬ê¸°ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ê³¼ ê³±í•´ì§ ì¶©ë¶„í•œ ì–‘ì˜ í›ˆë ¨ ì½”í¼ìŠ¤ë¥¼ í•™ìŠµí•œë‹¤ë©´ ë‹¨ì–´ ê°„ ìœ ì‚¬ë„ë¥¼ êµ¬í•  ìˆ˜ ìˆëŠ” ì„ë² ë”© ë²¡í„°ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŒ 08-01. RNN # ì…ë ¥ê³¼ ì¶œë ¥ì„ ì‹œí€€ìŠ¤ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ëŠ” ì‹œí€€ìŠ¤ ëª¨ë¸ ì€ë‹‰ì¸µì˜ ë…¸ë“œì—ì„œ í™œì„±í™” í•¨ìˆ˜ë¥¼ í†µí•´ ë‚˜ì˜¨ ê²°ê³¼ê°’ì„ ë‹¤ì‹œ ì€ë‹‰ì¸µ ë…¸ë“œì˜ ë‹¤ìŒ ê³„ì‚° ì…ë ¥ìœ¼ë¡œ ë³´ë‚´ëŠ” íŠ¹ì§• ì…€(ë©”ëª¨ë¦¬ ì…€, RNN ì…€): ì€ë‹‰ì¸µì—ì„œ í™œì„±í™” í•¨ìˆ˜ë¥¼ í†µí•´ ê²°ê³¼ë¥¼ ë‚´ë³´ë‚´ëŠ” ì—­í• ì„ í•˜ëŠ” ë…¸ë“œ, ì´ì „ì˜ ê°’ì„ ê¸°ì–µí•˜ëŠ” ì—­í•  Hidden state: í˜„ì¬ ì‹œì ì„ të¼ í•  ë•Œ, ë©”ëª¨ë¦¬ ì…€ì´ ë‹¤ìŒ ì‹œì ì¸ t+1ì˜ ìì‹ ì—ê²Œ ë³´ë‚´ëŠ” ê°’ ì…ë ¥ê³¼ ì¶œë ¥ì˜ ê¸¸ì´ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ê³„í•  ìˆ˜ ìˆì–´ ë‹¤ì–‘í•œ ìš©ë„ë¡œ ì‚¬ìš© ê°€ëŠ¥ one-to-many: í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ì…ë ¥ì— ëŒ€í•´ì„œ ì‚¬ì§„ì˜ ì œëª©ì¸ ì‹œí€€ìŠ¤ë¥¼ ì¶œë ¥í•˜ëŠ” ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‘ì—…ì— ì‚¬ìš© many-to-one: ë‹¨ì–´ ì‹œí€€ìŠ¤ì— ëŒ€í•´ì„œ í•˜ë‚˜ì˜ ì¶œë ¥ì„ í•˜ëŠ” ê°ì„± ë¶„ë¥˜, ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜ ë“±ì— ì‚¬ìš© many-to-many: ì‚¬ìš©ìê°€ ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ ëŒ€ë‹µ ë¬¸ì¥ì„ ì¶œë ¥í•˜ëŠ” ì±—ë´‡ì´ë‚˜ ë²ˆì—­ê¸°ì— ì‚¬ìš© RNN Parameter # í˜„ì¬ ì‹œì  $t$ì—ì„œì˜ hidden stateê°€ $h_t$ë¼ í•  ë•Œ, ë‘ ê°œì˜ ê°€ì¤‘ì¹˜ $W_x$, $W_h$ê°€ í•„ìš” $W_x$ëŠ” ì…ë ¥ì¸µì„ ìœ„í•œ ê°€ì¤‘ì¹˜, $W_h$ëŠ” $t-1$ì˜ hidden stateì¸ $h_{t-1}$ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ì€ë‹‰ì¸µ $h_t=tanh({W_x}{x_t}+{W_h}{h_{t-1}}+b)$, ì¶œë ¥ì¸µ $y_t=f({W_y}{h_t}+b)$ ì¶œë ¥ì¸µì˜ í™œì„±í™” í•¨ìˆ˜ $f$ëŠ” ì´ì§„ ë¶„ë¥˜ì—ì„œ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜, ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ë“± ì‚¬ìš© RNNì˜ ì…ë ¥ $x_t$ëŠ” ë‹¨ì–´ ë²¤í„°ë¡œ ê°„ì£¼, ë‹¨ì–´ ë²¡í„°ì˜ ì°¨ì›ì„ $d$, hidden stateì˜ í¬ê¸°ë¥¼ $D_h$ë¼ í•  ë•Œ,\në©”ëª¨ë¦¬ ì…€ $h_t$ = $tanh({W_h}\\times{h_{t-1}}\\times{W_x}\\times{x_t}+{b})$ $x_t$ $W_x$ $W_h$ $h_{t-1}$ $b$ $({d}\\times{1})$ $({D_h}\\times{d})$ $({D_h}\\times{D_h})$ $({D_h}\\times{1})$ $({D_h}\\times{1})$ Keras RNN # hidden_units: hidden stateì˜ í¬ê¸° (output_dim) timesteps: ì…ë ¥ ì‹œí€€ìŠ¤(ë¬¸ì¥)ì˜ ê¸¸ì´ (input_length) input_dim: ì…ë ¥ì˜ í¬ê¸°, ë‹¨ì–´ ë²¡í„°ì˜ ì°¨ì› RNN ì¸µì€ (batch_size, timesteps, input_dim) í¬ê¸°ì˜ 3D í…ì„œë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ ë©”ëª¨ë¦¬ ì…€ì˜ ìµœì¢… ì‹œì ì˜ hidden stateë§Œ ë¦¬í„´í•  ê²½ìš° (batch_size, output_dim) í¬ê¸°ì˜ 2D í…ì„œ ë°˜í™˜ ë©”ëª¨ë¦¬ ì…€ì˜ ê° ì‹œì (time step)ì˜ hidden state ê°’ë“¤ì„ ëª¨ì•„ ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ ë¦¬í„´í•  ê²½ìš° 3D í…ì„œë¥¼ ë°˜í™˜ return_sequences=True ì˜µì…˜ìœ¼ë¡œ ë°˜í™˜ê°’ ì„¤ì • Copy python from tensorflow.keras.layers import SimpleRNN model = Sequential() model.add(SimpleRNN(hidden_units, input_shape=(timesteps, input_dim))) ë©”ëª¨ë¦¬ ì…€ì—ì„œ hidden state ê³„ì‚°ì€ ë‹¤ìŒê³¼ ê°™ì€ ì½”ë“œë¡œ ë™ì‘\nCopy python hidden_state_t = 0 # ì´ˆê¸° ì€ë‹‰ ìƒíƒœë¥¼ 0(ë²¡í„°)ë¡œ ì´ˆê¸°í™” for input_t in input_length: # ê° ì‹œì ë§ˆë‹¤ ì…ë ¥ì„ ë°›ëŠ”ë‹¤. output_t = tanh(input_t, hidden_state_t) # ê° ì‹œì ì— ëŒ€í•´ì„œ ì…ë ¥ê³¼ ì€ë‹‰ ìƒíƒœë¥¼ ê°€ì§€ê³  ì—°ì‚° hidden_state_t = output_t # ê³„ì‚° ê²°ê³¼ëŠ” í˜„ì¬ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœê°€ ëœë‹¤. Deep RNN # ìˆœí™˜ ì‹ ê²½ë§ì—ì„œ ì€ë‹‰ì¸µì´ 1ê°œ ë” ì¶”ê°€ë˜ì–´ ì€ë‹‰ì¸µì´ 2ê°œì¸ ê¹Šì€ êµ¬ì¡° ì²«ë²ˆì§¸ ì€ë‹‰ì¸µì€ ë‹¤ìŒ ì€ë‹‰ì¸µì´ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— return_sequences=Trueë¥¼ ì„¤ì •í•˜ì—¬ ëª¨ë“  ì‹œì ì„ ì „ë‹¬ Copy python from tensorflow.keras.layers import SimpleRNN model = Sequential() model.add(SimpleRNN(hidden_units, input_shape=(timesteps, input_dim), return_sequences=True)) model.add(SimpleRNN(hidden_units, return_sequences=True)) Bidirectional RNN # tì—ì„œì˜ ì¶œë ¥ê°’ì„ ì˜ˆì¸¡í•  ë•Œ ì´ì „ ì‹œì ì˜ ì…ë ¥ ë¿ ì•„ë‹ˆë¼, ì´í›„ ì‹œì ì˜ ì…ë ¥ ë˜í•œ ì˜ˆì¸¡ ë¹ˆì¹¸ ì±„ìš°ê¸° ë“±ì˜ ë¬¸ì œì—ì„œ ë¯¸ë˜ ì‹œì ì˜ ì…ë ¥ì— íŒíŠ¸ê°€ ìˆê¸° ë•Œë¬¸ì— ì´ì „ê³¼ ì´í›„ì˜ ì‹œì ì„ ëª¨ë‘ ê³ ë ¤ í•˜ë‚˜ì˜ ì¶œë ¥ê°’ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ë‘ ê°œì˜ ë©”ëª¨ë¦¬ ì…€ì„ ì‚¬ìš© ì²« ë²ˆì§¸ ë©”ëª¨ë¦¬ ì…€ì€ ì• ì‹œì ì˜ hidden stateë¥¼ ì „ë‹¬ë°›ì•„ í˜„ì¬ì˜ hidden stateë¥¼ ê³„ì‚° (forward) ë‘ ë²ˆì§¸ ë©”ëª¨ë¦¬ ì…€ì€ ë’¤ ì‹œì ì˜ hidden stateë¥¼ ì „ë‹¬ë°›ì•„ í˜„ì¬ì˜ hidden stateë¥¼ ê³„ì‚° (backward) ì€ë‹‰ì¸µì„ ì¶”ê°€í•˜ë©´ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì–‘ì´ ë§ì•„ì§€ì§€ë§Œ, í›ˆë ¨ ë°ì´í„° ë˜í•œ ë§ì€ ì–‘ì´ í•„ìš” Copy python from tensorflow.keras.layers import Bidirectional model = Sequential() model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim))) 08-02. LSTM # Valina RNN(Simple RNN)ì€ ì¶œë ¥ ê²°ê³¼ê°€ ì´ì „ì˜ ê³„ì‚° ê²°ê³¼ì— ì˜ì¡´í•˜ì—¬ ë¹„êµì  ì§§ì€ ì‹œí€€ìŠ¤ì—ì„œë©´ íš¨ê³¼ë¥¼ ë´„ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œ: time stepì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ ì•ì˜ ì •ë³´ê°€ ë’¤ë¡œ ì¶©ë¶„íˆ ì „ë‹¬ë˜ì§€ ëª»í•˜ëŠ” í˜„ìƒ LSTM(ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬)ì€ ì€ë‹‰ì¸µì˜ ë©”ëª¨ë¦¬ ì…€ì— ì…ë ¥ ê²Œì´íŠ¸, ë§ê° ê²Œì´íŠ¸, ì¶œë ¥ ê²Œì´íŠ¸ë¥¼ ì¶”ê°€í•˜ì—¬\në¶ˆí•„ìš”í•œ ê¸°ì–µì„ ì§€ìš°ê³ , ê¸°ì–µí•´ì•¼í•  ê²ƒë“¤ì„ ê²°ì • ì „í†µì ì¸ RNNì—ì„œ cell state $C_t$ë¥¼ ì¶”ê°€í•˜ì—¬ ê¸´ ì‹œí€€ìŠ¤ì˜ ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ”ë° íƒì›”í•œ ì„±ëŠ¥ cell state ë˜í•œ ì´ì „ ì‹œì ì˜ cell stateê°€ ë‹¤ìŒ ì‹œì ì˜ cell stateë¥¼ êµ¬í•˜ê¸° ìœ„í•œ ì…ë ¥ìœ¼ë¡œì„œ ì‚¬ìš© ì…ë ¥ ê²Œì´íŠ¸: í˜„ì¬ ì •ë³´ë¥¼ ê¸°ì–µí•˜ê¸° ìœ„í•œ ê²Œì´íŠ¸ ì‚­ì œ ê²Œì´íŠ¸: ê¸°ì–µì„ ì‚­ì œí•˜ê¸° ìœ„í•œ ê²Œì´íŠ¸, ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ë°˜í™˜ê°’ì´ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë§ì€ ì •ë³´ê°€ ì‚­ì œ ì…€ ìƒíƒœ: ì‚­ì œ ê²Œì´íŠ¸ì—ì„œ ì¼ë¶€ ê¸°ì–µì„ ìƒì€ ìƒíƒœ, ì…ë ¥ ê²Œì´íŠ¸ì—ì„œ ì„ íƒëœ ê¸°ì–µì„ ì‚­ì œ ê²Œì´íŠ¸ì˜ ê²°ê³¼ê°’ê³¼ ë”í•¨ ì‚­ì œ ê²Œì´íŠ¸ëŠ” ì´ì „ ì‹œì ì˜ ì…ë ¥ì„ ì–¼ë§ˆë‚˜ ë°˜ì˜í• ì§€ ì˜ë¯¸, ì…ë ¥ ê²Œì´íŠ¸ëŠ” í˜„ì¬ ì‹œì ì˜ ì…ë ¥ì„ ì–¼ë§ˆë‚˜ ë°˜ì˜í• ì§€ ê²°ì • ì¶œë ¥ ê²Œì´íŠ¸: í˜„ì¬ ì‹œì  $t$ì˜ hidden stateë¥¼ ê²°ì •í•˜ëŠ” ì¼ì— ì‚¬ìš© 08-03. GRU # LSTMì˜ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œì— ëŒ€í•œ í•´ê²°ì±…ì„ ìœ ì§€í•˜ë©´ì„œ, hidden stateë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³„ì‚°ì„ ê°ì†Œ GRUëŠ” ì—…ë°ì´íŠ¸ ê²Œì´íŠ¸ì™€ ë¦¬ì…‹ ê²Œì´íŠ¸ë¡œ êµ¬ì„± ë°ì´í„°ì˜ ì–‘ì´ ì ì„ ë•ŒëŠ” ë§¤ê°œ ë³€ìˆ˜ì˜ ì–‘ì´ ì ì€ GRUê°€ ìœ ë¦¬, ë°˜ëŒ€ì˜ ê²½ìš°ì—” LSTMì´ ìœ ë¦¬ 08-04. Keras RNN and LSTM # ì…ë ¥ ìƒì„± # train_Xê°€ 2D í…ì„œì˜ í˜•íƒœì¼ ê²½ìš° batch_size 1ì„ ì¶”ê°€í•´ 3D í…ì„œë¡œ ë³€ê²½ Copy python train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]] train_X = np.array(train_X, dtype=np.float32) print(train_X.shape) # (1, 4, 5) SimpeRNN # return_sequences=Falseì¼ ê²½ìš° 2D í…ì„œ ë°˜í™˜ return_sequences=Trueì¼ ê²½ìš° timestepsë¥¼ í¬í•¨í•˜ëŠ” 3D í…ì„œ ë°˜í™˜ return_state=Trueì¼ ê²½ìš° return_sequencesì— ê´€ê³„ì—†ì´ ë§ˆì§€ë§‰ ì‹œì ì˜ hidden state ì¶œë ¥ Copy python rnn = SimpleRNN(3) hidden_state = rnn(train_X) # shape(1, 3) Copy python rnn = SimpleRNN(3, return_sequences=True) hidden_states = rnn(train_X) # shape(1, 4, 3) Copy python rnn = SimpleRNN(3, return_sequences=True, return_state=True) hidden_states, last_state = rnn(train_X) # shape(1, 4, 3), shape(1, 3) LSTM # return_state=Trueì¼ ê²½ìš° ë§ˆì§€ë§‰ cell stateë¥¼ í¬í•¨í•œ ì„¸ ê°œì˜ ê²°ê³¼ë¥¼ ë°˜í™˜ Copy python lstm = LSTM(3, return_sequences=False, return_state=True) hidden_state, last_state, last_cell_state = lstm(train_X) # each shape(1, 3) Bidirectional LSTM # ì •ë°©í–¥ê³¼ ì—­ë°©í–¥ì— ëŒ€í•œ hidden stateì™€ cell stateë¥¼ ë°˜í™˜ return_sequences=Falseì¼ ê²½ìš° ì •ë°©í–¥ LSTMì˜ ë§ˆì§€ë§‰ ì‹œì  hidden stateì™€\nì—­ë°©í–¥ LSTMì˜ ì²«ë²ˆì§¸ ì‹œì  hidden stateê°€ ì—°ê²°ëœ ì±„ ë°˜í™˜ return_sequences=Trueì¼ ê²½ìš° ê°ê°ì˜ ìˆœì„œ ë§ê²Œ ì—°ê²°ëœ hidden state ë°˜í™˜ Copy python bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, \\ kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init)) hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X) # shape(1, 6), shape(1, 3), shape(1, 3) 08-05. RNNLM # NNLMê³¼ ë‹¬ë¦¬ time stepì„ ë„ì…í•˜ì—¬ ì…ë ¥ì˜ ê¸¸ì´ê°€ ê³ ì •ë˜ì§€ ì•ŠëŠ” ì–¸ì–´ ëª¨ë¸ Teaching Forcing: í…ŒìŠ¤íŠ¸ ê³¼ì •ì—ì„œ RNN ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ë•Œ ì‚¬ìš©í•˜ëŠ” í›ˆë ¨ ê¸°ë²•,\nëª¨ë¸ì´ t ì‹œì ì—ì„œ ì˜ˆì¸¡í•œ ê°’ì„ t+1 ì‹œì ì— ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì‹¤ì œ ì•Œê³  ìˆëŠ” ì •ë‹µ(t ì‹œì ì˜ ë ˆì´ë¸”)ì„ ì‚¬ìš© í•œ ë²ˆ ì˜ëª» ì˜ˆì¸¡í•˜ë©´ ë’¤ì—ì„œì˜ ì˜ˆì¸¡ê°€ì§€ ì˜í–¥ì„ ë¯¸ì³ í›ˆë ¨ ì‹œê°„ì´ ëŠë ¤ì§€ê¸° ë•Œë¬¸ì— êµì‚¬ ê°•ìš”ë¥¼ ì‚¬ìš© í›ˆë ¨ ê³¼ì • ë™ì•ˆ í™œì„±í™” í•¨ìˆ˜ë¡œëŠ” softmax í•¨ìˆ˜, ì†ì‹¤ í•¨ìˆ˜ë¡œëŠ” cross-entropy í•¨ìˆ˜ë¥¼ ì‚¬ìš© one-hot vector $x_t$ë¥¼ ì…ë ¥ë°›ìœ¼ë©´ NNLMì—ì„œì™€ ë™ì¼í•œ embedding layerë¥¼ ê±°ì³\n${V}\\times{M}$ í¬ê¸°ì˜ embedding vectorë¡œ ë³€í™˜, $e_t=lookup(x_t)$ ì´í›„ RNNê³¼ ë™ì¼í•œ ê³¼ì •ì„ ê±°ì³ $\\hat{y_t}$ë¥¼ ë°˜í™˜, $h_t=\\tanh({W_x}{e_t}+{W_h}{h_{t-1}}+b)$ $\\hat{y}_t$ì˜ ê° ì°¨ì› ì•ˆì—ì„œì˜ ê°’ì€ $\\hat{y}_t$ì˜ jë²ˆì§¸ ì¸ë±ìŠ¤ê°€ ê°€ì§„ 0ê³¼ 1ì‚¬ì´ì˜ ê°’ì´ jë²ˆì§¸ ë‹¨ì–´ê°€ ë‹¤ìŒ ë‹¨ì–´ì¼ í™•ë¥  08-06. Text Generation using RNN # ë°ì´í„° ì „ì²˜ë¦¬ # Copy python # ì›ë³¸ í•œêµ­ì–´ ë¬¸ì¥ text = \u0026#34;\u0026#34;\u0026#34;ê²½ë§ˆì¥ì— ìˆëŠ” ë§ì´ ë›°ê³  ìˆë‹¤\\n ê·¸ì˜ ë§ì´ ë²•ì´ë‹¤\\n ê°€ëŠ” ë§ì´ ê³ ì™€ì•¼ ì˜¤ëŠ” ë§ì´ ê³±ë‹¤\\n\u0026#34;\u0026#34;\u0026#34; Copy python # ë‹¨ì–´ ì§‘í•© ìƒì„± tokenizer = Tokenizer() tokenizer.fit_on_texts([text]) vocab_size = len(tokenizer.word_index) + 1 print(\u0026#39;ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° : %d\u0026#39; % vocab_size) # 12 Copy python # ê° ë¼ì¸ë§ˆë‹¤ texts_to_sequences() í•¨ìˆ˜ë¥¼ ì ìš©í•´ì„œ í›ˆë ¨ ë°ì´í„° ìƒì„± print(sequences) [[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]] Copy python # íŒ¨ë”© í›„ ë¼ë²¨ ë¶„ë¦¬ (ê°€ì¥ ìš°ì¸¡ì— ìˆëŠ” ë‹¨ì–´, [ê²½ë§ˆì¥ì—, ìˆëŠ”]ì—ì„œ \u0026#39;ìˆëŠ”\u0026#39; ë“±ì„ ë¼ë²¨ë¡œ ì§€ì •) sequences = pad_sequences(sequences, maxlen=max_len, padding=\u0026#39;pre\u0026#39;) sequences = np.array(sequences) X = sequences[:,:-1] y = sequences[:,-1] Copy python # ë¼ë²¨ì— ëŒ€í•´ì„œ one-hot encoding ìˆ˜í–‰ y = to_categorical(y, num_classes=vocab_size) RNN ëª¨ë¸ ì„¤ê³„ # many-to-one êµ¬ì¡°ì˜ RNNì„ ì‚¬ìš© ëª¨ë“  ê°€ëŠ¥í•œ ë‹¨ì–´ ì¤‘ ë§ˆì§€ë§‰ ì‹œì ì—ì„œ í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œ ìˆ˜í–‰ í™œì„±í™” í•¨ìˆ˜ë¡œëŠ” softmax í•¨ìˆ˜, ì†ì‹¤ í•¨ìˆ˜ë¡œëŠ” cross-entropy í•¨ìˆ˜ ì‚¬ìš© ì²« ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, në²ˆ ë™ì•ˆ ì˜ˆì¸¡ì„ ë°˜ë³µí•˜ë©´ì„œ í˜„ì¬ ë‹¨ì–´ì™€ ë¬¸ì¥ì— ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ ì €ì¥ Copy python embedding_dim = 10 hidden_units = 32 model = Sequential() model.add(Embedding(vocab_size, embedding_dim)) model.add(SimpleRNN(hidden_units)) model.add(Dense(vocab_size, activation=\u0026#39;softmax\u0026#39;)) model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(X, y, epochs=200, verbose=2) LSTM ëª¨ë¸ ì„¤ê³„ # ë‰´ìš• íƒ€ì„ì¦ˆ ê¸°ì‚¬ ì œëª© ë°ì´í„° ì „ì²˜ë¦¬ (ë‹¨ì–´ ì§‘í•© í¬ê¸° 3494, ìƒ˜í”Œ ìµœëŒ€ ê¸¸ì´ 24) RNNê³¼ ë™ì¼í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  LSTM ëª¨ë¸ ì„¤ê³„, ì˜ˆì¸¡ ê³¼ì • ë˜í•œ ë™ì¼ Copy python embedding_dim = 10 hidden_units = 128 model = Sequential() model.add(Embedding(vocab_size, embedding_dim)) model.add(LSTM(hidden_units)) model.add(Dense(vocab_size, activation=\u0026#39;softmax\u0026#39;)) model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(X, y, epochs=200, verbose=2) 08-07. Char RNN # ì…ì¶œë ¥ì˜ ë‹¨ìœ„ë¥¼ word-levelì—ì„œ character-levelë¡œ ë³€ê²½í•œ RNN ë¬¸ì ë‹¨ìœ„ë¥¼ ì…ì¶œë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— embedding layerë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ ì´ìƒí•œ ë‚˜ë¼ì˜ ì•¨ë¦¬ìŠ¤ ë°ì´í„° ì‚¬ìš© (ë¬¸ìì—´ ê¸¸ì´ 159484, ë¬¸ì ì§‘í•© í¬ê¸° 56) í›ˆë ¨ ë°ì´í„°ì— appleì´ë¼ëŠ” ì‹œí€€ìŠ¤ê°€ ìˆê³  ì…ë ¥ì˜ ê¸¸ì´ê°€ 4ì¼ ë•Œ, \u0026lsquo;appl\u0026rsquo;ì„ ì…ë ¥í•˜ë©´ \u0026lsquo;pple\u0026rsquo;ì„ ì˜ˆì¸¡í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ train_X.shape(2658, 60, 56), train_y.shape(2658, 60, 56) Char RNN ëª¨ë¸ ì„¤ê³„ # Copy python hidden_units = 256 model = Sequential() model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True)) model.add(LSTM(hidden_units, return_sequences=True)) model.add(TimeDistributed(Dense(vocab_size, activation=\u0026#39;softmax\u0026#39;))) model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(train_X, train_y, epochs=80, verbose=2) "},{"id":74,"href":"/blog/2022-06-19/","title":"2022-06-19 Log","section":"Posts","content":"1. í–‰ë ¬ # feature 1 feature 2 1 5 3 4 5 2 1-1. í–‰ë ¬ì˜ ìš”ì†Œ # í–‰(row)ê³¼ ì—´(column)ë¡œ êµ¬ì„± ìŠ¤ì¹¼ë¼(scalar): í–‰ë ¬ì„ êµ¬ì„±í•˜ëŠ” ìš”ì†Œì¸ ê° ìˆ«ì, $a_{ij}$ ($i$: í–‰ ë²ˆí˜¸, $j$: ì—´ ë²ˆí˜¸) ë²¡í„°(vector): ìŠ¤ì¹¼ë¼ì˜ ì§‘í•©, í¬ê¸°ì™€ ë°©í–¥ì„ ëª¨ë‘ ê°€ì§, í–‰ë²¡í„° ë˜ëŠ” ì—´ë²¡í„°ë¡œ í‘œì‹œ í–‰ë ¬(matrix): í–‰ë²¡í„°ì˜ ì§‘í•© (ë˜ëŠ” ì—´ë²¡í„°ì˜ ì§‘í•©) í…ì„œ(tensor): 2ì°¨ì›ìœ¼ë¡œ êµ¬ì„±ëœ í–‰ë ¬ì´ ì•„ë‹Œ nì°¨ì›ìœ¼ë¡œ ì¼ë°˜í™”í•œ í–‰ë ¬ 1-2. í–‰ë ¬ì˜ ì¢…ë¥˜ # ëŒ€ê° í–‰ë ¬(diagonal matrix): ëŒ€ê° ì›ì†Œ ì´ì™¸ì˜ ëª¨ë“  ì„±ë¶„ì´ 0ì¸ í–‰ë ¬ ë‹¨ìœ„ í–‰ë ¬(identity matrix): ì£¼ ëŒ€ê°ì„ ì˜ ì›ì†Œê°€ ëª¨ë‘ 1ì´ë©° ë‚˜ë¨¸ì§€ëŠ” 0ì¸ ì •ì‚¬ê° í–‰ë ¬ í–‰ë ¬ì„ ëŒ€ê° í–‰ë ¬($D$)ì´ë‚˜ ë‹¨ìœ„ í–‰ë ¬($I$)ë¡œ ë³€í™˜ ì‹œ ì—°ì‚°ëŸ‰ì„ í¬ê²Œ ì¤„ì´ëŠ” íš¨ê³¼ ì „ì¹˜ í–‰ë ¬(transposed matrix): ê¸°ì¡´ í–‰ë ¬ì˜ í–‰ê³¼ ì—´ì„ ë°”ê¾¸ëŠ” í–‰ë ¬, $a_{ij} \\rightarrow a_{ji}$ 1-3. í–‰ë ¬ì˜ ì—°ì‚° # í–‰ë ¬ì˜ ë§ì…ˆ, ëº„ì…ˆ: ì—°ì‚° ëŒ€ìƒì´ ë˜ëŠ” í–‰ë ¬ì˜ í–‰ ë²ˆí˜¸ì™€ ì—´ ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ëŠ” ì›ì†Œë¼ë¦¬ ê³„ì‚° í–‰ë ¬ì˜ ìŠ¤ì¹¼ë¼ê³±: í–‰ë ¬ì„ êµ¬ì„±í•˜ëŠ” ëª¨ë“  ì›ì†Œì— ìŠ¤ì¹¼ë¼ë¥¼ ê³±í•¨ í–‰ë ¬ê³±: $AB_{ij}=a_{i1}b_{1j}+a_{i2}b_{2j}+\u0026hellip;+a_{ir}b_{rj}$, í–‰ë ¬ $A$ì˜ ì—´ í¬ê¸°ì™€ í–‰ë ¬ $B$ì˜ í–‰ í¬ê¸°ê°€ ê°™ì•„ì•¼ ê°€ëŠ¥ í–‰ë ¬ì˜ ì›ì†Œê³±: ì°¨ì›ì´ ë™ì¼í•œ ë‘ í–‰ë ¬ì˜ ë™ì¼ ìœ„ì¹˜ ì›ì†Œë¥¼ ì„œë¡œ ê³±í•¨, ë”¥ëŸ¬ë‹ ìµœì í™” ê´€ë ¨ ì•Œê³ ë¦¬ì¦˜ì— ìì£¼ ì‚¬ìš© í–‰ë ¬ì‹(determinant): í–‰ë ¬ì˜ íŠ¹ì„±ì„ í•˜ë‚˜ì˜ ìˆ«ìë¡œ í‘œí˜„, í–‰ë ¬ì„ êµ¬ì„±í•˜ê³  ìˆëŠ” ë²¡í„°ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ë„í˜•ì˜ ë¶€í”¼ë¥¼ ê³„ì‚° ì—­í–‰ë ¬(inverse matrix): í–‰ë ¬ $A$ì— ëŒ€í•´ì„œ $AB=I$ë¥¼ ë§Œì¡±í•˜ëŠ” í–‰ë ¬ $B$ ($A^{-1}$ë¡œ í‘œê¸°) 2. ë‚´ì  # $\u0026lt;u,v\u0026gt;=uã†v=u_1v_1+u_2v_2+\u0026hellip;+u_nv_n$ ê° ë²¡í„°ì˜ ìš”ì†Œë¥¼ ì„œë¡œ ê³±í•œ í›„ ë”í•¨ ë²¡í„°ì˜ ê¸¸ì´(norm)ë¥¼ êµ¬í•˜ê±°ë‚˜ ë²¡í„° ì‚¬ì´ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŒ ë‚´ì ì„ í†µí•´ ë‘ ë²¡í„° ì‚¬ì´ì˜ ê°ë„ë¥¼ ì¶”ì • ê°€ëŠ¥ (ë‚´ì ì´ ì–‘ìˆ˜ë©´ ì˜ˆê°, ë‚´ì ì´ ìŒìˆ˜ë©´ ë‘”ê°) 2-1. ë²¡í„°ì˜ ê¸¸ì´ # ë²¡í„° $u$ì˜ ê¸¸ì´ëŠ” $||u||$ë¡œ í‘œê¸° $u=(u_1,u_2,â‹¯,u_n)$ì¼ ë•Œ, $||u||=\\sqrt{u_1^2+u_2^2+â‹¯+u_n^2}$ ìœ„ ì‹ì€ í”¼íƒ€ê³ ë¼ìŠ¤ì˜ ì •ë¦¬ë¥¼ ì¼ë°˜í™”í•œ ê²ƒ ë²¡í„°ì˜ ê¸¸ì´ë¥¼ í†µí•´ $x$ ì¢Œí‘œë¥¼ $||u||\\cos(\\theta)$, $y$ ì¢Œí‘œë¥¼ $||u||\\sin(\\theta)$ë¡œ í‘œì‹œ ë‚´ì ê°’ $uã†v=||u||||v||\\cos(\\theta)$ ë²¡í„° $u$ë¥¼ ë²¡í„° $v$ì— ì •ì‚¬ì˜í•œ ë²¡í„°ì˜ ê¸¸ì´ $||proj_vu||=||u||\\cos(\\theta)$ $uã†v=||u||||v||\\cos(\\theta)=(||v||)\\times(||u||\\cos(\\theta))$ 3. ì„ í˜• ë³€í™˜ # ë‘ ë²¡í„° ê³µê°„ ì‚¬ì´ì˜ í•¨ìˆ˜ ì¢Œí‘œ í‰ë©´ ìƒ ë²¡í„°ë¥¼ í™•ëŒ€, ì¶•ì†Œ, íšŒì „, ë°˜ì‚¬í•˜ëŠ” ê²ƒì€ ëª¨ë‘ ë³€í™˜ 4. ë­í¬, ì°¨ì› # 4-1. ë²¡í„° ê³µê°„, ê¸°ì € # ë²¡í„° ê³µê°„(vector space): ë²¡í„° ì§‘í•©ì´ ì¡´ì¬í•  ë•Œ, í•´ë‹¹ ë²¡í„°ë“¤ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆëŠ” ê³µê°„ ê¸°ì €(basis): ë²¡í„° ê³µê°„ì„ ìƒì„±í•˜ëŠ” ì„ í˜• ë…ë¦½ì¸ ë²¡í„°ë“¤ ë¶€ë¶„ ê³µê°„(subspace): ë²¡í„° ê³µê°„ì˜ ì¼ë¶€ë¶„, ì „ì²´ ë²¡í„° ì§‘í•©ì˜ ë¶€ë¶„ ì§‘í•© 2ê°œì˜ ê¸°ì € ë²¡í„° ì§‘í•© $S$ì— ì†í•˜ëŠ” ë¶€ë¶„ ê³µê°„ì„ $W$ë¼ í•  ë•Œ, $W=span(S)$ ì˜ ê´€ê³„ë¥¼ ê°€ì§ 4-2. ë­í¬ì™€ ì°¨ì› # ì°¨ì›(dimension): ê¸°ì € ë²¡í„°ì˜ ê°œìˆ˜, ë²¡í„° ê³µê°„ì„ êµ¬ì„±í•˜ëŠ”ë° í•„ìš”í•œ ìµœì†Œí•œì˜ ë²¡í„° ê°œìˆ˜ ë­í¬(rank): ì—´ë²¡í„°ì— ì˜í•´ spanëœ ë²¡í„° ê³µê°„ì˜ ì°¨ì› ì˜ê³µê°„(numm space): í–‰ë ¬ $A$ê°€ ì£¼ì–´ì§ˆ ë•Œ $Ax=0$ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë“  ë²¡í„° $x$ì˜ ì§‘í•© 4-3. ì§êµ í–‰ë ¬ # ì§êµ í–‰ë ¬(orthogonal matrix): ì–´ë–¤ í–‰ë ¬ì˜ í–‰ë²¡í„°ì™€ ì—´ë²¡í„°ê°€ ìœ í´ë¦¬ë“œ ê³µê°„ì˜ ì •ê·œ ì§êµ ê¸°ì €ë¥¼ ì´ë£¨ëŠ” í–‰ë ¬ $AA^T=A^TA=I$ ì§êµ í–‰ë ¬ $A$ì˜ ì—­í–‰ë ¬ì€ ìì‹ ì˜ ì „ì¹˜ í–‰ë ¬, $A^T=A^{-1}$ "},{"id":75,"href":"/blog/programmers-problems-60059/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 60059] ìë¬¼ì‡ ì™€ ì—´ì‡  (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://programmers.co.kr/learn/courses/30/lessons/60059 ê°œìš” # numpy ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì¤‘ë³µ ìˆœì—´ì„ ì‚¬ìš©í•´ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ ì¡°ê±´ # 2ì°¨ì› ë°°ì—´ì¸ ì—´ì‡ (M)ë¥¼ íšŒì „í•˜ê±°ë‚˜ ì´ë™í•´ 2ì°¨ì› ë°°ì—´ì¸ ìë¬¼ì‡ (N)ì— ë§ëŠ”ì§€ ì—¬ë¶€ë¥¼ ë°˜í™˜í•˜ëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ í•´ì„¤ # 2ì°¨ì› ë°°ì—´ì„ numpy.ndarray í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ë©´ íšŒì „ ë° ì´ë™ ì—°ì‚°ì„ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤. 90ë„ ë‹¨ìœ„ë¡œ 4ë²ˆ íšŒì „ëœ ê°ê°ì˜ ëª©ë¡ì„ êµ¬í•˜ê³  ìƒí•˜ì¢Œìš° ì´ë™ì„ ìœ„í•´ ë°”ê¹¥ìª½ì— 0ìœ¼ë¡œ ì±„ì›Œì§„ paddingì„ ì¶”ê°€í•œë‹¤. paddingì´ ì±„ì›Œì§„ N+M-1í¬ê¸°ì˜ 2ì°¨ì› ë°°ì—´ì— ëŒ€í•´ ìë¬¼ì‡  í¬ê¸°ë§Œí¼ì˜ ë¶€ë¶„ë§Œ ì˜ë¼ë‚´ì–´ ìë¬¼ì‡ ì˜ êµ¬ë©ê³¼ ë¹„êµí•œë‹¤. OR ì—°ì‚° ì‹œ ìë¬¼ì‡ ê°€ 1ë¡œ ì±„ì›Œì§€ê³  ì—´ì‡ ì™€ ìë¬¼ì‡  ì‚¬ì´ì— ê²¹ì¹˜ëŠ” ë¶€ë¶„ì´ ì—†ë‹¤ë©´ ì—´ì‡ ê°€ ìë¬¼ì‡ ì— ë§ë‹¤ê³  íŒë‹¨í•œë‹¤. ì‹œí–‰ì°©ì˜¤ # ì—´ì‡ ì˜ í¬ê¸°ê°€ ìë¬¼ì‡ ì˜ í¬ê¸°ë³´ë‹¤ ì‘ì„ ê²½ìš°ë¥¼ ê³ ë ¤í•˜ì§€ ëª»í•˜ê³  ë‘˜ì˜ ì‚¬ì´ì¦ˆë¥¼ ë§ì¶”ëŠ” ê³¼ì •ì„ ë¬´ì‹œí•´ ì—ëŸ¬ê°€ ìƒê²¼ë‹¤. ì²˜ìŒì—” 0ìœ¼ë¡œ ì±„ì›Œì§„ ë‹¨ì¼ í–‰ ë˜ëŠ” ì—´ê³¼ concatenate ì—°ì‚°ì„ ì§„í–‰í•´ ì—´ì‡ ë¥¼ ì•„ë˜ìª½ê³¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œë§Œ ì´ë™í–ˆëŠ”ë°,\nê·¸ ë°˜ëŒ€ì˜ ê²½ìš°ë¥¼ ê³ ë ¤í•˜ì§€ ëª»í•´ì„œ ì—ëŸ¬ê°€ ìƒê²¼ë‹¤. ì´í›„ paddingì„ ì‚¬ìš©í•˜ëŠ” ì½”ë“œë¡œ ë³€ê²½í–ˆë‹¤. í†µê³„í•™ì  ì§€ì‹ì´ ë¶€ì¡±í•´ ì¸ë±ìŠ¤ ëª©ë¡ì— ëŒ€í•´ ì¤‘ë³µ ì¡°í•© ì—°ì‚°ì„ í–ˆì—ˆëŠ”ë° ì˜ëª»ë¨ì„ ì¸ì§€í•˜ê³  ì¤‘ë³µ ìˆœì—´ë¡œ ë³€ê²½í–ˆë‹¤. ì—´ì‡ ì™€ ìë¬¼ì‡ ì˜ ëŒê¸°ê°€ ë§Œë‚˜ì„  ì•ˆëœë‹¤ëŠ” ë¶€ë¶„ì„ ì²˜ë¦¬í•˜ì§€ ì•Šì•„ íŠ¹ì • ì¼€ì´ìŠ¤ì— ëŒ€í•´ ì‹¤íŒ¨ê°€ ë°œìƒí•˜ëŠ” ì´ìœ ë¥¼ ì¸ì§€í•˜ì§€ ëª»í–ˆë‹¤.\nXOR ì—°ì‚°ë„ í•˜ë‚˜ì˜ ë°©ë²•ì¼ ìˆ˜ ìˆì§€ë§Œ ëŒ€ì‹ ì— ë‘ ë°°ì—´ì˜ í•©ì„ ì‚¬ìš©í•´ ì¤‘ë³µë˜ëŠ” ë¶€ë¶„ì„ íŒë‹¨í–ˆë‹¤. í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ê°€ ë°±ì¤€ì²˜ëŸ¼ NumPy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì§€ì›í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ë§¤ìš° ë‚œí•´í•œ ë¬¸ì œì˜€ì„í…Œì§€ë§Œ,\në‹¤í–‰íˆ NumPy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ ë¹„êµì  ë‹¨ìˆœí•œ ë°©ë²•ìœ¼ë¡œ í’€ ìˆ˜ ìˆì—ˆë‹¤. í•´ì„¤ ì½”ë“œ # Copy python import numpy as np from itertools import product def solution(key, lock): key, lock = np.array(key), np.array(lock) rotated_keys = [np.pad(np.rot90(key, i),len(lock)-1) for i in range(4)] index_list = list(range(len(rotated_keys[0])-len(lock)+1)) for rotated_key in rotated_keys: for i, j in list(product(index_list, index_list)): key = rotated_key[i:i+len(lock),j:j+len(lock)] if (0 not in np.logical_or(key,lock)) and (2 not in (key + lock)): return True return False "},{"id":76,"href":"/blog/programmers-problems-81301/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 81301] ìˆ«ì ë¬¸ìì—´ê³¼ ì˜ë‹¨ì–´ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://programmers.co.kr/learn/courses/30/lessons/81301 ê°œìš” # ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•´ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ ì¡°ê±´ # ì¼ë¶€ ìˆ«ìê°€ ì˜ë‹¨ì–´ë¡œ ë³€í™˜ëœ ë¬¸ìì—´ì„ ì›ë˜ì˜ ìˆ«ìë¡œ ë˜ëŒë ¤ ë°˜í™˜í•˜ëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ í•´ì„¤ # ê°ê°ì˜ ì˜ë‹¨ì–´ì— ëŒ€í•œ ìˆ«ì ë§µê³¼ ë¬¸ìì—´ì˜ replace í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‹¤. í•´ì„¤ ì½”ë“œ # Copy python def solution(s): answer = s word_dict = {\u0026#39;zero\u0026#39;:\u0026#39;0\u0026#39;,\u0026#39;one\u0026#39;:\u0026#39;1\u0026#39;,\u0026#39;two\u0026#39;:\u0026#39;2\u0026#39;,\u0026#39;three\u0026#39;:\u0026#39;3\u0026#39;, \u0026#39;four\u0026#39;:\u0026#39;4\u0026#39;,\u0026#39;five\u0026#39;:\u0026#39;5\u0026#39;,\u0026#39;six\u0026#39;:\u0026#39;6\u0026#39;,\u0026#39;seven\u0026#39;:\u0026#39;7\u0026#39;, \u0026#39;eight\u0026#39;:\u0026#39;8\u0026#39;,\u0026#39;nine\u0026#39;:\u0026#39;9\u0026#39;} for key, value in word_dict.items(): answer = answer.replace(key, value) return int(answer) "},{"id":77,"href":"/blog/programmers-problems-17676/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 17676] ì¶”ì„ íŠ¸ë˜í”½ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://programmers.co.kr/learn/courses/30/lessons/17676 ê°œìš” # datetime ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ ì¡°ê±´ # íŠ¸ë˜í”½ ì²˜ë¦¬ ì¢…ë£Œ ì‹œê°„ ë° ì²˜ë¦¬ ì‹œê°„ì´ ì§ì§€ì–´ì§„ ë¡œê·¸ ë¬¸ìì—´ì„ í•´ì„í•˜ì—¬ ì´ˆë‹¹ ìµœëŒ€ ì²˜ë¦¬ëŸ‰ì„ ë°˜í™˜í•˜ëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ í•´ì„¤ # datetimeê³¼ timedelta ëª¨ë“ˆì„ í™œìš©í•˜ì—¬ ê°ê°ì˜ íŠ¸ë˜í”½ ë¡œê·¸ì— ëŒ€í•œ ì‹œì‘ê³¼ ë ì‹œê°„ì„ ê³„ì‚°í•œë‹¤. íŠ¸ë˜í”½ì˜ ì‹œì‘ ë˜ëŠ” ëì„ 1ì´ˆ êµ¬ê°„ì˜ ì‹œì‘ìœ¼ë¡œ ì •ì˜í•˜ê³  í•´ë‹¹ êµ¬ê°„ì—ì„œ ì‹œì‘ëê±°ë‚˜ ì§„í–‰ ì¤‘ì¸ íŠ¸ë˜í”½ ìˆ˜ë¥¼ í•©ì‚°í•œë‹¤. í•©ì‚°ëœ íŠ¸ë˜í”½ ìˆ˜ ì¤‘ì—ì„œ ìµœëŒ“ê°’ì„ ì´ˆë‹¹ ìµœëŒ€ ì²˜ë¦¬ëŸ‰ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ ë°˜í™˜í•œë‹¤. í•œê³„ # íŠ¸ë˜í”½ ë¡œê·¸ë¥¼ ì‹œì‘ ì‹œê°„ê³¼ ë ì‹œê°„ìœ¼ë¡œ ë¶„ë¦¬í•˜ì§€ ì•Šê³  ì‹œê°„ ë²”ìœ„ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤ë©´,\nêµ³ì´ 2N ê¸¸ì´ì˜ ë°˜ë³µë¬¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  êµì§‘í•© ì—°ì‚°ì„ ì‚¬ìš©í•´ì„œ ì‹œê°„ ë³µì¡ë„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆì—ˆì„ ê²ƒì´ë‹¤. í•´ì„¤ ì½”ë“œ # Copy python from datetime import datetime, timedelta def solution(lines): answer = 0 lines = sorted(map(interpret_log, lines)) delta = timedelta(seconds=1) for start in sum(lines, []): t = sum([check_time_range(time_range, start, start+delta) for time_range in lines]) answer = max(t, answer) start += delta return answer def interpret_log(line): line = line.split() line = [word.split(s) for word, s in zip(line, [\u0026#39;-\u0026#39;,\u0026#39;:\u0026#39;,\u0026#39;s\u0026#39;])] Y,m,d,H,M,S,ms = list(map(int,line[0]+line[1][:-1]+line[1][-1].split(\u0026#39;.\u0026#39;))) end_date = datetime(Y,m,d,H,M,S,ms*1000) duration = line[2][0] if \u0026#39;.\u0026#39; in line[2][0] else line[2][0]+\u0026#39;.0\u0026#39; S,ms = list(map(int,duration.split(\u0026#39;.\u0026#39;))) start_date = end_date - timedelta(seconds=S,milliseconds=ms-1) return [start_date, end_date] def check_time_range(time_range, start, end): con1 = start \u0026lt;= time_range[0] \u0026lt; end con2 = time_range[0] \u0026lt;= start \u0026lt;= time_range[1] return con1 or con2 "},{"id":78,"href":"/blog/programmers-problems-42888/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 42888] ì˜¤í”ˆì±„íŒ…ë°© (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://programmers.co.kr/learn/courses/30/lessons/42888 ê°œìš” # ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•´ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ ì¡°ê±´ # ì±„íŒ…ë°© ìƒíƒœ ë©”ì‹œì§€ì— ëŒ€í•´ ë‹‰ë„¤ì„ ë³€ê²½ ì‚¬í•­ì„ ì ìš©í•˜ì—¬\nìµœì¢…ì ìœ¼ë¡œ UI ìƒì—ì„œ ë³´ì—¬ì§€ëŠ” ë©”ì‹œì§€ë¥¼ ëª©ë¡ì„ ë°˜í™˜í•˜ëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ í•´ì„¤ # uidì— ëŒ€í•œ ë‹‰ë„¤ì„ì´ ì§ì§€ì–´ì§„ ë”•ì…”ë„ˆë¦¬(name_dict)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢…ì ì¸ ë‹‰ë„¤ì„ ëª©ë¡ì„ ê¸°ë¡í•œë‹¤. ë©”ì‹œì§€ê°€ Enterì™€ Changeë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° ë‹‰ë„¤ì„ì´ ì„¤ì • ë˜ëŠ” ë³€ê²½ëœ ê²ƒì´ë¼ ì¸ì§€í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ìˆ˜ì •í•œë‹¤. name_dictì—ì„œ uidì— ëŒ€í•œ ë‹‰ë„¤ì„ì„ ì°¸ì¡°í•˜ì—¬ ìƒíƒœ ë©”ì‹œì§€ë¥¼ ì¡°ê±´ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•œë‹¤. í•´ì„¤ ì½”ë“œ # Copy python def solution(record): answer = [] record = [rec.split() for rec in record] name_dict = {rec[1]:rec[2] for rec in record if rec[0] in {\u0026#39;Enter\u0026#39;,\u0026#39;Change\u0026#39;}} msg_dict = {\u0026#39;Enter\u0026#39;:\u0026#39;ë“¤ì–´ì™”ìŠµë‹ˆë‹¤.\u0026#39;,\u0026#39;Leave\u0026#39;:\u0026#39;ë‚˜ê°”ìŠµë‹ˆë‹¤.\u0026#39;} for rec in record: if rec[0] in {\u0026#39;Enter\u0026#39;,\u0026#39;Leave\u0026#39;}: answer.append(name_dict[rec[1]]+\u0026#39;ë‹˜ì´ \u0026#39;+msg_dict[rec[0]]) return answer "},{"id":79,"href":"/blog/programmers-problems-60057/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 60057] ë¬¸ìì—´ ì••ì¶• (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://programmers.co.kr/learn/courses/30/lessons/60057 ê°œìš” # ë¬¸ìì—´ ì²˜ë¦¬ ëŠ¥ë ¥ì´ ìš”êµ¬ë˜ëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ ì¡°ê±´ # ë¬¸ìì—´ì—ì„œ ë°˜ë³µë˜ëŠ” ë¬¸ì ë˜ëŠ” ë‹¨ì–´ë¥¼ ì••ì¶•í•˜ê³  ê°€ì¥ ì§§ê²Œ ì••ì¶•ëœ ê¸¸ì´ë¥¼ ë°˜í™˜í•œë‹¤. ë¬¸ì œ í•´ì„¤ # ë¬¸ìì—´ì„ ë‹¨ì¼ ë¬¸ìë¶€í„° 2ë“±ë¶„ì´ ë  ë•Œê¹Œì§€ í•œ ë‹¨ìœ„ì”© ëŠ˜ë ¤ê°€ë©´ì„œ ë¶„ë¦¬ëœ ë¬¸ìë“¤ì— ëŒ€í•œ ì••ì¶• ê³¼ì •ì„ ì§„í–‰í•œë‹¤. ë¶„ë¦¬ëœ ë¬¸ìë“¤ì„ ìˆœíšŒí•˜ë©´ì„œ ë°˜ë³µë˜ëŠ” ë¬¸ìì—´ì„ ë¬´ì‹œí•˜ê³  ë‚¨ì€ ë¬¸ìì—´ì˜ ê¸¸ì´ë¥¼ ì„¸ëŠ” ë°©ë²•ë„ ìˆì§€ë§Œ,\nì—¬ê¸°ì„  ë¬¸ìì—´ì„ í˜•ì‹ì— ë§ê²Œ ì••ì¶•ì‹œí‚¤ê³  ê·¸ ê¸¸ì´ë¥¼ êµ¬í•œë‹¤. ì´ì „ ë¬¸ìì—´ì´ ë‹´ê¸¸ ë©”ëª¨ë¦¬ì™€ í•´ë‹¹ ë¬¸ìì—´ì´ ë°˜ë³µëœ íšŸìˆ˜ë¥¼ ê¸°ë¡í•˜ëŠ” ë³€ìˆ˜ë¥¼ ê°ê° ì„ ì–¸í•œë‹¤. ë¶„ë¦¬ëœ ë¬¸ìë“¤ì„ ìˆœíšŒí•˜ë©´ì„œ í˜„ì¬ ë¬¸ìì™€ ë©”ëª¨ë¦¬ê°€ ë‹¤ë¥´ë©´(ë°˜ë³µë˜ì§€ ì•Šìœ¼ë©´)\nì••ì¶•ëœ ë¬¸ìì—´ì— ë©”ëª¨ë¦¬ë¥¼ ì¶”ê°€í•˜ê³  ì´ˆê¸°í™”í•œë‹¤. ëª¨ë“  ê³¼ì •ì— ëŒ€í•œ ìµœì†Œ ê¸¸ì´ ê°’ì„ ê¸°ë¡í•˜ê³  ë°˜í™˜í•œë‹¤. í•´ì„¤ ì½”ë“œ # Copy python def solution(s): answer = len(s) for unit in range(1,len(s)//2+1): s_range = list(range(0, len(s), unit))+[None] s_split = [s[s_range[i]:s_range[i+1]] for i in range(len(s_range)-1)]+[\u0026#39;\u0026#39;] new_s, memory, cnt = str(), s_split[0], 1 for s_unit in s_split[1:]: if memory != s_unit: new_s += ((str(cnt) if cnt \u0026gt; 1 else str()) + memory) memory, cnt = s_unit, 1 else: cnt += 1 answer = min(answer, len(new_s)) return answer "},{"id":80,"href":"/blog/programmers-problems-72410/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 72410] ì‹ ê·œ ì•„ì´ë”” ì¶”ì²œ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://programmers.co.kr/learn/courses/30/lessons/72410 ê°œìš” # ì •ê·œì‹ì„ ì‚¬ìš©í•´ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ ì¡°ê±´ # ìœ ì €ê°€ ì œì‹œí•œ ì•„ì´ë”” ë¬¸ìì—´ì„ ê·œì¹™ì— ë§ê²Œ ë³€ê²½í•˜ì—¬ ë°˜í™˜í•˜ëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ í•´ì„¤ # ì œì‹œëœ ì¡°ê±´ì— ëŒ€í•´ ì •ê·œì‹ì„ êµ¬í˜„í•˜ì—¬ ë¬¸ìì—´ì— ì ìš©í•˜ë©´ ëœë‹¤. ì •ê·œì‹ í™œìš© ëŠ¥ë ¥ì— ë”°ë¼ ë”ìš± ê°„ë‹¨í•œ ì½”ë“œë¡œ êµ¬í˜„í•  ìˆ˜ë„ ìˆë‹¤. í•´ì„¤ ì½”ë“œ # Copy python import re def solution(new_id): answer = new_id.lower() answer = re.sub(r\u0026#34;[^a-z0-9-_\\.]\u0026#34;,\u0026#34;\u0026#34;,answer) answer = re.sub(r\u0026#34;\\.+\u0026#34;,\u0026#34;.\u0026#34;,answer) answer = re.sub(r\u0026#34;^\\.\u0026#34;,\u0026#34;\u0026#34;,answer) answer = re.sub(r\u0026#34;\\.$\u0026#34;,\u0026#34;\u0026#34;,answer) answer = \u0026#39;a\u0026#39; if not answer else answer answer = answer[:15] answer = answer[:-1] if answer[-1] == \u0026#39;.\u0026#39; else answer answer += answer[-1]*(3-len(answer)) return answer "},{"id":81,"href":"/blog/programmers-problems-92334/","title":"[í”„ë¡œê·¸ë˜ë¨¸ìŠ¤/ì¹´ì¹´ì˜¤ 92334] ì‹ ê³  ê²°ê³¼ ë°›ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://programmers.co.kr/learn/courses/30/lessons/92334 ê°œìš” # ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•´ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ ì¡°ê±´ # ì¼ì • íšŸìˆ˜ ì´ìƒ ì‹ ê³ ë‹¹í•œ ë¶ˆëŸ‰ ì´ìš©ìë¥¼ ì‹ ê³ í•œ ì´ìš©ìë“¤ì—ê²Œ ë°œì†¡ë˜ëŠ” ë©”ì¼ì˜ íšŸìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” ë¬¸ì œë‹¤. ë¬¸ì œ í•´ì„¤ # ì´ìš©ì ìì‹ ì´ ì‹ ê³ ë‹¹í•œ íšŸìˆ˜(report_dict)ì™€ ì´ìš©ìê°€ ì‹ ê³ í•œ ëŒ€ìƒ ëª©ë¡(mail_dict)ì„ ê°ê° ê¸°ë¡í•  í•„ìš”ê°€ ìˆë‹¤. ê°ê°ì˜ ì‹ ê³  ê±´ìˆ˜ì— ëŒ€í•´ ë°˜ë³µí•˜ë©° ë‘ ê°€ì§€ ë”•ì…”ë„ˆë¦¬ì— ê¸°ë¡í•œë‹¤. ì´ìš©ìidë¥¼ keyë¡œ ì°¸ê³ í•˜ì—¬ ê°ê°ì˜ ì´ìš©ìë§ˆë‹¤ ìì‹ ì´ ì‹ ê³ í•œ ëŒ€ìƒ ì¤‘ ì •ì§€ëœ ëŒ€ìƒì˜ ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤. í•´ì„¤ ì½”ë“œ # Copy python def solution(id_list, report, k): report_dict = {id: 0 for id in id_list} mail_dict = {id: set() for id in id_list} for rep in set(report): user, target = rep.split() report_dict[target] += 1 mail_dict[user].add(target) answer = [] for user, targets in mail_dict.items(): answer.append(sum([1 if report_dict[target] \u0026gt;= k else 0 for target in targets])) return answer "},{"id":82,"href":"/blog/aischool-06-09-pipeline/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - Pipeline","section":"Posts","content":"Feature Transformer # Import Libraries # Copy python from sklearn.preprocessing import StandardScaler, OneHotEncoder from sklearn.compose import ColumnTransformer from sklearn.pipeline import Pipeline ColumnTransformer # Copy python numeric_features = [\u0026#39;CRIM\u0026#39;, \u0026#39;ZN\u0026#39;, \u0026#39;INDUS\u0026#39;, \u0026#39;NOX\u0026#39;, \u0026#39;RM\u0026#39;, \u0026#39;AGE\u0026#39;, \u0026#39;DIS\u0026#39;, \u0026#39;TAX\u0026#39;, \u0026#39;PTRATIO\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;LSTAT\u0026#39;] numeric_transformer = StandardScaler() categorical_features = [\u0026#39;CHAS\u0026#39;, \u0026#39;RAD\u0026#39;] categorical_transformer = OneHotEncoder(categories=\u0026#39;auto\u0026#39;) preprocessor = ColumnTransformer( transformers=[ (\u0026#39;num\u0026#39;, numeric_transformer, numeric_features), (\u0026#39;cat\u0026#39;, categorical_transformer, categorical_features)]) OneHotEncoder()ì˜ handle_unknown ì„¤ì •\nerror: ìˆ«ìë¡œ ë³€í™˜ëœ ë¶„ë¥˜í˜• ë²”ì£¼ì— ìƒˆë¡œìš´ ë¬¸ìì—´ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ê²½ìš° ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚´ ignore: ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹ë˜ëŠ” ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ 0ìœ¼ë¡œ ë°”ê¿ˆ Preprocessing-Only # Copy python preprocessor_pipe = Pipeline(steps=[(\u0026#39;preprocessor\u0026#39;, preprocessor)]) steps: ì „ì²˜ë¦¬ ë„êµ¬ë¥¼ ìˆœì„œëŒ€ë¡œ ì ìš© (ëª¨ë¸ë„ ì…ë ¥ ê°€ëŠ¥) Model Fitting # Copy python preprocessor_pipe.fit(x_train) x_train_transformed = preprocessor_pipe.transform(x_train) x_test_transformed = preprocessor_pipe.transform(x_test) Numeric Variablesì— ëŒ€í•œ 11ê°œì˜ ì—´,\nCategorical Variablesì— ëŒ€í•œ 2ê°œì˜ ì—´,\nì¹´í…Œê³ ë¦¬ ë³„ One-Hot Encodingì´ ì ìš©ëœ 9ê°œì˜ ì—´ì„ í•¨ê»˜ í‘œì‹œ Pipelineì„ í†µí•´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•  ê²½ìš° ë°ì´í„°ë¥¼ ì›ë˜ëŒ€ë¡œ ë˜ëŒë¦¬ëŠ” inverse_trasnform ë¶ˆê°€ëŠ¥ Preprocessing + Training # Copy python from sklearn.ensemble import GradientBoostingClassifier model = Pipeline(steps=[(\u0026#39;preprocessor\u0026#39;, preprocessor), (\u0026#39;classifier\u0026#39;, GradientBoostingClassifier(n_estimators=200, random_state=0))]) Preprocessingê³¼ Trainingì„ ê°™ì´ ë¬¶ì„ ê²½ìš° ë‹¤ë¥¸ ëª¨ë¸ì„ ë¼ì›Œë„£ê¸° ì–´ë ¤ì›€ ìœ„ ë‹¨ì  ë–„ë¬¸ì— ì „ì²˜ë¦¬ë§Œì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥ Preprocessing + Training + HPO # Copy python model = Pipeline(steps=[(\u0026#39;preprocessor\u0026#39;, preprocessor), (\u0026#39;classifier\u0026#39;, GradientBoostingClassifier())]) param_grid = { \u0026#39;classifier__loss\u0026#39;: [\u0026#39;deviance\u0026#39;, \u0026#39;exponential\u0026#39;], \u0026#39;classifier__learning_rate\u0026#39;: [0.01, 0.001], \u0026#39;classifier__n_estimators\u0026#39;: [200, 400], \u0026#39;classifier__min_samples_split\u0026#39;: [2, 4], \u0026#39;classifier__max_depth\u0026#39;: [2, 4], \u0026#39;classifier__random_state\u0026#39;: [0] } grid_search = GridSearchCV(model, param_grid, refit=True, cv=3, n_jobs=1, verbose=1, scoring= \u0026#39;accuracy\u0026#39;) "},{"id":83,"href":"/blog/aischool-06-08-model-stacking/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - Model Stacking","section":"Posts","content":"Model Stacking # ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì„ ëª¨ìœ¼ê³  Ensemble ê¸°ë²•ì„ ì‚¬ìš©í•´ ê°œì„ ëœ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒ ê¸°ì¡´ ëª¨ë¸ë“¤ë¡œë¶€í„° ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ëŠ” 1st Stageì™€\nì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ì ì¸ íŒë‹¨ì„ ì§„í–‰í•˜ëŠ” 2nd Stageë¡œ ë‚˜ë‰¨ 1st Stage # train_Xë¥¼ ê°€ì§€ê³  1ë²ˆ ëª¨ë¸ì„ Training Trainingì„ ê±°ì¹œ 1ë²ˆ ëª¨ë¸ì— train_Xë¥¼ ë„£ì—ˆì„ ë•Œ ê²°ê³¼(ì˜ˆì¸¡ê°’)ì„ ì €ì¥ ë‹¤ë¥¸ ëª¨ë¸ì—ë„ ë™ì¼í•œ ì‘ì—…ì„ í–ˆì„ ë•Œ ë‚˜ì˜¨ 1ì—´ì˜ ì˜ˆì¸¡ê°’ë“¤ì„ ë¬¶ì–´ S_trainì„ ìƒì„± (ê¸°ì¡´ Ensembleì€ S_trainì„ í–‰ë³„ë¡œ íˆ¬í‘œí•´ì„œ ë¶„ë¥˜í•¨) 2nd Stage # ìƒˆë¡œìš´ ëª¨ë¸ ìƒì„± (1st Stageì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥) S_train_X, train_Yë¥¼ ê°€ì§€ê³  ìƒˆë¡œìš´ ëª¨ë¸ì„ Training Test Model # test_Xë¥¼ 1st Stage ëª¨ë¸ì— ë„£ê³  ê²°ê³¼ë¡œ ë‚˜ì˜¨ ì˜ˆì¸¡ê°’ë“¤ì˜ ë¬¶ìŒ S_testë¥¼ ìƒì„± (2nd Stage ëª¨ë¸ì˜ í•™ìŠµ ë°ì´í„°ëŠ” ì›ë³¸ ë°ì´í„°ì™€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— test_Xë¥¼ ë°”ë¡œ ë„£ìœ¼ë©´ ì•ˆë¨) S_train_X, train_Yë¥¼ 2nd Stage ëª¨ë¸ì— ë„£ì—ˆì„ ë•Œ ê²°ê³¼ë¥¼ ê°€ì§€ê³  Accuracy ê³„ì‚° Functional API # Import Library # Copy python from vecstack import stacking 1st Level Models # Copy python models = [ ExtraTreesClassifier(random_state = 0, n_jobs = -1, n_estimators = 100, max_depth = 3), RandomForestClassifier(random_state = 0, n_jobs = -1, n_estimators = 100, max_depth = 3), XGBClassifier(seed = 0, n_jobs = -1, learning_rate = 0.1, n_estimators = 100, max_depth = 3)] Stacking # Copy python S_train, S_test = stacking(models, X_train, y_train, X_test, regression = False, metric = accuracy_score, n_folds = 4, stratified = True, shuffle = True, random_state = 0, verbose = 2) S_trainê³¼ S_testë¥¼ ê°™ì´ ìƒì„± (y_testëŠ” 2ì°¨ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ì—ì„œë§Œ ì‚¬ìš©) metric: Focusë¥¼ ë§ì¶œ ëŒ€ìƒ 2nd Level Model # Copy python model = XGBClassifier(seed = 0, n_jobs = -1, learning_rate = 0.1, n_estimators = 100, max_depth = 3, eval_metric=\u0026#39;mlogloss\u0026#39;) model = model.fit(S_train, y_train) y_pred = model.predict(S_test) accuracy_score(y_test, y_pred)ë¥¼ í™•ì¸í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ Scikit-learn API # Import Library # Copy python from vecstack import StackingTransformer 1st Level Estimators # Copy python estimators = [ (\u0026#39;ExtraTrees\u0026#39;, ExtraTreesClassifier(random_state = 0, n_jobs = -1, n_estimators = 100, max_depth = 3)), (\u0026#39;RandomForest\u0026#39;, RandomForestClassifier(random_state = 0, n_jobs = -1, n_estimators = 100, max_depth = 3)), (\u0026#39;XGB\u0026#39;, XGBClassifier(seed = 0, n_jobs = -1, learning_rate = 0.1, n_estimators = 100, max_depth = 3, eval_metric=\u0026#39;mlogloss\u0026#39;))] stackingê³¼ ë‹¤ë¥´ê²Œ ëª¨ë¸ ì´ë¦„ê³¼ ëª¨ë¸ ê°ì²´ë¥¼ ê°™ì´ íŠœí”Œë¡œ ë¬¶ìŒ StackingTransformer # Copy python stack = StackingTransformer(estimators, regression = False, metric = accuracy_score, n_folds = 4, stratified = True, shuffle = True, random_state = 0, verbose = 2) stackingê³¼ ë‹¤ë¥´ê²Œ x dataì™€ y dataë¥¼ ì…ë ¥í•˜ì§€ ì•Šê³  ê°ì²´ ìì²´ë¥¼ ëª¨ë¸ì²˜ëŸ¼ ì‚¬ìš© Model Fitting # Copy python stack = stack.fit(X_train, y_train) S_train = stack.transform(X_train) S_test = stack.transform(X_test) stackingì€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë„£ì„ ë•Œ ì–´ë ¤ì›€ì´ ìˆì§€ë§Œ,\nStackingTransformerëŠ” ì „ì²˜ë¦¬ ë„êµ¬ì²˜ëŸ¼ ì‚¬ìš© ê°€ëŠ¥ 2nd Level Estimator # Copy python model = XGBClassifier(seed = 0, n_jobs = -1, learning_rate = 0.1,n_estimators = 100, max_depth = 3, eval_metric=\u0026#39;mlogloss\u0026#39;) model = model.fit(S_train, y_train) y_pred = model.predict(S_test) "},{"id":84,"href":"/blog/aischool-06-07-pca/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - PCA","section":"Posts","content":"Principal Component Analysis # ì°¨ì› ì¶•ì†Œë¥¼ í†µí•´ ìµœì†Œ ì°¨ì›ì˜ ì •ë³´ë¡œ ì›ë˜ ì°¨ì›ì˜ ì •ë³´ë¥¼ ëª¨ì‚¬í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ ë°ì´í„°ì˜ ì—´ì˜ ìˆ˜ê°€ ë§ì•„ í•™ìŠµ ì†ë„ê°€ ëŠë ¤ì§ˆ ë•Œ ì—´ì˜ ìˆ˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì‚¬ìš© Dimension Reduction: ê³ ì°¨ì› ë²¡í„°ì—ì„œ ì¼ë¶€ ì°¨ì›ì˜ ê°’ì„ ëª¨ë‘ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ì°¨ì›ì„ ì¤„ì„ ì›ë˜ì˜ ê³ ì°¨ì› ë²¡í„°ì˜ íŠ¹ì„±ì„ ìµœëŒ€í•œ ì‚´ë¦¬ê¸° ìœ„í•´ ê°€ì¥ ë¶„ì‚°ì´ ë†’ì€ ë°©í–¥ìœ¼ë¡œ íšŒì „ ë³€í™˜ ì§„í–‰ ì „ì²´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì‚°ì´ ê°€ì¥ í° ì¶•ì„ ì°¾ì•„ PC 1ìœ¼ë¡œ ë§Œë“¤ê³ ,\nPC 1ì— ì§êµí•˜ëŠ” ì¶• ì¤‘ì—ì„œ ë¶„ì‚°ì´ ê°€ì¥ í° ì¶•ì„ PC 2ë¡œ ë§Œë“œëŠ” ê³¼ì • ë°˜ë³µ ì •ë³´ì˜ ëˆ„ë½ì´ ìˆê¸° ë•Œë¬¸ì— ê²½ìš°ì— ë”°ë¼ ëª¨ë¸ì˜ ì„±ëŠ¥ í•˜ë½ ë°œìƒ Feature Selection: ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” ì—´ ì¤‘ì— nê°œë¥¼ ì„ íƒ Feature Extraction: ê¸°ì¡´ì— ìˆëŠ” ì—´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì—´ë“¤ì„ ë§Œë“¤ì–´ëƒ„ (ì°¨ì› ì¶•ì†Œ) Learning Process # Import Libraries # Copy python from sklearn import decomposition from sklearn import datasets Load Model # Copy python iris = datasets.load_iris() x = iris.data y = iris.target Create Model # Copy python model = decomposition.PCA(n_components=1) componentì˜ ê°œìˆ˜ì— ìƒê´€ì—†ì´ PC 1ì€ ì–¸ì œë‚˜ ë™ì¼ Model Fitting # Copy python model.fit(x) x1 = model.transform(x) Plot Model # Histogram (components=1) # Copy python import seaborn as sns sns.distplot(x1[y==0], color=\u0026#34;b\u0026#34;, bins=20, kde=False) sns.distplot(x1[y==1], color=\u0026#34;g\u0026#34;, bins=20, kde=False) sns.distplot(x1[y==2], color=\u0026#34;r\u0026#34;, bins=20, kde=False) plt.xlim(-6, 6) plt.show() Scatter (components=3) # Copy python plt.scatter(x[:, 0], x[:, 1], c=iris.target) plt.xlabel(\u0026#39;PC1\u0026#39;) plt.ylabel(\u0026#39;PC2\u0026#39;) plt.show() ìµœì ì˜ PCA ê°œìˆ˜ # ë°ì´í„°ì…‹ì˜ ë¶„ì‚° ì •ë„ í™•ì¸ # model.explained_variance_ratio_ componentsê°€ ì „ì²´ ë¶„ì‚° ì •ë„ ì¤‘ ëª‡ í¼ì„¼íŠ¸ì¸ì§€ í™•ì¸ í•©ì³ì„œ 95í¼ì„¼íŠ¸ë¥¼ ë„˜ëŠ” PCA ê°œìˆ˜ê°€ ìµœì ì˜ ê°œìˆ˜ ìµœì ì˜ PCA ê°œìˆ˜ í™•ì¸ # Copy python np.argmax(np.cumsum(model.explained_variance_ratio_) \u0026gt;= 0.95 ) + 1 np.cumsum: ê°’ì˜ ëˆ„ì ëœ í•©ê³„ ê³„ì‚° np.argmax: ì£¼ì–´ì§„ ê°’ë“¤ ì¤‘ ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ ìµœì ì˜ PCA ê°œìˆ˜ ì ìš© # Copy python model = decomposition.PCA(n_components=0.95) model.fit(x) x = model.transform(x) "},{"id":85,"href":"/blog/aischool-06-06-k-means/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - K-Means","section":"Posts","content":"1. K-Means Algorithm # KëŠ” ì „ì²´ ë°ì´í„°ë¥¼ ëª‡ ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ë‚¼ ê²ƒì¸ì§€ ê²°ì •í•˜ëŠ” ìƒìˆ˜ ì–´ë–¤ K ê°’ì´ ì ì ˆí•œ ê²ƒì¸ì§€ íŒŒì•…í•˜ëŠ” ê²ƒì´ ì¤‘ìš” ê°ê°ì˜ ë°ì´í„°ë§ˆë‹¤ ì¤‘ì‹¬ê°’ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ ê³„ì† ë¬¼ì–´ë³´ê¸° ë•Œë¬¸ì— ê³„ì‚°ëŸ‰ì´ ë§ìŒ í´ëŸ¬ìŠ¤í„°ë§ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ GPU Accelerated t-SNE for CUDA í™œìš© Clustering Process # Kê°œì˜ ì„ì˜ì˜ ì¤‘ì‹¬ê°’ì„ ì„ íƒ ê° ë°ì´í„°ë§ˆë‹¤ ì¤‘ì‹¬ê°’ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ ê°€ê¹Œìš´ ì¤‘ì‹¬ê°’ì˜ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹ ê° í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ë°ì´í„°ë“¤ì˜ í‰ê· ê°’ìœ¼ë¡œ ê° ì¤‘ì‹¬ê°’ì„ ì´ë™ ë°ì´í„°ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° í• ë‹¹ì´ ë³€í•˜ì§€ ì•Šì„ ë•Œê¹Œì§€ 2ì™€ 3ì„ ë°˜ë³µ 2. Learning Process # Model Fitting # Copy python from sklearn import cluster kmeans = cluster.KMeans(n_clusters=2, random_state=0).fit(X) kmeans.labels_: í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ kmeans.cluster_centers_: í•™ìŠµì´ ëë‚œ ì¤‘ì‹¬ê°’ Model Predict # Copy python kmeans.predict([[0, 0], [8, 4]])) ê°ê°ì˜ ë²ˆí˜¸ê°€ ì–´ë–¤ í´ëŸ¬ìŠ¤í„°ì— ì†í•˜ëŠ”ì§€ ì˜ˆì¸¡ 3. K-Means for Iris Data # Import Libraries # Copy python import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from sklearn import cluster from sklearn import datasets from sklearn import metrics Axes3D: 3D ê³µê°„ì—ì„œ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ Model Fitting # Copy python estimators = [(\u0026#39;k=8\u0026#39;, cluster.KMeans(n_clusters=8)), (\u0026#39;k=3\u0026#39;, cluster.KMeans(n_clusters=3)), (\u0026#39;k=3(r)\u0026#39;, cluster.KMeans(n_clusters=3, n_init=1, init=\u0026#39;random\u0026#39;))] Plot Model # Copy python fignum = 1 titles = [\u0026#39;8 clusters\u0026#39;, \u0026#39;3 clusters\u0026#39;, \u0026#39;3 clusters, bad initialization\u0026#39;] for name, est in estimators: fig = plt.figure(fignum, figsize=(7, 7)) ax = Axes3D(fig, elev=48, azim=134) est.fit(X) labels = est.labels_ ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(np.float), edgecolor=\u0026#39;w\u0026#39;, s=100) ... fignum = fignum + 1 plt.show() plt.figure(fignum): plotì„ ì—¬ëŸ¬ ê°œ ìƒì„± (subplot()ì€ í•˜ë‚˜ì˜ plotì„ ë¶„ë¦¬) Axes3D(elev, azim): elevation (ì¶•ì˜ ê³ ë„), azimuth (ë°©ìœ„ê°) astype: ìƒ‰ê¹” ì¹ í•´ì£¼ëŠ” ì˜µì…˜ edgecolor: í…Œë‘ë¦¬ 1ë²ˆ ëª¨ë¸ì€ 8ê°œì˜ í´ëŸ¬ìŠ¤í„°ë¡œ ë‚˜ëˆˆ ëª¨ë¸ (ë¶ˆí•„ìš”í•˜ê²Œ ì„¸ë¶„í™”ì‹œí‚´) 3ë²ˆ ëª¨ë¸ì€ ì´ˆê¸° ì¤‘ì•™ê°’ì„ ëœë¤ìœ¼ë¡œ ì¡ì•„ì„œ íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì— ë°ì´í„°ê°€ ëª°ë¦¼ Ground Truth (ì›ë³¸) # Copy python fig = plt.figure(figsize=(7, 7)) ax = Axes3D(fig, elev=48, azim=134) for name, label in [(\u0026#39;Setosa\u0026#39;, 0), (\u0026#39;Versicolour\u0026#39;, 1), (\u0026#39;Virginica\u0026#39;, 2)]: ax.text3D(X[y == label, 3].mean(), X[y == label, 0].mean(), X[y == label, 2].mean()+2, name, horizontalalignment=\u0026#39;center\u0026#39;) ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=y, edgecolor=\u0026#39;w\u0026#39;, s=100) ... plt.show() 4. ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ # ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ê¸°ì¤€ # ê°™ì€ í´ëŸ¬ìŠ¤í„°ì— ìˆëŠ” ë°ì´í„°ë¼ë¦¬ ë­‰ì³ ìˆìŒ ì„œë¡œ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ì— ìˆëŠ” ë°ì´í„°ë¼ë¦¬ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆìŒ Elbow ê¸°ë²• # SSE(Sum of Squared Errors)ì˜ ê°’ì´ ì ì  ì¤„ì–´ë“¤ë‹¤ê°€ ì–´ëŠ ìˆœê°„\nì¤„ì–´ë“œëŠ” ë¹„ìœ¨ì´ ê¸‰ê²©í•˜ê²Œ ì‘ì•„ì§€ëŠ” ë¶€ë¶„ì´ ë°œìƒ ê²°ê³¼ë¬¼ì¸ ê·¸ë˜í”„ ëª¨ì–‘ì„ ë³´ë©´ íŒ”ê¿ˆì¹˜ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì´ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ê°€ ë¨ Copy python def elbow(X): total_distance = [] for i in range(1, 11): model = cluster.KMeans(n_clusters=i, random_state=0) model.fit(X) total_distance.append(model.inertia_) plt.plot(range(1, 11), total_distance, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;# of clusters\u0026#39;) plt.ylabel(\u0026#39;Total distance (SSE)\u0026#39;) plt.show() elbow(X) model.inertia_: ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„°ì™€ì˜ ê±°ë¦¬ ì œê³±ì˜ í•© inertia ê°’ì€ í´ëŸ¬ìŠ¤í„° ìˆ˜ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ê°ì†Œ ê°™ì€ í´ëŸ¬ìŠ¤í„°ì— ìˆëŠ” ë°ì´í„°ë¼ë¦¬ ë­‰ì³ìˆëŠ” ì •ë„ë§Œ í™•ì¸ ê°€ëŠ¥ Silhouette # í´ëŸ¬ìŠ¤í„°ë§ì˜ í’ˆì§ˆì„ ì •ëŸ‰ì ìœ¼ë¡œ ê³„ì‚°í•´ì£¼ëŠ” ë°©ë²• (ëª¨ë“  í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²•ì— ì ìš© ê°€ëŠ¥) ië²ˆì§¸ ë°ì´í„° x(i)ì— ëŒ€í•œ ì‹¤ë£¨ì—£ ê³„ìˆ˜ s(i) ê°’ì€ ì•„ë˜ì˜ ì‹ìœ¼ë¡œ ì •ì˜ a(i): í´ëŸ¬ìŠ¤í„° ë‚´ ë°ì´í„° ì‘ì§‘ë„(cohesion) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°’\n== ë°ì´í„° x(i)ì™€ ë™ì¼í•œ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ë‚˜ë¨¸ì§€ ë°ì´í„°ë“¤ê³¼ì˜ í‰ê·  ê±°ë¦¬ b(i): í´ëŸ¬ìŠ¤í„° ê°„ ë¶„ë¦¬ë„(separation) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°’\n== ë°ì´í„° x(i)ì™€ ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ëª¨ë“  ë°ì´í„°ë“¤ê³¼ì˜ í‰ê·  ê±°ë¦¬ í´ëŸ¬ìŠ¤í„°ì˜ ê°œìˆ˜ê°€ ìµœì í™”ë˜ì–´ ìˆìœ¼ë©´ ì‹¤ë£¨ì—£ ê³„ìˆ˜ì˜ ê°’ì€ 1ì— ê°€ê¹Œìš´ ê°’ì´ ë¨ ì‹¤ë£¨ì—£ ê³„ìˆ˜ì˜ í‰ê· ì´ 0.7 ì´ìƒì´ë©´ ì•ˆì •ì  Copy python from sklearn.metrics import silhouette_score silhouette_avg = silhouette_score(X, y_fitted) silhouette_avg: ì‹¤ë£¨ì—£ ê³„ìˆ˜ì˜ í‰ê·  í´ëŸ¬ìŠ¤í„°ë§ì˜ ê¸°ì¤€ì´ ì´ë¡ ì ìœ¼ë¡œëŠ” ë§ì„ ìˆ˜ ìˆì–´ë„ ì‹¤ìš©ì ìœ¼ë¡œëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n(íŒë‹¨ ê¸°ì¤€ì´ ì—†ì„ ë•Œ í™œìš©) "},{"id":86,"href":"/blog/aischool-06-05-kernelized-svm/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - Kernelized SVM","section":"Posts","content":"Support Vector Machine # íŒ¨í„´ ì¸ì‹ì„ ìœ„í•œ ì§€ë„ í•™ìŠµ ëª¨ë¸ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” Marginì„ ìµœëŒ€í™”í•˜ëŠ” ê²°ì • ê²½ê³„(Decision Boundary)ë¥¼ ì°¾ëŠ” ê¸°ë²• ê²°ì • ê²½ê³„ì™€ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„°ë¥¼ ê°€ë¡œì§€ë¥´ëŠ” ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ Plus \u0026amp; Minus Plane ì„¤ì • Support Vector: ê²°ì • ê²½ê³„ì™€ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„°ì˜ ì¢Œí‘œ Margin: b11(plus-plane)ê³¼ b12(minus-plane) ì‚¬ì´ì˜ ê±°ë¦¬, 2/w ê¸°ì¡´ì˜ Hard Margin SVMì€ ì†Œìˆ˜ì˜ Noiseë¡œ ì¸í•´ ê²°ì • ê²½ê³„ë¥¼ ì°¾ì§€ ëª»í•  ìˆ˜ ìˆìŒ Plus \u0026amp; Minus Planeì— ì•½ê°„ì˜ ì—¬ìœ  ë³€ìˆ˜ë¥¼ ë‘ì–´ ì—ëŸ¬ë¥¼ ë¬´ì‹œí•˜ëŠ” Soft Margin SVMë¡œ ë°œì „ arg min # $$arg\\ min\\lbrace\\frac{1}{2}{||w||}^2+C\\Sigma^n_{i=1}\\xi_i\\rbrace$$ $$\\text{ë‹¨, }y_i({w}\\cdot{x_i}-b)\\ge{1-\\xi_i},\\quad{\\xi_i\\ge{0}},\\quad{\\text{for all }1\\le{i}\\le{n}}$$\nì¤‘ê´„í˜¸ ì•ˆì˜ ê°’(w, Î¾, b)ì„ ìµœì†Œí™”í•˜ëŠ” ê°’ì„ ì°¾ëŠ” ê²ƒ Marginì„ ìµœëŒ€í™”í•˜ëŠ” ëª©ì  í•¨ìˆ˜(Objective Function) Margin(2/w)ì˜ ìµœëŒ€í™”ëŠ” w/2ì˜ ìµœì†Œí™”ì™€ ê°™ìŒ (ì œê³±ì€ ë¯¸ë¶„ í¸ì˜ì„±) Marginì„ ì¹¨ë²”í•œ ì—ëŸ¬(Î¾)ë¥¼ ëª¨ë‘ ë”í•˜ê³ (Î£), Hyper-Parameterì¸ Cë¥¼ ê³±í•¨ C: ì–¼ë§ˆ ë§Œí¼ ì—¬ìœ ë¥¼ ê°€ì§€ê³  ì˜¤ë¥˜ë¥¼ í—ˆìš©í•  ê²ƒì¸ì§€ íŒë‹¨í•´ì£¼ëŠ” ê°’ Cê°€ ì‘ì„ìˆ˜ë¡ ì—ëŸ¬ë¥¼ ë¬´ì‹œ, Cê°€ í¬ë©´ ì—ëŸ¬ì— ë¯¼ê° Kernel Support Vector Machine # ë°ì´í„°ê°€ ì„ í˜•ì ìœ¼ë¡œ ë¶„ë¦¬ë˜ì§€ ì•Šì„ ê²½ìš°(Lineaerly Unseparable)ì— ê²°ì • ê²½ê³„ë¥¼ ì°¾ëŠ” ê¸°ë²• ì›ë³¸ ë°ì´í„°ê°€ ë†“ì—¬ìˆëŠ” ì°¨ì›ì„ ë¹„ì„ í˜• ë§¤í•‘ì„ í†µí•´ ê³ ì°¨ì› ê³µê°„ìœ¼ë¡œ ë³€í™˜ Hyper-Parameterì¸ ì»¤ë„ í•¨ìˆ˜ë¥¼ ì»´í“¨í„°ê°€ ìŠ¤ìŠ¤ë¡œ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ Deep Learning ì»¤ë„ í•¨ìˆ˜ëŠ” ì¸ê³µì‹ ê²½ë§ì˜ ë ˆì´ì–´ì™€ ë¹„ìŠ· (Learnable Kernel) Feature Crosses # ë°ì´í„°ë¥¼ ì¸ê³µì‹ ê²½ë§ì— ë°€ì–´ë„£ê¸° ì´ì „ì—, ê¸°ì¡´ ì—´ë“¤ì˜ ì…ë ¥ê°’ì„ ì¡°í•©í•´ì„œ ìƒˆë¡œìš´ ë°ì´í„° ìƒì„± @ http://j.mp/2p5CbO2 SVC Models # Linear SVC # Copy python from sklearn.svm import LinearSVC linear_svm = LinearSVC().fit(X, y) Kernelized SVC # Copy python from sklearn.svm import SVC X, y = custom_mglearn.make_handcrafted_dataset() svm = SVC(kernel=\u0026#39;rbf\u0026#39;, C=10, gamma=0.1).fit(X, y) rbf: ëŒ€í‘œì ì¸ ì»¤ë„ í•¨ìˆ˜ (Radial Basis Function, ê°€ìš°ì‹œì•ˆ ì»¤ë„ í•¨ìˆ˜) gamma: ê°€ìš°ì‹œì•ˆ í•¨ìˆ˜ì˜ ë‹¨ë©´ì„ r ì´ë¼ í•  ë•Œ, ë°˜ì§€ë¦„ì˜ ì—­ìˆ˜(1/r) gammaê°€ ì‘ì•„ì§ˆìˆ˜ë¡ ë°˜ì§€ë¦„ì´ ì»¤ì ¸ ì„ ê³¼ ê°™ì€ í˜•íƒœê°€ ë¨ Learning Process # Copy python cancer = load_breast_cancer() # ìœ ë°©ì•” ë°ì´í„° (569í–‰, 30ì—´) X_train, X_test, y_train, y_test = train_test_split( cancer.data, cancer.target, random_state=0) svc = SVC(gamma=\u0026#39;auto\u0026#39;) svc.fit(X_train, y_train) train_test_split()ì— test_sizeê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 0.25ë¥¼ Test Dataë¡œ ì§€ì • SVC(gamma='auto'): gammaë¥¼ ì•Œì•„ì„œ ì§€ì • ë¶„ë¥˜ ëª¨ë¸ì˜ ê²½ìš°, model.score(X, Y)ë¥¼ ì‹¤í–‰í•˜ë©´ Accuracy Score ê³„ì‚° svc.score(X_train, y_train): Training Dataì˜ Accuracy svc.score(X_test, y_test): Test Dataì˜ Accuracy ë‘ ë°ì´í„°ì˜ Accuracy ì°¨ì´ê°€ ì‹¬í•œ ê²ƒì€ ì—´ë§ˆë‹¤ Scaleì´ ë‹¬ë¼ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œ Scaling í›„ Hyper-Parameterë¥¼ ë°”ê¿¨ì„ ë•Œ ë‘ ë°ì´í„°ì˜ ì°¨ì´ê°€ ì‹¬í•˜ë©´ Overfitting Feature Normalization (Scaling) # min, max, mean, stdë¥¼ ê³„ì‚°í•  ë•Œ Training Dataë§Œ ì‚¬ìš© Min-Max Normalization # min(ì—´) = 0, max(ì—´) = 1 new_X = (old_X - min) / (max - min) Standardization # mean(ì—´) = 0, std(ì—´) = 1 new_X = (old_X - mean) / std Scaler Model # Copy python sc = StandardScaler() # ë˜ëŠ” MinMaxScaler() sc.fit(train_X) train_X_scaled = sc.transform(train_X) test_X_scaled = sc.transform(test_X) ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ë©´ 2ì°¨ì› í–‰ë ¬ ìƒíƒœë¡œ Scalerë¥¼ í†µê³¼ì‹œí‚¤ê³  ëª¨ë¸ì— ì…ë ¥ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¬ ë•Œ Scalerë„ ê°™ì´ ê°€ì ¸ì™€ì•¼ í•¨ Stanardizationì´ Min-Max ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ìŒ (ì˜ˆì™¸ ìˆìŒ) Grid-Search # Copy python from sklearn.model_selection import GridSearchCV param_grid = {\u0026#39;C\u0026#39; : [0.1, 1, 10, 100, 1000], \u0026#39;gamma\u0026#39; : [1, 0.1, 0.01, 0.001, 0.0001], \u0026#39;kernel\u0026#39; : [\u0026#39;rbf\u0026#39;]} grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=1) grid.fit(X_train_scaled, y_train) Cì™€ gammaì˜ í›„ë³´êµ°ì„ ì¡°í•© ë‚´ë¶€ì ìœ¼ë¡œ K-Foldë¡œ ê²€ì¦í•˜ê¸° ë•Œë¬¸ì— í›„ë³´êµ°ì´ ë§ì•„ì§ˆìˆ˜ë¡ ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¼ refit=True: GridSearchCVë¥¼ ë‹¤ì‹œ íŠ¸ë ˆì´ë‹ ì‹œí‚´ verbose: ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ì„¤ëª…ì„ ìƒì„¸í•˜ê²Œ ì ì–´ì¤Œ GridSearchê°€ SVC ëª¨ë¸ì´ ë˜ì–´ Model Fitting, Model Predict ë“± ê³¼ì • ì§„í–‰ grid.best_params_: ìµœì ì˜ Cì™€ gammaì˜ ì¡°í•© ë°˜í™˜ ë‚´ë¶€ì ìœ¼ë¡œ ê²€ì¦ì„ ê±°ì¹œ ìƒíƒœì´ê¸° ë•Œë¬¸ì— Training Dataë¥¼ í•œ ë²ˆ ëŒë¦° ê²ƒê³¼ëŠ” ì •í™•ë„ê°€ ë‹¤ë¦„ Model Tuning (HPO) # Grid-Search (Machine Learning) Randomized-Search (Deep Learning) Bayesian-Search (ML/DL) Model Predict # Copy python from sklearn.metrics import classification_report grid_predictions = grid.predict(X_test_scaled) print(classification_report(y_test, grid_predictions)) precision: ëª¨ë¸ì´ ì–‘ì„±ìœ¼ë¡œ ë¶„ë¥˜í•œ ê²ƒ ì¤‘ ì§„ì§œ ê±¸ë¦° ê²ƒ recall: ì–‘ì„±ì¸ ê²ƒ ì¤‘ ëª¨ë¸ì´ ì–‘ì„±ì´ë¼ ë§ì¶˜ ê²ƒ f1-score: Precisionê³¼ Recallì˜ ì¡°í•© support: Test Data confusion_matrixë„ importí•´ì„œ ì‚¬ìš© ê°€ëŠ¥ precision recall f1-score support 0 0.98 0.94 0.96 53 1 0.97 0.99 0.98 90 accuracy 0.97 143 macro avg 0.97 0.97 0.97 143 weighted avg 0.97 0.97 0.97 143 "},{"id":87,"href":"/blog/aischool-06-04-knn/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - KNN","section":"Posts","content":"K-Nearest Neightbor Algorithm # ê¸°ì¡´ì˜ ê°€ê¹Œìš´ ì´ì›ƒ ë°ì´í„°ë¥¼ ì‚´í´ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ K=3ì¼ ê²½ìš°, ê°€ì¥ ê°€ê¹Œìš´ ë‚˜ë¨¸ì§€ 3ê°œ ì¤‘ 2ê°œê°€ Redë©´ Redë¡œ íŒë‹¨ K ê°’ì´ ì‘ì•„ì§ˆìˆ˜ë¡ ì•„ì£¼ ì‘ì€ ì˜í–¥ì—ë¡œ íŒë‹¨ì´ ë°”ë€ŒëŠ” Overfitting ë°œìƒ K ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ë©€ë¦¬ë³´ê³  ê²°ì •ì´ ëŠë ¤ì ¸ Overfitting ê°ì†Œ Learning Process # Load Data # Copy python iris = datasets.load_iris() # ë¶“ê½ƒ ë°ì´í„° (150í–‰, 4ì—´) Select Feature # Copy python x = iris.data[:, :2] # [ê½ƒë°›ì¹¨ ê¸¸ì´, ê½ƒë°›ì¹¨ ë„“ì´] y = iris.target Create Model # Copy python model = neighbors.KNeighborsClassifier(6) Model Fitting # Copy python model.fit(x, y) Model Predict # Copy python model.predict([[9, 2.5], [3.5, 11]]) # ê°ê°ì˜ ë¶„ë¥˜ í‘œì‹œ Plot Model # Data Points # Copy python plt.figure(figsize=(10,5)) plt.scatter(x[:, 0], x[:, 1]) plt.title(\u0026#34;Data points\u0026#34;) plt.show() Plot KNN # Copy python x_min, x_max = x[:,0].min() - 1, x[:,0].max() + 1 y_min, y_max = x[:,1].min() - 1, x[:,1].max() + 1 xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01)) Z = model.predict(np.c_[xx.ravel(), yy.ravel()]) Z = Z.reshape(xx.shape) Copy python cmap_light = ListedColormap([\u0026#39;#FFAAAA\u0026#39;, \u0026#39;#AAFFAA\u0026#39;,\u0026#39;#00AAFF\u0026#39;]) cmap_bold = ListedColormap([\u0026#39;#FF0000\u0026#39;, \u0026#39;#00FF00\u0026#39;,\u0026#39;#0000FF\u0026#39;]) plt.figure(figsize=(10,5)) plt.pcolormesh(xx, yy, Z, cmap=cmap_light) plt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap_bold, edgecolors=\u0026#39;gray\u0026#39;) plt.xlim(xx.min(), xx.max()) plt.ylim(yy.min(), yy.max()) plt.title(\u0026#34;3-Class classification (k = 1)\u0026#34;) plt.show() Kë¥¼ ë†’ì¼ìˆ˜ë¡ ê²°ì • ê²½ê³„ê°€ ë¶€ë“œëŸ¬ì›Œì§ "},{"id":88,"href":"/blog/aischool-06-03-gradient-boosting/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - Gradient Boosting","section":"Posts","content":"XG Boost # Extreme Gradient Boosting ëŒ€ìš©ëŸ‰ ë¶„ì‚° ì²˜ë¦¬ë¥¼ ìœ„í•œ Gradient Boosting ë¼ì´ë¸ŒëŸ¬ë¦¬ Decision Tree(ì˜ì‚¬ê²°ì •ë‚˜ë¬´) ì— Boosting ê¸°ë²•ì„ ì ìš©í•œ ì•Œê³ ë¦¬ì¦˜ AdaBoostëŠ” í•™ìŠµ ì„±ëŠ¥ì€ ì¢‹ìœ¼ë‚˜, ëª¨ë¸ì˜ í•™ìŠµ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ë‹¨ì  ë³‘ë ¬ ì²˜ë¦¬ ê¸°ë²•ì„ ì ìš©í•˜ì—¬ Gradient Boostë³´ë‹¤ í•™ìŠµ ì†ë„ë¥¼ ëŒì–´ì˜¬ë¦¼ Hyper-Parameterê°€ ë„ˆë¬´ ë§ê¸° ë•Œë¬¸ì— ê¶Œì¥ ì„¸íŒ… ì‚¬ìš© @ http://j.mp/2PukeTS Decision Tree # ì´í•´í•˜ê¸° ì‰½ê³  í•´ì„ë„ ìš©ì´í•¨ ì…ë ¥ ë°ì´í„°ì˜ ì‘ì€ ë³€ë™ì—ë„ Treeì˜ êµ¬ì„±ì´ í¬ê²Œ ë‹¬ë¼ì§ ê³¼ì í•©ì´ ì‰½ê²Œ ë°œìƒ (ì¤‘ê°„ì— ë©ˆì¶”ì§€ ì•Šìœ¼ë©´ Leaf ë…¸ë“œì— í•˜ë‚˜ì˜ ë°ì´í„°ë§Œ ë‚¨ê²Œ ë¨) ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Boosting ê¸°ë²• í™œìš© ex) í…Œë‹ˆìŠ¤ë¥¼ ì³¤ë˜ ê³¼ê±° ë°ì´í„°ë¥¼ ë³´ê³  ë‚ ì”¨ ì •ë³´ë¥¼ ì´ìš©í•´ ì˜ì‚¬ê²°ì • AdaBoost # Adaptive Boosting ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—¬ëŸ¬ weak learner ë“¤ì„ ë°˜ë³µì ìœ¼ë¡œ ìƒì„± ì•ì„  learnerê°€ ì˜ëª» ì˜ˆì¸¡í•œ ë°ì´í„°ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ê³  í•™ìŠµ ìµœì¢…ì ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ strong learnerë¥¼ ì´ìš©í•˜ì—¬ ì‹¤ì œ ì˜ˆì¸¡ ì§„í–‰ ì—ëŸ¬ë¥¼ ìµœì†Œí™”í•˜ëŠ” weightë¥¼ ë§¤ê¸°ê¸° ìœ„í•´ ê²½ì‚¬ í•˜ê°•ë²• ì‚¬ìš© ex) Regression: í‰ê· /ê°€ì¤‘í‰ê· , Classification: íˆ¬í‘œ XG Boost References # NGBoost Explained (Comparison to LightGBM and XGBoost) Gradient Boosting Interactive Playground Gradient Boosting explained Comparison for hyperparams of XGBoost \u0026amp; LightGBM XGBoost Parameters XG Boost í•˜ì´í¼ íŒŒë¼ë¯¸í„° ìƒì„¸ ì„¤ëª… Complete Guide to Parameter Tuning in XGBoost (with python codes) Microsoft EBM (Explainable Boosting Machine) ì •í˜•ë°ì´í„°ë¥¼ ìœ„í•œ ì¸ê³µì‹ ê²½ë§ ëª¨ë¸, TabNet Ensemble # ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì˜ˆì¸¡ ëª¨í˜•ì„ ìƒì„±í•œ í›„,\nì˜ˆì¸¡ ëª¨í˜•ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ ìµœì¢… ì˜ˆì¸¡ê²°ê³¼ë¥¼ ë„ì¶œí•´ë‚´ëŠ” ë°©ë²• ë‹¤ì–‘í•œ ëª¨ë¸ì´ ë¬¸ì œ ê³µê°„ì˜ ë‹¤ë¥¸ ì¸¡ë©´ì„ ë³´ë©´ì„œ ê°ê¸° ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì˜¤ì ì´ ìˆë‹¤ê³  ê°€ì •\n(ëª¨ë¸ ë³„ë¡œ ì•½ì ì„ ë³´ì™„) Boosting # weak learnerë“¤ì„ strong learnerë¡œ ë³€í™˜ì‹œí‚¤ëŠ” ì•Œê³ ë¦¬ì¦˜\n(ì•½í•œ í•™ìŠµê¸°ë¥¼ ì—¬ëŸ¬ê°œ ì‚¬ìš©í•´ì„œ í•˜ë‚˜ì˜ ê°•ê±´í•œ í•™ìŠµê¸°ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒ) ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ëª¨ë¸ì„ í•©ë¦¬ì ì¸ ìˆ˜ì¤€(60~70% ì„±ëŠ¥)ì—ì„œ ì—¬ëŸ¬ ì¢…ë¥˜ ìƒì„± ex) AdaBoost Gradient Boosting # ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‚¬ìš©í•´ì„œ AdaBoostë³´ë‹¤ ì„±ëŠ¥ì„ ê°œì„ í•œ Boosting ê¸°ë²• AdaBoostëŠ” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ì§€ì ì´ ì¡´ì¬í•˜ê²Œ ë˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ ë–¨ì–´ì§€ëŠ” ë‹¨ì \n(ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ì§€ì ê³¼ ê°€ê¹Œìš´ ë‹¤ë¥¸ ë°ì´í„°ë“¤ì´ ì˜ëª» ë¶„ë¥˜ë  ê°€ëŠ¥ì„±ì´ ë†’ìŒ) Gradient Boosting ê¸°ë²•ì€ ì´ì „ ëª¨ë¸ì— ì¢…ì†ì ì´ê¸° ë•Œë¬¸ì— ë³‘ë ¬ ì²˜ë¦¬ê°€ ë¶ˆê°€ëŠ¥ Bagging # Bootstrap Aggregating ê°€ì¤‘ì¹˜ë¥¼ ë§¤ê¸°ì§€ ì•Šê³  ê°ê°ì˜ ëª¨ë¸ì´ ì„œë¡œ ë…ë¦½ì  x ë°ì´í„° ì—´ë“¤ì˜ ì„œë¡œ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ ë…ë¦½ì ì¸ ëª¨ë¸ì„ ì—¬ëŸ¬ ì¢…ë¥˜ ìƒì„± ex) Random Forest Random Forest # ê° ëª¨ë¸ì€ ì„œë¡œ ë‹¤ë¥¸ ìƒ˜í”Œ ë°ì´í„°ì…‹ì„ í™œìš© (Bootstrap Sampling \u0026amp; Bagging) ê° ë°ì´í„°ì…‹ì€ ë³µì›ì¶”ì¶œì„ í†µí•´ ì›ë˜ ë°ì´í„°ì…‹ ë§Œí¼ì˜ í¬ê¸°ë¡œ ìƒ˜í”Œë§ (ëˆ„ë½ \u0026amp; ì¤‘ë³µ ë°œìƒ) ìœ„ ì„œë¡œ ë‹¤ë¥¸ ìƒ˜í”Œë¡œ ê° ëª¨ë¸ ìƒì„± ì‹œ, ê° ë…¸ë“œ ì§€ì ë§ˆë‹¤ xì—´ nê°œ ì¤‘ ëœë¤í•˜ê²Œ mê°œ ì¤‘ ë¶„ê¸° ì„ íƒ Classificationì—ì„œëŠ” root nì„ mìœ¼ë¡œ ì‚¬ìš© Regressionì—ì„œëŠ” n/3ì„ mìœ¼ë¡œ ì‚¬ìš© @ https://j.mp/3rZ05bN \u0026amp; https://j.mp/3GJ7QqH Learning Process # @ https://j.mp/3jRJH6n Import Libraries # Copy python import numpy as np import matplotlib.pyplot as plt from sklearn import ensemble from sklearn import datasets from sklearn.utils import shuffle from sklearn.metrics import mean_squared_error Load Data # Copy python boston = datasets.load_boston() X, y = shuffle(boston.data, boston.target, random_state=13) X = X.astype(np.float32) offset = int(X.shape[0] * 0.9) X_train, y_train = X[:offset], y[:offset] X_test, y_test = X[offset:], y[offset:] load ë¶€ë¶„ì—ì„œ ë‹¤ë¥¸ ë°ì´í„°ë„ ì‚¬ìš© ê°€ëŠ¥ boston.data: x data boston.target: y data int(X.shape[0] * 0.9): ì „ì²´ í–‰ ì¤‘ 90 í¼ì„¼íŠ¸ ì˜ë¯¸ boston.feature_names: ë°ì´í„°ì…‹ì—ì„œ ì—´ ì´ë¦„ boston.DESCR: ë°ì´í„°ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… Model Fitting # Copy python params = {\u0026#39;n_estimators\u0026#39;: 500, \u0026#39;max_depth\u0026#39;: 4, \u0026#39;min_samples_split\u0026#39;: 2, \u0026#39;learning_rate\u0026#39;: 0.01, \u0026#39;loss\u0026#39;: \u0026#39;ls\u0026#39;} clf = ensemble.GradientBoostingRegressor(**params) clf.fit(X_train, y_train) mse = mean_squared_error(y_test, clf.predict(X_test)) print(\u0026#34;MSE: %.4f\u0026#34; % mse) **params: ë”•ì…”ë„ˆë¦¬ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜ @ https://j.mp/2IPuJzY clf: Classifier Plot Deviance # Copy python test_score = np.zeros((params[\u0026#39;n_estimators\u0026#39;],), dtype=np.float64) for i, y_pred in enumerate(clf.staged_predict(X_test)): test_score[i] = clf.loss_(y_test, y_pred) plt.figure(figsize=(12, 6)) plt.subplot(1, 2, 1) plt.title(\u0026#39;Deviance\u0026#39;) plt.plot(np.arange(params[\u0026#39;n_estimators\u0026#39;]) + 1, clf.train_score_, \u0026#39;b-\u0026#39;, label=\u0026#39;Training Set Deviance\u0026#39;) plt.plot(np.arange(params[\u0026#39;n_estimators\u0026#39;]) + 1, test_score, \u0026#39;r-\u0026#39;, label=\u0026#39;Test Set Deviance\u0026#39;) plt.legend(loc=\u0026#39;upper right\u0026#39;) plt.xlabel(\u0026#39;Boosting Iterations\u0026#39;) plt.ylabel(\u0026#39;Deviance\u0026#39;) Deviance: í¸ì°¨ê°’, ì—ëŸ¬ n_estimators: ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ëª¨ë¸ì„ ëª‡ ê°œ ë§Œë“¤ì—ˆëŠ”ì§€ Test Dataì— ëŒ€í•œ ì—ëŸ¬ ë¼ì¸ì´ íŠ•ê²¨ì˜¬ë¼ê°€ëŠ” ì§€ì ì´ Overfitting Plot Feature Importance # Copy python feature_importance = clf.feature_importances_ feature_importance = 100.0 * (feature_importance / feature_importance.max()) sorted_idx = np.argsort(feature_importance) pos = np.arange(sorted_idx.shape[0]) + .5 plt.subplot(1, 2, 2) plt.barh(pos, feature_importance[sorted_idx], align=\u0026#39;center\u0026#39;) plt.yticks(pos, boston.feature_names[sorted_idx]) plt.xlabel(\u0026#39;Relative Importance\u0026#39;) plt.title(\u0026#39;Variable Importance\u0026#39;) plt.show() feature_importances_: íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì´ ê°€ì§€ê³  ìˆëŠ” ë³€ìˆ˜, ê°ê°ì˜ ì—´ë§ˆë‹¤ì˜ ì¤‘ìš”ë„ Feature ImportanceëŠ” ìƒëŒ€ì ì¸ ì¤‘ìš”ë„ì´ê¸° ë•Œë¬¸ì— í•©ê³„ê°€ 1 LSTAT(ì¸êµ¬ ì¤‘ í•˜ìœ„ ê³„ì¸µ ë¹„ìœ¨)ì´ ì§‘ê°’ì„ ì˜ˆì¸¡í•  ë•Œ ê°€ì¥ ì¤‘ìš”í•¨ Feature Importance References # Feature Importance Analysis (LIME) Permutation importance í•œê¸€ ì„¤ëª… Permutation importance with Pipeline "},{"id":89,"href":"/blog/aischool-06-02-logistic-regression/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - ë¡œì§€ìŠ¤í‹± íšŒê·€","section":"Posts","content":"Logistic Regression # ì´ì§„ ë¶„ë¥˜(0 ë˜ëŠ” 1) ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ëª¨ë¸ ë‹¤í•­ ë¡œì§€ìŠ¤í‹± íšŒê·€(k-class), ì„œìˆ˜ ë¡œì§€ìŠ¤í‹± íšŒê·€(k-class \u0026amp; ordinal)ë„ ì¡´ì¬ Sigmoid Functionì„ ì´ìš©í•˜ì—¬ ì…ë ¥ê°’ì´ ì–‘ì„± í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ ì„ ê³„ì‚° ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ MSE ì‹ì— ë„£ìœ¼ë©´ ì§€ìˆ˜ í•¨ì •ì˜ íŠ¹ì§• ë•Œë¬¸ì— í•¨ì •ì´ ë§ì€ ê·¸ë˜í”„ê°€ ë‚˜ì˜´ ë¶„ë¥˜ë¥¼ ìœ„í•œ Cost Functionì¸ Cross-Entropy í™œìš© ì„±ëŠ¥ ì§€í‘œë¡œëŠ” Cross-Entropy ì™¸ì— Accuracy ë“±ì„ ê°™ì´ ì‚¬ìš© ex) ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜, ì§ˆë³‘ ì–‘ì„±/ìŒì„± ë¶„ë¥˜ ë“± ì–‘ì„±/ìŒì„± ë¶„ë¥˜ ëª¨ë¸ # ì„ í˜• ëª¨ë¸ì€ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ë©´ ì–‘ì„±/ìŒì„± íŒë‹¨ ê¸°ì¤€ì´ í¬ê²Œ ë°”ë€œ ëª¨ë¸ì„ ì§€ìˆ˜ í•¨ìˆ˜ì¸ Sigmoid Functionìœ¼ë¡œ ë³€ê²½ Sigmoid Function # Î¸ ê°’ì— ë”°ë¼ ê¸°ìš¸ê¸°ë‚˜ xì¶•ì˜ ìœ„ì¹˜ê°€ ë°”ë€ŒëŠ” ì§€ìˆ˜ í•¨ìˆ˜ yì¶•ì„ ì´ë™í•˜ëŠ” ì„ í˜• í•¨ìˆ˜ì™€ ë‹¤ë¥´ê²Œ xì¶•ì„ ì´ë™ yê°€ 0.5ê°€ ë˜ëŠ” ì§€ì ì„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¹­ë˜ëŠ” í˜•íƒœ yê°’ì€ ì¡°ê±´ë¶€ í™•ë¥ ë¡œ í•´ì„ (Xê°€ ìˆì„ ë•Œ ì–‘ì„± í´ë˜ìŠ¤ì¼ í™•ë¥ ê°’) Cross-Entropy Function # ì˜ˆì¸¡ê°’ì˜ ë¶„í¬ì™€ ì‹¤ì œê°’ì˜ ë¶„í¬ë¥¼ ë¹„êµí•˜ì—¬ ê·¸ ì°¨ì´ë¥¼ Costë¡œ ê²°ì • ì¸ê³µì‹ ê²½ë§ì— ê° í–‰ì„ ì—´ë‹¨ìœ„ë¡œ ìª¼ê°œ ì…ë ¥ìœ¼ë¡œ ë„£ì—ˆì„ ë•Œ ë§ˆì§€ë§‰ì— ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ë§Œí¼ì˜ ìˆ˜ë¥¼ ë°˜í™˜ Softmax Functionì„ í†µê³¼ì‹œí‚¤ë©´ ê°œìˆ˜ëŠ” ê·¸ëŒ€ë¡œì§€ë§Œ í•©ì³¤ì„ ë•Œ 1ì´ë˜ëŠ” ìˆ«ìë¡œ ë³€ê²½ ì¸ê³µì‹ ê²½ë§ ê²°ê³¼ë¡œ ë±‰ì–´ë‚¸ ì¹´í…Œê³ ë¦¬ë³„ í™•ë¥ ì„ ì •ë‹µê³¼ ë¹„êµí•´ Cross-Entropy ê³„ì‚° One-Hot Encodingì´ ì ìš©ëœ ì •ë‹µì„ One-Hot Labelì´ë¼ ë¶€ë¦„ ì •ë‹µ í™•ë¥ ì´ ë†’ê³  ì˜¤ë‹µ í™•ë¥ ì´ ë‚®ì€ ëª¨ë¸ì´ ë‚˜ì€ ëª¨ë¸ Cross-EntropyëŠ” í•˜ë‚˜ì˜ ë¶„í¬ë¥¼ ë‹¤ë¥¸ ë¶„í¬ë¡œ ì˜®ê²¨ë‚´ëŠ” ê±°ë¦¬ë¼ê³ ë„ ë¶ˆë¦¼ Softmax Algorithm # $$S(y_i)=\\frac{e^{y_i}}{\\Sigma_j{e^{y_i}}}$$\në‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œë¥¼ ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ ëª¨ë¸ì˜ ê²°ê³¼ì— í•´ë‹¹í•˜ëŠ” ì ìˆ˜ë¥¼ ê° í´ë˜ìŠ¤ì— ì†Œì†ë  í™•ë¥ ì— í•´ë‹¹í•˜ëŠ” ê°’ë“¤ì˜ ë²¡í„°ë¡œ ë³€í™˜\n(í´ë˜ìŠ¤ ê°œìˆ˜ë§Œí¼ì˜ ìˆ«ìë¥¼ ì…ë ¥ ë°›ìœ¼ë©´ í•©ì´ 1ì´ ë˜ëŠ” í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜) ROC Curve # Receiver Operating Characteristic Curve ì–¼ë§ˆë‚˜ ì‹ í˜¸ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í• ì§€ë¥¼ ê·¸ë ¤ë‚¸ ê³¡ì„  Thresholdë¥¼ ëŒì–´ì˜¬ë¦¬ê±°ë‚˜ ëŒì–´ë‚´ë¦¬ëŠ” ê³¼ì •ì—ì„œ ë°œìƒ Thresholdë¥¼ ëŒì–´ë¡¤ë¦¬ë©´ ì–‘ì„± ê¸°ì¤€ì´ ì—„ê²©í•´ì§€ê³  ëŒì–´ë‚´ë¦¬ë©´ ì–‘ì„± ê¸°ì¤€ì´ ë„ˆê·¸ëŸ¬ì›Œì§ ëª¨ë¸ì´ ì—„ê²©í•  ë•ŒëŠ” ì–‘ì„±ìœ¨ì´ ë‚®ì§€ë§Œ ì´ë¥¼ ì–µì§€ë¡œ ëŒì–´ì˜¬ë¦¬ëŠ” ê³¼ì •ì—ì„œ ìœ„ì–‘ì„±ìœ¨ì´ ë°œìƒ ì„ ì´ ì§ê°ì¼ìˆ˜ë¡ ì´ìƒì ì¸ ëª¨ë¸, ë°˜ë©´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì•ˆì¢‹ì•„ ì‹¤ìˆ˜ê°€ ë§ìœ¼ë©´ ì„ ì´ ì•„ë˜ë¡œ ë‚´ë ¤ì˜´ Confusion Matrix # ë¶„ë¥˜ ëª¨ë¸ì´ í•™ìŠµ ê²°ê³¼ë¥¼ ë±‰ì–´ë‚¸ ê²ƒì„ ë°”íƒ•ìœ¼ë¡œ ë§Œë“  í‘œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ í˜¼ë™í•˜ê³  ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„ Accuracy(ì •í™•ì„±): (ì°¸ê¸ì • + ì°¸ë¶€ì •) / ì´ ì˜ˆì‹œ ìˆ˜ Recall(ì¬í˜„ìœ¨): ì •ë‹µì—ì„œ ì°¸ì¸ ê²ƒì„ ê³¨ë¼ëƒ„, TP / (FN + TP) Precision(ì •ë°€ë„): ë¶„ë¥˜í•œ ê²ƒë“¤ ì¤‘ ì •ë‹µì„ ê³¨ë¼ëƒ„, TP / (TP + FP) ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜ì˜ ê²½ìš° ì •ë°€ë„ë¥¼ ë†’ì¼ í•„ìš”ê°€ ìˆìŒ F1-Score: Recallê³¼ Precisionì˜ ì¡°í™”í‰ê· , 2RP / (R + P) F-beta score: Recallê³¼ Precisionì— ê°€ì¤‘ì¹˜ ë¶€ì—¬ AUC # Area Under the ROC Curve ROC ì»¤ë¸Œ ë°‘ì— ìˆëŠ” ì˜ì—­ì˜ í¬ê¸° 0.5ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì´ ë‚˜ì˜¤ë©°, 0.7 í›„ë°˜ì„ ì“¸ë§Œí•œ ëª¨ë¸ë¡œ íŒë‹¨ Learning Process # Load Data # pd.read_excel()ë¡œ ì—‘ì…€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì—‘ì…€ ë°ì´í„°ë¥¼ np.array() ì•ˆì— ë„£ì–´ Numpy Array í˜•íƒœë¡œ ë³€ê²½ Select Feature # ë–¨ì–´ì§„ ì—´ë“¤ì„ êº¼ë‚¼ ë•Œ data[:, (5, 12)] í˜•ì‹ìœ¼ë¡œ ì—´ì„ êº¼ëƒ„ Training \u0026amp; Test Set # Copy python from sklearn import model_selection x_train, x_test, y_train, y_test = \\ model_selection.train_test_split(boston_X, boston_Y, test_size=0.3, random_state=0) Create Model # Copy python from sklearn import linear_model model = linear_model.LogisticRegression() Model Fitting # Copy python model.fit(x_train, y_train) Model Predict # Copy python model.predict(x_train) Accuracy # Copy python from sklearn.metrics import accuracy_score print(accuracy_score(model.predict(x_test), y_test)) ì–‘ì„±/ìŒì„± í™•ë¥  # Copy python model.predict_proba(x_test) Plot ROC Curve # Copy python from sklearn.metrics import roc_curve, auc fpr, tpr, _ = roc_curve(y_true=y_test, y_score=pred_test[:,1]) roc_auc = auc(fpr, tpr) y_trueê°€ ì •ë‹µ, y_scoreê°€ ì–‘ì„±ì´ ë‚˜ì˜¬ í™•ë¥  fpr: ROC ì»¤ë¸Œë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ xì¢Œí‘œ tpr: ROC ì»¤ë¸Œë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ yì¢Œí‘œ Copy python plt.figure(figsize=(10, 10)) plt.plot(fpr, tpr, color=\u0026#39;darkorange\u0026#39;, lw=2, label=\u0026#39;ROC curve (area = %0.2f)\u0026#39; % roc_auc) plt.plot([0, 1], [0, 1], color=\u0026#39;navy\u0026#39;, lw=2, linestyle=\u0026#39;--\u0026#39;) plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) plt.legend(loc=\u0026#34;lower right\u0026#34;) plt.title(\u0026#34;ROC curve\u0026#34;) plt.show() "},{"id":90,"href":"/blog/aischool-06-00-machine-learning/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹","section":"Posts","content":"ì¸ê³µì§€ëŠ¥ # Intelligent Agentsë¥¼ ë§Œë“œëŠ” ê²ƒ ì£¼ë³€ í™˜ê²½ë“¤ì„ ì¸ì‹í•˜ê³  ì›í•˜ëŠ” í–‰ë™ì„ ì·¨í•˜ì—¬ ëª©í‘œë¥¼ ì„±ì·¨í•˜ëŠ” ê²ƒ Artificial Narrow Intelligence # ì œí•œëœ ê¸°ëŠ¥ë§Œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì¸ê³µì§€ëŠ¥ weak AI Artificial General Intelligence # ì‚¬ëŒë§Œí¼ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì¸ê³µì§€ëŠ¥ strong AI Artificial Super Intelligence # ëª¨ë“  ë¶„ì•¼ì—ì„œ ì‚¬ëŒë³´ë‹¤ ë›°ì–´ë‚œ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ # ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ (y = ax + b) ëª¨ë¸ì—ì„œ Î¸ëŠ” Parameter(ê°€ì¤‘ì¹˜, Weight) ì˜ë¯¸ ëª¨ë¸ì—ì„œ h(x)ëŠ” Hypotheses(ê°€ì„¤) ì˜ë¯¸ ëª¨ë¸ì—ì„œ bëŠ” Bias(í¸í–¥, ë³´ì •ì¹˜) ì˜ë¯¸ ë¨¸ì‹ ëŸ¬ë‹ # ì–´ë– í•œ ê³¼ì œë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì—ì„œ íŠ¹ì •í•œ í‰ê°€ ê¸°ì¤€ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµì˜ ê²½í—˜ì„ ìŒ“ëŠ” í”„ë¡œê·¸ë¨ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ # Supervised # ì…ë ¥ê°’ì— ëŒ€í•œ ì •ë‹µì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ í•™ìŠµ ë°ì´í„°ì™€ ì •ë‹µì´ ê°™ì´ ì¡´ì¬ íšŒê·€(Regression): ê²°ê³¼ê°€ ì‹¤ìˆ˜ ì˜ì—­ ì „ì²´ì—ì„œ ë‚˜íƒ€ë‚¨ ë¶„ë¥˜(Classification): ê²°ê³¼ê°€ íŠ¹ì • ë¶„ë¥˜ì— í•´ë‹¹í•˜ëŠ” ë¶ˆì—°ì†ê°’ìœ¼ë¡œ ë‚˜íƒ€ë‚¨ ex) ì£¼ì‹ ê°€ê²© ì˜ˆì¸¡, ì´ë¯¸ì§€ ì¸ì‹ ë“± Unsupervised # ì…ë ¥ê°’ ì†ì— ìˆ¨ì–´ìˆëŠ” ê·œì¹™ì„±ì„ ì°¾ê¸° ìœ„í•´ í•™ìŠµ ì •ë‹µì´ ì—†ëŠ” ë°ì´í„°ë¥¼ ì£¼ê³  ë¹„ìŠ·í•œ ì§‘ë‹¨ì„ ë¶„ë¥˜ ex) ê³ ê°êµ° ë¶„ë¥˜, ì¥ë°”êµ¬ë‹ˆ ë¶„ì„(Association Rule) ë“± Reinforcement # Trial \u0026amp; Errorë¥¼ í†µí•œ í•™ìŠµ ìµœì¢…ì ìœ¼ë¡œ ì–»ê²Œ ë  ê¸°ëŒ€ ë³´ìƒì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•œ í–‰ë™ ì„ íƒ ì •ì±… í•™ìŠµ ê° ìƒíƒœì— ëŒ€í•´ ê²°ì •í•œ í–‰ë™ì„ í†µí•´ í™˜ê²½ìœ¼ë¡œë¶€í„° ë°›ëŠ” ë³´ìƒì„ í•™ìŠµ ex) ë¡œë´‡ ì œì–´, ê³µì • ìµœì í™” ë“± Automated ML # ì–´ë–¤ ëª¨ë¸(í•¨ìˆ˜, ì•Œê³ ë¦¬ì¦˜)ì„ ì¨ì•¼í• ì§€ë¥¼ ì»´í“¨í„°ê°€ ì•Œì•„ì„œ ì •í•˜ê²Œ í•¨ ì¸ê³µì‹ ê²½ë§ ë ˆì´ì–´ì˜ ë²”ìœ„, í›„ë³´ ë“±ì„ ì •í•´ë†“ê³  ê·¸ ì•ˆì—ì„œ ê°€ì¥ ì¢‹ì€ ì¡°í•©ì„ ì°¾ìŒ ex) AutoML Tables (í–‰ì˜ ìˆ˜ê°€ 1000ê±´ì´ ë„˜ì–´ì•¼í•˜ëŠ” ì œì•½) í•™ìŠµ # ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” ë°©ë²•ì„ ì°¾ëŠ” ê³¼ì • ë°ì´í„°ì— ë§ëŠ” ëª¨ë¸ì„ ì°¾ëŠ” ê³¼ì • (= Model Fitting) ì‹¤ì œ ì •ë‹µê³¼ ì˜ˆì¸¡ ê²°ê³¼ ì‚¬ì´ì˜ ì˜¤ì°¨(Loss, Cost, Error)ë¥¼ ì¤„ì—¬ë‚˜ê°€ëŠ” ìµœì í™” ê³¼ì • í•™ìŠµ ê³¼ì • # ì´ˆê¸° ëª¨ë¸ì— ë°ì´í„°ë¥¼ ì…ë ¥ ê²°ê³¼ë¥¼ í‰ê°€ (ì˜ˆì¸¡/ë¶„ë¥˜ì˜ ì •í™•ë„ ë“±) ê²°ê³¼ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ëª¨ë¸ì„ ìˆ˜ì • (ëª¨ë¸ ë‚´ë¶€ Parameter ìˆ˜ì • ë“±) Model\u0026rsquo;s Capacity # 2ë²ˆ ëª¨ë¸ì€ 3ë²ˆ ëª¨ë¸ë³´ë‹¤ ì˜¤ì°¨ê°€ í¬ì§€ë§Œ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ìƒê²¼ì„ ë•Œ ë¹„ìŠ·í•˜ê²Œ ì˜ˆì¸¡ ê°€ëŠ¥ 3ë²ˆ ëª¨ë¸ì€ ì˜¤ì°¨ê°€ ê°€ì¥ ì ì§€ë§Œ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ìƒê²¼ì„ ë•Œ ì˜¤ì°¨ê°€ ë§¤ìš° ì»¤ì§ˆ ìˆ˜ ìˆìŒ 3ë²ˆ ëª¨ë¸ê³¼ ê°™ì€ Overfitting(ê³¼ì í•©)ì´ ë°œìƒí•˜ê¸° ì „ì— í•™ìŠµì„ ë©ˆì¶¤ Cross Validation # ìƒˆë¡œìš´ ë°ì´í„°ë“¤ì— ëŒ€í•´ì„œë„ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ê²Œ í•˜ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ 3ê°œ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ  í•™ìŠµ 60%ì˜ Training Dataë¡œ ëª¨ë¸ì„ í•™ìŠµ 20%ì˜ Validation Dataë¡œ ëª¨ë¸ì„ ìµœì í™”/ì„ íƒ 20%ì˜ Test Dataë¡œ ëª¨ë¸ì„ í‰ê°€ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ëŠ” ë¹„ìœ¨ì€ ëª¨ë¸ì— ë”°ë¼ ë‹¬ë¼ì§ K-Fold Cross Validation # í›„ë³´ ëª¨ë¸ ê°„ ë¹„êµ ë° ì„ íƒì„ ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ Training Dataë¥¼ K ë“±ë¶„í•˜ê³  ê·¸ ì¤‘ í•˜ë‚˜ë¥¼ Validation Dataë¡œ ì„¤ì • K ê°’ì€ ìì²´ì ìœ¼ë¡œ ê²°ì •í•˜ë©° ë³´í†µ 10-Fold ì‚¬ìš© (ì‹œê°„ì´ ì—†ìœ¼ë©´ 5-Fold) ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ KëŠ” ì£¼ë¡œ ì‚¬ìš©ìê°€ ê²°ì •í•˜ëŠ” ìƒìˆ˜ Stratified: ì¸µí™” í‘œì§‘ ë°©ë²•, ë°ì´í„°ì˜ ë¶„ë¥˜ ë³„ ë¹„ìœ¨ì´ ë‹¤ë¥´ë©´ K-Fold ì¡°ê° ì•ˆì—ì„œ ë¹„ìœ¨ì„ ìœ ì§€ì‹œí‚´ 10-Fold í•™ìŠµ ê³¼ì • # ë°ì´í„°ë¥¼ 80%ì˜ Training Dataì™€ 20%ì˜ Test Dataë¡œ ë‚˜ëˆ„ê³  Training Dataë¥¼ 10ë“±ë¶„\nPhase 1. Training Data(0:9) + Validation Data(TD 9)ë¥¼ ì‚¬ìš©í•´ ì ìˆ˜ ì¸¡ì •\nPhase 2. Training Data(0:8,9) + Validation Data(TD 8)ë¥¼ ì‚¬ìš©í•´ ì ìˆ˜ ì¸¡ì •\n. . .\nPhase 10. Training Data(1:10) + Validation Data(TD 0)ë¥¼ ì‚¬ìš©í•´ ì ìˆ˜ ì¸¡ì •\në§ˆì§€ë§‰ìœ¼ë¡œ Training Data ì „ì²´ë¥¼ í•™ìŠµí•˜ê³  Test Dataë¡œ ê²€ì¦\nScikit-learn # íŒŒì´ì¬ìœ¼ë¡œ ì „í†µì ì¸ ë¨¸ì‹  ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ë“¤ì„ êµ¬í˜„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ê³¼ì˜ í˜¸í™˜ì„±ì´ ì¢‹ìŒ (Numpy, Pandas, Matplotlib ë“±) ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ê³¼ì • # ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° Copy python sklearn.load_[DATA]() Train/Test setìœ¼ë¡œ ë°ì´í„° ë‚˜ëˆ” Copy python sklearn.model_selection.train_test_split(X, Y, test_size) ëª¨ë¸ ê°ì²´ ìƒì„± Copy python sklearn.linear_model.LinearRegression() sklearn.linear_model.LogisticRegression() sklearn.neighbors.KNeighborsClassifier(n_neighbors) sklearn.cluster.KMeans(n_clusters) sklearn.decomposition.PCA(n_components) sklearn.svm.SVC(kernel, C, gamma) ëª¨ë¸ í•™ìŠµ ì‹œí‚¤ê¸° Copy python model.fit(train_X, train_Y) ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡ (Scalerë¥¼ ì ìš©í–ˆìœ¼ë©´ ìƒˆë¡œìš´ ë°ì´í„°ì—ë„ ì ìš©) Copy python model.predict(test_X) model.predict_proba(test_X) sklearn.metrics.mean_squared_error(predicted_Y, test_Y) sklearn.metrics.accuracy_score(predicted_Y, test_Y) sklearn.metrics.precision_score sklearn.metrics.recall_score ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ ê¸°ì¤€ # Choosing the right estimator Feature Normalization # Numeric Column # Min-Max Algorithm Standardization Categorical Column # One-Hot Encoding, One-Hot Vector ì—´ê³¼ ëª©ë¡ ê°œìˆ˜ë§Œí¼ 0ìœ¼ë¡œ ì±„ì›Œì§„ í–‰ë ¬ì„ ë§Œë“¤ê³  ê°’ì´ í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ì— 1ì„ í‘œì‹œ ë²”ì£¼í˜• ë°ì´í„°(ì¹´í…Œê³ ë¦¬)ì˜ ìˆ«ìê°€ í¬ê³  ì‘ìŒì— ê´€ê³„ì—†ì´ ì¹´í…Œê³ ë¦¬ì˜ ìœ„ì¹˜ê°’ë§Œì„ íŒë‹¨ Supervised Algorithm # Linear Regression (ì„ í˜• íšŒê·€) # ì¢…ì† ë³€ìˆ˜ yì™€ ë…ë¦½ ë³€ìˆ˜ x ì‚¬ì´ì˜ ì„ í˜• ìƒê´€ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” íšŒê·€ë¶„ì„ ê¸°ë²• Logistic Regression (ë¡œì§€ìŠ¤í‹± íšŒê·€) # ì´ì§„ ë¶„ë¥˜(0 ë˜ëŠ” 1) ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ëª¨ë¸ ex) ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜, ì§ˆë³‘ ì–‘ì„±/ìŒì„± ë¶„ë¥˜ ë“± Gradient Boosting Regression (XG Boost) # ëŒ€ìš©ëŸ‰ ë¶„ì‚° ì²˜ë¦¬ë¥¼ ìœ„í•œ Gradient Boosting ë¼ì´ë¸ŒëŸ¬ë¦¬ ex) í…Œë‹ˆìŠ¤ë¥¼ ì³¤ë˜ ê³¼ê±° ë°ì´í„°ë¥¼ ë³´ê³  ë‚ ì”¨ ì •ë³´ë¥¼ ì´ìš©í•´ ì˜ì‚¬ê²°ì • K-Nearest Neightbor Algorithm (KNN) # ê¸°ì¡´ì˜ ê°€ê¹Œìš´ ì´ì›ƒ ë°ì´í„°ë¥¼ ì‚´í´ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ Kernel Support Vector Machine (KSVM) # ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” Marginì„ ìµœëŒ€í™”í•˜ëŠ” ê²°ì • ê²½ê³„ë¥¼ ì°¾ëŠ” ê¸°ë²• Unsupervised Algorithm # K-Means Algorithm # ë°ì´í„°ë¥¼ Kê°œì˜ í´ëŸ¬ìŠ¤í„°ë¡œ ë¶„ë¥˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ Principal Component Analysis # ì°¨ì› ì¶•ì†Œë¥¼ í†µí•´ ìµœì†Œ ì°¨ì›ì˜ ì •ë³´ë¡œ ì›ë˜ ì°¨ì›ì˜ ì •ë³´ë¥¼ ëª¨ì‚¬í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ Model Saving \u0026amp; Loading # Model Saving # Copy python import joblib joblib.dump(model, \u0026#39;model_v1.pkl\u0026#39;, compress=True) Model Loading # Copy python import joblib model_loaded = joblib.load(\u0026#39;model_v1.pkl\u0026#39;) "},{"id":91,"href":"/blog/aischool-06-01-linear-regression/","title":"[AI SCHOOL 5ê¸°] ë¨¸ì‹  ëŸ¬ë‹ ì‹¤ìŠµ - ì„ í˜• íšŒê·€","section":"Posts","content":"Linear Regression # ì¢…ì† ë³€ìˆ˜ yì™€ ë…ë¦½ ë³€ìˆ˜ x ì‚¬ì´ì˜ ì„ í˜• ìƒê´€ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” íšŒê·€ë¶„ì„ ê¸°ë²• ì •ë‹µì´ ìˆëŠ” ë°ì´í„°ì˜ ì¶”ì„¸ë¥¼ ì˜ ì„¤ëª…í•˜ëŠ” ì„ í˜• í•¨ìˆ˜ë¥¼ ì°¾ì•„ xì— ëŒ€í•œ yë¥¼ ì˜ˆì¸¡ Linear Combination (ì„ í˜• ê²°í•©): ë”í•˜ê¸°ì™€ ê³±í•˜ê¸°ë¡œë§Œ ì´ë£¨ì–´ì§„ ì‹ ë‹¨ìˆœ íšŒê·€ë¶„ì„: 1ê°œì˜ ë…ë¦½ë³€ìˆ˜(x)ê°€ 1ê°œì˜ ì¢…ì†ë³€ìˆ˜(y)ì— ì˜í–¥ì„ ë¯¸ì¹  ë•Œ ë‹¤ì¤‘ íšŒê·€ë¶„ì„: 2ê°œ ì´ìƒì˜ ë…ë¦½ë³€ìˆ˜(x)ê°€ 1ê°œì˜ ì¢…ì†ë³€ìˆ˜(y)ì— ì˜í–¥ì„ ë¯¸ì¹  ë•Œ ì„ í˜• íšŒê·€ëŠ” ê°€ì¥ ì í•©í•œ Î¸ë“¤ì˜ ì§‘í•©ì„ ì°¾ëŠ” ê²ƒì´ ëª©í‘œ Cost Function # ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ì˜ ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥(ì •í™•ë„)ì„ íŒë‹¨í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ Objective (MIN or MAX) í•¨ìˆ˜ ì•ˆì— Cost Functionì´ ì¡´ì¬ ì„ í˜• íšŒê·€ì—ì„œëŠ” Mean Squre(d) Error Function (í‰ê·  ì œê³± ì˜¤ì°¨ í•¨ìˆ˜) í™œìš© MSE(Cost)ê°€ ìµœì†Œê°€ ë˜ëŠ” Î¸(a \u0026amp; b)ë¥¼ ì°¾ì•„ì•¼í•˜ë©°,\nì´ë¥¼ ìœ„í•œ ìµœì í™” ê¸°ë²•ìœ¼ë¡œ Gradient Descent Algorithm (ê²½ì‚¬í•˜ê°•ë²•) í™œìš© Mean Squre Error Function # íšŒê·€ ë¶„ì„ì„ ìœ„í•œ Cost Function yì¶• ë°©í–¥ì˜ ì°¨ì´ë¥¼ ì—ëŸ¬ë¡œ íŒë‹¨í•˜ëŠ”ë° ì „ì²´ ì—ëŸ¬ë¥¼ ë‹¨ìˆœí•˜ê²Œ í•©ì¹  ê²½ìš°\nì–‘ ì—ëŸ¬ì™€ ìŒ ì—ëŸ¬ê°€ ìƒì‡„ë˜ì–´ ì˜¬ë°”ë¥¸ íŒë‹¨ì„ í•  ìˆ˜ ì—†ìŒ ë¶€í˜¸ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ ëª¨ë“  ì—ëŸ¬ì— ì œê³±ì„ ì·¨í•˜ê³  ê·¸ í‰ê· ì„ êµ¬í•œ ê²ƒì´ MSE MSE(Cost)ê°€ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì—ëŸ¬ê°€ ì ë‹¤ê³  íŒë‹¨ ê°’ì— ì œê³±ì„ ì·¨í•˜ê¸° ë•Œë¬¸ì— ì´ìƒì¹˜ê°€ ìˆìœ¼ë©´ ì˜í–¥ì„ ë§ì´ ë°›ì•„ ì´ìƒì¹˜ë¥¼ ì°¾ì•„ë‚´ê¸° ì‰¬ì›€ ì œê³± ëŒ€ì‹ ì— ì ˆëŒ“ê°’ì„ ì‚¬ìš©í•˜ëŠ” MAE Functionì€ ì´ìƒì¹˜ì— ì˜í–¥ì„ ëœ ë°›ìŒ Gradient Descent Algorithm # Cost Functionì˜ ê°’ì„ ìµœì†Œë¡œ ë§Œë“œëŠ” Î¸ë¥¼ ì°¾ì•„ë‚˜ê°€ëŠ” ë°©ë²• Cost Functionì˜ Gradient(ê¸°ìš¸ê¸°)ì— ìƒìˆ˜ë¥¼ ê³±í•œ ê°’ì„ ë¹¼ì„œ Î¸ë¥¼ ì¡°ì • ì–´ëŠ ë°©í–¥ìœ¼ë¡œ Î¸ë¥¼ ì›€ì§ì´ë©´ Costê°€ ì‘ì•„ì§€ëŠ”ì§€ í˜„ì¬ ìœ„ì¹˜ì—ì„œ í•¨ìˆ˜ë¥¼ ë¯¸ë¶„í•˜ì—¬ íŒë‹¨ ë³€ìˆ˜(Î¸)ë¥¼ ì›€ì§ì´ë©´ì„œ ì „ì²´ Cost ê°’ì´ ë³€í•˜ì§€ ì•Šê±°ë‚˜ ë§¤ìš° ëŠë¦¬ê²Œ ë³€í•  ë•Œê¹Œì§€ ì ‘ê·¼ MSEë¥¼ ë¯¸ë¶„í–ˆì„ ë•Œ 0ì´ ë‚˜ì˜¤ëŠ” ì§€ì ì„ ì°¾ì•„ë„ ë˜ì§€ë§Œ, ë¹…ë°ì´í„°ì—ì„œ x ë°ì´í„° ì—­í–‰ë ¬ì´ ì˜¤ë˜ê±¸ë¦¼ ê·¸ë˜í”„ ì¤‘ê°„ì— í•¨ì •ì²˜ëŸ¼ í˜ì¸ ë¶€ë¶„ì„ Local Minimaë¼ ë¶€ë¦„ (ëª©í‘œì ì€ Global Minima) ê°€ë˜ ë°©í–¥ì—ì„œ ì¡°ê¸ˆ ë” ê°€ëŠ” ë°œì „ëœ Gradient Descent ê¸°ë²•ì„ í†µí•´ í•¨ì •ì„ ë¹ ì ¸ë‚˜ê° Local Minimaë„ Global Minimaì™€ ë¹„ìŠ·í•˜ê²Œ ë–¨ì–´ì§€ê¸° ë•Œë¬¸ì— ì—ëŸ¬ê°€ ì ìŒ $$\\text{repeat until convergence}\\ { \\theta_j:=\\theta_j-{\\alpha}\\frac{\\delta}{\\delta\\theta_j}J(\\theta_0,\\theta_1)\\quad(\\text{for}j=0\\text{and}j=1) }$$\nê³„ì‚°ì‹ì—ì„œ J(Î¸0, Î¸1)ëŠ” MSEë¥¼ ì˜ë¯¸í•˜ë©° ì´ë¥¼ ë¯¸ë¶„í•œ ê²ƒì— âºë¥¼ ê³±í•¨ âºëŠ” í•œ ë²ˆ ì´ë™í•˜ëŠ” ê¸¸ì´ë¥¼ ê²°ì •í•˜ëŠ” ìƒìˆ˜ (Step Size, ë³´í­, Learning Rate) âºì™€ ê°™ì´ ì‚¬ëŒì´ ê²°ì •í•´ì•¼ í•˜ëŠ” ê°’ì„ Hyper-Parameterë¼ ë¶€ë¦„ Hyper-Parameter # ì‚¬ëŒì´ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°, ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„± ì‹œ ì§‘ì–´ ë„£ëŠ” íŒŒë¼ë¯¸í„° ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ê²ƒ, ì¸ê³µì‹ ê²½ë§ì˜ ì¸µì„ ëª‡ê°œë¡œ êµ¬ì„±í•  ê²ƒì¸ì§€ ë“± Hyper-Parameterë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì„ Model Tuning, Hyper-Parmas Tuning,\në˜ëŠ” Hyper-Parameter Optimizator(HPO)ë¼ ë¶€ë¦„ AutoML # Hyper-Parameter Tuningì„ ì»´í“¨í„°ì—ê²Œ ë§¡ê¹€ Automated FE (Feature Engineering): ê²°ì¸¡ì¹˜ ì±„ì›€, xì—´(feature) ìƒì„± Automated MS (Model Selection) Automated HPO (Hyper Parameter Optimization) Learning Process # Load Data # pd.read_excel()ë¡œ ì—‘ì…€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì—‘ì…€ ë°ì´í„°ë¥¼ np.array() ì•ˆì— ë„£ì–´ Numpy Array í˜•íƒœë¡œ ë³€ê²½ Select Feature # Numpy ArrayëŠ” 2ì°¨ì› í–‰ë ¬ì´ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— data[:, 1:2] í˜•ì‹ìœ¼ë¡œ ì—´ì„ êº¼ëƒ„ (data[:, 1]ëŠ” 1ì°¨ì› í–‰ë ¬ì„ ë°˜í™˜) Training \u0026amp; Test Set # Copy python from sklearn import model_selection x_train, x_test, y_train, y_test = \\ model_selection.train_test_split(boston_X, boston_Y, test_size=0.3, random_state=0) Create Model # Copy python from sklearn import linear_model model = linear_model.LinearRegression() Model Fitting # Copy python model.fit(x_train, y_train) model.coef_: aì— í•´ë‹¹í•˜ëŠ” Î¸ ê°’ model.intercept_: bì— í•´ë‹¹í•˜ëŠ” Î¸ ê°’ (y ì ˆí¸) Model Predict # Copy python model.predict(x_train) MSE # Copy python print(np.mean((model.predict(x_train) - y_train) ** 2)) Copy python from sklearn.metrics import mean_squared_error print(mean_squared_error(model.predict(x_train), y_train)) Training Dataì™€ Test Dataì˜ MSE ì°¨ì´ë¥¼ ì›ë³¸ ë°ì´í„°ì™€ í•¨ê»˜ ë¹„êµí•˜ì—¬ Overfitting íŒë‹¨ ì„ í˜•íšŒê·€ëŠ” ì„±ëŠ¥ì„ ê¸°ëŒ€í•˜ê¸° ì–´ë ¤ì›€ Plot Linear Model # Copy python plt.figure(figsize=(10, 10)) plt.scatter(x_test, y_test, color=\u0026#34;black\u0026#34;) # Test data plt.scatter(x_train, y_train, color=\u0026#34;red\u0026#34;, s=1) # Train data plt.plot(x_test, model.predict(x_test), color=\u0026#34;blue\u0026#34;, linewidth=3) plt.show() "},{"id":92,"href":"/blog/aischool-05-03-merge/","title":"[AI SCHOOL 5ê¸°] SQL í”„ë¡œê·¸ë˜ë° ì‹¤ìŠµ - Merge","section":"Posts","content":"INNER JOIN # Copy sql SELECT l.Title, r.Name FROM albums AS l INNER JOIN artists AS r ON r.ArtistId = l.ArtistId; Copy sql SELECT Title, Name FROM albums INNER JOIN artists USING(ArtistId); LEFT JOIN # Copy sql SELECT Name, Title FROM artists LEFT JOIN albums ON artists.ArtistId = albums.ArtistId ORDER BY Name; SELF JOIN # Copy sql SELECT m.firstname || \u0026#39; \u0026#39; || m.lastname AS \u0026#39;Manager\u0026#39;, e.firstname || \u0026#39; \u0026#39; || e.lastname AS \u0026#39;Receives reports from\u0026#39; FROM employees e INNER JOIN employees m ON m.employeeid = e.reportsto ORDER BY manager; \u0026lsquo;A í…Œì´ë¸”\u0026rsquo;ê³¼ A í…Œì´ë¸”ì˜ ë³µì‚¬ë³¸ì¸ \u0026lsquo;B í…Œì´ë¸”\u0026rsquo;ì„ í•©ì¹˜ê¸° Grouping Data # Copy sql SELECT albumid, COUNT(trackid) FROM tracks GROUP BY albumid ORDER BY COUNT(trackid) DESC; Copy sql SELECT albumid, COUNT(trackid) FROM tracks GROUP BY albumid HAVING albumid = 1; Copy sql SELECT albumid, COUNT(trackid) FROM tracks WHERE COUNT(trackid) BETWEEN 18 AND 20 GROUP BY albumid; ì—ëŸ¬ë°œìƒ: WHEREë¬¸ì—ëŠ” ì§‘ê³„í•¨ìˆ˜ ì‚¬ìš© ë¶ˆê°€ WHEREê°€ ì§‘ê³„í•¨ìˆ˜ë³´ë‹¤ ìš°ì„ ì ìœ¼ë¡œ ì‹¤í–‰ë˜ê¸° ë•Œë¬¸ Copy sql SELECT tracks.albumid, title, MIN(tracks.milliseconds), MAX(tracks.milliseconds), ROUND(AVG(tracks.milliseconds), 2) FROM tracks INNER JOIN albums ON albums.albumid = tracks.albumid GROUP BY tracks.albumid; ROUNDëŠ” në²ˆì§¸ ìë¦¬ê¹Œì§€ ë‚˜íƒ€ë‚˜ë„ë¡ ë°˜ì˜¬ë¦¼ Subquery # Copy sql SELECT AVG(SUM(bytes)) FROM tracks GROUP BY albumid; SELECT ë¬¸ì—ì„œ ì§‘ê³„í•¨ìˆ˜ì˜ ê²°ê³¼ ê°’ì— ë°”ë¡œ ì¤‘ì²©í•˜ì—¬ ì§‘ê³„í•¨ìˆ˜ ì ìš© ë¶ˆê°€ Copy sql SELECT AVG(SIZE) FROM (SELECT SUM(bytes) AS SIZE FROM tracks GROUP BY albumid); "},{"id":93,"href":"/blog/aischool-05-02-sql-crud/","title":"[AI SCHOOL 5ê¸°] SQL í”„ë¡œê·¸ë˜ë° ì‹¤ìŠµ - SQL CRUD","section":"Posts","content":"SELECT # Copy sql SELECT 10 / 5, 2 * 4; Copy sql SELECT trackid, name FROM tracks; Copy sql SELECT * FROM tracks; INSERT # Copy sql INSERT INTO artists (name) VALUES(\u0026#39;Bud Powell\u0026#39;); Copy python script = \u0026#34;\u0026#34;\u0026#34; INSERT INTO artists (name) VALUES (\u0026#34;?\u0026#34;); \u0026#34;\u0026#34;\u0026#34; data = [ (\u0026#34;Buddy Rich\u0026#34;), (\u0026#34;Candido\u0026#34;), (\u0026#34;Charlie Byrd\u0026#34;) ] cur.executemany(script, data) Copy sql SELECT ArtistId, Name FROM Artists ORDER BY ArtistId DESC; UPDATE # Copy sql UPDATE employees SET lastname = \u0026#39;Smith\u0026#39; WHERE employeeid = 3; Copy sql UPDATE employees SET city = \u0026#39;Toronto\u0026#39;, state = \u0026#39;ON\u0026#39;, postalcode = \u0026#39;M5P 2N7\u0026#39; WHERE employeeid = 4; Copy sql UPDATE employees SET email = UPPER(firstname || \u0026#34;.\u0026#34; || lastname || \u0026#34;@corp.co.kr\u0026#34;); Sorting # Copy sql SELECT TrackId, Name, Composer FROM tracks ORDER BY Composer; NULL Dataì¸ Noneì€ SQLite3ì—ì„œ ê°€ì¥ ì‘ì€ ê°’ìœ¼ë¡œ ì¸ì‹ Filtering # DISTINCT # Copy sql SELECT DISTINCT city FROM customers; NULLì„ í¬í•¨í•œ ì¤‘ë³µê°’ì„ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³  ì œì™¸ Copy sql SELECT DISTINCT city, country FROM customers; 2ê°œ ì—´ì˜ ê°’ì´ ëª¨ë‘ ë™ì¼í•œ í–‰ë“¤ì„ ì œì™¸ WHERE # Copy sql SELECT name, milliseconds, bytes, albumid FROM tracks WHERE (albumid = 10) AND (milliseconds \u0026gt; 250000); WHERE \u0026amp; LIKE # Copy sql SELECT trackid, name FROM tracks WHERE name LIKE \u0026#39;Wild%\u0026#39;; WHERE \u0026amp; IN # Copy sql SELECT TrackId, Name, MediaTypeId FROM Tracks WHERE MediaTypeId IN (1, 2) WHERE \u0026amp; LIMIT/OFFSET # Copy sql SELECT trackId, name FROM tracks LIMIT 10 OFFSET 7; LIMIT: ë¶ˆëŸ¬ì˜¤ëŠ” ê°’ì˜ ìˆ˜ OFFSET: OFFSETì— í•´ë‹¹í•˜ëŠ” ìˆ˜ë§Œí¼ ë–¼ì–´ë‚´ ê·¸ ì´í›„ì˜ ë°ì´í„° ë¶ˆëŸ¬ì˜´ WHERE \u0026amp; BETWEEN # Copy sql SELECT InvoiceId, BillingAddress, Total FROM invoices WHERE Total BETWEEN 14.91 AND 18.86 ORDER BY Total; WHERE \u0026amp; IS NULL # Copy sql SELECT Name, Composer FROM tracks WHERE Composer IS NULL ORDER BY Name; "},{"id":94,"href":"/blog/aischool-05-00-sql-programming/","title":"[AI SCHOOL 5ê¸°] SQL í”„ë¡œê·¸ë˜ë°","section":"Posts","content":"DBMS # DataBase Management System í•˜ë“œì›¨ì–´ì— ì €ì¥ëœ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê´€ë¦¬í•´ì£¼ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤(RDBMS)ê°€ ì£¼ë¡œ ì‚¬ìš© Oracle, MySQL(MariaDB), SQLite, MS SQL, PstgreSQL ë°ì´í„° ëª¨ë¸ë§ # í˜„ì‹¤ ì„¸ê³„ E-R ë‹¤ì´ì–´ê·¸ë¨ (ê°œë… ìŠ¤í‚¤ë§ˆ) Relation ëª¨ë¸ (ë…¼ë¦¬ì  ìŠ¤í‚¤ë§ˆ) ë¬¼ë¦¬ì ì¸ SQL ì½”ë“œ (ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ) ê°œë…ì  ë°ì´í„° ëª¨ë¸ë§ # í˜„ì‹¤ ì„¸ê³„ë¡œë¶€í„° ê°œì²´ë¥¼ ì¶”ì¶œ, ê°œì²´ë“¤ì˜ ê´€ê³„ë¥¼ ì •ì˜, E-R ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ê°œì²´(Entity): íšŒì›, ì œí’ˆ ë“± ì €ì¥í•  ê°€ì¹˜ê°€ ìˆëŠ” ë°ì´í„°ë¥¼ í¬í•¨í•œ ê°œì²´ ì†ì„±(Attribute): ì´ë¦„, ì´ë©”ì¼ ë“± ì˜ë¯¸ ìˆëŠ” ë°ì´í„°ì˜ ê°€ì¥ ì‘ì€ ë…¼ë¦¬ì  ë‹¨ìœ„ ê´€ê³„(Relationship): êµ¬ë§¤ ë“± ê°œì²´ì™€ ê°œì²´ ì‚¬ì´ì˜ ì—°ê´€ì„± ë° ê°œì²´ ì§‘í•© ê°„ ëŒ€ì‘ ê´€ê³„ ë…¼ë¦¬ì  ë°ì´í„° ëª¨ë¸ë§ # E-R ë‹¤ì´ì–´ê·¸ë¨ì„ ë°”íƒ•ìœ¼ë¡œ ë…¼ë¦¬ì ì¸ êµ¬ì¡°ë¥¼ Relation ëª¨ë¸ë¡œ í‘œí˜„ ë¦´ë ˆì´ì…˜(Relation): ê°œì²´ì— ëŒ€í•œ ë°ì´í„°ë¥¼ 2ì°¨ì› í…Œì´ë¸” êµ¬ì¡°ë¡œ í‘œí˜„í•œ ê²ƒ ì†ì„±(Attribute): ì—´, í•„ë“œ íŠœí”Œ(Tuble): í–‰, ë ˆì½”ë“œ, ì¸ìŠ¤í„´ìŠ¤ ì°¨ìˆ˜(Degree): ë¦´ë ˆì´ì…˜ ë‚´ ì†ì„±(Column)ì˜ ì´ ê°œìˆ˜ ì¹´ë””ë„ë¦¬í‹°(Cardinality): ë¦´ë ˆì´ì…˜ ë‚´ íŠœí”Œ(Row)ì˜ ì´ ê°œìˆ˜ ë¬¼ë¦¬ì  ë°ì´í„° ëª¨ë¸ë§ # Relation ëª¨ë¸ì„ ë¬¼ë¦¬ ì €ì¥ ì¥ì¹˜ì— ì €ì¥í•  ìˆ˜ ìˆëŠ” ë¬¼ë¦¬ì  êµ¬ì¡°ë¡œ êµ¬í˜„ SQL # Structured Query Language RDBMSì—ì„œ ë°ì´í„°ë¥¼ ê´€ë¦¬ ë° ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì§„ ì–¸ì–´ DDL(Data Definition Language): CREATE, ALTER, DROP DML(Data Manipulation Language): SELECT, INSERT, UPDATE, DELETE DCL(Data Control Language): GRANT, REVOKE NoSQL # ê´€ê³„í˜• ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, ëª…ì‹œì ì¸ ìŠ¤í‚¤ë§ˆê°€ ì—†ìŒ ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¶„ì‚° ì €ì¥ì— íŠ¹í™” Kye-Value, Document, Wide Column, Graph ë“± "},{"id":95,"href":"/blog/aischool-05-01-sqlite3/","title":"[AI SCHOOL 5ê¸°] SQL í”„ë¡œê·¸ë˜ë° ì‹¤ìŠµ - SQLite3","section":"Posts","content":"Connect SQLite3 # Copy python import sqlite3 dbpath = \u0026#34;maindb.db\u0026#34; conn = sqlite3.connect(dbpath) cur = conn.cursor() connnect(): DBMSì™€ ì—°ê²° conn.commit(): í˜„ì¬ ë³€ê²½ì‚¬í•­ ì €ì¥ conn.rollback(): ë§ˆì§€ë§‰ commit ì‹œì ìœ¼ë¡œ ë˜ëŒë¦¬ê¸° cursor(): DBì—ì„œ SQLë¬¸ì„ ì‹¤í–‰í•˜ëŠ” ê°ì²´ Execute Scripts # Datatypes # NULL: ê²°ì¸¡ì¹˜ INTEGER (or INT): ì •ìˆ˜ (ì–‘ìˆ˜ ë˜ëŠ” ìŒìˆ˜), int ê°’ REAL: ì‹¤ìˆ˜, float ê°’ TEXT (or VARCHAR): í…ìŠ¤íŠ¸, string ê°’ BLOB: ëª¨ë“  ì¢…ë¥˜ì˜ íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ë°”ì´ë„ˆë¦¬ ê°ì²´ Scripts # DROP TABLE IF EXISTS: í…Œì´ë¸”ì´ ì´ë¯¸ ìˆìœ¼ë©´ ì œê±° CREATE TABLE: í…Œì´ë¸” ìƒì„± AUTOINCREMENT: ê°’ì„ ë”°ë¡œ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ì¦ê°€ ìˆ«ì ë¶€ì—¬ NOT NULL: ë¹ˆ ê°’ì´ ì €ì¥ë˜ëŠ” ê²ƒì„ í—ˆìš©í•˜ì§€ ì•ŠìŒ INSERT INTO TABLE(FIELD, \u0026hellip;) VALUES(VALUE, \u0026hellip;):\ní…Œì´ë¸”ì— ë°ì´í„° ì¶”ê°€, ì „ì²´ í•„ë“œì— ê°’ ì¶”ê°€ ì‹œ í•„ë“œëª… ìƒëµ ê°€ëŠ¥ --: í•œ ì¤„ ì£¼ì„, /* ... */: ì—¬ëŸ¬ ì¤„ ì£¼ì„ Excecute # conn.executescript(): ìŠ¤í¬ë¦½íŠ¸ êµ¬ë¬¸ ì‹¤í–‰ cur.executemany(): ë§ì€ ë°ì´í„°ë¥¼ í•œë²ˆì— INSERT/UPDATE/DELETE\n(\u0026quot;INSERT INTO ... VALUES(?, ?, ?, ?, ?);\u0026quot;, date) cur.execute(): í•˜ë‚˜ì˜ SQLë¬¸ ì‹¤í–‰ cur.fetchall(): SQLë¬¸ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëª¨ë‘ ë°˜í™˜ (íŠœí”Œ í˜•íƒœ) cur.description: í…Œì´ë¸” ì •ë³´ conn.close(): DB ì—°ê²° í•´ì œ To Dataframe # pd.read_sql_query(query, conn) CREATE Table # Copy sql CREATE TABLE devices ( name TEXT NOT NULL, model TEXT NOT NULL, Serial INTEGER NOT NULL UNIQUE Copy sql CREATE TABLE contact_groups( contact_id INTEGER, group_id INTEGER, PRIMARY KEY (contact_id, group_id), FOREIGN KEY (contact_id) REFERENCES contacts(contact_id) ON DELETE CASCADE, FOREIGN KEY (group_id) REFERENCES groups(group_id) ON DELETE CASCADE ); CASCADE: css cascadeì™€ ë™ì¼ ALTER Table # Copy sql ALTER TABLE devices RENAME TO equipment; Copy sql ALTER TABLE equipment ADD COLUMN location text; Copy sql ALTER TABLE equipment RENAME COLUMN location TO loc; DROP Table # Copy sql DROP TABLE equipment ; Pandasë¡œ ì‚­ì œëœ í…Œì´ë¸” ìš”ì²­ ì‹œ no such table ì—ëŸ¬ ë°œìƒ DB ë‚´ í…Œì´ë¸” ëª©ë¡/êµ¬ì¡° í™•ì¸ # Copy sql SELECT name FROM sqlite_master WHERE type =\u0026#39;table\u0026#39; AND name NOT LIKE \u0026#39;sqlite_%\u0026#39;; sqlite_masterëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìƒì„±ë˜ëŠ” í…Œì´ë¸” sqlite_master í…Œì´ë¸”ì—ì„œ ìƒì„±ëœ ëª¨ë“  í…Œì´ë¸” ëª©ë¡/êµ¬ì¡° í™•ì¸ ê°€ëŠ¥ "},{"id":96,"href":"/blog/aischool-04-04-ab-test/","title":"[AI SCHOOL 5ê¸°] í†µê³„ë¶„ì„ ì‹¤ìŠµ - A/B Test","section":"Posts","content":"ë§ˆì¼€íŒ… ë¹„ìš© ë¶„ì„ # ë§¤ì›” ìœ íŠœë¸Œì— ê´‘ê³  ë¹„ìš©ì„ ì§€ì¶œí•˜ì—¬ ì‹ ê·œ ìœ ì €(êµ¬ë§¤ ê³ ê° or íšŒì›ê°€ì… ê³ ê°)ë¥¼ íšë“ ì›”ë³„ë¡œ 10,000ì› ë‹¨ìœ„ì˜ ìœ íŠœë¸Œ ê´‘ê³  ë¹„ìš©ê³¼ í•´ë‹¹ ì›”ì— ì‹ ê·œë¡œ íšë“ëœ ìœ ì € ìˆ˜ê°€ ì¸¡ì •ë˜ì—ˆë‹¤ê³  ê°€ì • ë¹„êµ ë°ì´í„° # ë‹¨ìˆœ CAC ê³„ì‚° # CAC(Customer Acquisition Cost, ì‹ ê·œê³ ê° ìœ ì¹˜ ë¹„ìš©) @ https://j.mp/35O5NRe Copy python cac = ad_df[\u0026#39;Marketing_Costs\u0026#39;].sum() / ad_df[\u0026#39;User_Acquired\u0026#39;].sum() print(cac * 10000) # Output 446ì› ìœ„ì˜ ê¸ˆì•¡ì— ì¶”ê°€ë¡œ íšë“í•˜ê¸°ë¥¼ ì›í•˜ëŠ” ìœ ì € ìˆ˜ë¥¼ ê³±í•œ ê¸ˆì•¡ì„\nìœ íŠœë¸Œ ê´‘ê³  ë¹„ìš©ìœ¼ë¡œ ì“°ë©´ ê·¸ë§Œí¼ ìœ ì €ê°€ ëŠ˜ì–´ë‚ ê¹Œ?\n== ìœ„ì˜ ê¸ˆì•¡ ë§Œí¼ ìœ íŠœë¸Œ ê´‘ê³ ì— ì“°ë©´ ì •ë§ë¡œ ìœ ì €ê°€ 1ëª… ëŠ˜ì–´ë‚ ê¹Œ?\ní”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ # Copy python stats.pearsonr(ad_df[\u0026#39;Marketing_Costs\u0026#39;], ad_df[\u0026#39;User_Acquired\u0026#39;]) # Output í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ : 0.8035775069546849 p-value : 0.0016386012345537505 p-valueê°€ 0.0016(\u0026lt;0.05)ì´ë¯€ë¡œ,\nì›”ë³„ ìœ íŠœë¸Œ ê´‘ê³  ë¹„ìš©ê³¼ ì‹ ê·œ ìœ ì € ìˆ˜ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ìƒê´€ê´€ê³„ê°€ ì—†ë‹¤ ì›”ë³„ ìœ íŠœë¸Œ ê´‘ê³  ë¹„ìš©ê³¼ ì‹ ê·œ ìœ ì € ìˆ˜ ì‚¬ì´ì—ëŠ”\ní†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê°•í•œ ìƒê´€ê´€ê³„(+0.8)ê°€ ìˆë‹¤ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê°’ì— ëŒ€í•œ í•´ì„ ê¸°ì¤€ (Strong/Moderate/Weak) @ https://j.mp/3mH8FWN íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ì—†ì´ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆëŠ” ë„êµ¬ @ https://j.mp/324551c A/B Test (ë…ë¦½í‘œë³¸) # í˜ì´ì§€ êµ¬ì„±ê³¼ ì„¸ë¶€ ë””ìì¸ì„ ë‹¤ë¥´ê²Œ ë§Œë“  2ê°œì˜ ì›¹ì‚¬ì´íŠ¸ ì‹œì•ˆì„ ê¸°ë°˜ìœ¼ë¡œ A/B Test ì§„í–‰ ì›¹ì‚¬ì´íŠ¸ ì‹œì•ˆ Aì™€ B ê°ê°ì— ìœ ì…ëœ ìœ ì €ë“¤ì´\nì‹¤ì œë¡œ ê° ì›¹ì‚¬ì´íŠ¸ ë‚´ì—ì„œ ì´íƒˆí•˜ê¸°ê¹Œì§€ì˜ ì‹œê°„(ì²´ë¥˜ì‹œê°„, Duration time)ì„ ì¸¡ì • T-Testë¥¼ ì§„í–‰í•˜ê¸° ì´ì „ì— Nullì¸ ë°ì´í„°ë“¤ì€ ì œì™¸ ë¹„êµ ë°ì´í„° # ë…ë¦½í‘œë³¸ T-Test # Copy python stats.ttest_ind(web_a.Duration_A.values, web_b.Duration_B.values, equal_var=False) # Output Ttest_indResult(statistic=3.0165632092150694, pvalue=0.008734970056646718) equal_var=True : ë‘ ê°œì˜ ì—´ì˜ ë¶„ì‚°ê°’ì´ ë™ì¼í• ê±°ë¼ ê°€ì • equal_var=False: ë¶„ì‚°ê°’ì´ ë™ì¼í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Falseë¡œ ì„¤ì • 2ê°œì˜ ì¸¡ì • ê·¸ë£¹ì´ ë™ì¼í•œ ìˆ˜ê°€ ì•„ë‹ˆê±°ë‚˜ ìœ ì‚¬í•œ ë¶„ì‚°ê°’ì„ ê°–ì§€ ì•Šì„ ê²½ìš°\nWelch\u0026rsquo;s t-testë¥¼ ì‚¬ìš© @ https://j.mp/3kLFwcE p-valueê°€ 0.0087(\u0026lt;0.05)ì´ë¯€ë¡œ,\nì›¹ ì‹œì•ˆ Aì™€ Bì— ëŒ€í•œ ì²´ë¥˜ì‹œê°„ì˜ í‰ê· ê°’ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ë‹¤ ì´ëŸ¬í•œ ì „ì œ í•˜ì— ìœ„ì™€ ê°™ì€ ì²´ë¥˜ì‹œê°„ ì¸¡ì • ê²°ê³¼ê°€ ë‚˜ì˜¬ í™•ë¥ ì´ 0.87%ë¼ê³  ì´í•´í•  ìˆ˜ ìˆìŒ ì›¹ ì‹œì•ˆ Aì™€ Bì— ëŒ€í•œ ìœ ì €ë“¤ì˜ ì²´ë¥˜ ì‹œê°„ ì‚¬ì´ì—ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆë‹¤ A/B Test (ì¹´ì´ì œê³± ê²€ì •) # ìµœì¢… êµ¬ë§¤ë¥¼ ìœ„í•œ ë²„íŠ¼ì„ 2ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì‹œì•ˆìœ¼ë¡œ ì œì‘í•´ ê°ê¸° ë‹¤ë¥¸ ìœ ì €ë“¤ì—ê²Œ ë…¸ì¶œ í•´ë‹¹ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ êµ¬ë§¤ê°€ í™•ì •ëœë‹¤ê³  ê°€ì • ë¹„êµ ë°ì´í„° # Conversion Rate (ì „í™˜ìœ¨) # ì „ì²´ ì›¹ì‚¬ì´íŠ¸ ì‚¬ìš©ì ì¤‘ì—ì„œ ì–¼ë§ˆë‚˜ ë§ì€ ì‚¬ìš©ìë“¤ì´ ë™ì‘ì„ ë§ˆì¹˜ëŠ”ì§€ì— ëŒ€í•œ ì§€í‘œ Copy python conversion_rate = click_df[\u0026#39;Clicked\u0026#39;] / (click_df[\u0026#39;Clicked\u0026#39;] + click_df[\u0026#39;Unclicked\u0026#39;]) * 100 # Output Button_A 5.746209 Button_B 7.737226 dtype: float64 Click-Through Rate (CTR, í´ë¦­ìœ¨) # ì–¼ë§ˆë‚˜ ë§ì€ ì‚¬ìš©ìë“¤ì´ ì›¹ì‚¬ì´íŠ¸ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ ê´‘ê³ ë¥¼ í´ë¦­í•˜ëŠ”ì§€ì— ëŒ€í•œ ì§€í‘œ Button_AëŠ” 5.75% Button_BëŠ” 7.73% ì¹´ì´ì œê³± ê²€ì • # ë²„íŠ¼ A/Bì— ëŒ€í•œ í´ë¦­ ì—¬ë¶€ê°€ ì •ë¦¬ëœ ìœ„ í…Œì´ë¸” == Contingency Table(ë¶„í• í‘œ)\n@ https://j.mp/384CcFR chi2_contingency í•¨ìˆ˜ í™œìš© ì‹œ Contingency Tableì„ ê¸°ë°˜ìœ¼ë¡œ ì¹´ì´ì œê³± ê²€ì •\n@ https://j.mp/3mH1Nsr Copy python stats.chi2_contingency([click_df[\u0026#39;Clicked\u0026#39;], click_df[\u0026#39;Unclicked\u0026#39;]])[1] # Output 0.004968535119697213 p-valueê°€ 0.0049(\u0026lt;0.05)ì´ë¯€ë¡œ,\në²„íŠ¼ A/Bì— ëŒ€í•œ í´ë¦­ ì—¬ë¶€ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì—°ê´€ì„±ì´ ì—†ë‹¤ëŠ” ì „ì œ í•˜ì—,\nì´ëŸ¬í•œ í´ë¦­ ìˆ˜ ì¸¡ì • ê²°ê³¼ê°€ ë‚˜ì˜¬ í™•ë¥ ì´ 0.49%ë¼ê³  ì´í•´í•  ìˆ˜ ìˆìŒ ë°°ë„ˆ ë²„íŠ¼ ì‹œì•ˆ Aì™€ Bì— ëŒ€í•œ ìœ ì €ë“¤ì˜ í´ë¦­ ìˆ˜ ì‚¬ì´ì—ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆë‹¤ A/B Test References # A/B Testingì— ëŒ€í•œ ê¸°ì´ˆì ì¸ ì •ë³´ë“¤ @ https://j.mp/3eeo2TA ë°ì´í„°ë¥¼ í™œìš©í•œ ë””ì§€í„¸ ë§ˆì¼€íŒ… íš¨ê³¼ë¶„ì„ @ https://j.mp/2P7YHCO P-hackingì— ëŒ€í•˜ì—¬ @ https://j.mp/3mLMOgP / https://j.mp/31XJBTF p-value # p-valueì˜ ë†’ê³  ë‚®ìŒê³¼ ë³„ê°œë¡œ ì‹¤ì œ ì‹¤í—˜ì˜ íš¨ê³¼ í¬ê¸° ì—­ì‹œë„ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼í•œë‹¤.\nì˜ˆë¥¼ ë“¤ì–´ ì–´ë–¤ ì›¹ì‚¬ì´íŠ¸ì˜ êµ¬ë§¤ ë²„íŠ¼ì˜ ë””ìì¸ì„ ë³€ê²½í•˜ì—¬ êµ¬ë§¤ ìˆ˜ê°€ n ë§Œí¼ ì¦ê°€ë˜ì—ˆê³ ,\në””ìì¸ ë³€ê²½ ì „/í›„ì— ëŒ€í•œ êµ¬ë§¤ ë²„íŠ¼ í´ë¦­ ìˆ˜ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ëŒ€ìƒìœ¼ë¡œ í†µê³„ ê²€ì • í›„ p-valueê°€ 0.05ë³´ë‹¤ ë‚®ê²Œ ë‚˜ì™”ë”ë¼ë„,\nì •ì‘ ì¦ê°€ëœ êµ¬ë§¤ ìˆ˜ì— í•´ë‹¹í•˜ëŠ” nì´ ë¯¸ë¯¸í•˜ë‹¤ë©´ ë‚®ì€ p-valueì—ë„ ë¶ˆêµ¬í•˜ê³  ë””ìì¸ ë³€ê²½ì˜ ì‹¤ì§ˆì ì¸ íš¨ìš©ì´ ì ê¸° ë•Œë¬¸ì´ë‹¤.\n(í†µê³„ì ìœ¼ë¡œë§Œ ìœ ì˜ë¯¸í•  ë¿ ë…ë¦½ë³€ìˆ˜ì˜ ë³€í™”ì— ë”°ë¥¸ ì¢…ì†ë³€ìˆ˜ì˜ ë³€í™”ê°’ì´ ì‹¤ì§ˆì /ì‹¤ìš©ì ì¸ ì˜ë¯¸ë¥¼ ê°–ì§€ ì•ŠìŒ)\n"},{"id":97,"href":"/blog/aischool-04-03-test-statistics/","title":"[AI SCHOOL 5ê¸°] í†µê³„ë¶„ì„ ì‹¤ìŠµ - T-Test \u0026 ìƒê´€ê´€ê³„ ë¶„ì„","section":"Posts","content":"Import Libraries # Copy python import pandas as pd import seaborn as sns import scipy as sp from scipy import stats import warnings warnings.filterwarnings(\u0026#34;ignore\u0026#34;) êµì°¨ë¶„ì„ # êµì°¨í‘œ (Cross-Table) # Copy python crosstab = pd.crosstab(df.propensity, df.skin, margins=True) crosstab.columns=[] crosstab.index=[] margins: í•©ê³„(All) ì¶”ê°€ ì—¬ë¶€ normalize: Normalization ì—¬ë¶€ Chi-square ê²€ì • # ë‘ ë²”ì£¼í˜• ë³€ìˆ˜ ì‚¬ì´ì˜ ê´€ê³„ê°€ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ë¥¼ ê²€ì • (ë…ë¦½ì„± ê²€ì •) ê·€ë¬´ê°€ì„¤: Indepedent (vice versa) ëŒ€ë¦½ê°€ì„¤: Not Independent Copy python stats.chisquare(df.column1, df.column2) # Output Power_divergenceResult(statistic=291.8166666666667, pvalue=0.023890557260065975) p-value # ê´€ì°° ë°ì´í„°ì˜ ê²€ì • í†µê³„ëŸ‰ì´ ê·€ë¬´ê°€ì„¤ì„ ì§€ì§€í•˜ëŠ” ì •ë„ ê·€ë¬´ê°€ì„¤ì´ ì°¸ì´ë¼ëŠ” ì „ì œ í•˜ì—, ê´€ì°°ì´ ì™„ë£Œëœ ê°’ì´ í‘œë³¸ì„ í†µí•´ ë‚˜íƒ€ë‚  í™•ë¥  p-valueê°€ 0.05(5%) ë¯¸ë§Œì¼ ê²½ìš°, ê´€ì¸¡ì¹˜ê°€ ë‚˜íƒ€ë‚  í™•ë¥ ì´ ë§¤ìš° ë‚®ë‹¤ê³  íŒë‹¨í•˜ì—¬ ê·€ë¬´ê°€ì„¤ ê¸°ê° p-valueê°€ 0.05(5%) ì´ìƒì¼ ê²½ìš°, ê´€ì¸¡ì¹˜ê°€ ë‚˜íƒ€ë‚  í™•ë¥ ì´ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨í•˜ì—¬ ê·€ë¬´ê°€ì„¤ ì§€ì§€ p-valueê°€ 0.05 ì´í•˜ë¼ëŠ” ê²ƒì´ í•­ìƒ ëŒ€ë¦½ê°€ì„¤ì„ ì˜ë¯¸í•˜ëŠ” ê²ƒì€ ì•„ë‹˜ (5%ë§Œí¼ ê·€ë¬´ê°€ì„¤ì´ ì°¸ì¼ ê°€ëŠ¥ì„±) Copy python crosstab.plot.bar(stacked=True) ë…ë¦½í‘œë³¸ T-test ë¶„ì„ ì‹œê°í™” # ì„œë¡œ ë‹¤ë¥¸ ì§‘ë‹¨ì—ì„œ ê°™ì€ ì—´ ë¹„êµ ë‘ ì§‘ë‹¨ ê°„ì˜ í‰ê·  ì°¨ì´ë¥¼ ê²€ì • ex) \u0026ldquo;ì„œë¡œ ë‹¤ë¥¸\u0026rdquo; ì„±ë³„ ê°„ì— ì „ë°˜ì ì¸ ë§Œì¡±ë„ì˜ í‰ê· ê°’ ì‚¬ì´ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ \u0026ldquo;ì—†ë‹¤\u0026rdquo; Copy python stats.ttest_ind(column1.values, column2.values) # Output Ttest_indResult(statistic=-0.494589803056421, pvalue=0.6213329051985961) Box-Plot # Histogram # Copy python sns.distplot(male, kde=False, fit=stats.norm, hist_kws={\u0026#39;color\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;alpha\u0026#39;: 0.2}, fit_kws={\u0026#39;color\u0026#39;: \u0026#39;r\u0026#39;}) sns.distplot(female, kde=False, fit=stats.norm, hist_kws={\u0026#39;color\u0026#39;: \u0026#39;g\u0026#39;, \u0026#39;alpha\u0026#39;: 0.2}, fit_kws={\u0026#39;color\u0026#39;: \u0026#39;g\u0026#39;}) ëŒ€ì‘í‘œë³¸ T-test ë¶„ì„ ì‹œê°í™” # ë™ì¼í•œ ì§‘ë‹¨ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ì—´ ë¹„êµ ë™ì¼í•œ ëª¨ì§‘ë‹¨ìœ¼ë¡œë¶€í„° ì¶”ì¶œëœ ë‘ ë³€ìˆ˜ì˜ í‰ê· ê°’ì„ ë¹„êµ ë¶„ì„ \u0026ldquo;ë™ì¼í•œ\u0026rdquo; ê³ ê° ì§‘ë‹¨ì´ í‰ê°€í•œ êµ¬ë§¤ ê°€ê²©ì— ëŒ€í•œ\në§Œì¡±ë„ì™€ êµ¬ë§¤ ë¬¸ì˜ì— ëŒ€í•œ ë§Œì¡±ë„ì˜ í‰ê· ê°’ ì‚¬ì´ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆë‹¤. Copy python stats.ttest_rel(df[\u0026#34;satisf_b\u0026#34;], df[\u0026#34;satisf_i\u0026#34;]) # Output Ttest_relResult(statistic=-7.155916401026872, pvalue=9.518854506666398e-12) Histogram # Copy python sns.distplot(df[\u0026#34;satisf_b\u0026#34;], kde=False, fit=stats.norm, hist_kws={\u0026#39;color\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;alpha\u0026#39;: 0.2}, fit_kws={\u0026#39;color\u0026#39;: \u0026#39;r\u0026#39;}) sns.distplot(df[\u0026#34;satisf_i\u0026#34;], kde=False, fit=stats.norm, hist_kws={\u0026#39;color\u0026#39;: \u0026#39;g\u0026#39;, \u0026#39;alpha\u0026#39;: 0.2}, fit_kws={\u0026#39;color\u0026#39;: \u0026#39;g\u0026#39;}) ë¶„ì‚°ë¶„ì„ ì‹œê°í™” # ë¶„ì‚°ë¶„ì„(ANalysis Of VAriance, ANOVA) ì„¸ ê°œì˜ ì§‘ë‹¨ì—ì„œ ì ì–´ë„ í•˜ë‚˜ì˜ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆëŠ”ê°€ ex) 3ê°€ì§€ êµ¬ë§¤ ë™ê¸°ì— ë”°ë¥¸ ì „ë°˜ì ì¸ ë§Œì¡±ë„ì˜ í‰ê· ê°’ ì¤‘ ì ì–´ë„ í•˜ë‚˜ëŠ” ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆë‹¤. Copy python stats.f_oneway(anova1, anova2, anova3) # Output F_onewayResult(statistic=4.732129410493065, pvalue=0.009632034309915485) Histogram # Copy python sns.distplot(anova1, kde=False, fit=sp.stats.norm, hist_kws={\u0026#39;color\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;alpha\u0026#39;: 0.2}, fit_kws={\u0026#39;color\u0026#39;: \u0026#39;r\u0026#39;}) sns.distplot(anova2, kde=False, fit=sp.stats.norm, hist_kws={\u0026#39;color\u0026#39;: \u0026#39;g\u0026#39;, \u0026#39;alpha\u0026#39;: 0.2}, fit_kws={\u0026#39;color\u0026#39;: \u0026#39;g\u0026#39;}) sns.distplot(anova3, kde=False, fit=sp.stats.norm, hist_kws={\u0026#39;color\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;alpha\u0026#39;: 0.2}, fit_kws={\u0026#39;color\u0026#39;: \u0026#39;b\u0026#39;}) ìƒê´€ê´€ê³„ ë¶„ì„ ì‹œê°í™” # ì—°ì†í˜• ë³€ìˆ˜ì—´ë“¤ë¼ë¦¬ ë¹„êµ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ # Copy python df.corr.corr() -1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìŒì˜ ìƒê´€ê´€ê³„ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì–‘ì˜ ìƒê´€ê´€ê³„ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìƒê´€ê´€ê³„ê°€ ì ìŒ PairPlot # Copy python sns.parilpot(df_corr) Iris Data # ë¶“ê½ƒì˜ í’ˆì¢…ì— ëŒ€í•œ ë°ì´í„° Copy text iris = sns.load_dataset(\u0026#34;iris\u0026#34;) sns.pairplot(iris, kind=\u0026#34;reg\u0026#34;) reg: ì¶”ì„¸ì„  sepal_width \u0026lt;-\u0026gt; petal_length\në‘ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ ì ¸ ìˆì–´ ìŒì˜ ìƒê´€ê´€ê³„ë¼ ë³´ê¸° ì–´ë ¤ì›€ ê·¸ë£¹ì„ ë‚˜ëˆ ì„œ ë¹„êµ (1. ì–‘ì˜ ìƒê´€ê´€ê³„, 2. ê´€ê³„ ì—†ìŒ) Simpson\u0026rsquo;s paradox # ì‹¬ìŠ¨ì˜ ì—­ì„¤ @ https://j.mp/31Kd6v7 \u0026amp; https://j.mp/3IswbTj ì‚¬ë¡€ë¡œ ì•Œì•„ë³´ëŠ” ì‹¬ìŠ¨ì˜ ì—­ì„¤ @ https://j.mp/3ICKS6q ì „ì²´ë¥¼ ë´¤ì„ ë•Œì™€ ì¼ë¶€ë¥¼ ë‚˜ëˆ ì„œ ë´¤ì„ ë•Œ ë‹¤ë¥¸ ê²°ê³¼ê°€ ë‚˜ì˜´ ì‹ ì¥ ê²°ì„ í¬ê¸°ë¥¼ ì¹˜ë£Œë²• a, bë¥¼ ì‚¬ìš©í•´ì„œ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ì¹˜ë£Œí•˜ëŠ”ì§€ ì‘ì€ ê²°ì„/í° ê²°ì„ ì¸ì›ìˆ˜ê°€ ë‹¬ë¼ì„œ b ì¹˜ë£Œë²• í™•ë¥ ì´ ë‚®ì•„ì§ \u0026gt; í•©ê³„ëŠ” ë†’ìŒ "},{"id":98,"href":"/blog/aischool-04-02-descriptive-statistics/","title":"[AI SCHOOL 5ê¸°] í†µê³„ë¶„ì„ ì‹¤ìŠµ - ë¹ˆë„ ë¶„ì„ \u0026 ê¸°ìˆ í†µê³„ëŸ‰ ë¶„ì„","section":"Posts","content":"Chart # Pie Chart # Copy python df[\u0026#39;column\u0026#39;].value_counts().plot(kind = \u0026#39;pie\u0026#39;) Bar Chart # Copy python df[\u0026#39;column\u0026#39;].value_counts().plot(kind = \u0026#39;bar\u0026#39;) Descriptive Statistics # df['column'].max(): ìµœëŒ“ê°’ (í–‰ë°©í–¥ ê¸°ì¤€: axis=1) df['column'].min(): ìµœì†Ÿê°’ df['column'].sum(): í•©ê³„ df['column'].mean(): í‰ê·  df['column'].variance(): ë¶„ì‚° df['column'].std(): í‘œì¤€í¸ì°¨ df['column'].describe(): ê¸°ìˆ í†µê³„ëŸ‰ ë¶„í¬ì˜ ì™œë„ì™€ ì²¨ë„ # df['column'].hist(): íˆìŠ¤í† ê·¸ë¨ df['column'].skew(): ì™œë„ (ë¶„í¬ê°€ ì¢Œìš°ë¡œ ì¹˜ìš°ì³ì§„ ì •ë„) ì™œë„(Skewness): 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •ê·œë¶„í¬ (ì ˆëŒ€ê°’ ê¸°ì¤€ 3 ë¯¸ì´ˆê³¼)\nìš°ì¸¡ìœ¼ë¡œ ì¹˜ìš°ì¹˜ë©´ ìŒ(negative)ì˜ ì™œë„, ì¢Œì¸¡ìœ¼ë¡œ ì¹˜ìš°ì¹˜ë©´ ì–‘(positive)ì˜ ì™œë„ df['column'].kurtosis(): ì²¨ë„ (ë¶„í¬ê°€ ë¾°ì¡±í•œ ì •ë„) ì²¨ë„(Kurtosis): 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •ê·œë¶„í¬ (ì ˆëŒ€ê°’ ê¸°ì¤€ 8 ë˜ëŠ” 10 ë¯¸ì´ˆê³¼) ì™œë„ê°€ 0, ì •ë„ê°€ 1ì¼ ë•Œ ì™„ì „í•œ ì •ê·œë¶„í¬ë¡œ ê°€ì • sns.distplot(df['column'], rug=True): distribution plot\nrug: ë§‰ëŒ€ ê·¸ë˜í”„ë¥¼ í‘œì‹œí• ì§€ ì—¬ë¶€ sns.jointplot(x='column1', y='column2', data=df): ì‚°ì ë„ì™€ íˆìŠ¤í† ê·¸ë¨ í•œë²ˆì— í‘œì‹œ sns.jointplot(..., kind=\u0026quot;kde\u0026quot;): ë°€ì§‘ëœ ë¶„í¬ ê³¡ì„ ì„ í‘œì‹œ Outlier íƒì§€ ë° ì œê±° # df.boxplot(column='column'): ë°ì´í„° ì „ì²´ì— ê±¸ì³ì„œ ë¶„í¬ ë°€ì§‘ë„ë¥¼ í‘œì‹œ IQR í™œìš© # IQR(Inter-Quantile Range): ë°”ë‹¥ë¶€í„° 75% ì§€ì ì˜ ê°’ - ë°”ë‹¥ë¶€í„° 25% ì§€ì ì˜ ê°’ ìƒí•œì¹˜: ë°”ë‹¥ë¶€í„° 75% ì§€ì ì˜ ê°’ + IQRì˜ 1.5ë°° í•˜í•œì¹˜: ë°”ë‹¥ë¶€í„° 25% ì§€ì ì˜ ê°’ - IQRì˜ 1.5ë°° ìƒí•œ/í•˜í•œì¹˜ë¥¼ ë„˜ìœ¼ë©´ Outlierë¡œ íŒë‹¨ Copy python Q1 = df[\u0026#39;column\u0026#39;].quantile(0.25) Q3 = df[\u0026#39;column\u0026#39;].quantile(0.75) IQR = Q3 - Q1 df_IQR = df[ (df[\u0026#39;column\u0026#39;] \u0026lt; Q3 + IQR * 1.5) \u0026amp; (df[\u0026#39;column\u0026#39;] \u0026gt; Q1 - IQR * 1.5) ] df_IQR.boxplot(column=\u0026#39;column\u0026#39;) Outlier ì œê±° ì „í›„ ë¶„í¬ ë¹„êµ # Histogram # Before After Joint-Plot # Before After Log í•¨ìˆ˜ë¥¼ í™œìš©í•œ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ # ì™œë„ í˜¹ì€ ì²¨ë„ê°€ ë„ˆë¬´ í° ê²½ìš°, Log í•¨ìˆ˜ë¥¼ ì ìš©í•´ ì™œë„/ì²¨ë„ë¥¼ ë‚®ì¶°ì£¼ëŠ” ì „ì²˜ë¦¬ë¥¼ ì ìš© processed_df['log_column'] = np.log(processed_df['column']) Before After "},{"id":99,"href":"/blog/aischool-04-01-numpy-pandas/","title":"[AI SCHOOL 5ê¸°] í†µê³„ë¶„ì„ ì‹¤ìŠµ - Numpy \u0026 Pandas","section":"Posts","content":"Numpy # Numpy Array ë‚´ë¶€ì˜ ë°ì´í„°ëŠ” í•˜ë‚˜ì˜ ìë£Œí˜•ìœ¼ë¡œ í†µì¼ Numpy Arrayì— ê°’ì„ ê³±í•˜ë©´ ì „ì²´ ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì‚¬ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ì™€ ë‹¬ë¦¬ ë°ì´í„°ì— ê°ê° ê³±í•´ì§ np.array([]): Numpy Array ìƒì„± np.dtype: Numpy Arrayì˜ Data Type np.shape: Numpy Array ëª¨ì–‘(ì°¨ì›) np.arange(): rangeë¥¼ ë°”íƒ•ìœ¼ë¡œ Numpy Array ìƒì„± np.reshape(): Numpy Array ëª¨ì–‘ì„ ë³€ê²½, ì—´ì— -1ì„ ì…ë ¥í•˜ë©´ ìë™ ê³„ì‚° np.dot(): í–‰ë ¬ê³± Pandas # pd.Series([], index=[]): Keyê°€ ìˆëŠ” ë¦¬ìŠ¤íŠ¸(Series) ìƒì„± Series.values: Seriesì˜ ê°’ Series.index: Seriesì˜ í‚¤ ê°’ df.ammount: ë„ì–´ì“°ê¸° ì—†ì´ ì˜ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ì—´ì€ ë³€ìˆ˜ì²˜ëŸ¼ êº¼ë‚´ ì“¸ ìˆ˜ ìˆìŒ df.insert(column, 'key', 'value'): index ê¸°ì¤€ìœ¼ë¡œ íŠ¹ì • ìœ„ì¹˜ì— ìƒˆë¡œìš´ ì—´ ì‚½ì… df[(con1) \u0026amp; (con2)]: ì—¬ëŸ¬ ê°œì˜ ì¡°ê±´ì„ ì‚¬ìš©í•  ë• ê°ê°ì˜ ì¡°ê±´ì„ ê´„í˜¸ ì•ˆì— ë¬¶ì–´ì•¼ í•¨ df['key'].value_counts(): ê°’ì˜ ì¶œí˜„ ë¹ˆë„ í•©ê³„ (sort=Falseë¡œ ì •ë ¬ í•´ì œ) df['key'].value_counts().plot(kind='pie'): ë¹ˆë„ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì›í˜•ì°¨íŠ¸ ìƒì„± df['key'].apply(): ì¡°ê±´ì— ë”°ë¼ ë³€í™˜ëœ ê°’ì„ ê°€ì§„ ì—´ ë°˜í™˜ df['key'].replace(): ë³€í™˜ê°’ì´ 1ëŒ€1 ëŒ€ì‘ ì‹œ apply() ëŒ€ì‹  replace() ì‚¬ìš© ê°€ëŠ¥\ndf['gender'].replace([1, 2], ['male', 'female']) "},{"id":100,"href":"/blog/aischool-03-04-web-crawling/","title":"[AI SCHOOL 5ê¸°] ì›¹ í¬ë¡¤ë§ ì‹¤ìŠµ - ì›¹ í¬ë¡¤ë§","section":"Posts","content":"Wadis ë§ˆê° ìƒí’ˆ ì¬ê³  ì²´í¬ # Google ë©”ì¼ ì„¤ì • # Copy python import smtplib from email.mime.text import MIMEText def sendMail(sender, receiver, msg): smtp = smtplib.SMTP_SSL(\u0026#39;smtp.gmail.com\u0026#39;, 465) smtp.login(sender, \u0026#39;your google app password\u0026#39;) msg = MIMEText(msg) msg[\u0026#39;Subject\u0026#39;] = \u0026#39;Product is available!\u0026#39; smtp.sendmail(sender, receiver, msg.as_string()) smtp.quit() Wadis ìƒí’ˆ ì¬ê³  ì²´í¬ # Copy python # ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ ì–¸ check_status = 1 url = \u0026#39;https://www.wadiz.kr/web/campaign/detail/{item_number}\u0026#39; # ìƒí’ˆ ì¬ê³ ê°€ í™•ì¸ë˜ì–´ ë©”ì¼ì´ ë°œì†¡ë˜ë©´ ì¢…ë£Œ while check_status: webpage = urlopen(url) source = BeautifulSoup(webpage, \u0026#39;html.parser\u0026#39;) target = source.find_all(\u0026#39;button\u0026#39;, {\u0026#39;class\u0026#39;:\u0026#39;rightinfo-reward-list\u0026#39;}) for item in target: # ê°€ê²©ì´ \u0026#39;179,000\u0026#39;ì› ìƒí’ˆ ì¤‘ if \u0026#39;179,000\u0026#39; in item.find(\u0026#39;dt\u0026#39;).get_text().strip(): # \u0026#39;ë¸”ë£¨\u0026#39; ìƒ‰ìƒì¸ ìƒí’ˆì— ëŒ€í•˜ì—¬ if \u0026#39;ë¸”ë£¨\u0026#39; in item.find(\u0026#39;p\u0026#39;).get_text().strip(): # íŒë§¤ ì¤‘ì¸ ìƒíƒœê°€ ë˜ë©´ (ë§ˆê°ëœ ìƒí’ˆì—” \u0026#34;soldout\u0026#34; í´ë˜ìŠ¤ê°€ ì¶”ê°€) if len(item.attrs[\u0026#39;class\u0026#39;]) == 2: sendMail(sender, receiver, msg) check_status = 0 ì„œìš¸ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤ # ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œë„ # Copy python url = \u0026#39;https://golmok.seoul.go.kr/regionAreaAnalysis.do\u0026#39; response = requests.get(url).content web_page = BeautifulSoup(response, \u0026#39;html.parser\u0026#39;) í•´ë‹¹ ì›¹ í˜ì´ì§€ëŠ” POST ìš”ì²­ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì£¼ê³  ë°›ê¸° ë•Œë¬¸ì— GET ë°©ì‹ìœ¼ë¡œëŠ” ì ‘ê·¼ ë¶ˆê°€ ê°œë°œì ë„êµ¬ì˜ Network íƒ­ì„ í™•ì¸í•˜ë©´ JSON ë°ì´í„° í™•ì¸ ê°€ëŠ¥ POST ìš”ì²­í•  ë•Œ Payloadë¥¼ ë³€ê²½í•˜ì—¬ JSON íŒŒì¼ ì¢…ë¥˜ ë³€ê²½ ê°€ëŠ¥ POST ìš”ì²­ # Copy python # Payload ì„¤ì • data = {\u0026#39;stdrYyCd\u0026#39;: \u0026#39;2021\u0026#39;, \u0026#39;stdrQuCd\u0026#39;: \u0026#39;4\u0026#39;, \u0026#39;stdrSlctQu\u0026#39;: \u0026#39;sameQu\u0026#39;, \u0026#39;svcIndutyCdL\u0026#39;: \u0026#39;CS000000\u0026#39;, \u0026#39;svcIndutyCdM\u0026#39;: \u0026#39;all\u0026#39;} response = requests.post(\u0026#39;https://golmok.seoul.go.kr/region/selectRentalPrice.json\u0026#39;, data=data).content result = json.loads(response) Output\nCopy json [{\u0026#39;GBN_CD\u0026#39;: \u0026#39;11\u0026#39;, \u0026#39;NM\u0026#39;: \u0026#39;ì„œìš¸ì‹œ ì „ì²´\u0026#39;, \u0026#39;GUBUN\u0026#39;: \u0026#39;si\u0026#39;, \u0026#39;BF1_FST_FLOOR\u0026#39;: \u0026#39;132504\u0026#39;, ... ë„¤ì´ë²„ ê¸ˆìœµ Top ì¢…ëª© # TOP ì¢…ëª© í…Œì´ë¸” ê°’ ì¶”ì¶œ # Copy python url = \u0026#39;http://finance.naver.com\u0026#39; response = requests.get(url).content web_page = BeautifulSoup(response, \u0026#39;html.parser\u0026#39;) top_items = web_page.find(\u0026#39;tbody\u0026#39;, {\u0026#39;id\u0026#39;:\u0026#39;_topItems1\u0026#39;}) item_rows = top_items.find_all(\u0026#39;tr\u0026#39;) TOP ì¢…ëª© í…Œì´ë¸” ê°’ í‘œì‹œ # Copy python for item in item_rows: item_name = item.find(\u0026#39;th\u0026#39;).get_text() item_price = item.find_all(\u0026#39;td\u0026#39;)[0].get_text() item_delta_price = item.find_all(\u0026#39;td\u0026#39;)[1].get_text() item_delta_percent = item.find_all(\u0026#39;td\u0026#39;)[2].get_text().strip() print(\u0026#39;{} : í˜„ì¬ê°€ {}, ì–´ì œë³´ë‹¤ {} {}, ë°±ë¶„ìœ¨ ë³€í™˜ ì‹œ {}\u0026#39;.format( item_name, item_price, item_delta_price[3:], item_delta_price[:2], item_delta_percent)) ë¶€ë™ì‚° ë§¤ë§¤ ë‚´ì—­ # ê³µê³µë°ì´í„°í¬í„¸ API ë°œê¸‰ # https://www.data.go.kr/data/15057267/openapi.do ìƒì—…ì—…ë¬´ìš© ë¶€ë™ì‚° ë§¤ë§¤ ì‹ ê³  ìë£Œ í™œìš©ì‹ ì²­ ìƒì„¸ ì •ë³´ëŠ” API ê¸°ìˆ ë¬¸ì„œ ì°¸ì¡° Python3 ìƒ˜í”Œ ì½”ë“œ # Copy python import requests url = \u0026#39;http://openapi.molit.go.kr/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcNrgTrade\u0026#39; params ={\u0026#39;serviceKey\u0026#39; : \u0026#39;ì„œë¹„ìŠ¤í‚¤\u0026#39;, \u0026#39;LAWD_CD\u0026#39; : \u0026#39;11110\u0026#39;, \u0026#39;DEAL_YMD\u0026#39; : \u0026#39;201512\u0026#39; } response = requests.get(url, params=params) print(response.content) request.get ìš”ì²­ ì‹œ paramsë¥¼ ì‚¬ìš©í•´ì„œ íŒŒë¼ë¯¸í„° í•œë²ˆì— ì…ë ¥ LAWD_CD: ë²•ì •ë™ì½”ë“œ 10ìë¦¬ ì¤‘ ì• 5ìë¦¬ @ https://www.code.go.kr/index.do ë¶€ë™ì‚° ë§¤ë§¤ ì‹ ê³  ìë£Œ XML ìš”ì²­ # Copy python response = requests.get(url, params=params).content web_page = BeautifulSoup(response, \u0026#39;lxml-xml\u0026#39;) ë§¤ë§¤ ë‚´ì—­ì„ DataFrameì— ì €ì¥ # Copy python loc_code = [] loc = [] date = [] price = [] building_usage = [] for item in items: try: loc_code.append(item.find(\u0026#39;ì§€ì—­ì½”ë“œ\u0026#39;).get_text()) loc.append(item.find(\u0026#39;ì‹œêµ°êµ¬\u0026#39;).get_text() + item.find(\u0026#39;ë²•ì •ë™\u0026#39;).get_text()) date.append(item.find(\u0026#39;ë…„\u0026#39;).get_text() + item.find(\u0026#39;ì›”\u0026#39;).get_text() + item.find(\u0026#39;ì¼\u0026#39;).get_text()) price.append(item.find(\u0026#39;ê±°ë˜ê¸ˆì•¡\u0026#39;).get_text()) building_usage.append(item.find(\u0026#39;ê±´ë¬¼ì£¼ìš©ë„\u0026#39;).get_text()) except: pass import pandas as pd df = pd.DataFrame({\u0026#39;ì§€ì—­ì½”ë“œ\u0026#39;:loc_code, \u0026#39;ë¶€ë™ì‚° ìœ„ì¹˜\u0026#39;:loc, \u0026#39;ê±°ë˜ ì¼ì\u0026#39;:date, \u0026#39;ê±°ë˜ ê¸ˆì•¡\u0026#39;:price, \u0026#39;ë¶€ë™ì‚° ìš©ë„\u0026#39;:building_usage}) "},{"id":101,"href":"/blog/aischool-03-03-selenium/","title":"[AI SCHOOL 5ê¸°] ì›¹ í¬ë¡¤ë§ ì‹¤ìŠµ - ì…€ë ˆë‹ˆì›€","section":"Posts","content":"Selenium # ë¸Œë¼ìš°ì €ì˜ ê¸°ëŠ¥ì„ ì²´í¬í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë„êµ¬ ë¸Œë¼ìš°ì €ë¥¼ ì¡°ì¢…í•´ì•¼í•  ë•Œë„ ì‚¬ìš© Import Libraries # Copy python # í¬ë¡¬ ë“œë¼ì´ë²„ íŒŒì¼ ìë™ ë‹¤ìš´ë¡œë“œ from webdriver_manager.chrome import ChromeDriverManager # í¬ë¡¬ ë“œë¼ì´ë²„ë¥¼ íŒŒì¼ì— ì—°ê²° from selenium.webdriver.chrome.service import Service from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.common.keys import Keys from bs4 import BeautifulSoup import time import pandas as pd import warnings warnings.filterwarnings(\u0026#34;ignore\u0026#34;) # ë¶ˆí•„ìš”í•œ Warning ë©”ì‹œì§€ ë¬´ì‹œ Virtual Browser # Copy python # í¬ë¡¬ ë“œë¼ì´ë²„ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í›„ ì„¸íŒ… service = Service(executable_path=ChromeDriverManager().install()) # ì„¸íŒ…ëœ í¬ë¡¬ ë“œë¼ì´ë²„ë¥¼ ì—°ê²°í•´ ê°€ìƒ ë¸Œë¼ìš°ì € ì‹¤í–‰ driver = webdriver.Chrome(service=service) driver.maximize_window(): ê°€ìƒ ë¸Œë¼ìš°ì € í¬ê¸° ìµœëŒ€í™” ì˜¬ë°”ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ ê°€ìƒ ë¸Œë¼ìš°ì €ì˜ ë‚´ë¶€ëŠ” ê±´ë“¤ì§€ ì•Šì•„ì•¼ í•¨ Google Translation # Google ë²ˆì—­ í˜ì´ì§€ ì ‘ì† # Copy python translate_url = \u0026#39;https://translate.google.co.kr/?sl=auto\u0026amp;tl=en\u0026amp;op=translate\u0026amp;hl=ko\u0026#39; driver.get(translate_url) driver.current_url: ê°€ìƒ ë¸Œë¼ìš°ì €ê°€ ì ‘ì†í•œ í˜ì´ì§€ì˜ URL ì£¼ì†Œ ë°˜í™˜ driver.page_source: ê°€ìƒ ë¸Œë¼ìš°ì €ê°€ ì ‘ì†í•œ í˜ì´ì§€ì˜ ì†ŒìŠ¤ì½”ë“œ ë°˜í™˜ driver.find_element: BeautifulSoupì˜ findì™€ ê°™ìŒ driver.find_elements: BeautifulSoupì˜ find_allê³¼ ê°™ìŒ ì›ë³¸ í…ìŠ¤íŠ¸ ì…ë ¥ # í´ë˜ìŠ¤ë‚˜ IDë¥¼ í†µí•œ ì ‘ê·¼ì´ ì–´ë ¤ìš¸ ê²½ìš° XPathë¥¼ í†µí•´ ì ‘ê·¼ ê°œë°œì ë„êµ¬ì—ì„œ full XPathë¥¼ ë³µì‚¬ Copy python origin_xpath = \u0026#39;ì›ë³¸ í…ìŠ¤íŠ¸ ë¶€ë¶„ì— í•´ë‹¹í•˜ëŠ” XPath\u0026#39; driver.find_element_by_xpath(origin_xpath).clear() driver.find_element_by_xpath(origin_xpath).send_keys(\u0026#39;ì›ë³¸ í…ìŠ¤íŠ¸\u0026#39;) .click(): íŠ¹ì • ë¶€ë¶„ í´ë¦­ .clear(): íŠ¹ì • ë¶€ë¶„ì— ì…ë ¥ëœ ê°’ ì§€ìš°ê¸° .send_keys(): íŠ¹ì • ë¶€ë¶„ì— ê°’ ì…ë ¥ ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° # Copy python translation_xpath = \u0026#39;ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ë¶€ë¶„ì— í•´ë‹¹í•˜ëŠ” XPath\u0026#39; translated_contents = driver.find_element_by_xpath(translation_xpath).text .text: ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ê°€ìƒ ë¸Œë¼ìš°ì € ì¢…ë£Œ # Copy python driver.close() driver.quit() Translated Word Cloud # Translated Word Cloud ìƒì„± ë°©ë²• # ê¸°ì‚¬ê¸€ ì „ì²´ë¥¼ ë²ˆì—­í•˜ê³  ë‹¨ì–´ë¥¼ ë¹ˆë„ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ ë¹ˆë„ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ì„ ì •í•˜ê³  í•´ë‹¹ ë‹¨ì–´ë“¤ë§Œì„ ë²ˆì—­ * ì„ ì •ëœ ë‹¨ì–´ë“¤ì„ ë²ˆì—­ # Copy python for key in translation_target: # keyë¥¼ ì›ë³¸ í…ìŠ¤íŠ¸ ë¶€ë¶„ì— ì…ë ¥ time.sleep(3) # translated_contents ë³€ìˆ˜ì— ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ì €ì¥ translation_result[translated_contents] = translation_target[key] driver.close() driver.quit() Translated Word Cloud # íŒŒíŒŒê³  ë²ˆì—­ # íŒŒíŒŒê³  ë²ˆì—­ í˜ì´ì§€ëŠ” í‚¤ì›Œë“œ ì…ë ¥ í›„ ë²ˆì—­ëœ ê²°ê³¼ë¥¼ ë³´ì´ëŠ” ì‹œê°„ ê°„ê²©ì´ ê¹€ ë”œë ˆì´ë¥¼ ì§€ì •í•˜ê³  ë°˜ë³µë¬¸ì„ ìˆ˜í–‰í•  ê²½ìš° ë²ˆì—­ì´ ëë‚˜ì§€ ì•Šì•„ ì˜ëª»ëœ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ê°€ëŠ¥ì„± ë²ˆì—­ì´ ì™„ë£Œë  ê²½ìš° ë‚˜íƒ€ë‚˜ëŠ” íƒœê·¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ê¸° ì‹œê°„ ì„¤ì • íŒŒíŒŒê³ ì—ì„œëŠ” ë²ˆì—­ëœ ë‹¨ì–´ì˜ ë°œìŒì— í•´ë‹¹í•˜ëŠ” \u0026lt;p\u0026gt; íƒœê·¸ê°€ ë‚˜íƒ€ë‚  ë•Œë¥¼ ë²ˆì—­ ì™„ë£Œë¡œ íŒë‹¨ expected_conditionsë¥¼ í™œìš©í•´ íŠ¹ì •í•œ íƒœê·¸ì˜ ë¡œë”©ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° ì„ ì •ëœ ë‹¨ì–´ë“¤ì„ ë²ˆì—­ # Copy python from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions from selenium.webdriver.common.by import By # ê°€ìƒ ë¸Œë¼ìš°ì € ì‹¤í–‰ # íŒŒíŒŒê³  ë²ˆì—­ í˜ì´ì§€(https://papago.naver.com/?sk=ko\u0026amp;tk=en) ì´ë™ for key in translation_target: driver.find_element_by_id(\u0026#39;txtSource\u0026#39;).clear() driver.find_element_by_id(\u0026#39;txtSource\u0026#39;).send_keys(key) time.sleep(3) wait = WebDriverWait(driver, timeout=10) wait.until(expected_conditions.presence_of_element_located((By.CSS_SELECTOR, \u0026#34;#targetEditArea \u0026gt; p\u0026#34;))) translated_contents = driver.find_element_by_id(\u0026#39;txtTarget\u0026#39;).text translation_result_papago[translated_contents] = translation_target[key] # ê°€ìƒ ë¸Œë¼ìš°ì € ì¢…ë£Œ WebDriverWait(): ê°€ìƒ ë¸Œë¼ìš°ì €ê°€ timeoutì„ ì´ˆê³¼í•˜ë©´ ì—ëŸ¬ ë°œìƒ wait.until(expected_conditions): ì§€ì •í•œ Tagê°€ í¬ì°©ë  ë•Œê¹Œì§€ ëŒ€ê¸° expected_conditions Documentation @ https://j.mp/3mCnc5G ì¸í„°íŒŒí¬ íˆ¬ì–´ # ì—¬í–‰ì§€ ê²€ìƒ‰ # Copy python # ê°€ìƒ ë¸Œë¼ìš°ì € ì‹¤í–‰ # ì¸í„°íŒŒí¬ íˆ¬ì–´ í˜ì´ì§€(http://tour.interpark.com/) ì´ë™ driver.find_element_by_id(\u0026#39;SearchGNBText\u0026#39;).send_keys(\u0026#39;ë³´ë¼ì¹´ì´\u0026#39;) driver.find_element_by_class_name(\u0026#39;search-btn\u0026#39;).click() ì—¬í–‰ì§€ ê²€ìƒ‰ ê²°ê³¼ í¬ë¡¤ë§ # Copy python # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ driver.find_element_by_class_name(\u0026#39;moreBtn\u0026#39;).click() # 2í˜ì´ì§€ë¡œ ë³€ê²½ driver.find_element_by_xpath(\u0026#39;/html/body/div[3]/div/div[1]/div[2]/div[4]/div[3]/ul/li[2]\u0026#39;).click() "},{"id":102,"href":"/blog/aischool-02-04-word-cloud/","title":"[AI SCHOOL 5ê¸°] í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤ìŠµ - ì›Œë“œí´ë¼ìš°ë“œ","section":"Posts","content":"Okt Library # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° KoNLPy íŒ¨í‚¤ì§€ì— ì†í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ KoNLPy í…ŒìŠ¤íŠ¸ # Copy python from konlpy.tag import Okt tokenizer = Okt() tokens = tokenizer.pos(\u0026#34;ì•„ë²„ì§€ ê°€ë°©ì— ë“¤ì–´ê°€ì‹ ë‹¤.\u0026#34;, norm=True, stem=True) print(tokens) norm: ì •ê·œí™”(Normalization), \u0026lsquo;ì•ˆë…•í•˜ì„¸ìš¯\u0026rsquo; -\u0026gt; \u0026lsquo;ì•ˆë…•í•˜ì„¸ìš”\u0026rsquo; stem: ì–´ê·¼í™”(Stemming, Lemmatization), (\u0026lsquo;í•œêµ­ì–´\u0026rsquo;, \u0026lsquo;Noun\u0026rsquo;) Pickle Library (Extra) # íŒŒì´ì¬ ë³€ìˆ˜ë¥¼ pickle íŒŒì¼ë¡œ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° Copy python with open(\u0026#39;raw_pos_tagged.pkl\u0026#39;, \u0026#39;wb\u0026#39;) as f: pickle.dump(raw_pos_tagged, f) with open(\u0026#39;raw_pos_tagged.pkl\u0026#39;,\u0026#39;rb\u0026#39;) as f: data = pickle.load(f) í¬ë¡¤ë§ ë°ì´í„° ì „ì²˜ë¦¬ # í¬ë¡¤ë§ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° # Copy python df = pd.read_excel(\u0026#39;result_220328_1314.xlsx\u0026#39;) articles = df[\u0026#39;Article\u0026#39;].tolist() articles = \u0026#39;\u0026#39;.join(articles) Article ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ë¦¬ìŠ¤íŠ¸í™” ì‹œí‚¤ê³  ë‹¤ì‹œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜ í˜•íƒœì†Œ ë‹¨ìœ„ ë¶„í•´ # Copy python from konlpy.tag import Okt tokenizer = Okt() raw_pos_tagged = tokenizer.pos(articles, norm=True, stem=True) ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ì‹œê°í™” # Copy python word_cleaned = [\u0026#39;ë¶ˆìš©ì–´ê°€ ì œê±°ëœ ë‹¨ì–´ ëª©ë¡\u0026#39;] # NLTKì˜ Text() í´ë˜ìŠ¤ì—ì„œ matplotlibì˜ plot ê¸°ëŠ¥ ì œê³µ word_counted = nltk.Text(word_cleaned) plt.figure(figsize=(15, 7)) word_counted.plot(50) ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ì‹œê°í™” (ë§‰ëŒ€ê·¸ë˜í”„) # Copy python # NLTKì˜ FreqDist() í´ë˜ìŠ¤ë¥¼ ì„ ì–¸í•˜ë©´ ì¸ë±ìŠ¤ ì—´ì´ ì§€ì •ëœ ê°ì²´ ìƒì„± word_frequency = nltk.FreqDist(word_cleaned) df = pd.DataFrame(list(word_frequency.values()), word_frequency.keys()) result = df.sort_values([0], ascending=False) result.plot(kind=\u0026#39;bar\u0026#39;, legend=False, figsize=(15,5)) plt.show() Word Cloud # Import Libraries # Copy python from wordcloud import WordCloud import matplotlib.pyplot as plt from PIL import Image import numpy as np import matplotlib.pyplot as plt Create WordCloud # Copy python word_cloud = WordCloud(font_path=\u0026#34;malgun.ttf\u0026#34;, width=2000, height=1000, background_color=\u0026#39;white\u0026#39;).generate_from_frequencies(word_dic) width, height: ì›Œë“œí´ë¼ìš°ë“œ í•´ìƒë„ background_color: ë°°ê²½ìƒ‰ max_words: ë‹¨ì–´ ìµœëŒ€ ê°¯ìˆ˜ (default: 200) max_font_size: ìµœëŒ€ ê¸€ì í¬ê¸° prefer_horizontal: ê°€ë¡œë¡œ ë³´ì—¬ì£¼ëŠ” ì •ë„, ê°€ë¡œë¡œë§Œ ê·¸ë¦¬ë ¤ë©´ 1.0 ì„¤ì • Show WordCloud # Copy python plt.figure(figsize=(15,15)) # í™”ë©´ì— ë³´ì—¬ì§€ëŠ” í¬ê¸° plt.imshow(word_cloud) plt.axis(\u0026#34;off\u0026#34;) plt.tight_layout(pad=0) plt.show() Masking # Copy python python_coloring = np.array(Image.open(\u0026#34;python_mask.jpg\u0026#34;)) word_cloud = WordCloud(font_path=\u0026#34;malgun.ttf\u0026#34;, width=2000, height=1000, mask=python_coloring, background_color=\u0026#39;white\u0026#39;).generate_from_frequencies(word_dic) np.arrayë¡œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—´ë©´ í”½ì…€ ë‹¨ìœ„ì˜ í–‰ë ¬ ìƒì„± mask íŒŒë¼ë¯¸í„°ì— Numpy Array ì „ë‹¬ WordCloudì˜ í•´ìƒë„ëŠ” ì›ë³¸ ì´ë¯¸ì§€ì˜ í•´ìƒë„ì— ì˜í–¥ì„ ë°›ìŒ Coloring # Copy python from wordcloud import ImageColorGenerator image_colors = ImageColorGenerator(python_coloring) ... plt.imshow(word_cloud.recolor(color_func=image_colors), interpolation=\u0026#39;bilinear\u0026#39;) ImageColorGenerator ê°ì²´ë¥¼ í†µí•´ ì´ë¯¸ì§€ë¡œë¶€í„° ìƒ‰ìƒì„ ì¶”ì¶œ recolor í•¨ìˆ˜ë¥¼ í†µí•´ ì´ë¯¸ì§€ ì»¬ëŸ¬ ë‹¤ì‹œ ì¹ í•˜ê¸° interpolation: ë¹„ì–´ìˆëŠ” í”½ì…€ ê°’ì„ ì¹ í•˜ëŠ” ë°©ë²•, bilinear(ë³´ê°„ë²•) colormap: ì„ì˜ë¡œ ìƒ‰ìƒ ì§€ì • ('Reds', 'Blues' ë“±) Save to Image File # Copy python word_cloud.to_file(\u0026#34;word_cloud_completed.png\u0026#34;) "},{"id":103,"href":"/blog/aischool-03-02-web-scraping-advanced/","title":"[AI SCHOOL 5ê¸°] ì›¹ í¬ë¡¤ë§ ì‹¤ìŠµ - ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¬í™”","section":"Posts","content":"Import Libraries # Copy python import requests from bs4 import BeautifulSoup import pandas as pd from datetime import datetime import time # time.sleep() import re ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë„¤ì´ë²„ ë‰´ìŠ¤ ì¶”ì¶œ # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ URL ë¶„ì„ # Copy html https://search.naver.com/search.naver? where=news\u0026amp; sm=tab_jum\u0026amp; \u0026lt;!-- ë¶ˆí•„ìš” --\u0026gt; query=ë°ì´í„°ë¶„ì„ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ URL ë¶ˆëŸ¬ì˜¤ê¸° # Copy python query = input() # ë°ì´í„°ë¶„ì„ url = f\u0026#39;https://search.naver.com/search.naver?where=news\u0026amp;query={query}\u0026#39; web = requests.get(url).content source = BeautifulSoup(web, \u0026#39;html.parser\u0026#39;) ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ ì£¼ì œ ê°€ì ¸ì˜¤ê¸° # Copy python news_subjects = source.find_all(\u0026#39;a\u0026#39;, {\u0026#39;class\u0026#39; : \u0026#39;news_tit\u0026#39;}) subject_list = [] for subject in news_subjects: subject_list.append(subject.get_text()) ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ ë§í¬ ê°€ì ¸ì˜¤ê¸° # Copy python urls_list = [] for urls in source.find_all(\u0026#39;a\u0026#39;, {\u0026#39;class\u0026#39; : \u0026#39;info\u0026#39;}): if urls.attrs[\u0026#39;href\u0026#39;].startswith(\u0026#39;https://news.naver.com\u0026#39;): urls_list.append(urls.attrs[\u0026#39;href\u0026#39;]) ë‹¨ì¼ ë‰´ìŠ¤ í˜ì´ì§€ ë¶„ì„ # ConnectionError # Copy python web_news = requests.get(urls_list[0]).content source_news = BeautifulSoup(web_news, \u0026#39;html.parser\u0026#39;) Copy bash ConnectionError: (\u0026#39;Connection aborted.\u0026#39;, RemoteDisconnected(\u0026#39;Remote end closed connection without response\u0026#39;)) ë¸Œë¼ìš°ì €ë¥¼ ê±°ì¹˜ì§€ ì•Šê³  HTML ì½”ë“œë¥¼ ìš”ì²­í•˜ë©´ ConnectionError ë°œìƒ ì‚¬ìš©ìì„ì„ ì•Œë¦¬ëŠ” í—¤ë” ì¶”ê°€ Copy python headers = {\u0026#39;User-Agent\u0026#39;:\u0026#39;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\u0026#39;} web_news = requests.get(urls_list[0], headers=headers).content source_news = BeautifulSoup(web_news, \u0026#39;html.parser\u0026#39;) ê¸°ì‚¬ ì œëª© / ë°œí–‰ ë‚ ì§œ ì¶”ì¶œ # Copy python title = source_news.find(\u0026#39;h3\u0026#39;, {\u0026#39;id\u0026#39; : \u0026#39;articleTitle\u0026#39;}).get_text() date = source_news.find(\u0026#39;span\u0026#39;, {\u0026#39;class\u0026#39; : \u0026#39;t11\u0026#39;}).get_text() Pandas Timestamp # Copy python # 2022.03.25. ì˜¤ì „ 10:18 date = source_news.find(\u0026#39;span\u0026#39;, {\u0026#39;class\u0026#39; : \u0026#39;t11\u0026#39;}).get_text() # 2022.03.25.10:18am pd_date = pd.Timestamp(reformatted_date) ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ # Copy python article = source_news.find(\u0026#39;div\u0026#39;, {\u0026#39;id\u0026#39; : \u0026#39;articleBodyContents\u0026#39;}).get_text() article = article.replace(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;) article = article.replace(\u0026#34;// flash ì˜¤ë¥˜ë¥¼ ìš°íšŒí•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€function _flash_removeCallback() {}\u0026#34;, \u0026#34;\u0026#34;) article = article.replace(\u0026#34;ë™ì˜ìƒ ë‰´ìŠ¤ \u0026#34;, \u0026#34;\u0026#34;) article = article.replace(\u0026#34;ë™ì˜ìƒ ë‰´ìŠ¤\u0026#34;, \u0026#34;\u0026#34;) article = article.strip() ê¸°ì‚¬ ë°œí–‰ ì–¸ë¡ ì‚¬ ì¶”ì¶œ # Copy python press_company = source_news.find(\u0026#39;address\u0026#39;, {\u0026#39;class\u0026#39; : \u0026#39;address_cp\u0026#39;}).find(\u0026#39;a\u0026#39;).get_text() print(press_company) ì—¬ëŸ¬ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ # ê° ê¸°ì‚¬ë“¤ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ # Copy python for url in urls_list: ... titles.append(title) dates.append(date) articles.append(article) article_urls.append(url) press_companies.append(press_company) ë°ì´í„°ì— ëŒ€í•œ DataFrame ìƒì„± # Copy python article_df = pd.DataFrame({\u0026#39;Title\u0026#39;:titles, \u0026#39;Date\u0026#39;:dates, \u0026#39;Article\u0026#39;:articles, \u0026#39;URL\u0026#39;:article_urls, \u0026#39;PressCompany\u0026#39;:press_companies}) ì—¬ëŸ¬ í˜ì´ì§€ì˜ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ # ê°ê°ì˜ í˜ì´ì§€ì— í•´ë‹¹í•˜ëŠ” ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ ìƒì„± # Copy python max_page = int(input()) # 5 query = input() # ë°ì´í„°ë¶„ì„ start_points = [] for point in range(1, max_page*10+1, 10): start_points.append(str(point)) ê°ê°ì˜ í˜ì´ì§€ì— ëŒ€í•œ ë°˜ë³µë¬¸ ì‹¤í–‰ # Copy python current_call = 1 last_call = (max_page - 1) * 10 + 1 while current_call \u0026lt;= last_call: url = \u0026#34;https://search.naver.com/search.naver?where=news\u0026amp;query=\u0026#34; + query + \\ \u0026#34;\u0026amp;start=\u0026#34; + str(current_call) web = requests.get(url).content source = BeautifulSoup(web, \u0026#39;html.parser\u0026#39;) ... # ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•  ë•ŒëŠ” ìš”ì²­ ì‚¬ì´ì— ë”œë ˆì´ ìƒì„± time.sleep(5) current_call += 10 ë‚ ì§œ ì§€ì •í•˜ì—¬ í¬ë¡¤ë§ # ë„¤ì´ë²„ ë‰´ìŠ¤ ë‚ ì§œ ì§€ì • ê²€ìƒ‰ ê²°ê³¼ URL ë¶„ì„ # Copy html https://search.naver.com/search.naver?where=news \u0026amp;query=ë°ì´í„°ë¶„ì„ \u0026amp;sm=tab_opt \u0026amp;sort=0 \u0026amp;photo=0 \u0026amp;field=0 \u0026amp;pd=4 \u0026amp;ds= \u0026amp;de= \u0026amp;docid= \u0026amp;related=0 \u0026amp;mynews=0 \u0026amp;office_type=0 \u0026amp;office_section_code=0 \u0026amp;news_office_checked= \u0026lt;!-- ë‚ ì§œ ì§€ì • (from{YYYYMMDD}to{YYYYMMDD}) --\u0026gt; \u0026amp;nso=so%3Ar%2Cp%3Afrom20220101to20220301 \u0026amp;is_sug_officeid=0 ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ì¿¼ë¦¬ ìƒì„± # Copy python start_date = input() # 2022.01.01 end_date = input() # 2022.03.01 start_date = start_date.replace(\u0026#34;.\u0026#34;, \u0026#34;\u0026#34;) end_date = end_date.replace(\u0026#34;.\u0026#34;, \u0026#34;\u0026#34;) ... while current_call \u0026lt;= last_call: url = \u0026#34;https://search.naver.com/search.naver?where=news\u0026amp;query=\u0026#34; + query \\ + \u0026#34;\u0026amp;nso=so%3Ar%2Cp%3Afrom\u0026#34; + start_date \\ + \u0026#34;to\u0026#34; + end_date \\ + \u0026#34;%2Ca%3A\u0026amp;start=\u0026#34; + str(current_call) web = requests.get(url).content source = BeautifulSoup(web, \u0026#39;html.parser\u0026#39;) ... ê¸°ì‚¬ ì •ë ¬ ìˆœì„œ ì§€ì •í•˜ì—¬ í¬ë¡¤ë§ # ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ ì •ë ¬ ìˆœì„œ ê²€ìƒ‰ ê²°ê³¼ URL ë¶„ì„ # Copy html https://search.naver.com/search.naver?where=news \u0026amp;query=ë°ì´í„°ë¶„ì„ \u0026amp;sm=tab_opt \u0026lt;!-- ê´€ë ¨ë„ìˆœ: 0, ìµœì‹ ìˆœ: 1, ì˜¤ë˜ëœìˆœ: 2 --\u0026gt; \u0026amp;sort=0 ... ì •ë ¬ ìˆœì„œì— í•´ë‹¹í•˜ëŠ” ì¿¼ë¦¬ ìƒì„± # Copy python query = input() # \u0026#34;ë°ì´í„°ë¶„ì„\u0026#34; \u0026lt; ì •í™•í•œ ê²€ìƒ‰ sort_type = int(input()) # 1 ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ # Copy python article_df.to_excel(\u0026#39;result_{}.xlsx\u0026#39;.format(datetime.now().strftime(\u0026#39;%y%m%d_%H%M\u0026#39;)), index=False, encoding=\u0026#39;utf-8\u0026#39;) "},{"id":104,"href":"/blog/leetcode-problems-1337/","title":"[LeetCode 1337] The K Weakest Rows in a Matrix (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://leetcode.com/problems/the-k-weakest-rows-in-a-matrix/ ê°œìš” # 2ì°¨ì› ë°°ì—´ì— ëŒ€í•´ ê°ê°ì˜ ë¦¬ìŠ¤íŠ¸ì˜ í•©ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ì„ í•˜ê³  ê·¸ ìˆœì„œë¥¼ ë°˜í™˜í•˜ëŠ” ë¬¸ì œì´ë‹¤. íŒŒì´ì¬ì—ì„œëŠ” ë‚´ì¥í•¨ìˆ˜ sort()ë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ í’€ ìˆ˜ ìˆë‹¤. ë¬¸ì œ í•´ì„¤ # ì…ë ¥ìœ¼ë¡œ 2ì°¨ì› ë°°ì—´ matê³¼ ì¶œë ¥ê°’ì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•˜ëŠ” ì •ìˆ˜ kê°€ ì£¼ì–´ì§„ë‹¤. matì— ìˆëŠ” ê°ê°ì˜ ë¦¬ìŠ¤íŠ¸ëŠ” 0ê³¼ 1ì˜ ì¡°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©° 1ì˜ ê°œìˆ˜ê°€ ë§ì€ ë¦¬ìŠ¤íŠ¸ê°€ ê°•í•œ ë¦¬ìŠ¤íŠ¸ì´ë‹¤. ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ê²ƒì€ 1. ë¦¬ìŠ¤íŠ¸ë¥¼ ì•½í•œ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³ \n2. ì •ë ¬í•˜ê¸° ì „ì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ì •ë ¬ëœ ìˆœì„œëŒ€ë¡œ ë°˜í™˜í•˜ëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ì™€ ë¦¬ìŠ¤íŠ¸ì˜ í•©ì„ ë”°ë¡œ ì €ì¥í•  í•„ìš”ê°€ ìˆìœ¼ë¯€ë¡œ forë¬¸ì„ í†µí•´ matì„ ìˆœíšŒí•œë‹¤. ìˆœíšŒí•˜ë©´ì„œ matì˜ ê° ë¦¬ìŠ¤íŠ¸ ë‚´ìš©ì„ [ì¸ë±ìŠ¤ ë²ˆí˜¸, ë¦¬ìŠ¤íŠ¸ì˜ í•©]ìœ¼ë¡œ ë®ì–´ì“°ê³ \nì´í›„ì— 1ë²ˆ ì›ì†Œ(ë¦¬ìŠ¤íŠ¸ì˜ í•©)ì„ ê¸°ì¤€ìœ¼ë¡œ matë¥¼ ì •ë ¬í•œë‹¤. ë§ˆì§€ë§‰ì— ì •ë ¬ëœ matì˜ 0ë²ˆ ì›ì†Œ(ì¸ë±ìŠ¤ ë²ˆí˜¸)ë¥¼ kê°œ ë§Œí¼ë§Œ ì¶”ì¶œí•´ì„œ ë°˜í™˜í•˜ë©´ ëœë‹¤. í•´ì„¤ ì½”ë“œ # Copy python class Solution(object): def kWeakestRows(self, mat, k): \u0026#34;\u0026#34;\u0026#34; :type mat: List[List[int]] :type k: int :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; for i in range(len(mat)): mat[i] = [i, sum(mat[i])] mat.sort(key=lambda x: x[1]) return [mat[i][0] for i in range(k)] "},{"id":105,"href":"/blog/boj-problems-2805/","title":"[ë°±ì¤€ 2805] ë‚˜ë¬´ ìë¥´ê¸° (PyPy3)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/2805 ê°œìš” # ì´ë¶„ íƒìƒ‰ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œì´ë‹¤. Python3ì„ ì‚¬ìš©í•˜ë©´ ì‹œê°„ì´ˆê³¼ê°€ ë°œìƒí•˜ë¯€ë¡œ PyPy3ë¥¼ ì‚¬ìš©í•œë‹¤. ë¬¸ì œ ì¡°ê±´ # ì¼ì • ë†’ì´ì— ëŒ€í•´ ëª¨ë“  ë‚˜ë¬´ë¥¼ ì˜ëì„ ë•Œ, ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì ˆë‹¨ê¸°ì˜ ìµœëŒ€ ë†’ì´(H)ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œì´ë‹¤. ì˜ë¦° ë‚˜ë¬´ì˜ ê¸¸ì´ì˜ í•©ì€ ìƒê·¼ì´ê°€ í•„ìš”ë¡œ í•˜ëŠ” ë‚˜ë¬´ì˜ ê¸¸ì´(M)ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ì•„ì•¼ í•œë‹¤. ë¬¸ì œ í•´ì„¤ # ë‚˜ë¬´ì˜ ìˆ˜(N)ì˜ ìµœëŒ“ê°’ì´ 1,000,000ì´ë¯€ë¡œ ëª¨ë“  ë²”ìœ„ì— ëŒ€í•´ ë°˜ë³µí•˜ëŠ” ìˆœì°¨ íƒìƒ‰ì„ ì´ìš©í•  ê²½ìš° ì‹œê°„ì´ˆê³¼ê°€ ë°œìƒí•œë‹¤. ì‹œê°„ ë³µì¡ë„ê°€ O(log n)ì¸ ì´ë¶„ íƒìƒ‰ì„ ì´ìš©í•˜ë©´ ì‹œê°„ ë³µì¡ë„ê°€ O(n)ì¸ ìˆœì°¨ íƒìƒ‰ì„ ì“°ëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ë‹¤. ì´ë¶„ íƒìƒ‰ì€ ì¤‘ê°„ê°’(md)ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ì¡°ê±´ì— ë”°ë¼\nìµœëŒ€/ìµœì†Ÿê°’ì˜ í¬ì¸í„°(mx/mn)ë¥¼ ì¡°ì •í•˜ëŠ” íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. ì˜ë¦° ë‚˜ë¬´ì˜ ê¸¸ì´ì˜ í•©(total)ì„ êµ¬í•  ë•Œ ì˜ë¦¬ì§€ ì•Šì€ ë‚˜ë¬´ì— ëŒ€í•œ ìŒìˆ˜ê°’ì„ í¬í•¨í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•œë‹¤. ì¡°ê±´ì„ ë§Œì¡±í•  ê²½ìš° ìµœì†Ÿê°’(mn)ì„ ì¤‘ê°„ê°’(md)ë³´ë‹¤ í¬ê²Œ ë§ì¶”ë©°,\në°˜ëŒ€ì˜ ê²½ìš° ìµœëŒ“ê°’(mx)ì„ ì¤‘ê°„ê°’(md)ë³´ë‹¤ ì‘ê²Œ ì¡°ì •í•œë‹¤. ì´ë¶„ íƒìƒ‰ì„ ë§ˆì¹˜ë©´ ìµœëŒ“ê°’(mx)ì— ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ìµœëŒ€ ë†’ì´(H)ì˜ ê°’ì´ ë‚¨ê²Œ ëœë‹¤. ì‹œê°„ ë³µì¡ë„ # ì‹œê°„ ë³µì¡ë„ê°€ O(log N)ì¸ ì´ë¶„ íƒìƒ‰ì˜ ë§¤ ë°˜ë³µë§ˆë‹¤ ì‹œê°„ ë³µì¡ë„ê°€ O(n)ì¸ forë¬¸ì„ ì‹¤í–‰í•˜ë¯€ë¡œ\nì‹œê°„ ë³µì¡ë„ëŠ” O(N log N) ì´ìƒì´ ëœë‹¤. Nì˜ ìµœëŒ“ê°’ 1,000,000ì— ëŒ€í•´ 20,000,000ë²ˆì´ ë„˜ëŠ” ì—°ì‚°ì´ ì‹¤í–‰ë˜ë¯€ë¡œ Python3ìœ¼ë¡œëŠ” ì‹œê°„ ì œí•œ 1ì´ˆë¥¼ ì´ˆê³¼í•œë‹¤. PyPy3ì— ëŒ€í•œ ì´í•´ê°€ ê¹Šì€ í¸ì´ ì•„ë‹ˆë¼ ìì„¸í•œ ì„¤ëª…ì€ ì–´ë µì§€ë§Œ,\në©”ëª¨ë¦¬ë¥¼ ë” ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹  ì½”ë“œë¥¼ ìºì‹±í•˜ëŠ” PyPy3ë¥¼ ì‚¬ìš©í•˜ë©´ ì‹œê°„ ì œí•œ ì•ˆì— í•´ê²°í•  ìˆ˜ ìˆë‹¤. í•´ì„¤ ì½”ë“œ # Copy python N, M = map(int, input().split()) trees = list(map(int, input().split())) mn, md, mx = 0, 0, max(trees) while mn \u0026lt;= mx: md = (mx + mn) // 2 total = 0 for tree in trees: total += tree - md if tree \u0026gt; md else 0 if total \u0026gt;= M: mn = md + 1 else: mx = md - 1 print(mx) "},{"id":106,"href":"/blog/aischool-02-03-text-analysis/","title":"[AI SCHOOL 5ê¸°] í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤ìŠµ - í…ìŠ¤íŠ¸ ë¶„ì„","section":"Posts","content":"Scikit-learn Library # Traditional Machine Learning (vs DL, ì¸ê³µì‹ ê²½ì„ ì¼ëŠ”ì§€ì˜ ì—¬ë¶€) Copy python from sklearn import datasets, linear_model, model_selection, metrics data_total = datasets.load_boston() x = data_total.data y = data_total.target train_x, test_x, train_y, test_y = model_selection.train_test_split(x, y, test_size=0.3) # í•™ìŠµ ì „ì˜ ëª¨ë¸ ìƒì„± model = linear_model.LinearRegression() # ëª¨ë¸ì— í•™ìŠµ ë°ì´í„°ë¥¼ ë„£ìœ¼ë©´ì„œ í•™ìŠµ ì§„í–‰ model.fit(train_x, train_y) # ëª¨ë¸ì—ê²Œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì£¼ë©´ì„œ ì˜ˆì¸¡ ìš”êµ¬ predictions = model.predict(test_x) # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„±ëŠ¥ ì ìˆ˜ í™•ì¸ metrics.mean_squared_error(predictions, test_y) ì‹¤ìŠµì—ì„œ ì‚¬ìš©í•  íŒ¨í‚¤ì§€ Copy python from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.metrics.pairwise import cosine_similarity Vectorizer # Copy python corpus = [doc1, doc2, doc3] vectorizer = TfidfVectorizer() X = vectorizer.fit_transform(corpus).todense() # vertorizer.fit(corpus) # X = vectorizer.trasnform(corpus) VectorizerëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì¸ ë‹¤ìˆ˜ì˜ ë°ì´í„°ì— ëŒ€í•œ ë²¡í„° ìƒì„± fit_transform()ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ë¥¼ ì°¨ì§€í•˜ëŠ” \u0026lsquo;0\u0026rsquo;ì´ë¼ëŠ” ê°’ë“¤ì„ ì œì™¸í•˜ê³ \nì¢Œí‘œì— ëŒ€í•œ ê°’ì˜ í˜•íƒœë¡œ í‘œì‹œ .todense(): \u0026lsquo;0\u0026rsquo;ì´ë¼ëŠ” ê°’ë“¤ì„ í¬í•¨í•˜ì—¬ í–‰ë ¬ì˜ í˜•íƒœë¡œ í‘œì‹œ X.shape: Vectorizerì˜ ëª¨ì–‘ í™•ì¸ (row, column) CountVectorizer(): ë‹¨ì–´ì˜ ì¶œì—° íšŸìˆ˜ë§Œìœ¼ë¡œ ë²¡í„° ìƒì„± Print Output # Copy python [[0.0071001 0.00332632 0. ... 0. 0.00166316 0. ] [0.00889703 0. 0.00138938 ... 0.00138938 0. 0.00138938]] Pandas Output # 3. Cosine Similarity # Copy python cosine_similarity(X[0], X[1]) [í•˜ë‚˜ì˜ í–‰ vs ì „ì²´ í–‰] êµ¬ë„ë¡œ í‘œì‹œ # Copy python similarity = cosine_similarity(X[0], X) # ìœ„ì—ì„œë¶€í„° ìˆœì„œëŒ€ë¡œ ë³´ê¸° ìœ„í•´ ì „ì¹˜ í–‰ë ¬(Transpose)ë¡œ í‘œì‹œ pd.DataFrame(similarity.T) [ê° í–‰ vs ì „ì²´ í–‰] êµ¬ë„ë¡œ í‘œì‹œ # Copy python similarity = cosine_similarity(X, X) result = pd.DataFrame(similarity) result.columns = [\u0026#39;Shawshank\u0026#39;, \u0026#39;Godfather\u0026#39;, \u0026#39;Inception\u0026#39;] result.index = [\u0026#39;Shawshank\u0026#39;, \u0026#39;Godfather\u0026#39;, \u0026#39;Inception\u0026#39;] ìœ ì‚¬ë„ í–‰ë ¬ ì‹œê°í™” # Copy python import seaborn as sns import matplotlib.pyplot as plt plt.figure(figsize=(10, 10)) sns.heatmap(result, annot=True, fmt=\u0026#39;f\u0026#39;, linewidths=5, cmap=\u0026#39;RdYlBu\u0026#39;) sns.set(font_scale=1.5) plt.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False) plt.show() "},{"id":107,"href":"/blog/aischool-02-02-text-data-exploration/","title":"[AI SCHOOL 5ê¸°] í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤ìŠµ - í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„","section":"Posts","content":"Tokenizing Text Data # Import Libraries # Copy python import nltk from nltk.corpus import stopwords from collections import Counter Set Stopwords # Copy python stop_words = stopwords.words(\u0026#34;english\u0026#34;) stop_words.append(\u0026#39;,\u0026#39;) stop_words.append(\u0026#39;.\u0026#39;) stop_words.append(\u0026#39;â€™\u0026#39;) stop_words.append(\u0026#39;â€\u0026#39;) stop_words.append(\u0026#39;â€”\u0026#39;) Open Text Data # Copy python file = open(\u0026#39;movie_review.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;) lines = file.readlines() Tokenize # Copy python tokens = [] for line in lines: tokenized = nltk.word_tokenize(line) for token in tokenized: if token.lower() not in stop_words: tokens.append(token) Counting Nouns # POS Tagging # Copy python tags = nltk.pos_tag(tokens) word_list = [] for word, tag in tags: if tag.startswith(\u0026#39;N\u0026#39;): word_list.append(word.lower()) Counting Nouns # Copy python counts = Counter(word_list) print(counts.most_common(10)) Output\nCopy python [(\u0026#39;movie\u0026#39;, 406), (\u0026#39;batman\u0026#39;, 303), (\u0026#39;film\u0026#39;, 284), (\u0026#39;joker\u0026#39;, 219), (\u0026#39;dark\u0026#39;, 136), (\u0026#39;ledger\u0026#39;, 131), (\u0026#39;knight\u0026#39;, 124), (\u0026#39;time\u0026#39;, 112), (\u0026#39;heath\u0026#39;, 110), (\u0026#39;performance\u0026#39;, 87)] Counting Adjectives # POS Tagging # Copy python tags = nltk.pos_tag(tokens) word_list = [] for word, tag in tags: if tag.startswith(\u0026#39;J\u0026#39;): word_list.append(word.lower()) Counting Adjectives # Copy python counts = Counter(word_list) print(counts.most_common(10)) Output\nCopy python [(\u0026#39;good\u0026#39;, 141), (\u0026#39;best\u0026#39;, 102), (\u0026#39;great\u0026#39;, 78), (\u0026#39;many\u0026#39;, 54), (\u0026#39;much\u0026#39;, 52), (\u0026#39;comic\u0026#39;, 43), (\u0026#39;real\u0026#39;, 29), (\u0026#39;bad\u0026#39;, 28), (\u0026#39;little\u0026#39;, 26), (\u0026#39;new\u0026#39;, 25)] Counting Verbs # POS Tagging # Copy python tags = nltk.pos_tag(tokens) word_list = [] for word, tag in tags: if tag.startswith(\u0026#39;V\u0026#39;): word_list.append(word.lower()) Counting Verbs # Copy python counts = Counter(word_list) print(counts.most_common(10)) Output\nCopy python [(\u0026#39;see\u0026#39;, 59), (\u0026#39;get\u0026#39;, 54), (\u0026#39;made\u0026#39;, 49), (\u0026#39;think\u0026#39;, 46), (\u0026#39;seen\u0026#39;, 45), (\u0026#39;make\u0026#39;, 45), (\u0026#39;say\u0026#39;, 41), (\u0026#34;\u0026#39;ve\u0026#34;, 37), (\u0026#34;\u0026#39;m\u0026#34;, 32), (\u0026#39;going\u0026#39;, 31)] Visualizing Tokens # Import Libraries # Copy python import matplotlib.pyplot as plt import re ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í† í° ë¶„ë¥˜ # Copy python tokens = [] for line in lines: tokenized = nltk.word_tokenize(line) for token in tokenized: if token.lower() not in stop_words: if re.match(\u0026#39;^[a-zA-Z]+\u0026#39;, token): tokens.append(token) ì •ê·œí‘œí˜„ì‹ ê°œë… ì†Œê°œ @ https://j.mp/3bJQJHg ì •ê·œí‘œí˜„ì‹ ê¸°ë³¸ ë¬¸ë²• ì •ë¦¬ @ https://j.mp/3bLXSqB ìƒì„¸í•œ ì •ê·œí‘œí˜„ì‹ ì„¤ëª… @ http://j.mp/2PzgFO8 ìƒì„¸í•œ ì •ê·œí‘œí˜„ì‹ ì˜ˆì œ @ https://hamait.tistory.com/342 ì í”„ íˆ¬ íŒŒì´ì¬ ì •ê·œí‘œí˜„ì‹ @ https://wikidocs.net/4308 Visualizing Tokens # Copy python plt.figure(figsize=(10, 3)) plt.title(\u0026#39;Top 25 Words\u0026#39;,fontsize=30) corpus.plot(25) Top 25 Words Chart # Similar Words # Copy python print(\u0026#39;Similar words : \u0026#39;) corpus.similar(\u0026#39;batman\u0026#39;) Output\nCopy bash Similar words : superhero film action movie character better iconic seen acting actor heath performance modern difficult villain second end good come best Collocation # Copy python print(\u0026#39;Collocation\u0026#39;) corpus.collocation() Output\nCopy bash Collocation Dark Knight; Heath Ledger; Christian Bale; comic book; Harvey Dent; Christopher Nolan; Bruce Wayne; Aaron Eckhart; Morgan Freeman; Gary Oldman; Batman Begins; Two Face; Gotham City; Maggie Gyllenhaal; Rachel Dawes; Michael Caine; special effect; Tim Burton; Jack Nicholson; dark knight "},{"id":108,"href":"/blog/aischool-02-01-processing-text-data/","title":"[AI SCHOOL 5ê¸°] í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤ìŠµ - í…ìŠ¤íŠ¸ ë¶„ì„","section":"Posts","content":"NLTK Library # NLTK(Natural Language Toolkit)ì€ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ Copy python import nltk nltk.download() ë¬¸ì¥ì„ ë‹¨ì–´ ìˆ˜ì¤€ì—ì„œ í† í°í™” # Copy python sentence = \u0026#39;NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\u0026#39; nltk.word_tokenize(sentence) Output\nCopy bash [\u0026#39;NLTK\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;leading\u0026#39;, \u0026#39;platform\u0026#39;, ... POS Tagging # Copy python tokens = nltk.word_tokenize(sentence) nltk.pos_tag(tokens) Output\nCopy bash [(\u0026#39;NLTK\u0026#39;, \u0026#39;NNP\u0026#39;), (\u0026#39;is\u0026#39;, \u0026#39;VBZ\u0026#39;), (\u0026#39;a\u0026#39;, \u0026#39;DT\u0026#39;), (\u0026#39;leading\u0026#39;, \u0026#39;VBG\u0026#39;), (\u0026#39;platform\u0026#39;, \u0026#39;NN\u0026#39;), ... NLTK POS Tags List # Stopwords ì œê±° # Copy python from nltk.corpus import stopwords stop_words = stopwords.words(\u0026#39;english\u0026#39;) stop_words.append(\u0026#39;,\u0026#39;) stop_words.append(\u0026#39;.\u0026#39;) result = [] for token in tokens: if token.lower() not in stopWords: result.append(token) Output\nCopy python [\u0026#39;NLTK\u0026#39;, \u0026#39;leading\u0026#39;, \u0026#39;platform\u0026#39;, \u0026#39;building\u0026#39;, \u0026#39;Python\u0026#39;, \u0026#39;programs\u0026#39;, \u0026#39;work\u0026#39;, \u0026#39;human\u0026#39;, \u0026#39;language\u0026#39;, \u0026#39;data\u0026#39;, \u0026#39;provides\u0026#39;, \u0026#39;easy-to-use\u0026#39;, \u0026#39;interfaces\u0026#39;, \u0026#39;50\u0026#39;, \u0026#39;corpora\u0026#39;, \u0026#39;lexical\u0026#39;, \u0026#39;resources\u0026#39;, \u0026#39;WordNet\u0026#39;, \u0026#39;along\u0026#39;, \u0026#39;suite\u0026#39;, \u0026#39;text\u0026#39;, \u0026#39;processing\u0026#39;, \u0026#39;libraries\u0026#39;, \u0026#39;classification\u0026#39;, \u0026#39;tokenization\u0026#39;, \u0026#39;stemming\u0026#39;, \u0026#39;tagging\u0026#39;, \u0026#39;parsing\u0026#39;, \u0026#39;semantic\u0026#39;, \u0026#39;reasoning\u0026#39;, \u0026#39;wrappers\u0026#39;, \u0026#39;industrial-strength\u0026#39;, \u0026#39;NLP\u0026#39;, \u0026#39;libraries\u0026#39;, \u0026#39;active\u0026#39;, \u0026#39;discussion\u0026#39;, \u0026#39;forum\u0026#39;] Lemmatizing # Lemmatization: ë‹¨ì–´ì˜ í˜•íƒœì†Œì /ì‚¬ì „ì  ë¶„ì„ì„ í†µí•´ íŒŒìƒì  ì˜ë¯¸ë¥¼ ì œê±°í•˜ê³ ,\nì–´ê·¼ì— ê¸°ë°˜í•˜ì—¬ ê¸°ë³¸ ì‚¬ì „í˜•ì¸ lemmaë¥¼ ì°¾ëŠ” ê²ƒ Copy python lemmatizer = nltk.wordnet.WordNetLemmatizer() print(lemmatizer.lemmatize(\u0026#34;cats\u0026#34;)) # cat print(lemmatizer.lemmatize(\u0026#34;geese\u0026#34;)) # goose print(lemmatizer.lemmatize(\u0026#34;better\u0026#34;)) # better print(lemmatizer.lemmatize(\u0026#34;better\u0026#34;, pos=\u0026#34;a\u0026#34;)) # good print(lemmatizer.lemmatize(\u0026#34;ran\u0026#34;)) # ran print(lemmatizer.lemmatize(\u0026#34;ran\u0026#34;, \u0026#39;v\u0026#39;)) # run defaultë¡œ n ì´ë¯€ë¡œ \u0026lsquo;cats\u0026rsquo;, \u0026lsquo;geese\u0026rsquo; ë“¤ì€ ê¸°ë³¸ëª…ì‚¬í˜•ì„ ë°˜í™˜ í˜•ìš©ì‚¬ \u0026lsquo;better\u0026rsquo;ëŠ” posì— aë¥¼ í•¨ê»˜ ì…ë ¥í•´ì£¼ì–´ì•¼ ì›í˜•ì¸ \u0026lsquo;good\u0026rsquo;ì„ ë°˜í™˜ ë™ì‚¬ \u0026lsquo;ran\u0026rsquo;ì€ posì— vë¥¼ í•¨ê»˜ ì…ë ¥í•´ì£¼ì–´ì•¼ ì›í˜•ì¸ \u0026lsquo;run\u0026rsquo;ì„ ë°˜í™˜ ì˜í™” ë¦¬ë·° ë°ì´í„° ì „ì²˜ë¦¬ # Copy python file = open(\u0026#39;moviereview.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) lines = file.readlines() sentence = lines[1] tokens = nltk.word_tokenize(sentence) lemmas = [] for token in tokens: if token.lower() not in stop_words: lemmas.append(lemmatizer.lemmatize(token)) "},{"id":109,"href":"/blog/aischool-03-01-web-scraping-basic/","title":"[AI SCHOOL 5ê¸°] ì›¹ í¬ë¡¤ë§ ì‹¤ìŠµ - ì›¹ ìŠ¤í¬ë˜í•‘ ê¸°ë³¸","section":"Posts","content":"BeautifulSoup Library # Copy python from bs4 import BeautifulSoup from urllib.request import urlopen ë‹¨ì–´ì˜ ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ # ë‹¤ìŒ ì–´í•™ì‚¬ì „ URL ë¶ˆëŸ¬ì˜¤ê¸° # Copy python # ì°¾ëŠ” ë‹¨ì–´ ì…ë ¥ word = \u0026#39;happiness\u0026#39; url = f\u0026#39;https://alldic.daum.net/search.do?q={word}\u0026#39; web = urlopen(url) web_page = BeautifulSoup(web, \u0026#39;html.parser\u0026#39;) ì°¾ëŠ” ë‹¨ì–´ ì¶œë ¥ # Copy python text_search = web_page.find(\u0026#39;span\u0026#39;, {\u0026#39;class\u0026#39;: \u0026#39;txt_emph1\u0026#39;}) print(f\u0026#39;ì°¾ëŠ” ë‹¨ì–´: {text_search.get_text()}\u0026#39;) ë‹¨ì–´ì˜ ëœ» ì¶œë ¥ # Copy python list_search = web_page.find(\u0026#39;ul\u0026#39;, {\u0026#39;class\u0026#39;: \u0026#39;list_search\u0026#39;}) list_text = list_search.find_all(\u0026#39;span\u0026#39;, {\u0026#39;class\u0026#39;: \u0026#39;txt_search\u0026#39;}) definitions = [definition.get_text() in list_text] print(f\u0026#39;ë‹¨ì–´ì˜ ëœ»: {definitions}\u0026#39;) Output\nCopy vim ì°¾ëŠ” ë‹¨ì–´: happiness ë‹¨ì–´ì˜ ëœ»: [\u0026#39;í–‰ë³µ\u0026#39;, \u0026#39;ë§Œì¡±\u0026#39;, \u0026#39;ê¸°ì¨\u0026#39;, \u0026#39;í–‰ìš´\u0026#39;] ì˜í™” ì •ë³´ ì¶œë ¥ # ë„¤ì´ë²„ ì˜í™” URL ë¶ˆëŸ¬ì˜¤ê¸° # Copy python # ì°¾ëŠ” ì˜í™” ë²ˆí˜¸ ì…ë ¥ (í–¥í›„ ì˜í™” ì œëª©ìœ¼ë¡œ ê²€ìƒ‰ êµ¬í˜„) movie = 208077 url = f\u0026#39;https://movie.naver.com/movie/search/result.naver?query={movie}\u0026#39; web = urlopen(url) web_page = BeautifulSoup(web, \u0026#39;html.parser\u0026#39;) ì˜í™” ì œëª© ì¶œë ¥ # Copy python title = web_page.find(\u0026#39;h3\u0026#39;, {\u0026#39;class\u0026#39;:\u0026#39;h_movie\u0026#39;}).find(\u0026#39;a\u0026#39;) print(f\u0026#39;Movie Title: {title.get_text()}\u0026#39;) ë„¤ì´ë²„ ì˜í™” ë°°ìš°/ì œì‘ì§„ URL ë¶ˆëŸ¬ì˜¤ê¸° # Copy python url = f\u0026#39;https://movie.naver.com/movie/bi/mi/detail.naver?query={movie}\u0026#39; web = urlopen(url) web_page = BeautifulSoup(web, \u0026#39;html.parser\u0026#39;) ê°ë… ì´ë¦„ ì¶œë ¥ # Copy python director = web_page.find(\u0026#39;div\u0026#39;, {\u0026#39;class\u0026#39;:\u0026#39;dir_product\u0026#39;}).find(\u0026#39;a\u0026#39;) print(f\u0026#39;Director: {director.get_text()}\u0026#39;) ì¶œì—° ë°°ìš°ë“¤ ì´ë¦„ ì¶œë ¥ # Copy python actor_list = web_page.find(\u0026#39;ul\u0026#39;, {\u0026#39;class\u0026#39;:\u0026#39;lst_people\u0026#39;}) actor_names = actor_list.find_all(\u0026#39;a\u0026#39;, {\u0026#39;class\u0026#39;:\u0026#39;k_name\u0026#39;}) actors = [actor.get_text() for actor in actor_names] print(f\u0026#39;Actors: {actors}\u0026#39;) Output\nCopy text Movie Title: ìŠ¤íŒŒì´ë”ë§¨: ë…¸ ì›¨ì´ í™ˆ Director: ì¡´ ì™“ì¸  Actors: [\u0026#39;í†° í™€ëœë“œ\u0026#39;, \u0026#39;ì  ë°ì´ì•„ ì½œë¨¼\u0026#39;, \u0026#39;ë² ë„¤ë”•íŠ¸ ì»´ë²„ë°°ì¹˜\u0026#39;, \u0026#39;ì¡´ íŒŒë¸Œë¡œ\u0026#39;, \u0026#39;ì œì´ì½¥ ë°°ëœëŸ°\u0026#39;, \u0026#39;ë§ˆë¦¬ì‚¬ í† ë©”ì´\u0026#39;, \u0026#39;ì•Œí”„ë¦¬ë“œ ëª°ë¦¬ë‚˜\u0026#39;] í‹°ìŠ¤í† ë¦¬ ê²Œì‹œê¸€ ì¶œë ¥ ë° ì €ì¥ # í‹°ìŠ¤í† ë¦¬ ê²Œì‹œê¸€ URL ë¶ˆëŸ¬ì˜¤ê¸° # Copy python # ì°¾ëŠ” ê¸€ ë²ˆí˜¸ ì…ë ¥ post_number = 22 url = f\u0026#39;https://minyeamer.tistory.com/{post_number}\u0026#39; web = urlopen(url) source = BeautifulSoup(web, \u0026#39;html.parser\u0026#39;) í‹°ìŠ¤í† ë¦¬ ê²Œì‹œê¸€ ì¶œë ¥ # Copy python all_text = source.find(\u0026#39;article\u0026#39;,{\u0026#39;class\u0026#39;: \u0026#39;content\u0026#39;}) tags = [\u0026#39;h2\u0026#39;, \u0026#39;h3\u0026#39;, \u0026#39;h4\u0026#39;, \u0026#39;li\u0026#39;, \u0026#39;p\u0026#39;, \u0026#39;blockquote\u0026#39;, \u0026#39;code\u0026#39;] article = all_text.find_all(tags) print(article) í‹°ìŠ¤í† ë¦¬ ê²Œì‹œê¸€ ì €ì¥ # Copy python from urllib.request import HTTPError for post_number in range(10): try: url = f\u0026#39;https://minyeamer.tistory.com/{post_number}\u0026#39; web = urlopen(url) source = BeautifulSoup(web, \u0026#39;html.parser\u0026#39;) except HTTPError: print(f\u0026#39;{i}ë²ˆ ê¸€ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\u0026#39;) pass with open(\u0026#39;tistory_all.txt\u0026#39;, \u0026#39;a\u0026#39;, encoding = \u0026#39;utf-8\u0026#39;) as f: all_text = source.find(\u0026#39;article\u0026#39;,{\u0026#39;class\u0026#39;: \u0026#39;content\u0026#39;}) tags = [\u0026#39;h2\u0026#39;, \u0026#39;h3\u0026#39;, \u0026#39;h4\u0026#39;, \u0026#39;li\u0026#39;, \u0026#39;p\u0026#39;, \u0026#39;blockquote\u0026#39;, \u0026#39;code\u0026#39;] article = all_text.find_all(tags) for content in article: f.write(content.get_text() + \u0026#39;\\n\u0026#39;) "},{"id":110,"href":"/blog/aischool-03-00-web-crawling/","title":"[AI SCHOOL 5ê¸°] ì›¹ í¬ë¡¤ë§","section":"Posts","content":"Web Crawling vs Web Scraping # Web Crawling: Botì´ webì„ linkë¥¼ í†µí•´ ëŒì•„ë‹¤ë‹ˆëŠ” ê²ƒ Web Scraping: Webpageì—ì„œ ì›í•˜ëŠ” ìë£Œë¥¼ ê¸‡ì–´ì˜¤ëŠ” ê²ƒ HTML Tags # Tag\u0026rsquo;s Name: html, head, body, p, span, li, ol, ul, div Tag\u0026rsquo;s Attribute: class, id, style, href, src The Process of Web Scraping # URL ë¶„ì„ (query ì¢…ë¥˜ ë“±) URL êµ¬ì„± HTTP Response ì–»ê¸° (urlopen(URL) or request.get(URL).content) HTTP source ì–»ê¸° (BeautifulSoup(HTTP Response, 'html.parser')) HTML Tag êº¼ë‚´ê¸° (.find('tag_name', {'attr_name':'attr_value'})) Tagë¡œë¶€í„° í…ìŠ¤íŠ¸ í˜¹ì€ Attribute values êº¼ë‚´ê¸° (Tag.get_text() or Tag.attrs) The Process of Data Analysis for Text Data # í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ str ìë£Œí˜•ìœ¼ë¡œ ì¤€ë¹„ Tokenize (í˜•íƒœì†Œ ë¶„ì„) POS Tagging (Part-of-speech, í’ˆì‚¬ í‘œì‹œ) Stopwords ì œê±° (ë¶ˆìš©ì–´ ì œê±°) ë‹¨ì–´ ê°¯ìˆ˜ ì¹´ìš´íŒ… \u0026amp; ë‹¨ì–´ ì‚¬ì „ ìƒì„± ë‹¨ì–´ ì‚¬ì „ ê¸°ë°˜ ë°ì´í„° ì‹œê°í™” (+ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ ì ìš©) TF-IDF # Term Frequency - Inverse Document Frequency íŠ¹ì • ë‹¨ì–´ê°€ ë¬¸ì„œì—ì„œ ì–´ë–¤ ì¤‘ìš”ë„ë¥¼ ê°€ì§€ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ ë§ì€ ë¬¸ì„œì— ê³µí†µì ìœ¼ë¡œ ë“¤ì–´ìˆëŠ” ë‹¨ì–´ëŠ” ë¬¸ì„œ êµ¬ë³„ ëŠ¥ë ¥ì´ ë–¨ì–´ì§„ë‹¤ íŒë‹¨í•˜ì—¬ ê°€ì¤‘ì¹˜ ì¶•ì†Œ Count Vectorizer # ë‹¨ì–´ì˜ ë¹ˆë„ìˆ˜ë§Œì„ ì‚¬ìš©í•´ì„œ ë²¡í„° ìƒì„± Document That Nice Car John Has Red A 1 1 1 0 0 0 B 1 0 1 1 1 1 TF-IDF Vectorizer # ë‹¨ì–´ì˜ ë¹ˆë„ìˆ˜(TF)ë¥¼ TF-IDF ê°’ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ê°€ì¤‘ì¹˜ê°€ ì¡°ì •ëœ ë²¡í„° ìƒì„± Cosine Similarity # ë‘ ë²¡í„° ì‚¬ì´ ê°ë„ì˜ ì½”ì‚¬ì¸ ê°’ì„ ì´ìš©í•˜ì—¬ ë‘ ë²¡í„°ì˜ ìœ ì‚¬í•œ ì •ë„ ì¸¡ì • ìœ ì‚¬ë„ê°€ -1ì´ë©´ ì„œë¡œ ì™„ì „íˆ ë°˜ëŒ€ë˜ëŠ” ê²½ìš° ìœ ì‚¬ë„ê°€ 0ì´ë©´ ì„œë¡œ ë…ë¦½ì ì¸ ê²½ìš° ìœ ì‚¬ë„ê°€ 1ì´ë©´ ì„œë¡œ ì™„ì „íˆ ê°™ì€ ê²½ìš° í…ìŠ¤íŠ¸ ë§¤ì¹­ì— ì ìš©ë  ê²½ìš° ë‘ ë²¡í„°ì— í•´ë‹¹ ë¬¸ì„œì—ì„œì˜ ë‹¨ì–´ ë¹ˆë„ê°€ ì ìš© Embedding # í•œêµ­ì–´ ì„ë² ë”© @ https://j.mp/3mduiBk "},{"id":111,"href":"/blog/aischool-01-03-data-visualization/","title":"[AI SCHOOL 5ê¸°] ë°ì´í„° ë¶„ì„ ì‹¤ìŠµ - ë°ì´í„° ì‹œê°í™”","section":"Posts","content":"Visualization Libraries # Plotly Altair Bokeh (Website Graph) @ https://j.mp/30772sU Data Chart Types # Numeric: ìˆ«ì ìì²´ì— ì˜ë¯¸ê°€ ìˆìŒ (ì˜¨ë„ ë“±), ì—°ì†í˜• Categoric: ìˆ«ì ë„ˆë¨¸ì— ì˜ë¯¸ê°€ ìˆìŒ (ì„±ë³„, ê°•ì•„ì§€ í’ˆì¢… ë“±), ë¶ˆì—°ì†í˜• @ https://goo.gl/ErLHCY @ http://j.mp/2JcEENe GeoJSON Data # Copy python import json # í•œêµ­ì˜ ì§€ë„ ë°ì´í„° ì°¸ì¡° # @ https://github.com/southkorea/southkorea-maps geo_path = \u0026#39;skorea_municipalities_geo_simple.json\u0026#39; geo_str = json.load(open(geo_path, encoding=\u0026#39;utf-8\u0026#39;)) JSON(Javascript Object Notation): ë°ì´í„° êµí™˜ì„ ìœ„í•œ í‘œì¤€ í¬ë§· GeoJSON: ì§€ë„ ë°ì´í„° í¬ë§· json.load: JSON íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° json.dump: JSON íŒŒì¼ ì €ì¥í•˜ê¸° PyPrnt Library # Copy python from pyprnt import prnt prnt(geo_str, truncate=True, width=80) PyPrnt: JSON êµ¬ì¡° íŒŒì•…ì— ìš©ì˜í•œ ë„êµ¬ @ http://j.mp/2WVZuGy Folium Library # Copy python import folium # Folium ê³µì‹ë¬¸ì„œ @ https://goo.gl/5UgneX seoul_map = folium.Map(location=, zoom_start=, tiles=) Folium: ì§€ë„ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ localtion: ì´ˆê¸° ì§€ë„ ì‹œì‘ ìœ„ì¹˜ zoom_start: ì´ˆê¸° ì§€ë„ í™•ëŒ€ ì •ë„ tiles: ì§€ë„ íƒ€ì… (default \u0026ldquo;Stamen Terrain\u0026rdquo; or \u0026ldquo;Stamen Toner\u0026rdquo;) ì´ˆê¸° ì¢Œí‘œë¥¼ [37.5502, 126.982], í™•ëŒ€ ì •ë„ë¥¼ 11ë¡œ ì„¤ì •í•˜ë©´ ì„œìš¸ì„ í‘œì‹œ ì‚´ì¸ì‚¬ê±´ ë°œìƒê±´ìˆ˜ ì‹œê°í™” # Copy python # Choropleth map @ https://goo.gl/yrTRHU seoul_map.choropleth(geo_data = geo_str, data = gu_df[\u0026#39;ì‚´ì¸\u0026#39;], columns = [gu_df.index, gu_df[\u0026#39;ì‚´ì¸\u0026#39;]], fill_color = \u0026#39;PuRd\u0026#39;, key_on = \u0026#39;feature.id\u0026#39;) geo_data: GeoJSON ë°ì´í„° data: ì‹œê°í™”ì˜ ëŒ€ìƒì´ ë  ë°ì´í„° columns: DataFrameì˜ index columnì„ ê°€ì ¸ì™€ ì¸ì‹ fill_color: matplolib colormapê³¼ ìœ ì‚¬ @ http://colorbrewer2.org key_on: GeoJSON ê·œì•½ì„ ë”°ë¦„, JSON íŒŒì¼ featureì˜ idì— ë§¤ì¹­ ê²½ì°°ì„œë³„ ê²€ê±°ìœ¨ ì ìˆ˜ ê³„ì‚° # ê²½ì°°ì„œë³„ ê²€ê±°ìœ¨ì— ëŒ€í•œ ì‹œê°í™” ì‹œ ë¬¸ì œì \nê²½ì°°ì„œë³„ ê²€ê±°ìœ¨ì˜ ìµœëŒ€-ìµœì†Œ ì°¨ì´ê°€ 17ë¡œ ë§¤ìš° ì ìŒ ê²€ê±°ìœ¨ì„ ì›í˜• ì°¨íŠ¸ë¡œ ë§Œë“¤ì—ˆì„ ë•Œ ê°ê°ì˜ ì°¨ì´ê°€ ì ì–´ì„œ ì§ê´€ì ì´ì§€ ëª»í•¨ Min-Max Algorithmì„ ì‚¬ìš©í•˜ì—¬ ê²€ê±°ìœ¨ ì ìˆ˜ ê³„ì‚°\n$$z_i=\\frac{x_i-\\text{min}(x)}{\\text{max}(x)-\\text{min}(x)}$$\nCopy python def re_range(x, oldMin, old_max, new_min, new_max): return (x - old_min)*(new_max - new_min) / (old_max - old_min) + new_min df[\u0026#39;ì ìˆ˜\u0026#39;] = re_range(df[\u0026#39;ê²€ê±°ìœ¨\u0026#39;], min(df[\u0026#39;ê²€ê±°ìœ¨\u0026#39;]), max(df[\u0026#39;ê²€ê±°ìœ¨\u0026#39;]), 1, 100) ê²½ì°°ì„œë³„ ì¢Œí‘œ ë°ì´í„° ìˆ˜ì§‘ # ê°•ë‚¨ê²½ì°°ì„œ ì¢Œí‘œ ë°ì´í„° ë‚´ìš© í™•ì¸\nCopy python import googlemaps gmaps = googlemaps.Client(key=\u0026#39;your-api-key\u0026#39;) gangnam_police_map = gmaps.geocode(\u0026#39;ì„œìš¸ê°•ë‚¨ê²½ì°°ì„œ\u0026#39;, language=\u0026#34;ko\u0026#34;) Copy json [{\u0026#39;address_components\u0026#39;: [{\u0026#39;long_name\u0026#39;: \u0026#39;ï¼‘ï¼‘\u0026#39;, \u0026#39;short_name\u0026#39;: \u0026#39;ï¼‘ï¼‘\u0026#39;, \u0026#39;types\u0026#39;: [\u0026#39;premise\u0026#39;]}, {\u0026#39;long_name\u0026#39;: \u0026#39;í…Œí—¤ë€ë¡œ114ê¸¸\u0026#39;, \u0026#39;short_name\u0026#39;: \u0026#39;í…Œí—¤ë€ë¡œ114ê¸¸\u0026#39;, \u0026#39;types\u0026#39;: [\u0026#39;political\u0026#39;, \u0026#39;sublocality\u0026#39;, \u0026#39;sublocality_level_4\u0026#39;]}, {\u0026#39;long_name\u0026#39;: \u0026#39;ê°•ë‚¨êµ¬\u0026#39;, \u0026#39;short_name\u0026#39;: \u0026#39;ê°•ë‚¨êµ¬\u0026#39;, \u0026#39;types\u0026#39;: [\u0026#39;political\u0026#39;, \u0026#39;sublocality\u0026#39;, \u0026#39;sublocality_level_1\u0026#39;]}, {\u0026#39;long_name\u0026#39;: \u0026#39;ì„œìš¸íŠ¹ë³„ì‹œ\u0026#39;, \u0026#39;short_name\u0026#39;: \u0026#39;ì„œìš¸íŠ¹ë³„ì‹œ\u0026#39;, \u0026#39;types\u0026#39;: [\u0026#39;administrative_area_level_1\u0026#39;, \u0026#39;political\u0026#39;]}, {\u0026#39;long_name\u0026#39;: \u0026#39;ëŒ€í•œë¯¼êµ­\u0026#39;, \u0026#39;short_name\u0026#39;: \u0026#39;KR\u0026#39;, \u0026#39;types\u0026#39;: [\u0026#39;country\u0026#39;, \u0026#39;political\u0026#39;]}, {\u0026#39;long_name\u0026#39;: \u0026#39;06175\u0026#39;, \u0026#39;short_name\u0026#39;: \u0026#39;06175\u0026#39;, \u0026#39;types\u0026#39;: [\u0026#39;postal_code\u0026#39;]}], \u0026#39;formatted_address\u0026#39;: \u0026#39;ëŒ€í•œë¯¼êµ­ ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ114ê¸¸ 11\u0026#39;, \u0026#39;geometry\u0026#39;: {\u0026#39;location\u0026#39;: {\u0026#39;lat\u0026#39;: 37.5094352, \u0026#39;lng\u0026#39;: 127.0669578}, \u0026#39;location_type\u0026#39;: \u0026#39;ROOFTOP\u0026#39;, \u0026#39;viewport\u0026#39;: {\u0026#39;northeast\u0026#39;: {\u0026#39;lat\u0026#39;: 37.5107841802915, \u0026#39;lng\u0026#39;: 127.0683067802915}, \u0026#39;southwest\u0026#39;: {\u0026#39;lat\u0026#39;: 37.5080862197085, \u0026#39;lng\u0026#39;: 127.0656088197085}}}, \u0026#39;partial_match\u0026#39;: True, \u0026#39;place_id\u0026#39;: \u0026#39;ChIJcbaB0UakfDURoyy8orQOWFg\u0026#39;, \u0026#39;plus_code\u0026#39;: {\u0026#39;compound_code\u0026#39;: \u0026#39;G358+QQ ëŒ€í•œë¯¼êµ­ ì„œìš¸íŠ¹ë³„ì‹œ\u0026#39;, \u0026#39;global_code\u0026#39;: \u0026#39;8Q99G358+QQ\u0026#39;}, \u0026#39;types\u0026#39;: [\u0026#39;establishment\u0026#39;, \u0026#39;point_of_interest\u0026#39;, \u0026#39;police\u0026#39;]}] gmaps.geocode: Google Mapsì˜ Geocodingì— ëŒ€í•œ í•¨ìˆ˜, ìœ„ë„/ê²½ë„ ë° ìš°í¸ë²ˆí˜¸ ë“± ë°˜í™˜ gmaps.reverse_geocode((lng, lat), lang=): ìœ„ë„/ê²½ë„ ê°’ìœ¼ë¡œ ì£¼ì†Œê°’ ë°˜í™˜ formatted_address: ë„ë¡œëª… ì£¼ì†Œ ë°˜í™˜ê°’ geometry.location: ìœ„ë„/ê²½ë„ ë°˜í™˜ê°’ (lat / lng) ê²½ì°°ì„œë³„ ì¢Œí‘œ ë°ì´í„° ìˆ˜ì§‘\nCopy python lat = [] lng = [] for name in df[\u0026#39;ê²½ì°°ì„œ\u0026#39;]: police_map = gmaps.geocode(name, language=\u0026#39;ko\u0026#39;) police_loc = seoul_police_map[0].get(\u0026#39;geometry\u0026#39;) lat.append(police_loc[\u0026#39;location\u0026#39;][\u0026#39;lat\u0026#39;]) lng.append(police_loc[\u0026#39;location\u0026#39;][\u0026#39;lng\u0026#39;]) df[\u0026#39;lat\u0026#39;] = lat df[\u0026#39;lng\u0026#39;] = lng ê²½ì°°ì„œë³„ ê²€ê±°ìœ¨ ë°ì´í„° ì‹œê°í™” # Copy python police_map = folium.Map(location=, zoom_start=) for n in df.index: folium.CircleMarker([df.at[n, \u0026#39;lat\u0026#39;], df.at[n, \u0026#39;lng\u0026#39;]], radius=df.at[n, \u0026#39;ì ìˆ˜\u0026#39;]*0.5, # meter ë‹¨ìœ„ color=\u0026#39;#3186cc\u0026#39;, fill=True, fill_color=\u0026#39;#3186cc\u0026#39;).add_to(map) ì‹œê°í™”ëœ ë°ì´í„° ì¢…í•© # Copy python police_map = folium.Map(location=, zoom_start=) police_map.choropleth(geo_data = geo_str, data = crime_ratio[\u0026#39;ì „ì²´ë°œìƒë¹„ìœ¨\u0026#39;], columns = [crime_ratio.index, crime_ratio[\u0026#39;ì „ì²´ë°œìƒë¹„ìœ¨\u0026#39;]], fill_color = \u0026#39;PuRd\u0026#39;, key_on = \u0026#39;feature.id\u0026#39;) for n in df.index: folium.CircleMarker([df.at[n, \u0026#39;lat\u0026#39;], df.at[n, \u0026#39;lng\u0026#39;]], radius=df.at[n, \u0026#39;ì ìˆ˜\u0026#39;]*0.7, color=\u0026#39;#3186cc\u0026#39;, fill=True, fill_color=\u0026#39;#3186cc\u0026#39;).add_to(police_map) Export DataFrame # DataFrame to csv file Copy python df.to_csv(\u0026#39;processed_data.csv\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) DataFrame to Excel file Copy python from pandas import ExcelWriter writer = ExcelWriter(\u0026#39;file_name.xlsx\u0026#39;) df.to_excel(writer) writer.save() Saving a folium map as an HTML file Copy python folium_map.save(\u0026#39;folium_map.html\u0026#39;) HTML íŒŒì¼ë¡œ ì‹œê°í™”ëœ ì§€ë„ ë°ì´í„° ì¶”ì¶œ\npolice-map.html GeoJSON Data (Not Simplified) # Copy python geo_path = \u0026#39;skorea-2018-municipalities-geo.json\u0026#39; geo_str = json.load(open(geo_path, encoding=\u0026#39;utf-8\u0026#39;)) features.properties.codeì—ì„œ ì„œìš¸ ë‚´ ì§€ì—­ì½”ë“œëŠ” 11ë¡œ ì‹œì‘ ê¸°ì¡´ features.idëŠ” feature.properties.nameê³¼ ë§¤ì¹­ choropleth ì‹¤í–‰ ì‹œ key_onì— feature.properties.name ì…ë ¥ ì„œìš¸ ë‚´ ì§€ì—­ë§Œ ìˆ˜ì§‘ # Copy python in_seoul = [] for feature in geo_str[\u0026#39;features\u0026#39;]: if feature[\u0026#39;properties\u0026#39;][\u0026#39;code\u0026#39;].startswith(\u0026#39;11\u0026#39;): in_seoul.append(feature) êµ¬ì²´ì ì¸ ë°ì´í„°ë¡œ êµ¬í˜„í•œ ì§€ë„ # "},{"id":112,"href":"/blog/boj-problems-11650/","title":"[ë°±ì¤€ 11650] ì¢Œí‘œ ì •ë ¬í•˜ê¸° (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/11650 ê°œìš” # ë°°ì—´ í˜•íƒœì˜ ìë£Œë“¤ì„ ì •ë ¬í•˜ëŠ” ê°„ë‹¨í•œ ë¬¸ì œì´ë‹¤. íŒŒì´ì¬ì—ì„œëŠ” ë‚´ì¥ í•¨ìˆ˜ sort()ë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ í’€ ìˆ˜ ìˆë‹¤. ë¬¸ì œ í•´ì„¤ # ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ê²ƒì€ xì¢Œí‘œ ê°’ê³¼ yì¢Œí‘œ ê°’ìœ¼ë¡œ êµ¬ì„±ëœ ë°°ì—´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ x ê°’, y ê°’ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” ê²ƒì´ë‹¤. ë°°ì—´ì˜ ìë£Œêµ¬ì¡°ëŠ” ì¸ë±ì‹±ìœ¼ë¡œ ì ‘ê·¼ì´ ê°€ëŠ¥í•œ ê²ƒì´ë©´ ì•„ë¬´ê±°ë‚˜ ìƒê´€ì—†ê¸°ì— ì¢Œí‘œ í‘œí˜„ì— ì§ê´€ì ì¸ íŠœí”Œì„ ì‚¬ìš©í•œë‹¤. ì •ë ¬ì˜ ê¸°ì¤€ì´ ë°˜ëŒ€ì˜€ìœ¼ë©´ ëŒë‹¤ ì‹ì„ ì¨ì•¼ê² ì§€ë§Œ ì¢Œí‘œì˜ ìœ„ì¹˜ê°€ ê³§ ì •ë ¬ ìˆœì„œì´ê¸° ë•Œë¬¸ì— Keyê°’ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. í•´ì„¤ ì½”ë“œ # Copy python import sys input = sys.stdin.readline points = [] for _ in range(int(input())): points.append(tuple(map(int, input().split()))) for point in sorted(points): print(point[0], point[1]) "},{"id":113,"href":"/blog/aischool-01-02-data-exploration/","title":"[AI SCHOOL 5ê¸°] ë°ì´í„° ë¶„ì„ ì‹¤ìŠµ - ë°ì´í„° íƒìƒ‰","section":"Posts","content":"Visualization Library # Copy python import seaborn as sns sns.heatmap(gu_df[]) Visualization Issues # í•œê¸€ ë°ì´í„° í‘œì‹œ ì˜¤ë¥˜ ì„œë¡œ ë‹¤ë¥¸ ìë¦¿ìˆ˜ë¡œ êµ¬ì„±ëœ ì—´ì— ë™ì¼í•œ ìŠ¤ì¼€ì¼ ì ìš© ì‹œê°í™”ëœ í…Œì´ë¸” í˜•íƒœì˜ ë¹„ì§ê´€ì„± ë¬¸ì œ ì¸êµ¬ìˆ˜ê°€ ê³ ë ¤ë˜ì§€ ì•Šì€ ë¶€ì •í™•í•œ ë°ì´í„° í•œê¸€ ë°ì´í„° ì‹œê°í™” # Copy python matplotlib inline # Windows font_name = font_manager.FontProperties(fname=\u0026#34;C:/~/malgun.ttf\u0026#34;).get_name() rc(\u0026#39;font\u0026#39;, family=font_name) # Mac rc(\u0026#39;font\u0026#39;, family=\u0026#39;AppleGothic\u0026#39;) Feature Scaling/Normalization # Min-Max Algorithm ì—´ì— ëŒ€í•œ ìµœì†Ÿê°’(min)ì„ 0, ì—´ì— ëŒ€í•œ ìµœëŒ“ê°’(max)ë¥¼ 1ë¡œ ë§ì¶¤ ê¸°ì¡´ ì—´ì„ old_x, ìƒˆë¡œìš´ ì—´ì„ new_xë¼ í•  ë•Œ,\nnew_x = ( old_x - min(column) ) / ( max(column) - min(column) ) Standardization ì—´ì— ëŒ€í•œ í‰ê· ê°’(mean)ì„ 0, ì—´ì— ëŒ€í•œ í‘œì¤€í¸ì°¨ ê°’(std)ë¥¼ 1ë¡œ ë§ì¶¤ ê¸°ì¡´ ì—´ì„ old_x, ìƒˆë¡œìš´ ì—´ì„ new_xë¼ í•  ë•Œ,\nnew_x = ( old_x - mean(column) ) / std(column) í‘œì¤€ ì ìˆ˜ (Z-score)ì™€ ë™ì¼ ì‹œê°í™” ê°œì„  # ì „ì²´ í…Œì´ë¸”ì˜ ì‚¬ì´ì¦ˆ ì¡°ì •\npit.figure(figsize = (x, y)) ì…€ í˜•ì‹ ë° ìƒ‰ìƒ ë“± ë³€ê²½\nsns.heatmap(norm, annot=, fmt=, linewidths=, cmap=) annot: ì…€ ë‚´ì— ìˆ˜ì¹˜ ì…ë ¥ ì—¬ë¶€ (defualt False) fmt: ì…€ ë‚´ì— ì…ë ¥ë  ìˆ˜ì¹˜ì˜ format ('f' == float) linewidths: ì…€ ê°„ ê±°ë¦¬ (ë‚´ë¶€ í…Œë‘ë¦¬) cmap: matplotlib colormap @https://goo.gl/YWpBES í…Œì´ë¸” ì œëª© ì„¤ì •\nplt.tile() ì‹œê°í™” ì„¤ì •ëœ í…Œì´ë¸” í‘œì‹œ\nplt.show() ë°ì´í„° ì •í™•ì„± ê°œì„  # ë²”ì£„ ë°œìƒ íšŸìˆ˜ì— ì¸êµ¬ìˆ˜ ë°˜ì˜ Copy python # ì‹œê°í™”ëœ ë°ì´í„°ì—ì„œ ì—´ë°©í–¥(axis=0)ì„ ê¸°ì¤€ìœ¼ë¡œ ì¸êµ¬ìˆ˜ ë°ì´í„°ë¥¼ ë‚˜ëˆ” (ì¸êµ¬ 10ë§Œ ë‹¨ìœ„) crime_ratio = crime_count_norm.div(gu_df[\u0026#39;ì¸êµ¬ìˆ˜\u0026#39;], axis=0) * 100000 êµ¬ë³„ 5ëŒ€ ë²”ì£„ ë°œìƒ ìˆ˜ì¹˜ í‰ê·  ê³„ì‚° Copy python crime_ratio[\u0026#39;ì „ì²´ë°œìƒë¹„ìœ¨\u0026#39;] = crime_ratio.mean(axis=1) ê° ì‚¬ê±´ë“¤ì˜ ì¤‘í˜•ë„ë¥¼ ê³ ë ¤í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ \u0026lsquo;ì‚´ì¸\u0026rsquo; ì—´ì— ìŠ¤ì¼€ì¼ ì ìš© ì¤‘ ì´ë¯¸ í° ê°’ì´ ê³±í•´ì¡Œê¸° ë•Œë¬¸ì— ê°€ì¤‘ì¹˜ê°€ ì ìš©ë˜ì—ˆë‹¤ê³ ë„ íŒë‹¨ ê°€ëŠ¥ Improved Visualization # Copy python plt.figure(figsize = (10,10)) sns.heatmap(crime_ratio.sort_values(by=\u0026#39;ì „ì²´ë°œìƒë¹„ìœ¨\u0026#39;, ascending=False), annot=True, fmt=\u0026#39;f\u0026#39;, linewidths=.5, cmap=\u0026#39;Reds\u0026#39;) plt.title(\u0026#39;ë²”ì£„ ë°œìƒ(ì „ì²´ë°œìƒë¹„ìœ¨ë¡œ ì •ë ¬) - ê° í•­ëª©ì„ ì •ê·œí™”í•œ í›„ ì¸êµ¬ë¡œ ë‚˜ëˆ”\u0026#39;) plt.show() "},{"id":114,"href":"/blog/aischool-01-01-data-analysis/","title":"[AI SCHOOL 5ê¸°] ë°ì´í„° ë¶„ì„ ì‹¤ìŠµ - ë°ì´í„° ë¶„ì„","section":"Posts","content":"Practice Data # ì„œìš¸ì‹œ ë²”ì£„í˜„í™© í†µê³„ìë£Œ ë²”ì£„ë³„ë¡œ ê²€ê±°ìœ¨ ê³„ì‚° # Copy python # gu_dfëŠ” ì‹¤ìŠµ ìë£Œì— ì„œìš¸ì‹œ ê²½ì°°ì²­ì˜ ì†Œì† êµ¬ ë°ì´í„°ë¥¼ ì¶”ê°€í•œ DataFrame gu_df[\u0026#39;ê°•ê°„ê²€ê±°ìœ¨\u0026#39;] = gu_df[\u0026#39;ê°•ê°„(ê²€ê±°)\u0026#39;]/gu_df[\u0026#39;ê°•ê°„(ë°œìƒ)\u0026#39;]*100 gu_df[\u0026#39;ê°•ë„ê²€ê±°ìœ¨\u0026#39;] = gu_df[\u0026#39;ê°•ë„(ê²€ê±°)\u0026#39;]/gu_df[\u0026#39;ê°•ë„(ë°œìƒ)\u0026#39;]*100 gu_df[\u0026#39;ì‚´ì¸ê²€ê±°ìœ¨\u0026#39;] = gu_df[\u0026#39;ì‚´ì¸(ê²€ê±°)\u0026#39;]/gu_df[\u0026#39;ì‚´ì¸(ë°œìƒ)\u0026#39;]*100 gu_df[\u0026#39;ì ˆë„ê²€ê±°ìœ¨\u0026#39;] = gu_df[\u0026#39;ì ˆë„(ê²€ê±°)\u0026#39;]/gu_df[\u0026#39;ì ˆë„(ë°œìƒ)\u0026#39;]*100 gu_df[\u0026#39;í­ë ¥ê²€ê±°ìœ¨\u0026#39;] = gu_df[\u0026#39;í­ë ¥(ê²€ê±°)\u0026#39;]/gu_df[\u0026#39;í­ë ¥(ë°œìƒ)\u0026#39;]*100 gu_df[\u0026#39;ê²€ê±°ìœ¨\u0026#39;] = gu_df[\u0026#39;ì†Œê³„(ê²€ê±°)\u0026#39;]/gu_df[\u0026#39;ì†Œê³„(ë°œìƒ)\u0026#39;]*100 í•´ë‹¹ ê³„ì‚°ë²•ì˜ ë¬¸ì œ:\nì´ì „ ì—°ë„ì— ë°œìƒí•œ ì‚¬ê±´ì´ ë§ì´ ê²€ê±°ë  ê²½ìš° ê²€ê±°ìœ¨ì´ 100%ë¥¼ ì´ˆê³¼ ë°œìƒ ê±´ìˆ˜ê°€ 0ì¸ ê²½ìš° ê²€ê±°ìœ¨ì— ê²°ì¸¡ì¹˜(N/A)ê°€ ë°œìƒ ì´ˆê³¼ëœ ê²€ê±°ìœ¨ì„ ìµœëŒ“ê°’ìœ¼ë¡œ ì¡°ì •:\nCopy python # ê²€ê±°ìœ¨ì— í•´ë‹¹ë˜ëŠ” ì—´ì˜ ì§‘í•© columns columns = [\u0026#39;ê°•ê°„ê²€ê±°ìœ¨\u0026#39;, \u0026#39;ê°•ë„ê²€ê±°ìœ¨\u0026#39;, \u0026#39;ì‚´ì¸ê²€ê±°ìœ¨\u0026#39;, \u0026#39;ì ˆë„ê²€ê±°ìœ¨\u0026#39;, \u0026#39;í­ë ¥ê²€ê±°ìœ¨\u0026#39;] ëª¨ë“  í–‰ì— ëŒ€í•´ ë°˜ë³µë¬¸ ì‹¤í–‰ Copy python for row_index, row in gu_df_rate.iterrows(): for column in columns: if row[column] \u0026gt; 100: gu_df.at[row_index, column] = 100 Masking ê¸°ë²• í™œìš© Copy python gu_df[ gu_df[columns] \u0026gt; 100 ] = 100 gu_df[columns] \u0026gt; 100ì€ Trueì™€ Falseë¡œ ì´ë£¨ì–´ì§„ í–‰ë ¬ì„ ë°˜í™˜ í•´ë‹¹ í–‰ë ¬ì„ gu_dfì˜ Keyë¡œ ì‚¬ìš©í•˜ë©´ Trueì— í•´ë‹¹í•˜ëŠ” ê°’ì´ ì±„ë¡œ ì¹œë“¯ ì†ì•„ ê±¸ëŸ¬ì§ ì¡°ê±´ì´ ë‘ ê°œ ì´ìƒì¼ ê²½ìš° ê´„í˜¸ë¡œ ê°ì‹¸ì£¼ì–´ì•¼ í•¨ Pandasì—ì„œëŠ” and, or, notì´ ë™ì‘í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— \u0026amp;, |, ~ ì‚¬ìš© gu_df[ (gu_df['ì‚´ì¸(ë°œìƒ)'] \u0026gt; 7) \u0026amp; (gu_df['í­ë ¥(ë°œìƒ)'] \u0026gt; 2000) ] ê²°ì¸¡ì¹˜ë¥¼ ì˜ë¯¸ìˆëŠ” ê°’ìœ¼ë¡œ ë³€ê²½:\nCopy python gu_df[\u0026#39;ì‚´ì¸ê²€ê±°ìœ¨\u0026#39;] = gu_df[\u0026#39;ì‚´ì¸ê²€ê±°ìœ¨\u0026#39;].fillna(100) ì¸êµ¬ ë°ì´í„° Merge # Copy python # ì¸êµ¬ ë°ì´í„°ì— í•´ë‹¹í•˜ëŠ” csv íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° popul_df = pd.read_csv(\u0026#39;pop_kor.csv\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) Pandas Merge Functions # Join: A.join(B) Aì™€ Bì˜ index ì—´ì´ ë™ì¼í•´ì•¼ í•¨ Merge: pd.merge(A, B, left_on=, right_on=, how=) DataFrame Aì˜ ê¸°ì¤€ left_onê³¼ DataFrame Bì˜ ê¸°ì¤€ right_onì„ ë¹„êµ how ì˜µì…˜ì—ëŠ” inner (êµì§‘í•©), full_outer (í•©ì§‘í•©),\nleft_outer (A ê¸°ì¤€ í•©), right_outer (B ê¸°ì¤€ í•©) ê°€ëŠ¥ Concatenate: pd.concat([A, B], axis=) ë¬´ì¡°ê±´ ê°–ë‹¤ ë¶™ì´ê¸° ë•Œë¬¸ì— ì‚¬ìš©ì— ì£¼ì˜ Additional Pandas Functions # df.iterrow(): ë°˜ë³µë¬¸ì„ ì‚¬ìš©í•´ ëª¨ë“  í–‰ì„ ì°¸ì¡°í•  ë•Œ ì‚¬ìš©, (í–‰ ì´ë¦„, Series) ë°˜í™˜ df.at[]: DataFrameì—ì„œ ë‹¨ì¼ ê°’ ì¶”ì¶œ (ë‹¨ì¼ ì¸ë±ì‹±ì—ì„œ df.loc[]ë³´ë‹¤ ë¹ ë¦„) df.[].fillna(): ê²°ì¸¡ì¹˜(N/A)ë¥¼ ì˜ë¯¸ìˆëŠ” ê°’ìœ¼ë¡œ ë°”ê¿ˆ (Seriesê°€ ê°€ì§€ê³  ìˆëŠ” í•¨ìˆ˜) df[df[]].str.contains()]: íŠ¹ì • ë¬¸ìê°€ í¬í•¨ëœ í–‰ì„ í‘œì‹œ Setting Index pd.read_csv('pop_kor.csv', encoding='utf-8', index_col=) pd.read_csv('pop_kor.csv', encoding='utf-8').set_index() "},{"id":115,"href":"/blog/aischool-01-00-data-analysis/","title":"[AI SCHOOL 5ê¸°] ë°ì´í„° ë¶„ì„","section":"Posts","content":"Data Types # Structured Data Relational Database Spread Sheets Semi-structured Data System Logs Sensor Data HTML Unstructured Data Image / Video Sound Document Data Collection Tools # Logstash: ë¡œê·¸ ë°ì´í„° (SQL êµ¬ì¡°í™”) Elasticsearch: ë°ì´í„°ê°€ ììœ ë¡œì›€ Kibana: ê·¸ë˜í”„ ìë™í™” Elastic Stack, Zepplin API Meanings # ì›¹ ìƒì—ì„œì˜ API ë¼ì´ë¸ŒëŸ¬ë¦¬/í”„ë¡œê·¸ë¨ ë„êµ¬ (í…ì„œí”Œë¡œìš°ì—ì„œì˜ í•¨ìˆ˜ ë“±) Open API # ê³µìµì ì¸ ëª©ì  ì„œë¹„ìŠ¤ í™œì„±í™” ëª©ì  (ì„œë“œíŒŒí‹° ì•± ì§€ì›) SNSì—ì„œ ë¬´ë¶„ë³„í•œ í¬ë¡¤ë§ìœ¼ë¡œ ì¸í•œ ì„œë²„ ê³¼ë¶€í•˜ ëŒ€ë¹„ Missing Data Handling # ëœë¤í•˜ê²Œ ì±„ì›Œë„£ê¸° ì£¼ë³€ (í–‰ì˜) ê°’ë“¤ë¡œ ì±„ì›Œë„£ê¸° ì—´ì˜ ëŒ€í‘¯ê°’ì„ ê³„ì‹¼í•´ì„œ ì±„ì›Œë„£ê¸° (mea, median) ì „ì²´ í–‰ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ë‚¸ í›„ ê·¸ë£¹ ë‚´ í•´ë‹¹ ì—´ì˜ ê°’ì„ ì˜ˆì¸¡í•´ ì±„ì›Œë„£ê¸° ë‚˜ë¨¸ì§€ ì—´ë“¤ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ëª¨ë¸ì„ ë§Œë“  í›„ í•´ë‹¹ ì—´ì˜ ê°’ì„ ì˜ˆì¸¡í•´ ì±„ì›Œë„£ê¸° íŠ¹ì • ê¸°ì¤€ ë¹„ìœ¨ ì´ìƒìœ¼ë¡œ ë¹ ì ¸ìˆì„ ì‹œ í•´ë‹¹ ì—´ ì‚­ì œ Pandas Functions # Referring # df = pd.read_excel(): ì—‘ì…€ íŒŒì¼ ì—´ê¸° (ì—‘ì…€ íŒŒì¼ ì›ë³¸ì€ í–‰ê³¼ ì—´ë¡œ êµ¬ì„±ëœ pandas.DataFrame() íƒ€ì…) df.head(): ìœ„ì—ì„œë¶€í„° ê°’ì„ ì°¸ì¡° (default 5) df.tail(): ë°‘ì—ì„œë¶€í„° ê°’ì„ ì°¸ì¡° (default 5) df.describe(): ê¸°ìˆ  í†µê³„ëŸ‰ ë°˜í™˜ (í‰ê· , ìµœì†Ÿê°’ ë“±) df.info(): DataFrame ì •ë³´ ë°˜í™˜ (Non-Null í–‰ì—ì„œ ìœ íš¨ì„± í™•ì¸) df.loc[row]: DataFrameì—ì„œ í–‰ êº¼ë‚´ê¸° (ì¶”ê°€ë¡œ columnë„ ì§€ì • ê°€ëŠ¥) df.iloc[row]: DataFrameì—ì„œ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í–‰ êº¼ë‚´ê¸° df[column]: DataFrameì—ì„œ ì—´ êº¼ë‚´ê¸° df[column].apply(lambda x: x+1): íŠ¹ì • ì—´ì— ì†í•œ ê°’ì— 1ì”© ë”í•´ì„œ ë°˜í™˜ Modifiying # df.drop([row]): DataFrameì—ì„œ í–‰ ì‚­ì œ del df[column]: DataFrameì—ì„œ ì—´ ì‚­ì œ df.rename(columns=, inplace=True):\nDataFrameì—ì„œ ì—´ ì´ë¦„ ë°”ê¾¸ê¸° (inplace ì˜µì…˜ì€ ë®ì–´ì“°ê¸°ë¥¼ ì˜ë¯¸) df.sort_values(by=, inplace=True):\nDataFrameì—ì„œ ì—´ ë‚´ë¶€ì˜ ê°’ì„ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ ì‹œ ascending=False ì˜µì…˜ ì¶”ê°€) pd.pivot_table(df, index=, aggfunc=np.mean):\nê¸°ì¡´ DataFrameì—ì„œ íŠ¹ì • í–‰ì„ indexë¡œ ì„¤ì •í•œ ìƒˆë¡œìš´ DataFrame ìƒì„± (í”¼ë²— í…Œì´ë¸”) aggfunc ì˜µì…˜ì— ê³„ì‚°ì‹ì„ ë„£ì„ ìˆ˜ ìˆìŒ (count, np.sum ë“±) Copying # df_2 = df: ì–•ì€ ë³µì‚¬ (ì›ë³¸ ë³€ê²½ ì‹œ ë³µì‚¬ë³¸ë„ ê°™ì´ ë³€ê²½) df_3 = df.copy(): ê¹Šì€ ë³µì‚¬ (ì›ë³¸ ë³€ê²½ì´ ë³µì‚¬ë³¸ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŒ) "},{"id":116,"href":"/blog/boj-problems-4949/","title":"[ë°±ì¤€ 4949] ê· í˜•ì¡íŒ ì„¸ìƒ (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/4949 ê°œìš” # ìŠ¤íƒì„ ì´ìš©í•˜ì—¬ í’€ ìˆ˜ ìˆëŠ” ë¬¸ì œì´ë‹¤. ë¬¸ìì—´ ì²˜ë¦¬ì— ê´€í•œ ëŠ¥ë ¥ì´ ì¶”ê°€ë¡œ ìš”êµ¬ëœë‹¤. ìµœëŒ€ ì…ë ¥ í¬ê¸°ê°€ ì •í•´ì§€ì§€ ì•Šì•˜ê¸°ì— ì‹œê°„ ë³µì¡ë„ëŠ” ë¬´ì‹œí•œë‹¤. ë¬¸ì œ í•´ì„¤ # í•´ë‹¹ ë¬¸ì œì—ì„œ ê³ ë ¤í•´ì•¼í•  ë¬¸ìëŠ” ì¢…ë£Œ ì¡°ê±´ì¸ ì (\u0026rsquo;.\u0026rsquo;)ì„ ì œì™¸í•˜ë©´ ì†Œê´„í˜¸ì™€ ëŒ€ê´„í˜¸ ë¿ì´ë‹¤. ê· í˜•ì¡íŒ ë¬¸ì¥ì˜ êµ¬ë¶„ ì—¬ë¶€ëŠ” 1. ë‹«íŒ ê´„í˜¸ê°€ ì—´ë¦° ê´„í˜¸ë³´ë‹¤ ì•ì— ë‚˜ì˜¨ ê²½ìš° 2. ì—´ë¦° ê´„í˜¸ê°€ ì•ˆ ë‹«íŒ ê²½ìš°ë¡œ íŒë‹¨í–ˆë‹¤. ë¬¸ì í•˜ë‚˜í•˜ë‚˜ë§ˆë‹¤ í™•ì¸í•˜ë©° ê´„í˜¸ë¥¼ ê³¨ë¼ë‚¼ ìˆ˜ë„ ìˆì§€ë§Œ ì´ë²ˆì—” ì •ê·œì‹ì„ ì‚¬ìš©í•´ë³¸ë‹¤. ìš°ì„  ì •ê·œì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ reì— ì†í•œ sub ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ ê´„í˜¸ë¥¼ ì œì™¸í•œ ëª¨ë“  ë¬¸ìë¥¼ ì œê±°í•œë‹¤. ë‚˜ë¨¸ì§€ ë¬¸ìì— ëŒ€í•´ forë¬¸ì„ ëŒë ¤ ì—´ë¦° ê´„í˜¸ë©´ ìŠ¤íƒì— ì¶”ê°€, ë‹«íŒ ê´„í˜¸ë©´ ìŠ¤íƒì— ë‚¨ì€ ê°’ì„ ëº€ë‹¤. ë‹¨, ë‹«íŒ ê´„í˜¸ì˜ ê²½ìš° ìŠ¤íƒì— ì—´ë¦° ê´„í˜¸ê°€ ì—†ê±°ë‚˜ ìŠ¤íƒ ë§¨ ìœ„ì˜ ê°’ì´ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ê´„í˜¸ë©´ ê· í˜•ì´ ê¹¨ì¡Œë‹¤ íŒë‹¨í•œë‹¤. ì½”ë“œì˜ ì¤‘ë³µì„ ë°œìƒì‹œí‚¤ì§€ ì•Šê¸° ìœ„í•´ ê· í˜•ì´ ê¹¨ì§„ ê²½ìš°ë¥¼ IndexErrorì˜ ë°œìƒìœ¼ë¡œ í†µì¼í•˜ê³ \nì´ ë•Œ ì¡°ê±´ ë³€ìˆ˜ë¥¼ ì¬ì„¤ì •í•˜ê³  ë°˜ë³µë¬¸ì„ ì¤‘ì§€ì‹œí‚¨ë‹¤. ë°˜ë³µë¬¸ì´ ì¢…ë£Œëœ í›„ ìŠ¤íƒê³¼ ì¡°ê±´ ë³€ìˆ˜ì— ëŒ€í•œ NAND ê²°ê³¼ë¥¼ í†µí•´ ê· í˜•ì¡íŒ ë¬¸ì¥ì˜ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì—¬ ê²°ê³¼ë¥¼ ì¶œë ¥í•œë‹¤. í•´ì„¤ ì½”ë“œ # Copy python import re match = {\u0026#39;)\u0026#39;: \u0026#39;(\u0026#39;, \u0026#39;]\u0026#39;: \u0026#39;[\u0026#39;} while True: balanced_stack = [] unbalanced = False sentence = input() if sentence == \u0026#39;.\u0026#39;: break sentence = re.sub(\u0026#39;[^\\(\\)\\[\\]]+\u0026#39;, \u0026#39;\u0026#39;, sentence) for bracket in sentence: if bracket in {\u0026#39;(\u0026#39;, \u0026#39;[\u0026#39;}: balanced_stack.append(bracket) else: try: if balanced_stack[-1] == match[bracket]: balanced_stack.pop() else: raise IndexError except IndexError: unbalanced = True break if not(balanced_stack or unbalanced): print(\u0026#39;yes\u0026#39;) else: print(\u0026#39;no\u0026#39;) "},{"id":117,"href":"/blog/boj-problems-2164/","title":"[ë°±ì¤€ 2164] ì¹´ë“œ2 (Python)","section":"Posts","content":"ë¬¸ì œ ë§í¬ # https://www.acmicpc.net/problem/2164 ê°œìš” # íë¥¼ ì´ìš©í•˜ì—¬ í’€ ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ë¬¸ì œì´ë‹¤. ì–‘ìª½ì—ì„œ ë°ì´í„°ë¥¼ ë¹¼ê³  ì§‘ì–´ë„£ëŠ” ì‘ì—…ì´ ìš”êµ¬ë˜ê¸° ë•Œë¬¸ì— dequeì˜ ì‚¬ìš©ì„ ê¶Œì¥í•œë‹¤. 1ë²ˆ ì¹´ë“œì˜ ìœ„ì¹˜ë¥¼ ì•ìœ¼ë¡œ í•˜ëƒ ë’¤ë¡œ í•˜ëƒëŠ” í¬ê²Œ ìƒê´€ì—†ê¸° ë•Œë¬¸ì— ì•ì—ì„œë¶€í„° ì •ì˜í•˜ê² ë‹¤. ë¬¸ì œ í•´ì„¤ # ë¬¸ì œì—ì„œ ì œì‹œëœ í–‰ë™ì€ 1. ì œì¼ ìœ„ì˜ ì¹´ë“œë¥¼ ë²„ë¦°ë‹¤ 2. ì œì¼ ìœ„ì— ë‚¨ì€ ì¹´ë“œë¥¼ ì œì¼ ì•„ë˜ë¡œ ì˜®ê¸´ë‹¤ ì´ë‹¤. í•´ë‹¹ í–‰ë™ì„ ì¹´ë“œê°€ í•œ ì¥ì´ ë‚¨ì„ ë•Œê¹Œì§€ ë¬´í•œíˆ ë°˜ë³µí•˜ë©´ ëœë‹¤. 1ë²ˆ í–‰ë™ì„ í•˜ê¸° ìœ„í•´ì„  1ë²ˆ ì¹´ë“œë¥¼ íì˜ ë§¨ ì•ìœ¼ë¡œ ì •í–ˆê¸°ì— íì˜ ì™¼ìª½ì—ì„œ ê°’ì„ ë¹¼ë‚´ë©´ ëœë‹¤. íì˜ ì™¼ìª½ì—ì„œ ê°’ì„ ë¹¼ë‚´ê¸° ìœ„í•´ popleft() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤. 2ë²ˆ í–‰ë™ì€ ë§ˆì°¬ê°€ì§€ë¡œ íì˜ ì™¼ìª½ì—ì„œ ê°’ì„ ë¹¼ë‚´ê³ , ì¶”ê°€ë¡œ ë¹¼ë‚¸ ê°’ì„ ë§¨ ë’¤ì— ì¶”ê°€í•œë‹¤. íì˜ ì™¼ìª½ì—ì„œ ë¹¼ë‚¸ ê°’ì„ ë‹¤ì‹œ ë„£ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— append() ì•ˆì— popleft()ë¥¼ ë„£ì–´ì¤€ë‹¤. ë‘ ê°€ì§€ ë™ì‘ì„ whileë¬¸ ì•ˆì— ë„£ê³  ì¹´ë“œê°€ 1ê°œë³´ë‹¤ ë§ì´ ë‚¨ìœ¼ë©´ ë°˜ë³µí•˜ë„ë¡ ì¡°ê±´ì„ ì„¤ì •í•œë‹¤. whileë¬¸ì´ ì¢…ë£Œëœ í›„ í•˜ë‚˜ì˜ ê°’ì´ ë‚¨ì•„ìˆëŠ” íì—ì„œ pop()ì„ ì‚¬ìš©í•´ ë§ˆì§€ë§‰ ë‚¨ì€ ì¹´ë“œë¥¼ ì¶œë ¥í•œë‹¤. ì‹œê°„ ë³µì¡ë„ # ë¬¸ì œì—ì„œ ì£¼ì–´ì§„ ì‹œê°„ì€ 2ì´ˆë‹¤. ê°€ì¥ ë‹¨ìˆœí•˜ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ íë¥¼ êµ¬í˜„í•  ê²½ìš° del() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ê°’ì„ ì‚­ì œí•´ì•¼ í•  ê²ƒì´ê³ \nì´ë¥¼ Në²ˆ ë§Œí¼ ë°˜ë³µí•  ê²ƒì´ë¯€ë¡œ ì´ ë•Œì˜ ì‹œê°„ ë³µì¡ë„ëŠ” O(N^2)ë¥¼ ì´ˆê³¼í•œë‹¤. Nì˜ ìµœëŒ“ê°’ì´ 500,000ì´ë¯€ë¡œ ëŒ€ì¶© ì–´ë¦¼ì¡ì•„ë„ ì—°ì‚° íšŸìˆ˜ê°€ 2ì–µì„ í›Œì© ì´ˆê³¼í•œë‹¤. ë°˜ë©´, dequeë¡œ íë¥¼ êµ¬í˜„í•œ í•´ì„¤ì˜ ê²½ìš° ì‹œê°„ ë³µì¡ë„ê°€ O(1)ì¸ popleft()ë¥¼\nNë²ˆ ë§Œí¼ ë°˜ë³µí•˜ê¸° ë•Œë¬¸ì— O(N)ì˜ ì‹œê°„ ë³µì¡ë„ë¥¼ ê°€ì§„ë‹¤. ì´ëŠ” ì œí•œ ì‹œê°„ ë‚´ì— ì¶©ë¶„íˆ ìˆ˜í–‰í•˜ê³ ë„ ì—¬ìœ ê°€ ë‚¨ì„ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. í•´ì„¤ ì½”ë“œ # Copy python from collections import deque N = int(input()) cards = deque([i for i in range(1, N+1)]) while len(cards) \u0026gt; 1: cards.popleft() cards.append(cards.popleft()) print(cards.pop()) "},{"id":118,"href":"/blog/big-o-list/","title":"Big-O List","section":"Posts","content":"List # Operation Example Big-O Index l[i] O(1) Store l[i] = 0 O(1) Length len(l) O(1) Append l.append(x) O(1) Pop l.pop() O(1) Slice l[a:b] O(b-a) Construction list(x) O(len(x)) Check l1 == l2 O(len(n)) Insert l[a:b] = x O(n) Containment x in l O(n) Copy l.copy() O(n) Remove l.remove() O(n) Count l.count(x) O(n) Index l.index(x) O(n) Pop l.pop(i) O(n) Extreme value min(l)/max(l) O(n) Iteration for v in l: O(n) Reverse l.reverse() O(n) Sort l.sort() O(n Log n) Multiply k * l O(k n) Set # Operation Example Big-O Length len(s) O(1) Add s.add(x) O(1) Containment x in s O(1) Remove s.remove() O(1) Pop s.pop() O(1) Construction set(x) O(len(x)) Check s1 == s2 O(len(s)) Union s + t O(len(s)+len(t)) Intersection s \u0026amp; t O(len(s)+len(t)) Difference s - t O(len(s)+len(t)) Symmetric Diff s ^ t O(len(s)+len(t)) Iteration for v in s: O(n) Copy s.copy() O(n) Dictionary # Operation Example Big-O Index d[k] O(1) Store d[k] = v O(1) Length len(d) O(1) Pop d.pop() O(1) View d.keys() O(1) Construction dict(x) O(len(x)) Iteration for k in d: O(n) Sort # Method Best Average Worst Insertion Sort O(n) O(n^2) O(n^2) Selection Sort O(n^2) O(n^2) O(n^2) Bubble Sort O(n^2) O(n^2) O(n^2) Shell Sort O(n) O(n^1.5) O(n^1.5) Quick Sort O(n log n) O(n log n) O(n^2) Heap Sort O(n log n) O(n log n) O(n log n) Merge Sort O(n log n) O(n log n) O(n log n) Radix Sort O(dn) O(dn) O(dn) Search # Method Search Insert Delete Sequential O(n) O(1) O(n) Binary O(log n) O(log n + n) O(log n + n) Binary Search Tree (Balanced) O(log n) O(log n) O(log n) Binary Search Tree (Left-Associative) O(n) O(n) O(n) Hashing (Best) O(1) O(1) O(1) Hashing (Worst) O(n) O(n) O(n) Heap # Operation Example Big-O Push heapq.heappush(heap, x) O(log n) Pop heapq.heappop(heap) O(log n) Construction heapq.heapify(heap) O(n) DFS/BFS # Nì€ ë…¸ë“œ, EëŠ” ê°„ì„ ì¼ ë•Œ\nì¸ì ‘ ë¦¬ìŠ¤íŠ¸: O(N+E) ì¸ì ‘ í–‰ë ¬: O(N^2) "},{"id":119,"href":"/blog/aischool-00-02-python-advanced/","title":"[ì½”ë“œë¼ì´ì–¸] íŒŒì´ì¬ ì‹¬í™”","section":"Posts","content":"Crawling # í¬ë¡¤ëŸ¬ëŠ” ì›¹ í˜ì´ì§€ì˜ ë°ì´í„°ë¥¼ ëª¨ì•„ì£¼ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ í¬ë¡¤ë§ì€ í¬ë¡¤ëŸ¬ë¥¼ ì‚¬ìš©í•´ ì›¹ í˜ì´ì§€ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ë‚´ëŠ” í–‰ìœ„ Request # request ëª¨ë“ˆì˜ get() í•¨ìˆ˜ëŠ” ì„œë²„ì—ê²Œ html ì •ë³´ë¥¼ ìš”ì²­ get() í•¨ìˆ˜ëŠ” url, íŒŒë¼ë¯¸í„° ê°’ì„ ë°›ê³  request.Responseë¥¼ ë°˜í™˜ ì •ìƒì ì¸ ì‘ë‹µì„ ë°›ì„ ê²½ìš° Response [200] ë°˜í™˜ ì‘ë‹µê°’ì„ reponse ë³€ìˆ˜ì— ë„£ê³  response.textë¥¼ ì¶œë ¥í•˜ë©´ html ì½”ë“œ ì¶œë ¥ BeautifulSoup # bs4 ëª¨ë“ˆì˜ BeautifulSoup ê¸°ëŠ¥ì€ ì…ë ¥ê°’ì„ ì˜ë¯¸ìˆëŠ” ë°ì´í„°ë¡œ ë³€í™˜ Copy python soup = BeautifulSoup(response.text, \u0026#39;html.parser\u0026#39;) soup.title # html ì½”ë“œì—ì„œ titleì— í•´ë‹¹í•˜ëŠ” íƒœê·¸ë¥¼ ë°˜í™˜ soup.title.string # title íƒœê·¸ì—ì„œ ë¬¸ìì—´ ê°’ë§Œ ë½‘ì•„ ë°˜í™˜ soup.findAll(\u0026#39;span\u0026#39;) # ëª¨ë“  span íƒœê·¸ë¥¼ ë°˜í™˜ soup.findAll(\u0026#39;a\u0026#39;, \u0026#39;link_favorsch\u0026#39;) # link_favorsch í´ë˜ìŠ¤ë§Œ ë°˜í™˜ Copy python results = soup.findAll(\u0026#39;a\u0026#39;, \u0026#39;link_favorsch\u0026#39;) result.get_text() # resultì—ì„œ íƒœê·¸ë¥¼ ì œì™¸í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜ File # open(file, mode): íŒŒì¼ì„ ìƒì„±, ì°¸ì¡°, ìˆ˜ì •í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ modeì—ëŠ” r (read), w (write), a (append)ê°€ ìˆìŒ Copy python file = open(\u0026#34;rankresult.txt\u0026#34;, \u0026#34;w\u0026#34;) file.write(result.get_text()+\u0026#34;\\n\u0026#34;) Copy python file = open(\u0026#34;rankresult.txt\u0026#34;, \u0026#34;a\u0026#34;) file.write(result.get_text()+\u0026#34;\\n\u0026#34;) API # APIëŠ” ëˆ„êµ°ê°€ê°€ ë§Œë“  í”„ë¡œê·¸ë¨ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•  ë•Œ í•„ìš”í•œ ì¸í„°í˜ì´ìŠ¤ API KeyëŠ” APIë¥¼ ëˆ„ê°€ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ìˆëŠ” í‚¤ OpenWeatherMap API # Current Weather Data API ì‚¬ìš© https://api.openweathermap.org/data/2.5/weather?q={city name}\u0026amp;appid={API key} f-stringì„ ì´ìš©í•˜ì—¬ city nameê³¼ API Keyë¥¼ ë³€ìˆ˜ë¡œ ì„¤ì • requests.get(api)ë¡œ API ìš”ì²­ API íŒŒë¼ë¯¸í„°ì— langì„ krë¡œ ì¶”ê°€í•˜ì—¬ ë°˜í™˜ê°’ì„ í•œêµ­ì–´ë¡œ ë³€ê²½ API íŒŒë¼ë¯¸í„°ì— unitsë¥¼ metricìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ì˜¨ë„ ë‹¨ìœ„ë¥´ ì„­ì”¨ë¡œ ë³€ê²½ JSON # ìë°”ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜¤ë¸Œì íŠ¸ì— ë”°ë¥´ëŠ” ë¬¸ì ê¸°ë°˜ ë°ì´í„° í¬ë§· json.loads(str)ë¡œ ë¬¸ìì—´ì„ JSON (ë”•ì…”ë„ˆë¦¬ íƒ€ì…)ìœ¼ë¡œ ë³€ê²½ Translator # googletrans: ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­ì„ ë„ì™€ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ googletransì˜ Translatorë¥¼ importí•˜ê³  Translator()ë¡œ Translator ìƒì„± Copy python \u0026gt;\u0026gt;\u0026gt; translator.detect(sentence) # ë¬¸ì¥ì— ëŒ€í•œ ì–¸ì–´ ê°ì§€ ê²°ê³¼ë¥¼ ë°˜í™˜ \u0026gt;\u0026gt;\u0026gt; Detected(lang=ko, confidence=1.0) \u0026gt;\u0026gt;\u0026gt; translator.translate(sentence, \u0026#39;en\u0026#39;) # ë¬¸ì¥ì— ëŒ€í•œ ë³€ì—­ ê²°ê³¼ë¥¼ ë°˜í™˜ \u0026gt;\u0026gt;\u0026gt; Translated(src=ko, dest=en, text=Hello, ... Mail # IMAP # ë‹¤ë¥¸ ë©”ì¼ ì„œë²„ì—ì„œ ë³´ë‚¸ ë©”ì¼ì„ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë³´ë‚´ê¸° ìœ„í•œ í”„ë¡œí† ì½œ SMTP # ê°„ë‹¨í•˜ê²Œ ë©”ì¼ì„ ë³´ë‚´ê¸° ìœ„í•œ í”„ë¡œí† ì½œ SMTP ë©”ì¼ ì„œë²„ë¥¼ ì—°ê²°í•œë‹¤. (smtp.gmail.com:465) Copy python smtp = smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) SMTP ë©”ì¼ ì„œë²„ì— ë¡œê·¸ì¸í•œë‹¤. Copy python smtp.login(\u0026#39;MAIL_ADDRESS\u0026#39;, \u0026#39;PASSWORD\u0026#39;) SMTP ë©”ì¼ ì„œë²„ì— ë©”ì¼ì„ ë³´ë‚´ê³  ì—°ê²°ì„ ëŠëŠ”ë‹¤. Copy python smtp.send_message() smtp.quit() MIME # ì „ììš°í¸ì„ ìœ„í•œ ì¸í„°ë„· í‘œì¤€ í¬ë§· email.message ëª¨ë“ˆì˜ .EmailMessageê¸°ëŠ¥ ì‚¬ìš© MIMEì˜ Headerì—ëŠ” Subject, To ë“±ì´ ì¡´ì¬ ì´ë©”ì¼ì„ ë§Œë“ ë‹¤. Copy python message = EmailMessage() ì´ë©”ì¼ì— ë‚´ìš©ì„ ë‹´ëŠ”ë‹¤. Copy python message.set_content(\u0026#39;content\u0026#39;) ë°œì‹ ì, ìˆ˜ì‹ ìë¥¼ ì„¤ì •í•œë‹¤. Copy python message[\u0026#39;Subject\u0026#39;] = \u0026#39;subject\u0026#39; message[\u0026#39;from\u0026#39;] = \u0026#39;user1@gmail.com\u0026#39; message[\u0026#39;To\u0026#39;] = \u0026#39;user2@gmail.com Attach Image # Read Image Copy python with open(\u0026#39;codelion.png\u0026#39;,\u0026#39;rb\u0026#39;) as image: image_file = image.read() Attach Image Copy python # ì´ë¯¸ì§€ íŒŒì¼ ì²¨ë¶€ (ë©”ì¼ í˜•ì‹ì´ mixedë¡œ ë°”ë€œ) add_attachment(image, maintype=\u0026#39;image\u0026#39;, subtype=\u0026#39;png\u0026#39;) ì´ë¯¸ì§€ íŒŒì¼ì˜ í™•ì¥ìë¥¼ íŒë‹¨ Copy python imghdr.what(\u0026#39;filename\u0026#39;, image) Validation # ì •ê·œí‘œí˜„ì‹\n^â‘ [a-zA-Z0-9.+_-]+@â‘¡[a-zA-Z0-9]+â‘¢\\.[a-zA-z]{2,3}$\nâ‘  [aë¶€í„° zê¹Œì§€, Aë¶€í„° Zê¹Œì§€, 0ë¶€í„° 9ê¹Œì§€, . , + , _ , -] | +: 1íšŒ ì´ìƒ ë°˜ë³µ\nâ‘¡ @ | [aë¶€í„° zê¹Œì§€, Aë¶€í„° Zê¹Œì§€, 0ë¶€í„° 9ê¹Œì§€] | +: 1íšŒ ì´ìƒ ë°˜ë³µ\nâ‘¢ . (ê°œí–‰ë¬¸ì ) | [aë¶€í„° zê¹Œì§€, Aë¶€í„° Zê¹Œì§€] | {2,3}: ìµœì†Œ 2íšŒ, ìµœëŒ€ 3ë²ˆ ë°˜ë³µ Copy python re.match(reg, \u0026#39;example@gmail.com\u0026#39;) ì í•©í•˜ì§€ ì•Šì€ ì´ë©”ì¼ í˜•ì‹ì¼ ê²½ìš° Noneì„ ë°˜í™˜ ifë¬¸ì„ ì‚¬ìš©í•´ Noneì´ ì•„ë‹ˆë©´ ë©”ì¼ì„ ë³´ë‚´ë„ë¡ ì„¤ì • Others # í•¨ìˆ˜: ì…ë ¥í•œ ê°’ì„ ì‚¬ìš©í•´ ê²°ê³¼ë¬¼ì„ ë§Œë“¤ì–´ ë°˜í™˜í•˜ëŠ” ì¡°ë¦½ê¸° ëª¨ë“ˆ: í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ íŒŒì¼ type(): ê°ì²´ì˜ íƒ€ì…ì„ ë°˜í™˜ datetime.today().strftime(\u0026quot;%Yë…„ %mì›” %dì¼\u0026quot;): ì˜¤ëŠ˜ì˜ ë‚ ì§œ ë°˜í™˜ ë¡œë´‡ì´ ì•„ë‹˜ì„ ì•Œë¦¬ëŠ” í—¤ë”\nCopy python headers = {\u0026#39;User-Agent\u0026#39;:\u0026#39;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\u0026#39;} "},{"id":120,"href":"/blog/aischool-00-01-python-basic/","title":"[ì½”ë“œë¼ì´ì–¸] íŒŒì´ì¬ ê¸°ì´ˆ","section":"Posts","content":"forë¬¸ # ë¬¸ì¥ì„ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•  ë–„ ë³µì‚¬ ë¶™ì—¬ë„£ê¸°ë¡œ ê¸¸ê²Œ ëŠ˜ì´ì§€ ì•Šê³  ë‹¨ìˆœí•˜ê²Œ í‘œí˜„í•˜ê¸° ìœ„í•œ êµ¬ë¬¸ forë¬¸ì— ì ìš©ë˜ëŠ” ë¬¸ì¥ì€ ë“¤ì—¬ì“°ê¸°ë¥¼ í•´ì•¼ í•¨ Copy python for _ in range(30): print(random.choice([\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;])) whileë¬¸ # forë¬¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ë¬¸ì¥ì„ ë°˜ë³µì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ë¬¸ ì¡°ê±´ì„ ì¶©ì¡±í•  ê²½ìš° ë°˜ë³µì„ ë©ˆì¶¤ Trueë¥¼ ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš© ì‹œ ë¬´í•œë£¨í”„ ë°œìƒ while True: break ëª…ë ¹ì–´ë¥¼ í†µí•´ ë°˜ë³µë¬¸ ì¢…ë£Œ ê°€ëŠ¥ ë³€ìˆ˜ # ê°ì²´ì— ì´ë¦„í‘œë¥¼ ë¶™ì´ê³  ì´ë¦„í‘œê°€ ë¶ˆë¦¬ë©´ ë‚´ìš©ë¬¼ì¸ ê°ì²´ë¥¼ ë°˜í™˜\nlunch = random.choice([\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;]) ë”•ì…”ë„ˆë¦¬ # \u0026ldquo;xxì€ xxì´ë‹¤\u0026quot;ë¥¼ ì½”ë“œë¡œ í‘œí˜„í•œ ìë£Œêµ¬ì¡° ë”•ì…”ë„ˆë¦¬ì˜ get ëª…ë ¹ì–´ëŠ” Keyì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ë°˜í™˜ ê°’ì„ ì¶”ê°€í•  ë•ŒëŠ” dict[a] = b í˜•ì‹ìœ¼ë¡œ ì¶”ê°€ ë”•ì…”ë„ˆë¦¬ì˜ clear ëª…ë ¹ì–´ëŠ” ë”•ì…”ë„ˆë¦¬ ë‚´ìš©ì„ ì´ˆê¸°í™” ì§‘í•© # ì¤‘ë³µëœ ê°’ì„ ì œê±°í•˜ì—¬ í‘œí˜„í•˜ëŠ” ìë£Œêµ¬ì¡° set()ìœ¼ë¡œ ì§‘í•© ìƒì„± í•©ì§‘í•©: set1 | set2 êµì§‘í•©: set1 \u0026amp; set2 ì°¨ì§‘í•©: set1 - set2 ì¡°ê±´ë¬¸ # ìƒí™©ì— ë”°ë¥¸ ì²˜ë¦¬ë¥¼ í•˜ê¸° ìœ„í•œ êµ¬ë¬¸ if ì¡°ê±´:ìœ¼ë¡œ ì¡°ê±´ë¬¸ ì„ ì–¸ ê°™ì€ ê²½ìš°ë¥¼ êµ¬í•  ë• a == b ë‚˜ë¨¸ì§€ ê²½ìš°ì— ëŒ€í•´ì„œëŠ” else ì‚¬ìš© pip/conda # pip: íŒŒì´ì¬ì—ì„œ ì§€ì›ë°›ëŠ” íŒ¨í‚¤ì§€ë§Œì„ ê°€ì ¸ì˜´ (ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ë§ìœ¼ë©´ ì„¤ì¹˜) conda: ì•„ë‚˜ì½˜ë‹¤ì—ì„œ ì§€ì›ë°›ëŠ” íŒ¨í‚¤ì§€ë§Œì„ ê°€ì ¸ì˜´ (ì•„ë‚˜ì½˜ë‹¤ì—ì„œ ìœ ë¦¬) condaì˜ ì¥ì : ê¸°ì¡´ Python ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ì¶©ëŒì„ ì²´í¬í•¨ condaì˜ ë‹¨ì : ì„¤ì¹˜ ì†ë„ê°€ ë„ˆë¬´ ëŠë¦¼ ì„¤ì¹˜ê°€ ë„ˆë¬´ ëŠë¦¬ê±°ë‚˜ ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ ì˜í–¥ì´ ì—†ì„ ê²½ìš° pip ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì°¸ì¡° íŒŒì¼ ìƒì„± ì‹œ pip install -r requirements.txt ê¸°íƒ€ ëª…ë ¹ì–´ # random.choice(): ë¦¬ìŠ¤íŠ¸ ì•ˆì—ì„œ ëœë¤í•œ ê°ì²´ í•˜ë‚˜ë¥¼ ë°˜í™˜ time.sleep(): ì…ë ¥ê°’ë§Œí¼ì˜ ì‹œê°„(ì´ˆ) ë™ì•ˆ ë”œë ˆì´ ë°œìƒ len(): ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ì˜ ëª©ë¡ ê°œìˆ˜ ë°˜í™˜ "},{"id":121,"href":"/blog/ai-school-00-00-start/","title":"[AI SCHOOL 5ê¸°] ì²« ì£¼ì°¨","section":"Posts","content":"AI SCHOOL ì§€ì› ê³¼ì • # ì•„ì§ êµ°ì— ë³µë¬´ ì¤‘ì´ë˜ ì‹œì ˆ, ì „ì—­í•œ í›„ ë°”ë¡œ ì·¨ì—…í•˜ê¸° ìœ„í•´ êµ­ë¹„, ë¶€íŠ¸ìº í”„ ê³¼ì •ì„ íƒìƒ‰í•˜ë˜ ì¤‘ AI SCHOOLì„ ë°œê²¬í–ˆë‹¤. ì´ë–„ ê°œì¸ì ìœ¼ë¡œ ê°€ê²© ë¹„êµ, ì‚¬ìš©ì ë§ì¶¤ ì¶”ì²œ ë“±ì˜ ê¸°ëŠ¥ì„ í¬í•¨í•œ ì„œë¹„ìŠ¤ë¥¼ êµ¬ìƒí•˜ê³  ìˆì—ˆëŠ”ë° AI ê¸°ìˆ ì´ ë°”ë¡œ ê·¸ê²ƒì´ì—ˆë‹¤. AI SCHOOLê³¼ í•¨ê»˜ ëˆˆì— ë“¤ì—ˆë˜ ê²Œ SWë§ˆì—ìŠ¤íŠ¸ë¡œì˜€ì§€ë§Œ 5ì›”ê¹Œì§€ëŠ” êµ°ì¸ ì‹ ë¶„ì¸ ë‚˜ì™€ëŠ” ë§ì§€ ì•Šì•„ ì•„ì‰½ê²Œ í¬ê¸°í–ˆë‹¤. AI SCHOOLì˜ ì§€ì› ê³¼ì •ì€ ì„œë¥˜(ìê¸°ì†Œê°œì„œ)ì™€ ê³¼ì œ(ì˜ìƒ) ìˆœìœ¼ë¡œ ì§„í–‰ë˜ì—ˆë‹¤. ì˜ìƒì„ ì°ì–´ì•¼ í•  ë•Œ ì•„ì§ êµ°ëŒ€ ì•ˆì— ìˆì—ˆê¸°ì— ì–´ë ¤ì› ì§€ë§Œ ëª¨ì¢…ì˜ ë°©ë²•ìœ¼ë¡œ ì´¬ì˜ì— ì„±ê³µí–ˆë‹¤. ì´ë•Œ ì²˜ìŒìœ¼ë¡œ ì˜ìƒ í¸ì§‘ í”„ë¡œê·¸ë¨ ì¤‘ ë‹¤ë¹ˆì¹˜ ë¦¬ì¡¸ë¸Œë¥¼ ì‚¬ìš©í–ˆëŠ”ë° ê½¤ ì¬ë¯¸ìˆì—ˆë‹¤. ë‹¤í–‰íˆ AI SCHOOLì— í•©ê²©í–ˆê³  ì¡°ê¸°ì „ì—­ í›„ ê³§ë°”ë¡œ ë°ìŠ¤í¬ ì„¸íŒ…ì— ë“¤ì–´ê°”ë‹¤. ì²« ì£¼ì°¨ ì˜¨ë¼ì¸ ê°•ì˜ # AI SCHOOL ì²« ë‚ ì— ì˜¤ë¦¬ì—”í…Œì´ì…˜ì„ ì§„í–‰í•˜ê³  ì´ ë‚ ì„ í¬í•¨í•œ 4ì¼ ë™ì•ˆ ì˜¨ë¼ì¸ ê°•ì˜ë¥¼ ìˆ˜ê°•í–ˆë‹¤. ì¼ë‹¨ ë§Œë“œëŠ” PYTHON, [ê¸°ì´ˆ] ê°™ì´ í‘¸ëŠ” PYTHON í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ê¸°ëŠ¥ì„ íŒŒì´ì¬ ê¸°ì´ˆ ë¬¸ë²•ë§Œì„ ì‚¬ìš©í•´ êµ¬í˜„í•˜ëŠ” ê°•ì˜ë‹¤. ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬, ì§‘í•© ë“±ì˜ ìë£Œêµ¬ì¡°ì™€ forë¬¸, whileë¬¸ ë“±ì˜ ë°˜ë³µë¬¸ì„ ë°°ìš¸ ìˆ˜ ìˆì—ˆë‹¤. [ì‹¬í™”] ê°™ì´ í‘¸ëŠ” PYTHON ì›¹ì„ í†µí•´ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ íŒŒì´ì¬ì„ í†µí•´ êµ¬í˜„í•˜ëŠ” ê°•ì˜ë‹¤. í•¨ìˆ˜ë‚˜ í´ë˜ìŠ¤ ë“±ì„ ë°°ìš°ì§€ ì•Šê³  ë°”ë¡œ ë„˜ì–´ê°€ëŠ” ëŠë‚Œì€ ìˆì—ˆì§€ë§Œ ì†ë„ê° ìˆì–´ì„œ ì¢‹ì•˜ë‹¤. í¬ë¡¤ë§, API, êµ¬ê¸€ ë²ˆì—­ê¸°, ë©”ì¼ ì „ì†¡ ë“±ì˜ ê¸°ìˆ ì„ ë‹¤ë¤˜ë‹¤. íŒŒì´ì¬ìœ¼ë¡œëŠ” ì•Œê³ ë¦¬ì¦˜ ë°–ì— ì•ˆí•´ë´¤ê¸°ì— ìƒˆë¡œìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë§ˆì£¼í•˜ì—¬ êµ‰ì¥íˆ ì¦ê²ê²Œ ë”°ë¼í•˜ë©´ì„œ ë°°ì› ë‹¤. ì´ë²ˆ ì£¼ëŠ” ì•„ì§ ì „ì—­ í›„ ë°ìŠ¤í¬ ë° ë¬¼ê±´ ì •ë¦¬ ë“±ìœ¼ë¡œ ë§ì´ ë°”ë¹  ì°¨ë¶„íˆ ê³µë¶€í•˜ì§€ ëª»í–ˆë˜ê²Œ ì•„ì‰¬ì› ë‹¤. ë‹¤í–‰íˆ ê¸ˆìš”ì¼ ì „ê¹Œì§€ ë°ìŠ¤í¬ ì„¸íŒ…ì€ ë§ì¶°ì„œ ì •ìƒì ìœ¼ë¡œ ì¤Œì— ì°¸ì—¬í•  ìˆ˜ ìˆì—ˆë‹¤. ì¤Œì„ í†µí•œ ì²« ë²ˆì§¸ ìˆ˜ì—…ì€ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì˜ ì‚¬ìš©ë²•ì„ ìµíˆê³  ì•ì„œ ì˜¨ë¼ì¸ ê°•ì˜ë¥¼ í†µí•´ ë°°ì› ë˜ íŒŒì´ì¬ ë¬¸ë²•ì„ ë‹¤ë“¬ì—ˆë‹¤. 1íšŒì°¨ ì±•í‹€ë¦¬ ë° íŠ¹ê°• # ì½”ë“œë¼ì´ì–¸ ì˜¨ë¼ì¸ ê°•ì˜ê°€ ëë‚œ ì‹œì ë¶€í„° 1íšŒì°¨ ì±•í‹€ë¦¬(ë„ì „ê³¼ì œ)ê°€ ì§„í–‰ë˜ì—ˆë‹¤. ë”¥ëŸ¬ë‹ì— ëŒ€í•œ ì´í•´ ì „ë¬´í•œ ë‚˜ë¡œì„œ numpy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê³¼ì œëŠ” ë§ì´ ìƒì†Œí–ˆë‹¤. ì–´ì°Œì €ì°Œ ê²€ìƒ‰í•˜ë©° í•´ê²°í•  ìˆœ ìˆì—ˆê³  ê²€ìƒ‰ ì¤‘ì— ìŠ¬ì© ë³¸ í¼ì…‰íŠ¸ë¡  ë“±ì˜ ê°œë…ì— í¥ë¯¸ê°€ ìƒê²¼ë‹¤. í† ìš”ì¼ ì˜¤í›„ì— ì±•í‹€ë¦¬ í•´ì„¤ì„ ìœ„í•œ íŠ¹ë³„ ê°•ì˜ê°€ ì§„í–‰ë˜ì—ˆë‹¤.\n(ìˆ˜ê°•ìƒë“¤ì„ ìœ„í•´ ì£¼ë§ì—ë„ ì—…ë¬´í•˜ì‹œëŠ” ë§¤ë‹ˆì €ë‹˜ë“¤ê»˜ ê°ì‚¬ë¥¼ í‘œí•©ë‹ˆë‹¤.) ì´ˆì²­ ê°•ì‚¬ ë¶„ì„ í†µí•´ ì§„í–‰ëœ íŠ¹ë³„ê°•ì˜ì—ì„œëŠ” numpy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë‹¤ë£¨ëŠ” ë²•ì— ëŒ€í•´ ë°°ì› ë‹¤. ì´ë¯¸ ê³ ìƒí•˜ë©´ì„œ ì°¾ì•„ë³¸ ë‚´ìš©ì„ ë³µìŠµí•˜ëŠ” ê¸°ë¶„ì´ì—ˆì§€ë§Œ ì œì¶œí•œ ì½”ë“œì— ë¬¸ì œê°€ ì—†ìŒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. "},{"id":122,"href":"/blog/2022-03-06/","title":"2022-03-06 Log","section":"Posts","content":"defaultdict() # collections ëª¨ë“ˆì— í¬í•¨ëœ dictì˜ ì„œë¸Œ í´ë˜ìŠ¤ dictì™€ ì‘ë™ ë°©ì‹ì€ ë™ì¼í•˜ì§€ë§Œ ì¸ìë¡œ ì£¼ì–´ì§„ ê°ì²´ì˜ ê¸°ë³¸ê°’ì„ ì´ˆê¸°ê°’ìœ¼ë¡œ ì§€ì • ê°€ëŠ¥ Copy python \u0026gt;\u0026gt;\u0026gt; int_dict = defaultdict(int) \u0026gt;\u0026gt;\u0026gt; int_dict \u0026gt;\u0026gt;\u0026gt; defaultdict(\u0026lt;class \u0026#39;int\u0026#39;\u0026gt;, {}) intë¥¼ ì¸ìë¡œ ë„£ì„ ê²½ìš° ê°’ì„ ì§€ì •í•˜ì§€ ì•Šì€ í‚¤ëŠ” ê·¸ ê°’ì´ 0ìœ¼ë¡œ ì§€ì •ë¨ Copy python \u0026gt;\u0026gt;\u0026gt; int_dict[\u0026#39;key1\u0026#39;] 0 \u0026gt;\u0026gt;\u0026gt; int_dict defaultdict(\u0026lt;class \u0026#39;int\u0026#39;\u0026gt;, {\u0026#39;key\u0026#39;: 0}) infinite # ì–‘ì˜ ë¬´í•œëŒ€ float('inf') ìŒì˜ ë¬´í•œëŒ€ float('-inf') Prim\u0026rsquo;s Algorithm # ì‹œì‘ ì •ì ì„ ì„ íƒí•œ í›„, ì •ì ì— ì¸ì ‘í•œ ê°„ì„  ì¤‘ ìµœì†Œ ë¹„ìš©ì˜ ê°„ì„ ì„ ì—°ê²°í•˜ì—¬\nìµœì†Œ ì‹ ì¥ íŠ¸ë¦¬(MST)ë¥¼ í™•ì¥í•´ê°€ëŠ” ë°©ì‹ Kruskal\u0026rsquo;s Algorithmì´ ë¹„ìš©ì´ ê°€ì¥ ì‘ì€ ê°„ì„ ë¶€í„° ë‹¤ìŒ ê°„ì„ ì„ ì„ íƒí•˜ëŠ”ë° ë°˜í•´,\nPrim\u0026rsquo;s Algorithmì€ íŠ¹ì • ì •ì ì—ì„œë¶€í„° ë‹¤ìŒ ì •ì ì„ ê°±ì‹ í•´ë‚˜ê°€ë©° ë¹„ìš©ì´ ì‘ì€ ê°„ì„ ì„ ì„ íƒ Prim\u0026rsquo;s Algorithmì˜ ì‹œê°„ ë³µì¡ë„ëŠ” ìµœì•…ì˜ ê²½ìš° O(E log E)\n(while êµ¬ë¬¸ì—ì„œ ëª¨ë“  ê°„ì„ ì— ëŒ€í•´ ë°˜ë³µí•˜ê³ , ìµœì†Œ í™ êµ¬ì¡°ë¥¼ ì‚¬ìš©) Reference: www.fun-coding.org/Chapter20-prim-live.html íŒŒì´ì¬ êµ¬í˜„ ì½”ë“œ\nCopy python def prim(edge_list: list, start_node: int) -\u0026gt; list: mst = list() adjacent_edge_list = defaultdict(list) for weight, n1, n2 in edge_list: adjacent_edge_list[n1].append((weight, n1, n2)) adjacent_edge_list[n1].append((weight, n2, n1)) connected_nodes = {start_node} candidate_edge_list = adjacent_edge_list[start_node] heapq.heapify(candidate_edge_list) while candidate_edge_list: weight, n1, n2 = heapq.heappop(candidate_edge_list) if n2 not in connected_nodes: connected_nodes.add(n2) mst.append((weight, n1, n2)) for edge in adjacent_edge_list[n2]: if edge[2] not in connected_nodes: heapq.heappush(candidate_edge_list, edge) return mst Prim\u0026rsquo;s Algorithm ê°œì„  # ê°„ì„ ì´ ì•„ë‹Œ ë…¸ë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ íë¥¼ ì ìš© ë…¸ë“œë§ˆë‹¤ Key ê°’ì„ ê°€ì§€ê³  ìˆê³ , Key ê°’ì„ ìš°ì„ ìˆœìœ„ íì— ë„£ìŒ Key ê°’ì´ 0ì¸ ì •ì ì˜ ì¸ì ‘í•œ ì •ì ë“¤ì— ëŒ€í•´ Key ê°’ê³¼ ì—°ê²°ëœ ë¹„ìš©ì„ ë¹„êµí•˜ì—¬\nKey ê°’ì´ ì‘ìœ¼ë©´ í•´ë‹¹ ì •ì ì˜ Key ê°’ì„ ê°±ì‹  ê°œì„ ëœ Prim\u0026rsquo;s Algorithmì˜ ì‹œê°„ ë³µì¡ë„ëŠ” O(E log V) í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ heapdict ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©\n(ê¸°ì¡´ì˜ heap ë‚´ìš©ì„ ì—…ë°ì´íŠ¸í•˜ë©´ ì•Œì•„ì„œ ìµœì†Œ í™ì˜ êµ¬ì¡°ë¡œ ì—…ë°ì´íŠ¸ë¨) íŒŒì´ì¬ êµ¬í˜„ ì½”ë“œ\nCopy python from heapdict import heapdict def prim(graph: dict, start_node: int) -\u0026gt; (list, int): mst, keys, pi, total_weight = list(), heapdict(), dict(), 0 for node in graph.keys(): keys[node] = float(\u0026#39;inf\u0026#39;) pi[node] = None keys[start_node], pi[start_node] = 0, start_node while keys: current_node, current_key = keys.popitem() mst.append([pi[current_node], current_node, current_key]) total_weight += current_key for adjacent, weight in graph[current_node].items(): if adjacent in keys and weight \u0026lt; keys[adjacent]: keys[adjacent] = weight pi[adjacent] = current_node return mst, total_weight struggling with a problem # ë°±ì¤€ ê³¨ë“œ 5ë¥¼ í˜¼ìì„œ í‘¼ í›„ ê¸°ê³ ë§Œì¥í•´ì ¸ì„œ ê³¨ë“œ 4ì˜ 1197ë²ˆ ë¬¸ì œì— ë„ì „í•´ë³´ì•˜ë‹¤. ì´í‹€ì— ê±¸ì³ ë„ì „í–ˆì§€ë§Œ í¬ê¸°í•˜ê³  ì •ë‹µì„ ë³´ê²Œë˜ì—ˆìŒì—ë„ ë¬¸ì œë¥¼ í•´ê²°í•œ ê²ƒ ê°™ì§€ ì•Šë‹¤. í•´ë‹¹ ë¬¸ì œëŠ” nê°œì˜ ì •ì ë“¤ì— ëŒ€í•œ ê°„ì„ ë“¤ ì¤‘ì—ì„œ ê°€ì¥ ê°€ì¤‘ì¹˜ê°€ ì‘ì€ ê²½ë¡œì˜ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤. ì²˜ìŒì—” ë…¸ë“œí•˜ë©´ DFSì™€ BFS ë°–ì— ëª°ëê¸° ë•Œë¬¸ì— ë‹¹ì—°í•˜ê²Œ DFSë¡œ ì ‘ê·¼í–ˆë‹¤:\në¨¼ì € ë¶€ëª¨, ìì‹, ê°€ì¤‘ì¹˜, ì¸ë±ìŠ¤ë¥¼ ë³€ìˆ˜ë¡œ ê°€ì§€ëŠ” Node í´ë˜ìŠ¤ë¥¼ ì„ ì–¸í•˜ì—¬\nê°„ì„ ì˜ ì •ë³´ë¥¼ ë…¸ë“œ ë‚´ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì— ì €ì¥í•˜ê²Œ í•œë‹¤. ì „ì²´ ë…¸ë“œ ì¤‘ ìì‹ ë…¸ë“œë¥¼ ê°€ì§„ ë…¸ë“œì— í•œí•´ ê°€ì¤‘ì¹˜ ìµœì†Ÿê°’ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•œë‹¤. í•´ë‹¹ í•¨ìˆ˜ëŠ” rootì—ì„œë¶€í„° end-pointê¹Œì§€ ìˆœíšŒí•˜ë©´ì„œ ê°€ì¤‘ì¹˜ í•©ì˜ ìµœì†Ÿê°’ì„ êµ¬í•˜ëŠ” ë™ì‘ì„ ìˆ˜í–‰í•œë‹¤. í•¨ìˆ˜ì˜ ê²°ê³¼ëŠ” ë”°ë¡œ ë°˜í™˜ë˜ì§€ ì•Šê³  root ë…¸ë“œì˜ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì— ì €ì¥ëœë‹¤. ì´ëŸ¬í•œ ë…¼ë¦¬ë¥¼ ê°€ì§€ê³  ì‘ì„±í•œ ì•Œê³ ë¦¬ì¦˜ì´ ê¸€ ë°‘ì— ìˆëŠ” ì²« ë²ˆì§¸ ì½”ë“œì´ë‹¤. í•˜ì§€ë§Œ í•´ë‹¹ ì½”ë“œëŠ” 1ì´ˆì˜ ì‹œê°„ ì œí•œ ì•ˆì— ëŒì•„ê°€ê¸°ì—” ë¬´ë¦¬ê°€ ìˆì—ˆë‹¤. DFSë¡œ ì•ˆëœë‹¤ëŠ” ê²ƒì„ ê¹¨ë‹«ê³  ì§ˆë¬¸ê¸€ì„ í›‘ì–´ë³¸ í›„ í¬ë£¨ìŠ¤ì¹¼ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•˜ê¸°ë¡œ í–ˆë‹¤:\nìš°ì„  ê³ ë ¤í•´ì•¼ë  ê²ƒì€ í¬ë£¨ìŠ¤ì¹¼ ì•Œê³ ë¦¬ì¦˜ì´ ëª¨ë“  ë…¸ë“œë¥¼ ì—°ê²°ì‹œí‚¤ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ì´ë¼ëŠ” ê²ƒì´ë‹¤. í•´ë‹¹ ë¬¸ì œëŠ” root ë…¸ë“œì—ì„œë¶€í„° ì‹œì‘í•˜ëŠ” ëª¨ë“  ê²½ë¡œë¥¼ ê³ ë ¤í•´ì•¼ í•˜ëŠ”ë° í¬ë£¨ìŠ¤ì¹¼ ì•Œê³ ë¦¬ì¦˜ì„\nì‚¬ìš©í•  ê²½ìš° ê°€ì¥ ì‘ì€ ê°€ì¤‘ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” ê²½ë¡œë§Œì„ ì„ íƒí•˜ê³  ë‚˜ë¨¸ì§€ë¥¼ ë¬´ì‹œí•˜ê²Œ ëœë‹¤. ì´ ê²½ìš° ë°œìƒí•˜ëŠ” ë°˜ë¡€ê°€ ë‹¤ìŒê³¼ ê°™ë‹¤. Copy bash 3 3 1 2 2 1 3 3 2 3 9999 output: 10001 answer: 3 í¬ë£¨ìŠ¤ì¹¼ ì•Œê³ ë¦¬ì¦˜ì— ì˜í•´ 1 -\u0026gt; 2ì˜ ê°„ì„ ì„ ì„ íƒí•˜ê³  1 -\u0026gt; 3ì˜ ê°„ì„ ì„ ë¬´ì‹œí•  ê²½ìš°\nìµœì¢…ì ìœ¼ë¡œëŠ” 1 -\u0026gt; 2 -\u0026gt; 3ì˜ ê²½ë¡œì— ëŒ€í•œ ê°€ì¤‘ì¹˜ 10001ì„ ê²°ê³¼ë¡œ ì–»ê²Œ ëœë‹¤. ì´ì— ëŒ€í•œ í•´ê²°ì±…ìœ¼ë¡œ ìƒê°í•œ ê²ƒì´ EtherChannelì˜ Active/Passive ê°œë…ì´ë‹¤. ì•ì„œ ì‹œë„í•œ DFS ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì— í¬ë£¨ìŠ¤ì¹¼ ì•Œê³ ë¦¬ì¦˜ì„ ì¡°í•©í•´ì„œ ëª¨ë“  ê²½ë¡œë¥¼ íƒìƒ‰í•˜ëŠ”ë°\nê°€ì¤‘ì¹˜ê°€ ê°€ì¥ ì‘ì€ ê²½ë¡œë¡œ ì´ì–´ì§€ëŠ” ìì‹ ë…¸ë“œë¥¼ Activeë¡œ, ë‚˜ë¨¸ì§€ë¥¼ Passiveë¡œ ë¶„ë¥˜í•œë‹¤. ë§Œì•½ í•œ ë…¸ë“œì— ìƒˆë¡œìš´ ìì‹ ë…¸ë“œê°€ ì¶”ê°€ë˜ë©´ ìì‹ ë…¸ë“œë“¤ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¹„êµí•´ì„œ Activeë¥¼ ê°±ì‹ í•˜ê³ \ní•´ë‹¹ ë…¸ë“œì˜ ë¶€ëª¨ ë…¸ë“œë¥¼ íƒ€ê³  ì˜¬ë¼ê°€ë©° ë™ì¼í•œ ì‘ì—…ì„ ë°˜ë³µí•œë‹¤. í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì€ root ë…¸ë“œì—ì„œë¶€í„° ëª¨ë“  ìì‹ ë…¸ë“œë¥¼ íƒìƒ‰í•´ì•¼ í–ˆë˜ DFS ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ê³¼ëŠ” ë°˜ëŒ€ë¡œ\nìì‹ ë…¸ë“œì—ì„œë¶€í„° root ë…¸ë“œê¹Œì§€ì˜ ê²½ë¡œë§Œì„ íƒìƒ‰í•˜ê¸° ë•Œë¬¸ì— ì‹œê°„ ì´ˆê³¼ë¥¼ í”¼í•  ìˆ˜ ìˆì—ˆë‹¤. í•˜ì§€ë§Œ ì—¬ëŸ¬ ì¡°ê±´ë“¤ì„ ê³ ë ¤í•˜ë‹¤ë³´ë‹ˆ ì‘ì„±ìì¸ ë‚˜ì¡°ì°¨ë„ ì•Œì•„ë³´ê¸° í˜ë“¤ì •ë„ë¡œ ì½”ë“œê°€ ë§ì´ ë³µì¡í•´ì¡Œê³ \nroot ë…¸ë“œê°€ ê¸°ì¤€ì¸ë° êµ³ì´ ì•„ë˜ì„œë¶€í„° ìœ„ë¥¼ íƒìƒ‰í•˜ëŠ” ë°©ì‹ì´ ë§ˆìŒì— ë“¤ì§€ ì•Šì•˜ë‹¤. ê·¸ë¦¬ê³  ê°€ì¥ í° ë¬¸ì œëŠ” í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì—ë„ ë°˜ë¡€ê°€ ìˆì–´ì„œ ì •ë‹µì´ ë  ìˆ˜ ì—†ì—ˆë‹¤ëŠ” ê²ƒì´ë‹¤. í•˜ë£¨ë™ì•ˆ ê³ ë¯¼í•œ ëì— í¬ë£¨ìŠ¤ì¹¼ ì•Œê³ ë¦¬ì¦˜ì„ í¬ê¸°í•˜ê³  ì´ì™€ ë¹„ìŠ·í•˜ë‹¤ëŠ” í”„ë¦¼ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•˜ê²Œ ë˜ì—ˆë‹¤:\nì´ì œê¹Œì§€ ì‚¬ìš©í–ˆë˜ Node ì¸ìŠ¤í„´ìŠ¤ ë‚´ì— ëª¨ë“  ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ì ‘ê·¼ë°©ì‹ì„ ë²„ë¦¬ê³ \ní”„ë¦¼ ì•Œê³ ë¦¬ì¦˜ì˜ ê¸°ë³¸ì— ì§‘ì¤‘í–ˆë‹¤. ë¶€ëª¨ ë…¸ë“œì˜ ê°’ì„ ìì‹ ë…¸ë“œì˜ ë°°ì—´ ê°’ì— ì €ì¥í•˜ëŠ” Union-Find ì•Œê³ ë¦¬ì¦˜ì„ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê³ \nëª¨ë“  ë…¸ë“œì— ëŒ€í•´ í”„ë¦¼ ì•Œê³ ë¦¬ì¦˜ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì†Œ ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•˜ëŠ” ë°©ì‹ì„ êµ¬ìƒí–ˆë‹¤. í•˜ì§€ë§Œ ì´ ê²½ìš°ì— ë‘ ê°€ì§€ ë¬¸ì œì ì´ ìˆì—ˆë‹¤. í”„ë¦¼ ì•Œê³ ë¦¬ì¦˜ë„ ê²°êµ­ ëª¨ë“  ë…¸ë“œë¥¼ ì—°ê²°í•˜ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ì´ê¸° ë•Œë¬¸ì—,\nrootì—ì„œ end-pointê¹Œì§€ ê°”ë‹¤ í•˜ë”ë¼ë„ ê±°ê¸°ì„œ ë©ˆì¶”ì§€ ì•Šê³  ë‹¤ë¥¸ ê²½ë¡œë¥¼ íƒìƒ‰í•˜ëŠ” ë¬¸ì œê°€ ìƒê¸´ë‹¤. í•´ë‹¹ ë¬¸ì œì— ëŒ€í•œ í•´ê²°ì±…ìœ¼ë¡œ Find ì—°ì‚°ì„ ì‘ìš©í•œ ê¹Šì´ íƒìƒ‰ ê³¼ì •ì„ ì¶”ê°€í–ˆë‹¤. ë§¤ ë°˜ë³µë§ˆë‹¤ í˜„ì¬ ë…¸ë“œì— ëŒ€í•´ Find ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê³  ì¬ê·€í•œ íšŸìˆ˜ ë°˜í™˜í•˜ì—¬ ê¹Šì´ë¡œ ì§€ì •í•œë‹¤. ê¹Šì´ê°€ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ì§€ ì•Šì„ ê²½ìš° end-pointê¹Œì§€ ë„ë‹¬í–ˆë‹¤ íŒë‹¨í•˜ì—¬ ë°˜ë³µì„ ë©ˆì¶˜ë‹¤. ëª¨ë“  ê²½ë¡œì˜ ê¹Šì´ê°€ 1ì¼ ê²½ìš° 1ë²ˆ ì¡°ê±´ì„ ë¬´ì‹œí•˜ê³  ë‹¤ë¥¸ ê²½ë¡œë¥¼ íƒìƒ‰í•˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤. root ë…¸ë“œì—ì„œ ì‹œì‘í–ˆëŠ”ë° ë‹¤ì‹œ root ë…¸ë“œë¡œ ëŒì•„ì˜¬ ê²½ìš° í•´ë‹¹ ë…¸ë“œ ìì²´ë¥¼ ë¬´ì‹œí•œë‹¤. ìœ„ ì¡°ê±´ì— ê±¸ë¦´ ê²½ìš° ì–‘ì˜ ë¬´í•œëŒ€ ê°’ì„ ë°˜í™˜í•˜ì—¬ ê°€ì¤‘ì¹˜ íŒë‹¨ ê³¼ì •ì—ì„œ ì œì™¸ì‹œí‚¬ ìˆ˜ ìˆì—ˆë‹¤. ì´ë ‡ê²Œ ë§ì€ ì‹œí–‰ì°©ì˜¤ë¥¼ ê±°ì³¤ì§€ë§Œ í•˜ë‚˜ë¥¼ í•´ê²°í•˜ë©´ ë‹¤ë¥¸ ë¹ˆí‹ˆì´ ìƒê²¨ë²„ë ¤ í¬ê¸°í•  ìˆ˜ë°–ì— ì—†ì—ˆë‹¤. ì‹¬ì§€ì–´ ë°±ì¤€ì—ì„œëŠ” heapdict ëª¨ë“ˆì„ ì§€ì›í•˜ì§€ ì•Šì•„ í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•  ìˆ˜ë„ ì—†ì—ˆë‹¤. ì–¸ì  ê°€ ì´ ë¬¸ì œë¥¼ ì™„ë²½í•˜ê²Œ í•´ê²°í•˜ê¸° ìœ„í•´ ë””ë²„ê·¸ ê°’ì„ ë‚¨ê¸´ë‹¤. Copy bash 3 3 1 2 2 1 3 3 2 3 9999 graph = {1: {2: 1, 3: 3}, 2: {1: 1, 3: 2}, 3: {2: 2, 1: 3}} mst1 = [[1, 1, 0], [1, 2, 1], [2, 3, 2]], weight: 3 mst2 = [[2, 2, 0], [2, 1, 1], [2, 3, 2]], weight: 3 mst3 = [[3, 3, 0], [3, 2, 2], [2, 1, 1]], weight: 3 output: 3 answer: 3 Copy bash 6 8 1 3 -1 1 5 3 1 6 2 2 5 5 2 6 6 3 4 9 3 5 -1 5 6 -1 graph = {1: {3: -1, 5: 3, 6: 2}, 3: {1: -1, 4: 9, 5: -1}, 5: {1: 3, 2: 5, 3: -1, 6: -1}, 6: {1: 2, 2: 6, 5: -1}, 2: {5: 5, 6: 6}, 4: {3: 9}} mst1 = [[1, 1, 0], [1, 3, -1], [3, 5, -1], [5, 6, -1], [5, 2, 5], [3, 4, 9]], w = 11 mst2 = [[3, 3, 0], [3, 5, -1], [5, 6, -1], [3, 1, -1], [5, 2, 5], [3, 4, 9]], w = 11 mst3 = [[5, 5, 0], [5, 6, -1], [5, 3, -1], [3, 1, -1], [5, 2, 5], [3, 4, 9]] 11 mst4 = [[6, 6, 0], [6, 5, -1], [5, 3, -1], [3, 1, -1], [5, 2, 5], [3, 4, 9]] 11 mst5 = [[2, 2, 0], [2, 5, 5], [5, 6, -1], [5, 3, -1], [3, 1, -1], [3, 4, 9]] 11 mst6 = [[4, 4, 0], [4, 3, 9], [3, 5, -1], [5, 6, -1], [3, 1, -1], [5, 2, 5]] 11 output: 11 answer: -3 Copy bash 3 3 1 2 2 1 3 3 2 3 9999 graph = {1: {2: 2, 3: 3}, 2: {1: 2, 3: 9999}, 3: {1: 3, 2: 9999}} mst1 = [[1, 1, 0], [1, 2, 2], [1, 3, 3]], weight = 5 mst2 = [[2, 2, 0], [2, 1, 2], [1, 3, 3]], weight = 5 mst3 = [[3, 3, 0], [3, 1, 3], [1, 2, 2]], weight = 5 output: 5 answer: 3 ê²°ë¡ :\ní•´ë‹¹ ë¬¸ì œì— ëŒ€í•œ ì •ë‹µì„ ì°¾ì•„ë³¸ ê²°ê³¼ í”„ë¦¼ ì•Œê³ ë¦¬ì¦˜ì„ heapdict ì—†ì´ êµ¬í˜„í•œ ì•Œê³ ë¦¬ì¦˜ì„ ë³´ì•˜ëŠ”ë°\në…¸ë“œì— ëŒ€í•œ ë°©ë¬¸ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì—¬ ê²½ë¡œë¥¼ êµ¬í•˜ëŠ” ë°©ì‹ì´ì—ˆë‹¤. ë°±ì¤€ì—ì„œëŠ” í•´ë‹¹ ë¬¸ì œê°€ í†µê³¼ë˜ì—ˆì§€ë§Œ ìœ„ ì„¸ ê°œì˜ ë°ì´í„°ë¥¼ ë„£ì—ˆì„ ë•Œ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê°’ì´ ë‚˜ì™”ë‹¤. ì•„ë§ˆ ë‚´ê°€ ë¬¸ì œë¥¼ ì œëŒ€ë¡œ ì´í•´í•˜ì§€ ëª»í–ˆê±°ë‚˜ ì±„ì  ë°ì´í„° ìì²´ê°€ ì ì–´ì„œ ê·¸ë¬ì„ ê²ƒì´ë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ë‹¤ë¥¸ ì‚¬ëŒì´ ì‘ì„±í•œ ì •ë‹µì„ ë³´ê²Œ ëì§€ë§Œ ì™„ì „íˆ ë‚©ë“í•˜ì§€ëŠ” ëª»í–ˆë‹¤. My First Algorithm (DFS) class Node: def __init__(self, index): self.index = index self.data = 2147483647 self.parent = [] self.child = [] def print_node(self): print(self.index, self.data, self.parent, self.child) def spanning_tree(nodes, check, root, parent, data): for child in parent.child: weight = data + child[1] child = nodes[child[0]] if child.child: if not check[child.index]: spanning_tree(nodes, check, root, child, weight) else: check[parent.index] = True if weight \u0026lt; root.data: root.data = weight\nV, E = map(int, input().split()) graph = [Node(i) for i in range(V+1)] visited = [False for _ in range(V+1)]\nfor _ in range(E): A, B, C = map(int, input().split()) graph[A].child.append((B,C)) graph[B].parent.append((A,C))\nmin_weight = 2147483647\nfor node in graph: if node.child and not node.parent: spanning_tree(graph, visited, node, node, 0) if node.data \u0026lt; min_weight: min_weight = node.data\nprint(min_weight) My Second Algorithm (Kruskal's Algorithm) class Node: def __init__(self, index): self.index = index self.data = 0 self.root = self self.parent = self self.active = None self.passive = [] def get_branch(self): if self.active: return self.passive + [self.active] else: return [] def set_branch(self, node, data): if self.root == node.root: if data \u0026lt; node.data: node.parent = self node.data = data else: node.root = self.root node.parent = self node.data += data if not self.active: self.active = node self.data += node.data node.data = self.data else: self.passive.append(node) self.update_data() def update_data(self): branch = self.get_branch() branch.sort(key=lambda n: n.data, reverse=True) active = branch.pop() if active != self.active: self.active = active self.passive = branch self.data = self.active.data def union_root(source: Node, target: Node, data: int) -\u0026gt; None: root = source.root if target.root in [source, source.root, target]: source.set_branch(target, data) while source != root: source = source.parent source.update_data()\nV, E = map(int, input().split())\ngraph = [Node(i) for i in range(V + 1)] edge_dict = {}\nfor _ in range(E): A, B, C = map(int, input().split()) edge_dict[(A, B)] = C\nedge_list = sorted(edge_dict.items(), key=lambda x: [x[1], x[0]])\nfor (a, b), c in edge_list: node_a, node_b = graph[a], graph[b] if node_a.parent != node_b.parent: union_root(node_a, node_b, c)\nweight = 2147483647\nfor edge_node in graph: if (edge_node.root == edge_node) and edge_node.get_branch(): if edge_node.data \u0026lt; weight: weight = edge_node.data\nprint(weight) My Third Algorithm (Prim's Algorithm) def prim(nodes: dict, start: int) -\u003e int or float: mst, keys, pi = [], heapdict(), dict() depth, total_weight = -1, 0 for n in nodes.keys(): keys[n] = float('inf') pi[n] = None keys[start], pi[start] = 0, start while keys: current_node, current_key = keys.popitem() current_depth = get_depth(pi, start, current_node, 0) if current_depth \u0026lt;= depth: if pi[current_node] == start: return float('inf') break depth = current_depth mst.append([pi[current_node], current_node, current_key]) total_weight += current_key for adjacent, weight in nodes[current_node].items(): if adjacent in keys and weight \u0026lt; keys[adjacent]: keys[adjacent] = weight pi[adjacent] = current_node return total_weight def get_depth(nodes: dict, root: int, start: int, data: int) -\u0026gt; int: if start == root: return data if nodes[start] == root: return data+1 return get_depth(nodes, root, nodes[start], data+1)\nV, E = map(int, input().split()) graph = defaultdict(dict)\nfor _ in range(E): A, B, C = map(int, input().split()) graph[A][B] = C graph[B][A] = C\nweight_list = [] for node in graph.keys(): heapq.heappush(weight_list, prim(graph, node))\nprint(heapq.heappop(weight_list)) Answer Algorithm V, E = map(int, input().split()) graph = [[] for _ in range(V+1)] visited = [False for _ in range(V+1)] heap = [[0, 1]] for _ in range(E): A, B, C = map(int, input().split()) graph[A].append([C, B]) graph[B].append([C, A]) total_weight = 0 node_cnt = 0 while heap: if node_cnt == V: break weight, node = heapq.heappop(heap) if not visited[node]: visited[node] = True total_weight += weight node_cnt += 1 for i in graph[node]: heapq.heappush(heap, i)\nprint(total_weight) Userful Reference\nGraph Editor\n"},{"id":123,"href":"/blog/2022-03-05/","title":"2022-03-05 Log","section":"Posts","content":"Operator Overloading # ì—°ì‚°ì ì˜¤ë²„ë¡œë”©ì€ ì¸ìŠ¤í„´ìŠ¤ ê°ì²´ë¼ë¦¬ ì„œë¡œ ì—°ì‚°ì„ í•  ìˆ˜ ìˆê²Œ ê¸°ì¡´ ì—°ì‚°ìì˜ ê¸°ëŠ¥ì„ ì¤‘ë³µìœ¼ë¡œ ì •ì˜í•˜ëŠ” ê²ƒ ì—°ì‚°ì ì˜¤ë²„ë¡œë”©ì˜ ì˜ˆì‹œ Method Operator Example __add__(self, other) + (Binomial) A + B, A += B __pos__(self) + (Unary) +A _sub__(self, other) - (Binomial) A - B, A -= B __neg__(self) - (Unary) -A __mul__(self, other) * A * B, A *= B __truediv__(self, other) / A / B, A /= B __floordiv__(self, other) // A // B, A //= B __mod__(self, other) % A % B, A %= B __pow__(self, other) pow(), ** pow(A, B), A ** B __eq__(self, other) == A == B __lt__(self, other) \u0026lt; A \u0026lt; B __gt__(self, other) \u0026gt; A \u0026gt; B __lshift__(self, other) \u0026laquo; A \u0026laquo; B __rshift__(self, other) \u0026raquo; A \u0026raquo; B __and__(self, other) \u0026amp; A \u0026amp; B, A \u0026amp;= B __xor__(self, other) ^ A ^ B, A ^= B __or__(self, other) | A | B, A |= B __invert__(self) ~ ~A __abs__(self) abs() abs(A) Union-Find Algorithm # ë‘ ë…¸ë“œê°€ ê°™ì€ ê·¸ë˜í”„ì— ì†í•˜ëŠ”ì§€ íŒë³„í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ ë…¸ë“œë¥¼ í•©ì¹˜ëŠ” Union ì—°ì‚°ê³¼ ë£¨íŠ¸ ë…¸ë“œë¥¼ ì°¾ëŠ” Find ì—°ì‚°ìœ¼ë¡œ ì´ë£¨ì–´ì§ ë°°ì—´ì— ë‚˜ì—´ëœ ëª¨ë“  ë…¸ë“œë“¤ì€ ê¸°ë³¸ì ìœ¼ë¡œ ìê¸° ìì‹ ì˜ ê°’ì„ ê°€ì§ ë…¸ë“œë¥¼ í•©ì¹  ë•Œ ìì‹ ë…¸ë“œì˜ ë°°ì—´ ê°’ì— ë¶€ëª¨ ë…¸ë“œì˜ ë°°ì—´ ê°’ì„ ë„£ìŒ ê°„ë‹¨í•œ êµ¬í˜„ ì½”ë“œ\nCopy python def find(graph: list, x: int) -\u0026gt; int: if graph[x] == x: return x graph[x] = find(graph, graph[x]) def union(graph: list, x: int, y: int) -\u0026gt; None: x = find(graph, x) y = find(graph, y) if x == y: return graph[y] = x Kruskal\u0026rsquo;s Algorithm # ê°€ì¥ ì ì€ ë¹„ìš©ìœ¼ë¡œ ëª¨ë“  ë…¸ë“œë¥¼ ì—°ê²°í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ (ìµœì†Œ ë¹„ìš© ì‹ ì¥ íŠ¸ë¦¬) ëª¨ë“  ê°„ì„  ì •ë³´ë¥¼ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•œ ë’¤ ë¹„ìš©ì´ ì ì€ ê°„ì„ ë¶€í„° ê·¸ë˜í”„ì— í¬í•¨ Reference: https://blog.naver.com/ndb796/221230994142 ê°„ë‹¨í•œ êµ¬í˜„ ì½”ë“œ\nCopy python class Edge: def __init__(self, a: int, b: int, cost: int): self.parent = a self.child = b self.cost = cost def get_parent(graph: list, x: int) -\u0026gt; int: if graph[x] == x: return x graph[x] = get_parent(graph, graph[x]) def union_parent(graph: list, a: int, b: int) -\u0026gt; None: a = get_parent(graph, a) b = get_parent(graph, b) if a \u0026lt; b: graph[b] = a else: graph[a] = b def find(graph: list, a: int, b: int) -\u0026gt; int: a = get_parent(graph, a) b = get_parent(graph, b) if a == b: return True else: return False def sort_edge(edge_list: list) -\u0026gt; list: return sorted(edge_list, key=lambda x: [x.cost, x.parent, x.child]) def union_edge(graph: list, edge_list: list) -\u0026gt; int: cost = 0 for edge in edge_list: if not find(graph, edge.parent, edge.child): cost += edge.cost union_parent(graph, edge.parent, edge.child) return cost "},{"id":124,"href":"/blog/2022-03-04/","title":"2022-03-04 Log","section":"Posts","content":"1. Set # ë°±ì¤€ 1107ë²ˆ(ë¦¬ëª¨ì»¨) ë¬¸ì œë¥¼ í’€ ë•Œ ìœ ìš©í•˜ê²Œ ì‚¬ìš© í•´ë‹¹ ë¬¸ì œëŠ” íŠ¹ì • ê¸¸ì´ì˜ ë¬¸ìì—´ì— ëŒ€í•´ ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•©ì„ íƒìƒ‰í•´ì•¼ í•˜ëŠ”ë°\nì‹œê°„ë³µì¡ë„ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì¤‘ë³µì´ ì—†ëŠ” ì§‘í•©ì„ ì‚¬ìš© ë¹ˆì§‘í•©ì€ set() ëª…ë ¹ì–´ë¡œ ê°„ë‹¨í•˜ê²Œ ì •ì˜ Setì€ Dictionaryì™€ ë™ì¼í•œ Hash Table ê¸°ë°˜ì´ê¸° ë•Œë¬¸ì—\nx in s ì—°ì‚°ì˜ ì‹œê°„ë³µì¡ë„ê°€ O(1)\në¦¬ìŠ¤íŠ¸ì˜ x in s ì—°ì‚° ì‹œê°„ë³µì¡ë„ê°€ O(n)ì¸ ê²ƒê³¼ëŠ” í° ì°¨ì´ Setì„ ì‘ìš©í•´ ì‘ì„±í•œ ì½”ë“œ ì¼ë¶€\nCopy python buttons = set([str(i) for i in range(10)]) channels = {N,} diff = {abs(int_N-100)} if M \u0026gt; 0: buttons -= set(list(input().split())) channels = set() for i in range(1, count+1): product = itertools.product(buttons, repeat=i) channels |= set(map(\u0026#39;\u0026#39;.join, product)) min_chan, max_chan = \u0026#39;0\u0026#39;, \u0026#39;1\u0026#39; for _ in range(count-1): min_chan += max(buttons) for _ in range(count): max_chan += min(buttons) if set(max_chan) \u0026amp; buttons == set(max_chan): channels.add(max_chan) if set(min_chan) \u0026amp; buttons == set(min_chan): channels.add(min_chan) 2. Dictionary # ë°±ì¤€ 1620ë²ˆ(ë‚˜ëŠ”ì•¼ í¬ì¼“ëª¬ ë§ˆìŠ¤í„° ì´ë‹¤ì†œ) ë¬¸ì œë¥¼ í’€ ë•Œ ì‚¬ìš© í•´ë‹¹ ë¬¸ì œëŠ” ë¬¸ìì—´ ë˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ì…ë ¥í–ˆì„ ë•Œ ëŒ€ì¹­ë˜ëŠ” ê°’ì„ ì¶œë ¥í•´ì•¼ í•˜ëŠ”ë°\nì²˜ìŒì—” ì‹œê°„ë³µì¡ë„ê°€ O(n)ì¸ Listì˜ index(x)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì´ˆê³¼ê°€ ë°œìƒ ë¬¸ìì—´ê³¼ ì¸ë±ìŠ¤ì˜ ê´€ê³„ë¥¼ Dictionaryë¡œ êµ¬í˜„í•´ íƒìƒ‰ ì‹œê°„ë³µì¡ë„ë¥¼ O(1)ë¡œ ê°œì„  3. Coutner # ë°±ì¤€ 10816ë²ˆ(ìˆ«ìì¹´ë“œ 2) ë¬¸ì œë¥¼ í’€ ë•Œ ì‚¬ìš© í•´ë‹¹ ë¬¸ì œëŠ” ìˆ«ì ì¹´ë“œì˜ ê°’ì„ ì…ë ¥í–ˆì„ ë•Œ í•´ë‹¹ ì¹´ë“œì˜ ê°œìˆ˜ë¥¼ ì¶œë ¥í•´ì•¼ í•˜ëŠ”ë°\nì²˜ìŒì—” ì‹œê°„ë³µì¡ë„ê°€ O(n)ì¸ Listì˜ count(x)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì´ˆê³¼ê°€ ë°œìƒ ì „ì²´ ì¹´ë“œì— ëŒ€í•œ Counterë¥¼ ì •ì˜í•˜ì—¬ íƒìƒ‰ ì‹œê°„ë³µì¡ë„ë¥¼ O(1)ë¡œ ê°œì„  4. Combination # ë°±ì¤€ 1010ë²ˆ(ë‹¤ë¦¬ ë†“ê¸°) ë¬¸ì œë¥¼ í’€ ë•Œ ì‚¬ìš© í•´ë‹¹ ë¬¸ì œëŠ” ê°•ì— ë‹¤ë¦¬ë¥¼ ë†“ëŠ” ê²½ìš°ì˜ ìˆ˜ë¥¼ ì¶œë ¥í•´ì•¼ í•˜ëŠ”ë°\nmath ëª¨ë“ˆì˜ comb í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ê²½ìš°ì˜ ìˆ˜ë¥¼ ê³„ì‚° 5. Permutation # ë°±ì¤€ 1107ë²ˆ(ë¦¬ëª¨ì»¨) ë¬¸ì œë¥¼ í’€ ë•Œ ìœ ìš©í•˜ê²Œ ì‚¬ìš© í•´ë‹¹ ë¬¸ì œì—ì„œ íŠ¹ì • ê¸¸ì´ì˜ ë¬¸ìì—´ì— ëŒ€í•´ ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•©ì„ ë‚˜ì—´í•˜ëŠ”ë°,\nìˆœì„œë¥¼ ê³ ë ¤í•˜ê³  ì¤‘ë³µì„ í—ˆìš©í•˜ê¸° ìœ„í•´ ì¤‘ë³µ ìˆœì—´(Product)ì„ ì‚¬ìš© Permutationì„ ì‘ìš©í•´ ì‘ì„±í•œ ì½”ë“œ ì¼ë¶€\nCopy python buttons = set([str(i) for i in range(10)]) ... for i in range(1, count+1): product = itertools.product(buttons, repeat=i) channels |= set(map(\u0026#39;\u0026#39;.join, product)) 6. Binary Search # ë°±ì¤€ 1654ë²ˆ(ëœì„  ìë¥´ê¸°) ë¬¸ì œë¥¼ í’€ ë•Œ ìœ ìš©í•˜ê²Œ ì‚¬ìš© í•´ë‹¹ ë¬¸ì œëŠ” ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ì„ ë“¤ì„ ë™ì¼í•œ ê¸¸ì´ë¡œ ê°€ì¥ ê¸¸ê²Œ ì˜ë¼ì•¼ ë˜ëŠ”ë°\nì²˜ìŒì—” ê°€ì¥ ê¸´ ì„ ë¶€í„° ê°€ì¥ ì§§ì€ ì„ ê¹Œì§€ì˜ ë²”ìœ„ ë‚´ì—ì„œ ì™„ì „íƒìƒ‰ì„ ì§„í–‰í•˜ì—¬ ì‹œê°„ì´ˆê³¼ê°€ ë°œìƒ ì™„ì „íƒìƒ‰ì„ ì´ë¶„íƒìƒ‰ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ì‹œê°„ë³µì¡ë„ ê°œì„  Binary Searchë¥¼ ì‘ìš©í•´ ì‘ì„±í•œ ì½”ë“œ ì¼ë¶€\nCopy python while mn \u0026lt; mx: md = (mx + mn) // 2 count = 0 for i in range(K): count += k[i] // md if count \u0026lt; N: mx = md else: mn = md + 1 7. Heap # ë°±ì¤€ 7662ë²ˆ(ì´ì¤‘ ìš°ì„ ìˆœìœ„ í) ë¬¸ì œë¥¼ í’€ ë•Œ ìœ ìš©í•˜ê²Œ ì‚¬ìš© í•´ë‹¹ ë¬¸ì œëŠ” ìµœì†Ÿê°’ê³¼ ìµœëŒ“ê°’ ì‚­ì œ ê¸°ëŠ¥ì„ ëª¨ë‘ ê°€ì§€ê³  ìˆëŠ” ì´ì¤‘ ìš°ì„ ìˆœìœ„ íë¥¼ êµ¬í˜„í•˜ëŠ” ê²ƒ ì²˜ìŒì—” Listì˜ pop(x), index(x), max(x)/min(x)ë¥¼ í˜¼í•©í•˜ì—¬ ì‚¬ìš©í•œ ê²ƒ ë•Œë¬¸ì—\nO(n^3) ì´ìƒì˜ ì‹œê°„ë³µì¡ë„ë¥¼ ë§Œë“¤ì–´ì„œ ì‹œê°„ì´ˆê³¼ê°€ ë°œìƒ ë‘ë²ˆì§¸ ì‹œë„ì—ì„  Listì˜ pop(x)ì™€ heapq ëª¨ë“ˆì˜ heappop(x)ë¥¼ ì‚¬ìš©í•´ ì‹œê°„ë³µì¡ë„ë¥¼ O(1()ë¡œ ê°œì„ \ní•˜ì§€ë§Œ, Heapì€ ì´ì§„íŠ¸ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ì™€ëŠ” êµ¬ì¡°ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ì¸ë±ìŠ¤ë¡œ ì°¸ì¡° ì‹œ ì—ëŸ¬ê°€ ë°œìƒ ì„¸ë²ˆì§¸ ì‹œë„ì—ì„  ë‹¨ì¼ íë¥¼ Max Heapê³¼ Min Heapìœ¼ë¡œ ë‚˜ëˆ„ê³  ê°ê°ì—ì„œ heappop(x), heappush(x)ë¥¼ ìˆ˜í–‰\ní•˜ì§€ë§Œ, Max Heap ë˜ëŠ” Min Heapì—ì„œ ì‚­ì œëœ ê°’ì´ ë°˜ëŒ€ìª½ Heapì—ì„œ ë‚¨ì•„ìˆëŠ” ê²½ìš°ê°€ ìˆì–´ ì—ëŸ¬ê°€ ë°œìƒ í•´ë‹¹ ì—ëŸ¬ì— ëŒ€í•œ í•´ê²°ì±…ìœ¼ë¡œ Max Heapê³¼ Min Heapì„ ë™ê¸°í™”ë¥¼ ì‹œí‚¤ëŠ” ë°©ë²•ë„ ìˆì§€ë§Œ,\nê°’ì´ ìœ íš¨í•œì§€ íŒë‹¨í•˜ëŠ” Dictionaryë¥¼ êµ¬í˜„í•´ ê°’ì— ëŒ€í•œ ì°¸/ê±°ì§“ ì—¬ë¶€ë¥¼ ì°¸ì¡°í•˜ëŠ” ë°©ë²•ì„ ì´ìš©\ní•´ë‹¹ Dictionaryë¥¼ heappop(x) ì‚¬ìš© ì‹œ í•œ ë²ˆ, ìµœëŒ€/ìµœì†Ÿê°’ ì¶œë ¥ ì‹œ í•œ ë²ˆì”© ì°¸ì¡°í•´ ì—ëŸ¬ í•´ê²° Heapì„ ì‘ìš©í•´ ì‘ì„±í•œ ì½”ë“œ ì¼ë¶€\nCopy python if cmd == \u0026#39;I\u0026#39;: n = int(n) heapq.heappush(min_Q, n) heapq.heappush(max_Q, -n) try: valid[n] += 1 except KeyError: valid[n] = 1 ins += 1 elif cmd == \u0026#39;D\u0026#39;: try: if n == \u0026#39;1\u0026#39;: max_pop = -heapq.heappop(max_Q) while not valid[max_pop]: max_pop = -heapq.heappop(max_Q) valid[max_pop] -= 1 ins -= 1 elif n == \u0026#39;-1\u0026#39;: min_pop = heapq.heappop(min_Q) while not valid[min_pop]: min_pop = heapq.heappop(min_Q) valid[min_pop] -= 1 ins -= 1 except IndexError: min_Q, max_Q = [], [] continue Copy python max_pop, min_pop = 0, 0 while True: max_pop = -heapq.heappop(max_Q) if valid[max_pop]: break while True: min_pop = heapq.heappop(min_Q) if valid[min_pop]: break print(max_pop, min_pop) 8. DFS/BFS # ë°±ì¤€ 1260ë²ˆ(DFSì™€ BFS) ë¬¸ì œë¥¼ í’€ ë•Œ ì‚¬ìš© í•´ë‹¹ ë¬¸ì œëŠ” DFSì™€ BFSë¡œ íƒìƒ‰í–ˆì„ ë•Œì˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” ê¸°ë³¸ì ì¸ ë¬¸ì œ DFSëŠ” ê¹Šì´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ íƒìƒ‰, BFSëŠ” ë„ˆë¹„ë¥¼ ìš°ì„ ì ìœ¼ë¡œ íƒìƒ‰ DFSëŠ” ê²½ë¡œì˜ íŠ¹ì§•ì„ ì €ì¥í•  ë•Œ ì‚¬ìš©, BFSëŠ” ìµœë‹¨ê±°ë¦¬ë¥¼ êµ¬í•  ë•Œ ì‚¬ìš© DFSëŠ” ìŠ¤íƒ ë˜ëŠ” ì¬ê·€í•¨ìˆ˜ë¡œ êµ¬í˜„, BFSëŠ” í(ë°í¬)ë¥¼ ì´ìš©í•´ì„œ êµ¬í˜„ DFS/BFSë¥¼ ì‘ìš©í•´ ì‘ì„±í•œ ì½”ë“œ ì¼ë¶€\nCopy python def dfs(nodes, visited, node): visited[node] = True next_nodes = nodes[node] while next_nodes: next_node = heapq.heappop(next_nodes) if not visited[next_node]: print(next_node, end=\u0026#39; \u0026#39;) dfs(nodes, visited, next_node) Copy python def bfs(nodes, visited, root): queue = deque() visited[root] = True queue.append(root) while queue: node = queue.popleft() visited[node] = True print(node, end=\u0026#39; \u0026#39;) next_nodes = nodes[node] while next_nodes: next_node = heapq.heappop(next_nodes) if not visited[next_node]: visited[next_node] = True queue.append(next_node) "},{"id":125,"href":"/blog/police-map/","title":"Police Map","section":"Posts","content":"\u003c!DOCTYPE html\u003e "}]