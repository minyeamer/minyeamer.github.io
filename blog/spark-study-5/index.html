<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=keywords content="Apache Spark,Spark SQL,SQL,View,PySpark,데이터 엔지니어링,스파크,Study"><meta name=description content="Apache Spark의 Spark SQL을 다루며, SQL 쿼리 실행부터 테이블/뷰 관리, 메타데이터 캐싱까지 단계별로 안내합니다. 빅데이터 분석과 데이터 엔지니어링을 위한 강력 …"><meta name=author content="minyeamer"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-5/><link rel=icon href=https://minyeamer.github.io/images/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://minyeamer.github.io/images/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://minyeamer.github.io/images/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><link rel=mask-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><meta name=google-site-verification content="u1tWcHmHUZWfFT1cHaku6sqU-bK40N3WLR-C-4VUWN0"><meta name=naver-site-verification content="6eaf8e9da1a6104780f056f1a7797fe5a3a5a0da"><meta property="og:title" content="Apache Spark - 스파크 SQL과 테이블/뷰 관리"><meta property="og:description" content="Apache Spark의 Spark SQL을 다루며, SQL 쿼리 실행부터 테이블/뷰 관리, 메타데이터 캐싱까지 단계별로 안내합니다. 빅데이터 분석과 데이터 엔지니어링을 위한 강력 …"><meta property="og:type" content="article"><meta property="og:url" content="https://minyeamer.github.io/blog/spark-study-5/"><meta property="og:image" content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-05T23:03:04+09:00"><meta property="article:modified_time" content="2025-07-05T23:03:04+09:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0"><meta name=twitter:title content="Apache Spark - 스파크 SQL과 테이블/뷰 관리"><meta name=twitter:description content="Apache Spark의 Spark SQL을 다루며, SQL 쿼리 실행부터 테이블/뷰 관리, 메타데이터 캐싱까지 단계별로 안내합니다. 빅데이터 분석과 데이터 엔지니어링을 위한 강력 …"><meta name=twitter:site content="@https://x.com/minyeamer"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://minyeamer.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Apache Spark - 스파크 SQL과 테이블/뷰 관리","item":"https://minyeamer.github.io/blog/spark-study-5/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Spark - 스파크 SQL과 테이블/뷰 관리","name":"Apache Spark - 스파크 SQL과 테이블\/뷰 관리","description":"Apache Spark의 Spark SQL을 다루며, SQL 쿼리 실행부터 테이블/뷰 관리, 메타데이터 캐싱까지 단계별로 안내합니다. 빅데이터 분석과 데이터 엔지니어링을 위한 강력한 도구를 습득하고 실무에 적용하세요.\n","keywords":["Apache Spark","Spark SQL","SQL","View","PySpark","데이터 엔지니어링","스파크","Study"],"articleBody":"Spark SQL # 스파크 SQL은 다음과 같은 특징을 갖는다.\n정형화 API가 엔진으로 제공한다. 다양한 정형 데이터(Parquet 등)를 읽거나 쓸 수 있다. 외부 BI 툴(태블로 등)의 데이터 소스나 RDBMS(MySQL 등)의 데이터를 쿼리할 수 있다. 정형 데이터에 대해 SQL 쿼리를 실행할 수 있는 대화형 쉘을 제공한다. Spark SQL 사용법 # Copy python spark.sql(\"SELECT * FROM table\") SparkSession 객체에 sql() 함수를 사용한다. 쿼리 결과로는 DataFrame 객체가 반환된다.\nSpark SQL 활용 (Python) # databricks/LearningSparkV2의 databricks-datasets/learning-spark-v2/flights 경로에서 미국 항공편 운항 지연 데이터세트 departuredelays.csv 를 가져온다. 해당 데이터를 활용해 아래와 같이 임시뷰를 생성한다.\nCopy python from pyspark.sql import SparkSession spark = (SparkSession .builder .appName(\"SparkSQLExampleApp\") .getOrCreate()) # 데이터 경로 csv_file = \"data/flights/departuredelays.csv\" # 스키마를 추론하여 데이터를 읽기 df = (spark.read.format(\"csv\") .option(\"inferSchema\", \"true\") .option(\"header\", \"true\") .load(csv_file)) # 데이터로부터 임시뷰를 생성 df.createOrReplaceTempView(\"delay_flights\") 스파크 SQL을 사용해 임시뷰에 대해 SQL 쿼리를 실행할 수 있다. 스파크 SQL은 ANSI:2003과 호환되는 SQl 인터페이스를 제공한다.\nCopy python spark.sql(\"\"\" SELECT distance, origin, destination FROM delay_flights WHERE distance \u003e 1000 ORDER BY distance DESC;\"\"\").show(10) Copy bash +--------+------+-----------+ |distance|origin|destination| +--------+------+-----------+ | 4330| HNL| JFK| | 4330| HNL| JFK| | 4330| HNL| JFK| | 4330| HNL| JFK| | 4330| HNL| JFK| | 4330| HNL| JFK| | 4330| HNL| JFK| | 4330| HNL| JFK| | 4330| HNL| JFK| | 4330| HNL| JFK| +--------+------+-----------+ only showing top 10 rows 위의 쿼리는 아래 파이썬 예제와 같이 동등한 DataFrame API로 표현할 수 있다.\nCopy python from pyspark.sql.functions import col, desc (df.select(\"distance\", \"origin\", \"destination\") .where(col(\"distance\") \u003e 1000) .orderBy(desc(\"distance\"))).show(10) SQL 쿼리로 단순 SELECT 조회뿐 아니라 현재 생성된 임시뷰 목록을 조회할 수도 있다.\nCopy python spark.sql(\"SHOW TABLES;\").show() Copy bash +---------+-------------+-----------+ |namespace| tableName|isTemporary| +---------+-------------+-----------+ | |delay_flights| true| +---------+-------------+-----------+ 앞에서 스키마를 추론하여 DataFrame을 읽었는데, SQL 쿼리로 어떤 스키마로 인식되었는지 확인해 보았다. DataFrame 객체의 스키마 df.schema 의 출력 결과와 동일하다.\nCopy python spark.sql(\"DESC delay_flights;\").show() Copy bash +-----------+---------+-------+ | col_name|data_type|comment| +-----------+---------+-------+ | date| int| NULL| | delay| int| NULL| | distance| int| NULL| | origin| string| NULL| |destination| string| NULL| +-----------+---------+-------+ Table \u0026 View # 스파크는 테이블을 위한 별도 메타스토어를 생성하지 않고 기본적으로 /user/hive/warehouse 경로에 있는 아파치 하이브 메타스토어를 사용해 테이블에 대한 모든 메타데이터를 유지한다.\n스파크는 관리형과 비관리형이라는 두 가지 유형의 테이블로 만들 수 있다.\n관리형 테이블은 스파크가 메타데이터와 파일 저장소의 데이터를 모두 관리한다. 따라서, DROP TABLE 과 같은 SQL 명령에 대해 메타데이터와 실제 데이터를 모두 삭제한다.\n반면에 비관리형 테이블은 스파크가 메타데이터만 관리하고 외부 데이터 소스에서 데이터를 직접 관리한다. 그래서, DROP TABLE 명령에도 실제 데이터는 그대로 두고 메타데이터만 삭제한다.\n테이블 생성하기 # 스파크는 기본적으로 default 데이터베이스 안에 테이블을 생성한다. SparkSession을 열고 현재 접속한 데이터베이스를 조회하면 알 수 있다.\nCopy python spark.sql(\"SELECT current_database();\").show() Copy bash +----------------+ |current_schema()| +----------------+ | default| +----------------+ 우선, SQL 명령어를 실행하여 새로운 데이터베이스 learn_spark_db 를 생성할 수 있다. 생성한 데이터베이스를 사용하고 다시 현재 접속한 데이터베이스를 확인해 보았다.\nCopy python spark.sql(\"CREATE DATABASE learn_spark_db;\") spark.sql(\"USE learn_spark_db;\") spark.sql(\"SELECT current_database();\").show() Copy bash +----------------+ |current_schema()| +----------------+ | learn_spark_db| +----------------+ 관리형 테이블 생성하기 # CREATE 문을 사용하여 현재 데이터베이스 안에 관리형 테이블을 생성할 수 있다.\nCopy python table = \"managed_delay_flights\" schema = \"date STRING, delay INT, distaince INT, origin STRING, destination STRING\" spark.sql(\"CREATE TABLE {} ({});\".format(table, schema)) 위 SQL 쿼리는 마찬가지로 아래처럼 DataFrame API로 표현할 수도 있다. 이미 테이블을 만들었을 경우, 아래 파이썬 예제를 그대로 실행하면 TABLE_OR_VIEW_ALREADY_EXISTS 에러가 발생하므로 mode=\"overwrite\" 옵션을 넣어주어 기존 테이블을 덮어쓴다.\nCopy python csv_file = \"data/flights/departuredelays.csv\" flights_df = spark.read.csv(csv_file, schema=schema) flights_df.write.saveAsTable(table, mode=\"overwrite\") 테이블을 생성하게 되면 현재 위치 아래의 spark-warehouse/{{DB명}}.db/{{테이블명}} 경로에 .parquet 파일들이 생성된다. 스파크 공식문서 중 Hive Table을 참고하면, 기본 디렉토리인 spark-warehouse 는 SparkSession을 실행할 때 spark.sql.warehouse.dir 설정을 통해 변경할 수 있다.\nCopy python warehouse_location = abspath('spark-warehouse') spark = SparkSession \\ .builder \\ .appName(\"Python Spark SQL Hive integration example\") \\ .config(\"spark.sql.warehouse.dir\", warehouse_location) \\ .enableHiveSupport() \\ .getOrCreate() 정적 설정이라 세션 실행 중에는 변경할 수 없어서 세션을 종료하고 다시 실행했다. saved 경로로 변경하고 다시 관리형 테이블을 생성해보니 해당 위치에 Parquet 파일들이 만들어졌다.\nCopy python from pyspark.sql import SparkSession from pathlib import Path warehouse_location = Path(\"saved\") warehouse_location.mkdir(exist_ok=True) spark = (SparkSession .builder .appName(\"SparkSQLExampleApp\") .config(\"spark.sql.warehouse.dir\", str(warehouse_location.absolute())) .getOrCreate()) 비관리형 테이블 생성하기 # 기존 CREATE 문을 사용하는 SQL 쿼리에서 뒤에 USING 키워드로 시작하는 CSV 파일 경로를 붙여주어 외부 데이터 소스로부터 비관리형 테이블을 생성할 수 있다.\nCopy python import os table = \"unmanaged_delay_flights\" schema = \"date STRING, delay INT, distaince INT, origin STRING, destination STRING\" csv_file = os.path.join(os.getcwd(), \"data/flights/departuredelays.csv\") spark.sql(\"CREATE TABLE {} ({}) USING csv OPTIONS (PATH '{}');\".format(table, schema, csv_file)) CSV 파일의 상대경로로 SQL 쿼리를 실행해보니까 FileStreamSink: Assume no metadata directory. 경고 메시지가 발생했는데 절대경로로 바꿔주니까 해결되었다.\nSQL 쿼리를 DataFrame API로 표현하면 아래와 같다. 관리형 테이블을 만드는 구문이랑 거의 비슷한데, path 옵션으로 /tmp 경로를 지정하는데 차이가 있다.\nCopy python (flights_df .write .option(\"path\", \"/tmp/data/delay_flights\") .saveAsTable(table, mode=\"overwrite\")) 뷰 생성하기 # 기존 테이블을 토대로 뷰를 만들 수 있다. 전역(모든 SparkSession) 또는 세션 범위에서 생성할 수 있고, Spark Application이 종료되면 뷰는 사라진다.\n전역 임시 뷰는 SQL 쿼리에서는 GLOBAL TEMP VIEW 키워드를 추가하고, 파이썬에서는 createOrReplaceGlobalTempView() 함수를 호출하여 생성할 수 있다.\nCopy python table = \"us_origin_airport_SFO\" spark.sql(\"\"\" CREATE OR REPLACE GLOBAL TEMP VIEW {} AS SELECT date, delay, origin, destination FROM delay_flights WHERE origin = 'SFO'; \"\"\".format(table)) Copy python from pyspark.sql.functions import col table = \"us_origin_airport_SFO\" (df.select(\"date\", \"delay\", \"origin\", \"destination\") .where(col(\"origin\") == \"SFO\") .createOrReplaceGlobalTempView(table)) 전역 임시 뷰는 global_temp 라는 전역 임시 데이터베이스에 생성되며, global_temp. 처럼 명시하여 뷰 테이블에 접근할 수 있다. 일반 임시 뷰는 현재 데이터베이스에 생성되므로 global_temp 접두사를 붙일 필요가 없다.\nCopy python spark.sql(\"SELECT * FROM global_temp.{};\".format(table)).show(5) 메타데이터 보기 # 스파크는 관리형 및 비관리형 테이블에 대한 메타데이터를 관리한다. 메타데이터는 스파크 SQL의 상위 추상화 모듈인 카탈로그에 저장된다. 카탈로그에서 아래와 같이 데이터베이스, 테이블, 칼럼 목록을 조회할 수 있다.\nCopy python \u003e\u003e\u003e spark.catalog.listDatabases() [Database(name='default', catalog='spark_catalog', description='default database', locationUri='file:/Users/cuz/Documents/Github/study/spark/saved')] Copy python \u003e\u003e\u003e spark.catalog.listTables() [Table(name='delay_flights', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)] Copy python \u003e\u003e\u003e spark.catalog.listColumns(\"delay_flights\") [Column(name='date', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False, isCluster=False), Column(name='delay', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False, isCluster=False), Column(name='distance', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False, isCluster=False), Column(name='origin', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False, isCluster=False), Column(name='destination', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False, isCluster=False)] SQL 테이블 캐싱하기 # 스파크 공식문서 중 CACHE TABLE을 참고하면, CACHE TABLE 쿼리를 사용하여 임시 뷰를 캐싱할 수 있다. CACHE LAZY TABLE 과 같이 LAZY 파라미터를 추가하면 테이블이 사용되는 시점까지 캐싱을 미룰 수 있다.\nCopy python spark.sql(\"CACHE TABLE delay_flights;\") 테이블 캐시가 활성화 상태인지 보려면 카탈로그가 가진 isCached 함수를 참고할 수 있다. 캐시가 활성화되었다면 True, 아니면 False 를 반환한다.\nCopy python \u003e\u003e\u003e spark.catalog.isCached(\"delay_flights\") True Copy python \u003e\u003e\u003e spark.catalog.isCached(\"global_temp.us_origin_airport_sfo\") False 테이블 캐시를 삭제하고 싶다면 UNCACHE TABLE 쿼리를 사용한다.\nCopy python \u003e\u003e\u003e spark.sql(\"UNCACHE TABLE delay_flights;\") \u003e\u003e\u003e spark.catalog.isCached(\"delay_flights\") False 테이블을 DataFrame으로 변환하기 # SQL 쿼리로 테이블 전체를 읽을 수도 있지만, table() 함수를 사용할 수도 있다.\nCopy python spark.sql(\"SELECT * FROM delay_flights;\") Copy python spark.table(\"delay_flights\") sql() 과 table() 모두 DataFrame 객체를 반환한다.\nReferences # https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/ https://github.com/databricks/LearningSparkV2/tree/master/databricks-datasets/learning-spark-v2/flights https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-cache-table.html https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-uncache-table.html ","wordCount":"1066","inLanguage":"en","image":"https:\/\/dl.dropboxusercontent.com\/scl\/fi\/iafnblb6k95kbw7bwn2xj\/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6\u0026dl=0","datePublished":"2025-07-05T23:03:04+09:00","dateModified":"2025-07-05T23:03:04+09:00","author":{"@type":"Person","name":"minyeamer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://minyeamer.github.io/blog/spark-study-5/"},"publisher":{"@type":"Person","name":"Minystory","logo":{"@type":"ImageObject","url":"https://minyeamer.github.io/images/favicons/favicon.ico"}}}</script><title>Apache Spark - 스파크 SQL과 테이블/뷰 관리 | Minystory</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-5/><link rel=stylesheet href=/book.min.da9f864e1bccfac13510edef0c8dbe217c58d1ba58855d698051f162d9101fc5.css integrity="sha256-2p+GThvM+sE1EO3vDI2+IXxY0bpYhV1pgFHxYtkQH8U=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/search-input.min.001a2de4432bf89598db2196086b6547f20e393567b4b1b3a77de6490593f192.js integrity="sha256-ABot5EMr+JWY2yGWCGtlR/IOOTVntLGzp33mSQWT8ZI=" crossorigin=anonymous></script><link rel=preload href=/search-data.min.b5fc1c1b32ff60714603f9f856445cfd05f75b2319514d42e837b0ce77aa76dc.json as=fetch crossorigin><script>window.SEARCH_DATA_URL="/search-data.min.b5fc1c1b32ff60714603f9f856445cfd05f75b2319514d42e837b0ce77aa76dc.json"</script><script defer src=/search.min.f30f9834d4764fd9751da64098c954d01085f648ba9ca421a3c97582f8c47253.js integrity="sha256-8w+YNNR2T9l1HaZAmMlU0BCF9ki6nKQho8l1gvjEclM=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-BJ8Z9RMBPJ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BJ8Z9RMBPJ")</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css crossorigin=anonymous><script defer src=/scroll-progress.min.841ade7e507a5f6d59c4e7bf2fe2b2ca034070677ff7957eec55610a024dd776.js integrity="sha256-hBreflB6X21ZxOe/L+KyygNAcGd/95V+7FVhCgJN13Y=" crossorigin=anonymous></script><script defer src=/dark-mode.min.e41c6440ffd9967d6f6a419ff3ce09b862009fe1646ab265f5cb2817d2a508e3.js integrity="sha256-5BxkQP/Zln1vakGf884JuGIAn+FkarJl9csoF9KlCOM=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.9.0/highlightjs-line-numbers.min.js></script><script defer src=/copy-code.min.aaeef965f0b4992e55f976edaecb34a89d414e1791caa18c3f4f4376c6d8b5a8.js integrity="sha256-qu75ZfC0mS5V+Xbtrss0qJ1BTheRyqGMP09DdsbYtag=" crossorigin=anonymous></script><script defer src=/toc-highlightjs.093016f0ef312174ad862fdcf5792e88ab5442bd39beecc38d15643f71ab5c31.min integrity="sha256-CTAW8O8xIXSthi/c9XkuiKtUQr05vuzDjRVkP3GrXDE=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-posts book-layout-post"><div class=scroll-progress><div class=scroll-progress-bar></div></div><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><div class=sidebar-profile><div class=profile-img-wrap><a href=https://minyeamer.github.io/><img src=/images/profile/menu.jpg alt=Profile class=profile-img></a></div><div class=sidebar-social><a href=https://github.com/minyeamer target=_blank title=GitHub><i class="fa-brands fa-github"></i>
</a><a href=/categories/ title=Categories><i class="fa-solid fa-folder"></i>
</a><a href=/tags/ title=Tags><i class="fa-solid fa-tags"></i>
</a><button id=dark-mode-toggle class=dark-mode-toggle aria-label="Toggle dark mode">
<i class="fa-solid fa-circle-half-stroke"></i></button></div></div><h2 class=book-brand><a class="flex align-center" href=/><span>Minystory</span></a></h2><div class="book-search hidden"><div class=search-input-container><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/ onkeydown='event.key==="Enter"&&goToSearchPage()'>
<button type=button id=book-search-button class=book-search-btn onclick=goToSearchPage()>
<i class="fa-solid fa-magnifying-glass"></i></button></div><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden");function goToSearchPage(){const t=document.getElementById("book-search-input"),e=t.value.trim();e&&(window.location.href="/search/?q="+encodeURIComponent(e))}</script><div class=book-categories><input type=checkbox class="hidden toggle" id=categories-control checked>
<label for=categories-control class="categories-toggle categories-link"><a href=/categories/><i class="fa-solid fa-folder"></i>
<span>전체</span>
<span class=category-count>(37)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul class=categories-menu id=categories-menu><li><input type=checkbox class="hidden toggle" id=cat-algorithm>
<label for=cat-algorithm class="categories-toggle categories-link"><a href=/categories/algorithm/><i class="fa-solid fa-folder"></i>
Algorithm
<span class=category-count>(4)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/algorithm/graph/><i class="fa-solid fa-file"></i>
Graph
<span class=category-count>(1)</span></a></li><li class=categories-link><a href=/categories/algorithm/python/><i class="fa-solid fa-file"></i>
Python
<span class=category-count>(2)</span></a></li><li class=categories-link><a href=/categories/algorithm/sql/><i class="fa-solid fa-file"></i>
SQL
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-cloud>
<label for=cat-cloud class="categories-toggle categories-link"><a href=/categories/cloud/><i class="fa-solid fa-folder"></i>
Cloud
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/cloud/kubernetes/><i class="fa-solid fa-file"></i>
Kubernetes
<span class=category-count>(2)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-analysis>
<label for=cat-data-analysis class="categories-toggle categories-link"><a href=/categories/data-analysis/><i class="fa-solid fa-folder"></i>
Data Analysis
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-analysis/dacon/><i class="fa-solid fa-file"></i>
Dacon
<span class=category-count>(2)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-engineering>
<label for=cat-data-engineering class="categories-toggle categories-link"><a href=/categories/data-engineering/><i class="fa-solid fa-folder"></i>
Data Engineering
<span class=category-count>(19)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-engineering/apache-airflow/><i class="fa-solid fa-file"></i>
Apache Airflow
<span class=category-count>(7)</span></a></li><li class=categories-link><a href=/categories/data-engineering/apache-spark/><i class="fa-solid fa-file"></i>
Apache Spark
<span class=category-count>(8)</span></a></li><li class=categories-link><a href=/categories/data-engineering/crawling/><i class="fa-solid fa-file"></i>
Crawling
<span class=category-count>(4)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-frontend>
<label for=cat-frontend class="categories-toggle categories-link"><a href=/categories/frontend/><i class="fa-solid fa-folder"></i>
Frontend
<span class=category-count>(7)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/frontend/blog/><i class="fa-solid fa-file"></i>
Blog
<span class=category-count>(7)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-linux>
<label for=cat-linux class="categories-toggle categories-link"><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
<span class=category-count>(1)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/linux/ubuntu/><i class="fa-solid fa-file"></i>
Ubuntu
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-project>
<label for=cat-project class="categories-toggle categories-link"><a href=/categories/project/><i class="fa-solid fa-folder"></i>
Project
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/project/open-source/><i class="fa-solid fa-file"></i>
Open Source
<span class=category-count>(1)</span></a></li><li class=categories-link><a href=/categories/project/tools/><i class="fa-solid fa-file"></i>
Tools
<span class=category-count>(1)</span></a></li></ul></li></ul></div><div class=recent-posts><div class=recent-posts-header><i class="fa-solid fa-clock"></i>
<span>최신글</span></div><ul class=recent-posts-list><li class=recent-post-item><a href=/blog/hugo-blog-3/ title="Hugo 블로그 만들기 (3) - Taxonomies로 태그/카테고리 페이지 커스터마이징"><div class=recent-post-title>Hugo 블로그 만들기 (3) - Taxonomies로 태그/카테고리 페이지 커스터마이징</div><div class=recent-post-date><time datetime=2025-11-22>2025.11.22</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-2/ title="Hugo 블로그 만들기 (2) - 메인 레이아웃 커스터마이징 (메뉴, 목차, 헤더)"><div class=recent-post-title>Hugo 블로그 만들기 (2) - 메인 레이아웃 커스터마이징 (메뉴, 목차, 헤더)</div><div class=recent-post-date><time datetime=2025-11-04>2025.11.04</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-1/ title="Hugo 블로그 만들기 (1) - 프로젝트 구성과 GitHub Pages 배포 (Submodule 활용)"><div class=recent-post-title>Hugo 블로그 만들기 (1) - 프로젝트 구성과 GitHub Pages 배포 (Submodule 활용)</div><div class=recent-post-date><time datetime=2025-11-01>2025.11.01</time></div></a></li><li class=recent-post-item><a href=/blog/openup-handson/ title="[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기"><div class=recent-post-title>[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기</div><div class=recent-post-date><time datetime=2025-10-28>2025.10.28</time></div></a></li><li class=recent-post-item><a href=/blog/uv-project/ title="[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리"><div class=recent-post-title>[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리</div><div class=recent-post-date><time datetime=2025-07-23>2025.07.23</time></div></a></li></ul></div></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><i class="fa-solid fa-bars book-icon" id=menu-icon></i></label><h3><a href=https://minyeamer.github.io/ class=site-title>Minystory</a></h3><label for=toc-control><i class="fa-solid fa-list book-icon" id=toc-icon></i></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#spark-sql>Spark SQL</a><ul><li><a href=#spark-sql-사용법>Spark SQL 사용법</a></li><li><a href=#spark-sql-활용-python>Spark SQL 활용 (Python)</a></li></ul></li><li><a href=#table--view>Table & View</a><ul><li><a href=#테이블-생성하기>테이블 생성하기</a></li><li><a href=#관리형-테이블-생성하기>관리형 테이블 생성하기</a></li><li><a href=#비관리형-테이블-생성하기>비관리형 테이블 생성하기</a></li><li><a href=#뷰-생성하기>뷰 생성하기</a></li><li><a href=#메타데이터-보기>메타데이터 보기</a></li><li><a href=#sql-테이블-캐싱하기>SQL 테이블 캐싱하기</a></li><li><a href=#테이블을-dataframe으로-변환하기>테이블을 DataFrame으로 변환하기</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></aside></header><article class="markdown book-article"><header class=post-header><div class=post-header-category><a href=/categories/data-engineering/apache-spark/ class=post-header-category-link>Data Engineering/Apache Spark</a></div><h1 class=post-header-title>Apache Spark - 스파크 SQL과 테이블/뷰 관리</h1><div class=post-header-date><time datetime=2025-07-05T23:03:04+09:00>2025. 7. 5. 23:03</time></div></header><div class=book-cover><img src="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0" alt="Cover Image" class=book-cover-img></div><h2 id=spark-sql>Spark SQL
<a class=anchor href=#spark-sql>#</a></h2><p>스파크 SQL은 다음과 같은 특징을 갖는다.</p><ul><li>정형화 API가 엔진으로 제공한다.</li><li>다양한 정형 데이터(Parquet 등)를 읽거나 쓸 수 있다.</li><li>외부 BI 툴(태블로 등)의 데이터 소스나 RDBMS(MySQL 등)의 데이터를 쿼리할 수 있다.</li><li>정형 데이터에 대해 SQL 쿼리를 실행할 수 있는 대화형 쉘을 제공한다.</li></ul><h3 id=spark-sql-사용법>Spark SQL 사용법
<a class=anchor href=#spark-sql-%ec%82%ac%ec%9a%a9%eb%b2%95>#</a></h3><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT * FROM table&#34;</span><span class=p>)</span></span></span></code></pre></div></div><p><code>SparkSession</code> 객체에 <code>sql()</code> 함수를 사용한다. 쿼리 결과로는 <code>DataFrame</code> 객체가 반환된다.</p><h3 id=spark-sql-활용-python>Spark SQL 활용 (Python)
<a class=anchor href=#spark-sql-%ed%99%9c%ec%9a%a9-python>#</a></h3><p><a href=https://github.com/databricks/LearningSparkV2/tree/master/databricks-datasets/learning-spark-v2/flights target=_blank rel="noopener noreferrer">databricks/LearningSparkV2</a>의
<code>databricks-datasets/learning-spark-v2/flights</code> 경로에서 미국 항공편 운항 지연 데이터세트
<code>departuredelays.csv</code> 를 가져온다. 해당 데이터를 활용해 아래와 같이 임시뷰를 생성한다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>SparkSession</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spark</span> <span class=o>=</span> <span class=p>(</span><span class=n>SparkSession</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>builder</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&#34;SparkSQLExampleApp&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>getOrCreate</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 데이터 경로</span>
</span></span><span class=line><span class=cl><span class=n>csv_file</span> <span class=o>=</span> <span class=s2>&#34;data/flights/departuredelays.csv&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 스키마를 추론하여 데이터를 읽기</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=p>(</span><span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&#34;csv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>option</span><span class=p>(</span><span class=s2>&#34;inferSchema&#34;</span><span class=p>,</span> <span class=s2>&#34;true&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>option</span><span class=p>(</span><span class=s2>&#34;header&#34;</span><span class=p>,</span> <span class=s2>&#34;true&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>csv_file</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 데이터로부터 임시뷰를 생성</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>createOrReplaceTempView</span><span class=p>(</span><span class=s2>&#34;delay_flights&#34;</span><span class=p>)</span></span></span></code></pre></div></div><p>스파크 SQL을 사용해 임시뷰에 대해 SQL 쿼리를 실행할 수 있다.
스파크 SQL은 ANSI:2003과 호환되는 SQl 인터페이스를 제공한다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>SELECT distance, origin, destination
</span></span></span><span class=line><span class=cl><span class=s2>FROM delay_flights
</span></span></span><span class=line><span class=cl><span class=s2>WHERE distance &gt; 1000
</span></span></span><span class=line><span class=cl><span class=s2>ORDER BY distance DESC;&#34;&#34;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------+------+-----------+
</span></span><span class=line><span class=cl><span class=p>|</span>distance<span class=p>|</span>origin<span class=p>|</span>destination<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------+------+-----------+
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    4330<span class=p>|</span>   HNL<span class=p>|</span>        JFK<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------+------+-----------+
</span></span><span class=line><span class=cl>only showing top <span class=m>10</span> rows</span></span></code></pre></div></div><p>위의 쿼리는 아래 파이썬 예제와 같이 동등한 DataFrame API로 표현할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>col</span><span class=p>,</span> <span class=n>desc</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;distance&#34;</span><span class=p>,</span> <span class=s2>&#34;origin&#34;</span><span class=p>,</span> <span class=s2>&#34;destination&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>col</span><span class=p>(</span><span class=s2>&#34;distance&#34;</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>1000</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=n>desc</span><span class=p>(</span><span class=s2>&#34;distance&#34;</span><span class=p>)))</span><span class=o>.</span><span class=n>show</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span></span></span></code></pre></div></div><p>SQL 쿼리로 단순 <code>SELECT</code> 조회뿐 아니라 현재 생성된 임시뷰 목록을 조회할 수도 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SHOW TABLES;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+---------+-------------+-----------+
</span></span><span class=line><span class=cl><span class=p>|</span>namespace<span class=p>|</span>    tableName<span class=p>|</span>isTemporary<span class=p>|</span>
</span></span><span class=line><span class=cl>+---------+-------------+-----------+
</span></span><span class=line><span class=cl><span class=p>|</span>         <span class=p>|</span>delay_flights<span class=p>|</span>       true<span class=p>|</span>
</span></span><span class=line><span class=cl>+---------+-------------+-----------+</span></span></code></pre></div></div><p>앞에서 스키마를 추론하여 DataFrame을 읽었는데, SQL 쿼리로 어떤 스키마로 인식되었는지 확인해 보았다.
DataFrame 객체의 스키마 <code>df.schema</code> 의 출력 결과와 동일하다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;DESC delay_flights;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+-----------+---------+-------+
</span></span><span class=line><span class=cl><span class=p>|</span>   col_name<span class=p>|</span>data_type<span class=p>|</span>comment<span class=p>|</span>
</span></span><span class=line><span class=cl>+-----------+---------+-------+
</span></span><span class=line><span class=cl><span class=p>|</span>       date<span class=p>|</span>      int<span class=p>|</span>   NULL<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>      delay<span class=p>|</span>      int<span class=p>|</span>   NULL<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>   distance<span class=p>|</span>      int<span class=p>|</span>   NULL<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>     origin<span class=p>|</span>   string<span class=p>|</span>   NULL<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>destination<span class=p>|</span>   string<span class=p>|</span>   NULL<span class=p>|</span>
</span></span><span class=line><span class=cl>+-----------+---------+-------+</span></span></code></pre></div></div><h2 id=table--view>Table & View
<a class=anchor href=#table--view>#</a></h2><p>스파크는 테이블을 위한 별도 메타스토어를 생성하지 않고 기본적으로 <code>/user/hive/warehouse</code> 경로에 있는
아파치 하이브 메타스토어를 사용해 테이블에 대한 모든 메타데이터를 유지한다.</p><p>스파크는 관리형과 비관리형이라는 두 가지 유형의 테이블로 만들 수 있다.</p><p><strong>관리형 테이블</strong>은 스파크가 메타데이터와 파일 저장소의 데이터를 모두 관리한다.
따라서, <code>DROP TABLE</code> 과 같은 SQL 명령에 대해 메타데이터와 실제 데이터를 모두 삭제한다.</p><p>반면에 <strong>비관리형 테이블</strong>은 스파크가 메타데이터만 관리하고 외부 데이터 소스에서 데이터를 직접 관리한다.
그래서, <code>DROP TABLE</code> 명령에도 실제 데이터는 그대로 두고 메타데이터만 삭제한다.</p><h3 id=테이블-생성하기>테이블 생성하기
<a class=anchor href=#%ed%85%8c%ec%9d%b4%eb%b8%94-%ec%83%9d%ec%84%b1%ed%95%98%ea%b8%b0>#</a></h3><p>스파크는 기본적으로 <code>default</code> 데이터베이스 안에 테이블을 생성한다.
SparkSession을 열고 현재 접속한 데이터베이스를 조회하면 알 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT current_database();&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+----------------+
</span></span><span class=line><span class=cl><span class=p>|</span>current_schema<span class=o>()</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+----------------+
</span></span><span class=line><span class=cl><span class=p>|</span>         default<span class=p>|</span>
</span></span><span class=line><span class=cl>+----------------+</span></span></code></pre></div></div><p>우선, SQL 명령어를 실행하여 새로운 데이터베이스 <code>learn_spark_db</code> 를 생성할 수 있다.
생성한 데이터베이스를 사용하고 다시 현재 접속한 데이터베이스를 확인해 보았다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;CREATE DATABASE learn_spark_db;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;USE learn_spark_db;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT current_database();&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+----------------+
</span></span><span class=line><span class=cl><span class=p>|</span>current_schema<span class=o>()</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+----------------+
</span></span><span class=line><span class=cl><span class=p>|</span>  learn_spark_db<span class=p>|</span>
</span></span><span class=line><span class=cl>+----------------+</span></span></code></pre></div></div><h3 id=관리형-테이블-생성하기>관리형 테이블 생성하기
<a class=anchor href=#%ea%b4%80%eb%a6%ac%ed%98%95-%ed%85%8c%ec%9d%b4%eb%b8%94-%ec%83%9d%ec%84%b1%ed%95%98%ea%b8%b0>#</a></h3><p><code>CREATE</code> 문을 사용하여 현재 데이터베이스 안에 관리형 테이블을 생성할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>table</span> <span class=o>=</span> <span class=s2>&#34;managed_delay_flights&#34;</span>
</span></span><span class=line><span class=cl><span class=n>schema</span> <span class=o>=</span> <span class=s2>&#34;date STRING, delay INT, distaince INT, origin STRING, destination STRING&#34;</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;CREATE TABLE </span><span class=si>{}</span><span class=s2> (</span><span class=si>{}</span><span class=s2>);&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>table</span><span class=p>,</span> <span class=n>schema</span><span class=p>))</span></span></span></code></pre></div></div><p>위 SQL 쿼리는 마찬가지로 아래처럼 DataFrame API로 표현할 수도 있다.
이미 테이블을 만들었을 경우, 아래 파이썬 예제를 그대로 실행하면 <code>TABLE_OR_VIEW_ALREADY_EXISTS</code> 에러가
발생하므로 <code>mode="overwrite"</code> 옵션을 넣어주어 기존 테이블을 덮어쓴다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>csv_file</span> <span class=o>=</span> <span class=s2>&#34;data/flights/departuredelays.csv&#34;</span>
</span></span><span class=line><span class=cl><span class=n>flights_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>csv</span><span class=p>(</span><span class=n>csv_file</span><span class=p>,</span> <span class=n>schema</span><span class=o>=</span><span class=n>schema</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>flights_df</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>saveAsTable</span><span class=p>(</span><span class=n>table</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s2>&#34;overwrite&#34;</span><span class=p>)</span></span></span></code></pre></div></div><p>테이블을 생성하게 되면 현재 위치 아래의 <code>spark-warehouse/{{DB명}}.db/{{테이블명}}</code> 경로에
<code>.parquet</code> 파일들이 생성된다. 스파크 공식문서 중
<a href=https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html target=_blank rel="noopener noreferrer">Hive Table</a>을 참고하면,
기본 디렉토리인 <code>spark-warehouse</code> 는 SparkSession을 실행할 때 <code>spark.sql.warehouse.dir</code> 설정을 통해 변경할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>warehouse_location</span> <span class=o>=</span> <span class=n>abspath</span><span class=p>(</span><span class=s1>&#39;spark-warehouse&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span> \
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>builder</span> \
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&#34;Python Spark SQL Hive integration example&#34;</span><span class=p>)</span> \
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&#34;spark.sql.warehouse.dir&#34;</span><span class=p>,</span> <span class=n>warehouse_location</span><span class=p>)</span> \
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>enableHiveSupport</span><span class=p>()</span> \
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span></span></span></code></pre></div></div><p>정적 설정이라 세션 실행 중에는 변경할 수 없어서 세션을 종료하고 다시 실행했다.
<code>saved</code> 경로로 변경하고 다시 관리형 테이블을 생성해보니 해당 위치에 Parquet 파일들이 만들어졌다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>SparkSession</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>warehouse_location</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&#34;saved&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>warehouse_location</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spark</span> <span class=o>=</span> <span class=p>(</span><span class=n>SparkSession</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>builder</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&#34;SparkSQLExampleApp&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&#34;spark.sql.warehouse.dir&#34;</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>warehouse_location</span><span class=o>.</span><span class=n>absolute</span><span class=p>()))</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>getOrCreate</span><span class=p>())</span></span></span></code></pre></div></div><h3 id=비관리형-테이블-생성하기>비관리형 테이블 생성하기
<a class=anchor href=#%eb%b9%84%ea%b4%80%eb%a6%ac%ed%98%95-%ed%85%8c%ec%9d%b4%eb%b8%94-%ec%83%9d%ec%84%b1%ed%95%98%ea%b8%b0>#</a></h3><p>기존 <code>CREATE</code> 문을 사용하는 SQL 쿼리에서 뒤에 <code>USING</code> 키워드로 시작하는
CSV 파일 경로를 붙여주어 외부 데이터 소스로부터 비관리형 테이블을 생성할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>table</span> <span class=o>=</span> <span class=s2>&#34;unmanaged_delay_flights&#34;</span>
</span></span><span class=line><span class=cl><span class=n>schema</span> <span class=o>=</span> <span class=s2>&#34;date STRING, delay INT, distaince INT, origin STRING, destination STRING&#34;</span>
</span></span><span class=line><span class=cl><span class=n>csv_file</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>getcwd</span><span class=p>(),</span> <span class=s2>&#34;data/flights/departuredelays.csv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;CREATE TABLE </span><span class=si>{}</span><span class=s2> (</span><span class=si>{}</span><span class=s2>) USING csv OPTIONS (PATH &#39;</span><span class=si>{}</span><span class=s2>&#39;);&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>table</span><span class=p>,</span> <span class=n>schema</span><span class=p>,</span> <span class=n>csv_file</span><span class=p>))</span></span></span></code></pre></div></div><p>CSV 파일의 상대경로로 SQL 쿼리를 실행해보니까 <code>FileStreamSink: Assume no metadata directory.</code>
경고 메시지가 발생했는데 절대경로로 바꿔주니까 해결되었다.</p><p>SQL 쿼리를 DataFrame API로 표현하면 아래와 같다. 관리형 테이블을 만드는 구문이랑 거의 비슷한데,
<code>path</code> 옵션으로 <code>/tmp</code> 경로를 지정하는데 차이가 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=p>(</span><span class=n>flights_df</span>
</span></span><span class=line><span class=cl>	<span class=o>.</span><span class=n>write</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>option</span><span class=p>(</span><span class=s2>&#34;path&#34;</span><span class=p>,</span> <span class=s2>&#34;/tmp/data/delay_flights&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>saveAsTable</span><span class=p>(</span><span class=n>table</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s2>&#34;overwrite&#34;</span><span class=p>))</span></span></span></code></pre></div></div><h3 id=뷰-생성하기>뷰 생성하기
<a class=anchor href=#%eb%b7%b0-%ec%83%9d%ec%84%b1%ed%95%98%ea%b8%b0>#</a></h3><p>기존 테이블을 토대로 뷰를 만들 수 있다. 전역(모든 SparkSession) 또는 세션 범위에서 생성할 수 있고,
Spark Application이 종료되면 뷰는 사라진다.</p><p>전역 임시 뷰는 SQL 쿼리에서는 <code>GLOBAL TEMP VIEW</code> 키워드를 추가하고,
파이썬에서는 <code>createOrReplaceGlobalTempView()</code> 함수를 호출하여 생성할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>table</span> <span class=o>=</span> <span class=s2>&#34;us_origin_airport_SFO&#34;</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>CREATE OR REPLACE GLOBAL TEMP VIEW </span><span class=si>{}</span><span class=s2> AS
</span></span></span><span class=line><span class=cl><span class=s2>SELECT date, delay, origin, destination FROM delay_flights
</span></span></span><span class=line><span class=cl><span class=s2>WHERE origin = &#39;SFO&#39;;
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>table</span><span class=p>))</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>col</span>
</span></span><span class=line><span class=cl><span class=n>table</span> <span class=o>=</span> <span class=s2>&#34;us_origin_airport_SFO&#34;</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;date&#34;</span><span class=p>,</span> <span class=s2>&#34;delay&#34;</span><span class=p>,</span> <span class=s2>&#34;origin&#34;</span><span class=p>,</span> <span class=s2>&#34;destination&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>col</span><span class=p>(</span><span class=s2>&#34;origin&#34;</span><span class=p>)</span> <span class=o>==</span> <span class=s2>&#34;SFO&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>createOrReplaceGlobalTempView</span><span class=p>(</span><span class=n>table</span><span class=p>))</span></span></span></code></pre></div></div><p>전역 임시 뷰는 <code>global_temp</code> 라는 전역 임시 데이터베이스에 생성되며,
<code>global_temp.&lt;view_name></code> 처럼 명시하여 뷰 테이블에 접근할 수 있다.
일반 임시 뷰는 현재 데이터베이스에 생성되므로 <code>global_temp</code> 접두사를 붙일 필요가 없다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT * FROM global_temp.</span><span class=si>{}</span><span class=s2>;&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>table</span><span class=p>))</span><span class=o>.</span><span class=n>show</span><span class=p>(</span><span class=mi>5</span><span class=p>)</span></span></span></code></pre></div></div><h3 id=메타데이터-보기>메타데이터 보기
<a class=anchor href=#%eb%a9%94%ed%83%80%eb%8d%b0%ec%9d%b4%ed%84%b0-%eb%b3%b4%ea%b8%b0>#</a></h3><p>스파크는 관리형 및 비관리형 테이블에 대한 메타데이터를 관리한다.
메타데이터는 스파크 SQL의 상위 추상화 모듈인 카탈로그에 저장된다.
카탈로그에서 아래와 같이 데이터베이스, 테이블, 칼럼 목록을 조회할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>spark</span><span class=o>.</span><span class=n>catalog</span><span class=o>.</span><span class=n>listDatabases</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>Database</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;default&#39;</span><span class=p>,</span> <span class=n>catalog</span><span class=o>=</span><span class=s1>&#39;spark_catalog&#39;</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s1>&#39;default database&#39;</span><span class=p>,</span> <span class=n>locationUri</span><span class=o>=</span><span class=s1>&#39;file:/Users/cuz/Documents/Github/study/spark/saved&#39;</span><span class=p>)]</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>spark</span><span class=o>.</span><span class=n>catalog</span><span class=o>.</span><span class=n>listTables</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>Table</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;delay_flights&#39;</span><span class=p>,</span> <span class=n>catalog</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>namespace</span><span class=o>=</span><span class=p>[],</span> <span class=n>description</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>tableType</span><span class=o>=</span><span class=s1>&#39;TEMPORARY&#39;</span><span class=p>,</span> <span class=n>isTemporary</span><span class=o>=</span><span class=kc>True</span><span class=p>)]</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>spark</span><span class=o>.</span><span class=n>catalog</span><span class=o>.</span><span class=n>listColumns</span><span class=p>(</span><span class=s2>&#34;delay_flights&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>Column</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;date&#39;</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>dataType</span><span class=o>=</span><span class=s1>&#39;int&#39;</span><span class=p>,</span> <span class=n>nullable</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>isPartition</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isBucket</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isCluster</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
</span></span><span class=line><span class=cl> <span class=n>Column</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;delay&#39;</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>dataType</span><span class=o>=</span><span class=s1>&#39;int&#39;</span><span class=p>,</span> <span class=n>nullable</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>isPartition</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isBucket</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isCluster</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
</span></span><span class=line><span class=cl> <span class=n>Column</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;distance&#39;</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>dataType</span><span class=o>=</span><span class=s1>&#39;int&#39;</span><span class=p>,</span> <span class=n>nullable</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>isPartition</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isBucket</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isCluster</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
</span></span><span class=line><span class=cl> <span class=n>Column</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;origin&#39;</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>dataType</span><span class=o>=</span><span class=s1>&#39;string&#39;</span><span class=p>,</span> <span class=n>nullable</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>isPartition</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isBucket</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isCluster</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
</span></span><span class=line><span class=cl> <span class=n>Column</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;destination&#39;</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>dataType</span><span class=o>=</span><span class=s1>&#39;string&#39;</span><span class=p>,</span> <span class=n>nullable</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>isPartition</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isBucket</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>isCluster</span><span class=o>=</span><span class=kc>False</span><span class=p>)]</span></span></span></code></pre></div></div><h3 id=sql-테이블-캐싱하기>SQL 테이블 캐싱하기
<a class=anchor href=#sql-%ed%85%8c%ec%9d%b4%eb%b8%94-%ec%ba%90%ec%8b%b1%ed%95%98%ea%b8%b0>#</a></h3><p>스파크 공식문서 중 <a href=https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-cache-table.html target=_blank rel="noopener noreferrer">CACHE TABLE</a>을 참고하면,
<code>CACHE TABLE</code> 쿼리를 사용하여 임시 뷰를 캐싱할 수 있다.
<code>CACHE LAZY TABLE</code> 과 같이 <code>LAZY</code> 파라미터를 추가하면 테이블이 사용되는 시점까지 캐싱을 미룰 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;CACHE TABLE delay_flights;&#34;</span><span class=p>)</span></span></span></code></pre></div></div><p>테이블 캐시가 활성화 상태인지 보려면 카탈로그가 가진 <code>isCached</code> 함수를 참고할 수 있다.
캐시가 활성화되었다면 <code>True</code>, 아니면 <code>False</code> 를 반환한다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>spark</span><span class=o>.</span><span class=n>catalog</span><span class=o>.</span><span class=n>isCached</span><span class=p>(</span><span class=s2>&#34;delay_flights&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=kc>True</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>spark</span><span class=o>.</span><span class=n>catalog</span><span class=o>.</span><span class=n>isCached</span><span class=p>(</span><span class=s2>&#34;global_temp.us_origin_airport_sfo&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=kc>False</span></span></span></code></pre></div></div><p>테이블 캐시를 삭제하고 싶다면 <code>UNCACHE TABLE</code> 쿼리를 사용한다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;UNCACHE TABLE delay_flights;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>spark</span><span class=o>.</span><span class=n>catalog</span><span class=o>.</span><span class=n>isCached</span><span class=p>(</span><span class=s2>&#34;delay_flights&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=kc>False</span></span></span></code></pre></div></div><h3 id=테이블을-dataframe으로-변환하기>테이블을 DataFrame으로 변환하기
<a class=anchor href=#%ed%85%8c%ec%9d%b4%eb%b8%94%ec%9d%84-dataframe%ec%9c%bc%eb%a1%9c-%eb%b3%80%ed%99%98%ed%95%98%ea%b8%b0>#</a></h3><p>SQL 쿼리로 테이블 전체를 읽을 수도 있지만, <code>table()</code> 함수를 사용할 수도 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT * FROM delay_flights;&#34;</span><span class=p>)</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>table</span><span class=p>(</span><span class=s2>&#34;delay_flights&#34;</span><span class=p>)</span></span></span></code></pre></div></div><p><code>sql()</code> 과 <code>table()</code> 모두 <code>DataFrame</code> 객체를 반환한다.</p><h2 id=references>References
<a class=anchor href=#references>#</a></h2><ul><li><a href=https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/ target=_blank rel="noopener noreferrer">https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/</a></li><li><a href=https://github.com/databricks/LearningSparkV2/tree/master/databricks-datasets/learning-spark-v2/flights target=_blank rel="noopener noreferrer">https://github.com/databricks/LearningSparkV2/tree/master/databricks-datasets/learning-spark-v2/flights</a></li><li><a href=https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html</a></li><li><a href=https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-cache-table.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-cache-table.html</a></li><li><a href=https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-uncache-table.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-uncache-table.html</a></li></ul></article><div class=book-nav><button class=book-nav-btn3 onclick='window.scrollTo({top:0,behavior:"smooth"})' title="Go to top">
<i class="fa fa-chevron-up"></i>
</button>
<button class=book-nav-btn3 onclick='window.scrollTo({top:document.body.scrollHeight,behavior:"smooth"})' title="Go to bottom">
<i class="fa fa-chevron-down"></i>
<button class=book-nav-btn3 onclick=history.back() title="Go back">
<i class="fa-solid fa-arrow-left"></i></button></div><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class=post-tags><a href=/tags/apache-spark/ class=tag>#Apache Spark</a>
<a href=/tags/spark-sql/ class=tag>#Spark SQL</a>
<a href=/tags/sql/ class=tag>#SQL</a>
<a href=/tags/view/ class=tag>#View</a>
<a href=/tags/pyspark/ class=tag>#PySpark</a>
<a href=/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81/ class=tag>#데이터 엔지니어링</a>
<a href=/tags/%EC%8A%A4%ED%8C%8C%ED%81%AC/ class=tag>#스파크</a>
<a href=/tags/study/ class=tag>#Study</a></div><div class=post-navigation><a href=/blog/spark-study-4/ class="post-nav-link post-nav-prev"><span class=post-nav-direction><i class="fa-solid fa-backward"></i> PREV</span>
<span class=post-nav-title>Apache Spark - DataFrame과 Dataset API 활용하기</span>
</a><a href=/blog/spark-study-6/ class="post-nav-link post-nav-next"><span class=post-nav-direction>NEXT <i class="fa-solid fa-forward"></i></span>
<span class=post-nav-title>Apache Spark - 다양한 데이터 소스 읽기/쓰기 (Parquet, JSON, CSV, Avro)</span></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script><div class=book-comments><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://minyeamer.github.io/blog/spark-study-5/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-5/"};(function(){var e=document,t=e.createElement("script");t.src="https://minyeamer.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})();function reloadDisqus(){window.DISQUS&&DISQUS.reset({reload:!0,config:function(){this.page.url="https://minyeamer.github.io/blog/spark-study-5/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-5/"}})}</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#spark-sql>Spark SQL</a><ul><li><a href=#spark-sql-사용법>Spark SQL 사용법</a></li><li><a href=#spark-sql-활용-python>Spark SQL 활용 (Python)</a></li></ul></li><li><a href=#table--view>Table & View</a><ul><li><a href=#테이블-생성하기>테이블 생성하기</a></li><li><a href=#관리형-테이블-생성하기>관리형 테이블 생성하기</a></li><li><a href=#비관리형-테이블-생성하기>비관리형 테이블 생성하기</a></li><li><a href=#뷰-생성하기>뷰 생성하기</a></li><li><a href=#메타데이터-보기>메타데이터 보기</a></li><li><a href=#sql-테이블-캐싱하기>SQL 테이블 캐싱하기</a></li><li><a href=#테이블을-dataframe으로-변환하기>테이블을 DataFrame으로 변환하기</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></div></aside></main></body></html>