<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content><meta name=keywords content="Apache Spark,Spark Architecture,SparkSession,Cluster Manager,PySpark,데이터 엔지니어링,스파크,Study"><meta name=description content="Apache Spark의 기본 개념과 아키텍처를 다루며, 스파크의 시작부터 컴포넌트, Spark Driver, SparkSession, Cluster Manager, 배포 모드까지 …"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><link rel=icon href=https://minyeamer.github.io/images/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://minyeamer.github.io/images/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://minyeamer.github.io/images/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><link rel=mask-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><meta name=google-site-verification content="u1tWcHmHUZWfFT1cHaku6sqU-bK40N3WLR-C-4VUWN0"><meta name=naver-site-verification content="6eaf8e9da1a6104780f056f1a7797fe5a3a5a0da"><meta property="og:title" content="Apache Spark - 스파크의 기본 개념과 아키텍처"><meta property="og:description" content="Apache Spark의 기본 개념과 아키텍처를 다루며, 스파크의 시작부터 컴포넌트, Spark Driver, SparkSession, Cluster Manager, 배포 모드까지 …"><meta property="og:type" content="article"><meta property="og:url" content="https://minyeamer.github.io/blog/spark-study-1/"><meta property="og:image" content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;raw=1"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-22T18:42:10+09:00"><meta property="article:modified_time" content="2025-06-22T18:42:10+09:00"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-8/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-7/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-6/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-5/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-4/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-3/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;raw=1"><meta name=twitter:title content="Apache Spark - 스파크의 기본 개념과 아키텍처"><meta name=twitter:description content="Apache Spark의 기본 개념과 아키텍처를 다루며, 스파크의 시작부터 컴포넌트, Spark Driver, SparkSession, Cluster Manager, 배포 모드까지 …"><meta name=twitter:site content="@https://x.com/minyeamer"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://minyeamer.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Apache Spark - 스파크의 기본 개념과 아키텍처","item":"https://minyeamer.github.io/blog/spark-study-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Spark - 스파크의 기본 개념과 아키텍처","name":"Apache Spark - 스파크의 기본 개념과 아키텍처","description":"Apache Spark의 기본 개념과 아키텍처를 다루며, 스파크의 시작부터 컴포넌트, Spark Driver, SparkSession, Cluster Manager, 배포 모드까지 단계별로 안내합니다. 데이터 엔지니어링과 빅데이터 처리를 위한 필수 지식을 습득하고 실무에 적용하세요.\n","keywords":["Apache Spark, Spark Architecture, SparkSession, Cluster Manager, PySpark, 데이터 엔지니어링, 스파크, Study"],"articleBody":" Apache Spark 배우기 1. 스파크의 기본 개념과 아키텍처 2. 로컬 환경에서 설치하고 PySpark 실행하기 3. 스파크 애플리케이션 구조와 RDD 이해하기 4. DataFrame과 Dataset API 활용하기 5. 스파크 SQL과 테이블/뷰 관리 6. 다양한 데이터 소스 읽기/쓰기 (Parquet, JSON, CSV, Avro) 7. 외부 데이터베이스 연동 (PostgreSQL, MySQL) 8. 사용자 정의 함수(UDF)와 고차 함수 활용하기 숨기기 목록 보기 1/8 Study Overview #러닝 스파크 2nd 개정판 과정을 따릅니다.\n목적 # 대용량 데이터 처리를 위한 아파치 스파크를 이론적으로 학습 책에서 대상으로 하는 스파크 3.x 버전과 25년 5월 출시된 Spark 4.0 버전을 비교 각 챕터에서 배운 것으로 실습할만한 것이 있다면 추가로 시도하기 실습은 PySpark API를 사용하며, 최신화된 PySpark 4.0.0 문서를 참조 챕터 # 아파치 스파크 소개: 통합 분석 엔진 아파치 스파크 다운로드 및 시작 아파치 스파크의 정형화 API 스파크 SQL과 데이터 프레임: 내장 데이터 소스 소개 스파크 SQL과 데이터 프레임: 외부 데이터 소스와 소통하기 스파크 SQL과 데이터세트 스파크 애플리케이션의 최적화 및 튜닝 정형화 스트리밍 아파치 스파크를 통한 안정적인 데이터 레이크 구축 MLlib을 사용한 머신러닝 아파치 스파크로 머신러닝 파이프라인 관리, 배포 및 확장 에필로그: 아파치 스파크 3.0 Spark Overview #스파크의 시작 #RDBMS 같은 전통적인 저장 시스템으로는 구글이 방대한 규모의 인터넷 문서를 다룰 수 없어 구글 파일 시스템(GFS), 맵리듀스(MapReduce), 빅테이블(BigTable) 등을 만들어 냈다. GFS는 클러스터 환경에서 분산 파일시스템을 제공하고, 빅테이블은 GFS를 기반으로 대규모 데이터 저장 수단을 제공한다. 맵리듀스는 함수형 프로그래밍 기반으로 대규모 데이터 분산 처리를 구현했다. 클러스터의 워커 노드들이 분산된 데이터에 연산을 하고(Map), 그 결과를 하나로 합쳐(Reduce) 최종 결과를 생성해낸다. 이러한 접근 방식은 네트워크 트래픽을 크게 감소시키면서 로컬 디스크에 대한 I/O를 극대화한다.\nGFS는 하둡 파일 시스템과 맵리듀스 구현에 영향을 주었다. HDFS의 맵리듀스에는 몇 가지 단점이 있었다. 첫째, 운영이 복잡해 관리가 쉽지 않았다. 둘째, 배치 처리를 위한 맵리듀스 API의 기본 설정 코드가 너무 많이 필요했다. 셋째, 맵리듀스 태스크가 필요해질 때마다 중간 과정의 데이터를 로컬 디스크에 써야 했다. 반복적인 I/O 작업에 의해 거대한 맵리듀스 작업에 며칠이 걸리기도 했다.\nUC 버클리 연구원들은 동적이고 반복적인 작업에서 비효율적인 맵리듀스를 개선하여 단순하고 빠르고 쉬운 스파크를 만들기로 했다. 구체적으로는 더 높은 장애 내구성을 갖고, 병렬성을 높이면서, 맵리듀스 연산을 위한 중간 결과를 메모리에 저장하고, 간편한 API를 다양한 언어로 제공하고자 했다.\n아파치 스파크란? #아파치 스파크는 데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 위한 통합형 엔진이다. 중간 연산을 메모리에 저장하고 머신러닝, SQL, 스트리밍 처리, 그래프 처리 등을 간편하게 API로 지원한다.\n스파크의 설계 철학에는 속도, 사용 편리성, 모듈성, 확장성이 있다.\n속도 스파크는 하드웨어 산업의 발전으로 메모리 성능 향상에 많은 이득을 얻었는데, 모든 중간 결과를 메모리에 저장해 I/O 작업을 제한하고 속도를 향상시켰다. 또한, 질의 연산을 DAG로 구성해 효율적인 연산 그래프를 만들고 병렬 수행을 지원한다.\n사용 편리성 데이터프레임이나 데이터세트 같이 고수준으로 추상화된 자료 구조를 사용해 단순성을 실현시켰다. 다양한 언어로 연산을 지원하여 사용자들이 편한 언어로 빅데이터를 처리할 수 있다.\n모듈성 문서화가 잘된 API를 제공하며, 스파크 SQL이나 정형화 스트리밍 등의 핵심 컴포넌트를 하나의 엔진 안에서 연동된 상태로 사용할 수 있다.\n확장성 스파크는 저장보다는 빠른 병렬 연산 엔진에 초점을 맞춰, 수많은 데이터 소스에서 데이터를 읽어 들여 메모리에서 처리하는 것이 가능하다. 서드파티 패키지 목록에는 다양한 외부 데이터 소스가 포함되어 있다.\n아파치 컴포넌트 #다양한 워크로드를 위해 스파크 SQL, 스파크 MLlib, 스파크 정형화 스트리밍, GraphX를 제공한다. 자바, R, 스칼라, SQL, 파이썬 중 어느 것으로 스파크 코드를 작성해도 바이트 코드로 변환되어 워커 노드의 JVM에서 실행된다.\n스파크 SQL RDBMS 테이블이나 CSV와 같은 구조화된 데이터 파일 포맷에서 데이터를 읽어 들여 영구적이거나 임시적인 테이블을 생성한다. SQL 계통의 질의를 써서 데이터를 데이터프레임으로 읽어 들일 수 있다.\n스파크 MLlib 범용 머신러닝 알고리즘들이 들어 있다. 특성을 추출 및 가공하고 학습/검증 파이프라인을 구축하는 기능을 지원하며, 경사 하강법 최적화를 포함한 저수준 ML 기능을 포함한다.\n스파크 정형화 스트리밍 실시간으로 연결하고 반응하기 위한 데이터 모델은 스트림을 연속적으로 증가하는 테이블이자, 끝에 새로운 레코드가 추가되는 형태이다. 단순히 정형화 테이블로 보고 쿼리를 날리면 된다. 정형화 스트리밍 모델의 하부에는 스파크 SQL 엔진이 장애 복구와 지연 데이터의 모든 측면을 관리한다.\nGraphX 그래프를 조작하고 그래프 병렬 연산을 수행하기 위한 라이브러리다. 분석, 연결 탐색 등 표준적인 그래프 알고리즘과 커뮤니티 사용자들이 기여한 알고리즘을 포함한다.\nSpark Architecture # Spark Driver #SparkSession 객체를 초기화하는 책임을 가진 Spark Application의 일부이다. Spark Driver는 여러 가지 역할을 한다.\nCluster Manager와 통신하며 Spark Executor들을 위해 필요한 자원을 요청한다. 모든 스파크 작업을 DAG 연산 형태로 변환해 스케줄링한다. 각 실행 단위를 태스크로 나누어 Spark Executor들에게 분배한다. 자원이 한번 할당되면 그 다음부터는 Driver가 Executor와 직접 통신한다. SparkSession #스파크 2.0에서 모든 스파크 연산과 데이터에 대한 통합 연결 채널이 만들어졌다.\nSparkContext, SQLContext, HiveContext, SparkConf, StreamingContext 등이 합쳐졌다. 일원화된 연결 채널을 통해 JVM 실행 파라미터들을 만들고 데이터프레임이나 데이터세트를 정의한다. 데이터 소스에서 데이터를 읽고 메타데이터에 접근해 스파크 SQL 질의를 실행할 수 있다. SparkSession은 모든 스파크 기능을 한 군데에서 접근할 수 있는 시작점을 제공한다.\npyspark.sql.SparkSession 문서를 참조해 SparkSession 생성\nCopy python spark = ( SparkSession.builder .master(\"local\") # 원격 접속의 경우 .remote(\"sc://localhost\") .appName(\"LearnSpark\") .config(\"spark.sql.shuffle.partitions\", 6) .getOrCreate() )Cluster Manager #Spark Application이 실행되는 클러스터에서 자원을 관리 및 할당하는 책임을 가진다. Standalone, Hadoop YARN, Apache Mesos, Kubernetes 네 종류의 Cluster Manager를 지원한다.\nSpark Executor #클러스터의 각 워커 노드에서 동작하며, Driver와 통신하며 Task를 실행하는 역할을 한다. 대부분의 배포 모드에서 노드당 하나의 Executor만 실행한다.\n배포 모드 #스파크가 여러 환경에서 돌아갈 수 있도록 다양한 배포 모드를 지원한다. 추상화되어 있어 Cluster Manager는 실행 환경에 대한 정보가 필요없고, YARN이나 Kubernetes 같은 인기 있는 환경에 배포가 가능하다.\nMode Spark Driver Spark Executor Cluster Manager Local 단일 서버 같은 머신에서 단일 JVM 위에서 실행 Driver와 동일한 JVM 위에서 동작 동일한 호스트에서 실행 Standalone Cluster의 아무 노드에서나 실행 Cluster의 각 노드가 자체적인 Executor를 실행 Cluster의 아무 호스트에나 할당 YARN(Client) Cluster 외부의 Client에서 동작 YARM의 노드 매니저의 컨테이너 YARN의 리소스 매니저가 노드 매니저에 컨테이너 할당 YARN(Cluster) YARN 애플리케이션 마스터에서 동작 YARN(Client)와 동일 YARN(Client)와 동일 Kubernetes Kubernetes Pod에서 동작 각 워커가 자신의 Pod 내에서 실행 Kubernetes 마스터 분산 데이터 #물리적인 데이터는 HDFS나 클라우드 저장소에 존재한다. 데이터는 파티션으로 물리적인 수준에서 분산되고, 스파크는 파티션을 추상화하여 메모리의 데이터프레임 객체를 바라본다.\n파티셔닝은 효과적인 병렬 처리를 가능하게 해준다. 데이터를 조각내 청크나 파티션 단위로 분산해 Spark Executor가 네트워크 사용을 최소화하고 가까이 있는 데이터만 처리한다.\n스파크 활용사례 #데이터 사이언스 #데이터 사이언티스트들은 데이터를 정제하고 패턴을 발견하기 위해 데이터를 살펴본다. 대부분은 SQL에 능하고, NumPy나 pandas 같은 라이브러리를 편하게 사용한다. 모델 구축을 위해 분류, 회귀, 클러스터링 알고리즘을 어떻게 사용할지도 알아야 한다.\n스파크는 MLlib은 모델 파이프라인을 구축할 수 있는 일반적인 머신러닝 알고리즘들을 제공한다. 또한, 스파크 SQL로 일회성 데이터 탐색을 가능하게 해준다.\n데이터 엔지니어링 #클러스터링 모델은 독립적으로 존재하지 않고 아파치 카프카 같은 스트리밍 엔진과 연계해 동작한다. 데이터 파이프라인은 다양한 소스에서 오는 원본 데이터를 최종 단계로까지 변형해주며, 그런 데이터는 NoSQL이나 RDBMS 등에 저장된다.\n스파크의 정형화 스트리밍 API를 써서 실시간 또는 정적인 데이터 소스에 대한 ETL 파이프라인을 구축할 수 있게 해준다. 또한, 스파크가 연산을 쉽게 병렬화 해주어 고수준 언어에만 집중해 ETL을 수행할 수 있게 지원한다.\n스파크 사용 사례 # 클러스터 전체에 걸쳐 분산된 대규모 데이터세트의 병렬 처리 데이터 탐색이나 시각화를 위한 일회성이나 대화형 질의 수행 MLlib을 이용해 머신러닝 모델을 구축, 훈련, 평가 ","wordCount":"1074","inLanguage":"ko","image":"https:\/\/dl.dropboxusercontent.com\/scl\/fi\/iafnblb6k95kbw7bwn2xj\/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6\u0026raw=1","datePublished":"2025-06-22T18:42:10+09:00","dateModified":"2025-06-22T18:42:10+09:00","author":{"@type":"Person","name":"minyeamer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://minyeamer.github.io/blog/spark-study-1/"},"publisher":{"@type":"Person","name":"Minystory","logo":{"@type":"ImageObject","url":"https://minyeamer.github.io/images/favicons/favicon.ico"}}}</script><script>(function(){const e=256+768*1.3;window.innerWidth>e&&localStorage.getItem("menu-expanded")==="false"&&document.documentElement.classList.add("menu-initial-collapsed")})()</script><title>Apache Spark - 스파크의 기본 개념과 아키텍처</title><link rel=icon href=/images/favicon.ico><link rel=manifest href=/data/manifest.json><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-1/><link rel=stylesheet href=/main.min.2ce58856be3fcaae3b5b9d806c99660d9d3fb40adf78d46340b5c421dd9f16de.css integrity="sha256-LOWIVr4/yq47W52AbJlmDZ0/tArfeNRjQLXEId2fFt4=" crossorigin=anonymous><script async src="https://www.googletagmanager.com/gtag/js?id=G-BJ8Z9RMBPJ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BJ8Z9RMBPJ")</script><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css crossorigin=anonymous><script>(function(){const e=console.warn;console.warn=function(...n){const t=(new Error).stack||"";if(t.includes("highlight.min.js")||t.includes("highlightjs-line-numbers"))return;e.apply(console,n)}})()</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.9.0/highlightjs-line-numbers.min.js crossorigin=anonymous></script><script defer src=/js/scroll-progress.min.841ade7e507a5f6d59c4e7bf2fe2b2ca034070677ff7957eec55610a024dd776.js integrity="sha256-hBreflB6X21ZxOe/L+KyygNAcGd/95V+7FVhCgJN13Y=" crossorigin=anonymous></script><script defer src=/js/menu-toggle.min.dd99cf31bd583912ea1bbd2c953c8c6b53d89da9846e8f05c9189de9369c97c9.js integrity="sha256-3ZnPMb1YORLqG70slTyMa1PYnamEbo8FyRid6Tacl8k=" crossorigin=anonymous></script><script defer src=/js/toc-toggle.min.48870f47596275987bbd50f04ba301b2b9469da2b3ed9d94e569774691851717.js integrity="sha256-SIcPR1lidZh7vVDwS6MBsrlGnaKz7Z2U5Wl3RpGFFxc=" crossorigin=anonymous></script><script defer src=/js/set-theme.min.986446861d7c48b101b4a6f53724b7fc97d6efec2a87906c6630cb9e503897c4.js integrity="sha256-mGRGhh18SLEBtKb1NyS3/JfW7+wqh5BsZjDLnlA4l8Q=" crossorigin=anonymous></script><script defer src=/js/copy-code.min.e18ffc44cf6beb1757c467945bb2897b0e1cb2ee52f08b460ee3ee57f0db6d60.js integrity="sha256-4Y/8RM9r6xdXxGeUW7KJew4csu5S8ItGDuPuV/DbbWA=" crossorigin=anonymous></script><script defer src=/js/toc-highlight.min.7917ead4ecb7378779bfbf3f988251ac76bd55ca7f12fd5919870777dbcd6095.js integrity="sha256-eRfq1Oy3N4d5v78/mIJRrHa9Vcp/Ev1ZGYcHd9vNYJU=" crossorigin=anonymous></script><script defer src=/js/reading-time.min.c8cf75fb9d8569d73b13b6a2bf6f52c235ff03ad7848e0386ccce2d7dcb8d9be.js integrity="sha256-yM91+52Fadc7E7aiv29SwjX/A614SOA4bMzi19y42b4=" crossorigin=anonymous></script><script defer src=/js/image-zoom.min.73ef1954212429af5df3e0386860f8f9b32748998c0ed1eb62ed800e348a2fab.js integrity="sha256-c+8ZVCEkKa9d8+A4aGD4+bMnSJmMDtHrYu2ADjSKL6s=" crossorigin=anonymous></script><script>window.siteSearch=window.siteSearch||{}</script><script>window.siteSearch.contentUrl="/data/content.min.208f65a3c5fc26dd696b689f81a3931598786454457d4e6a5e5e2270a14b8918.json"</script><script>window.siteSearch.categoriesUrl="/data/categories.min.249a3bfbb1ae8ee6e09c08bd2449462f8e161c8a98748da0169c2abe6f79598e.json"</script><script>window.siteSearch.tagsUrl="/data/tags.min.11b7d30fcd3cbb5269823c54a83c4889d580a62df2d1988344ddf158197da767.json"</script><script defer src=/fuse.min.js></script><script defer src=/js/search/init.min.3ec02e8ced439eef10e68b1663c5dab0c0ec89f63a79e154e33b0d62221bdbdb.js integrity="sha256-PsAujO1Dnu8Q5osWY8XasMDsifY6eeFU4zsNYiIb29s=" crossorigin=anonymous></script><script defer src=/js/search/input.min.27eda7796db42efef8727211d407e1e656de277ab39ea388861f5c738641668c.js integrity="sha256-J+2neW20Lv74cnIR1Afh5lbeJ3qznqOIhh9cc4ZBZow=" crossorigin=anonymous></script><script defer src=/js/search/list.min.65c865585bcec3cd299a342aed710907648722cc5cea50ba08b5495a08033d42.js integrity="sha256-ZchlWFvOw80pmjQq7XEJB2SHIsxc6lC6CLVJWggDPUI=" crossorigin=anonymous></script></head><body dir=ltr class="site-kind-page site-type-posts site-layout-post"><div class=scroll-progress><div class=scroll-progress-bar></div></div><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><div class=menu-overlay></div><main class=container><aside class=site-menu aria-label=메뉴><div class=menu-content><nav><div class=menu-profile><div class=profile-image-wrap><a href=https://minyeamer.github.io/><img src=/images/profile/menu.jpg alt=Profile class=profile-image decoding=async></a></div><h2 class=profile-title><a class="flex align-center" href=https://minyeamer.github.io/><span>Minystory</span></a></h2></div><div class=menu-links><a href=https://github.com/minyeamer target=_blank id=github-link title=GitHub><i class="fa-brands fa-github"></i>
</a><a href=/categories/ id=categories-link title=Categories><i class="fa-solid fa-folder"></i>
</a><a href=/tags/ id=tags-link title=Tags><i class="fa-solid fa-tags"></i>
</a><button class=dark-mode-toggle id=theme-toggle-button aria-label="Toggle color scheme">
<i class="fa-solid fa-circle-half-stroke"></i></button></div><div class=menu-search id=search-input data-hotkeys=s/ role=button tabindex=0 aria-label=검색><i class="fa-solid fa-magnifying-glass search-icon"></i>
<span class=search-placeholder><code>/</code> 를 눌러 검색하세요</span></div><div class=menu-categories><input type=checkbox class="hidden toggle" id=categories-control checked>
<label for=categories-control class="categories-label categories-toggle"><a href=/categories/ class=categories-root><i class="fa-solid fa-folder"></i>
전체
<span class=category-count>(40)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li><input type=checkbox class="hidden toggle" id=cat-algorithm>
<label for=cat-algorithm class="categories-label categories-toggle"><a href="/search/?category1=Algorithm"><i class="fa-solid fa-folder"></i>Algorithm<span class=category-count>(4)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Algorithm&category2=Graph"><i class="fa-solid fa-file"></i>Graph<span class=category-count>(1)</span></a></li><li class=categories-label><a href="/search/?category1=Algorithm&category2=Python"><i class="fa-solid fa-file"></i>Python<span class=category-count>(2)</span></a></li><li class=categories-label><a href="/search/?category1=Algorithm&category2=SQL"><i class="fa-solid fa-file"></i>SQL<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-cloud>
<label for=cat-cloud class="categories-label categories-toggle"><a href="/search/?category1=Cloud"><i class="fa-solid fa-folder"></i>Cloud<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Cloud&category2=Kubernetes"><i class="fa-solid fa-file"></i>Kubernetes<span class=category-count>(2)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-analysis>
<label for=cat-data-analysis class="categories-label categories-toggle"><a href="/search/?category1=Data%20Analysis"><i class="fa-solid fa-folder"></i>Data Analysis<span class=category-count>(3)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Data%20Analysis&category2=Dacon"><i class="fa-solid fa-file"></i>Dacon<span class=category-count>(3)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-engineering>
<label for=cat-data-engineering class="categories-label categories-toggle"><a href="/search/?category1=Data%20Engineering"><i class="fa-solid fa-folder"></i>Data Engineering<span class=category-count>(19)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Data%20Engineering&category2=Apache%20Airflow"><i class="fa-solid fa-file"></i>Apache Airflow<span class=category-count>(7)</span></a></li><li class=categories-label><a href="/search/?category1=Data%20Engineering&category2=Apache%20Spark"><i class="fa-solid fa-file"></i>Apache Spark<span class=category-count>(8)</span></a></li><li class=categories-label><a href="/search/?category1=Data%20Engineering&category2=Crawling"><i class="fa-solid fa-file"></i>Crawling<span class=category-count>(4)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-frontend>
<label for=cat-frontend class="categories-label categories-toggle"><a href="/search/?category1=Frontend"><i class="fa-solid fa-folder"></i>Frontend<span class=category-count>(9)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Frontend&category2=Blog"><i class="fa-solid fa-file"></i>Blog<span class=category-count>(9)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-linux>
<label for=cat-linux class="categories-label categories-toggle"><a href="/search/?category1=Linux"><i class="fa-solid fa-folder"></i>Linux<span class=category-count>(1)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Linux&category2=Ubuntu"><i class="fa-solid fa-file"></i>Ubuntu<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-project>
<label for=cat-project class="categories-label categories-toggle"><a href="/search/?category1=Project"><i class="fa-solid fa-folder"></i>Project<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Project&category2=Open%20Source"><i class="fa-solid fa-file"></i>Open Source<span class=category-count>(1)</span></a></li><li class=categories-label><a href="/search/?category1=Project&category2=Tools"><i class="fa-solid fa-file"></i>Tools<span class=category-count>(1)</span></a></li></ul></li></ul></div><div class=recent-posts><div class=recent-post-label><i class="fa-solid fa-clock"></i>
<span>최신글</span></div><ul class=recent-post-list><li class=recent-post-item><a href=/blog/hugo-blog-5/ title="Hugo Disqus 댓글 연동 - 본문 레이아웃 개선하기 (헤더/푸터)"><div class=recent-post-title>Hugo Disqus 댓글 연동 - 본문 레이아웃 개선하기 (헤더/푸터)</div><div class=recent-post-date><time datetime=2025-12-15>2025.12.15</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-4/ title="Hugo 검색 기능 구현 - Fuse.js로 검색 인덱스 최적화하기"><div class=recent-post-title>Hugo 검색 기능 구현 - Fuse.js로 검색 인덱스 최적화하기</div><div class=recent-post-date><time datetime=2025-12-14>2025.12.14</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-3/ title="Hugo Taxonomies 커스터마이징 - 태그/카테고리 템플릿 구현"><div class=recent-post-title>Hugo Taxonomies 커스터마이징 - 태그/카테고리 템플릿 구현</div><div class=recent-post-date><time datetime=2025-11-22>2025.11.22</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-2/ title="Hugo Book 테마 커스터마이징 - 메뉴/목차/헤더 레이아웃 개선"><div class=recent-post-title>Hugo Book 테마 커스터마이징 - 메뉴/목차/헤더 레이아웃 개선</div><div class=recent-post-date><time datetime=2025-11-04>2025.11.04</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-1/ title="Hugo 블로그 만들기 - Git Submodule로 구성하고 배포하기"><div class=recent-post-title>Hugo 블로그 만들기 - Git Submodule로 구성하고 배포하기</div><div class=recent-post-date><time datetime=2025-11-01>2025.11.01</time></div></a></li></ul></div></nav><script>(function(){var e=document.querySelector("aside .menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=main-wrap><header class=site-header><div class="flex align-center justify-between"><label for=menu-control aria-label="메뉴 접기/펼치기" title="메뉴 접기/펼치기"><i class="fa-solid fa-bars menu-icon" id=menu-icon></i></label><div class=mobile-search id=mobile-search-input role=button tabindex=0 aria-label=검색><i class="fa-solid fa-magnifying-glass search-icon"></i>
<span class=mobile-title>Minystory</span>
<i class=mobile-title-pad></i></div><label for=toc-control aria-label="목차 접기/펼치기" title="목차 접기/펼치기"><i class="fa-solid fa-list menu-icon" id=toc-icon></i></label></div></header><article class="content-wrap markdown"><header class=content-header><div class=content-category><a href="/search/?category1=Data%20Engineering&category2=Apache%20Spark" class=content-category-link>Data Engineering/Apache Spark</a></div><h1 class=content-title>Apache Spark - 스파크의 기본 개념과 아키텍처</h1><div class=content-datetime><time datetime=2025-06-22T18:42:10+09:00>2025. 6. 22. 18:42
</time><span id=reading-time></span></div></header><div class=content-cover-wrap><img src="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;raw=1" class=content-cover alt="Cover Image" decoding=async></div><div id=series-anchor></div><div class=sc-series><div class=series-bookmark><svg width="32" height="48" fill="currentColor" viewBox="0 0 32 48" class="series-corner-image"><path fill="currentColor" d="M32 0H0v48h.163l16-16L32 47.836V0z"/></svg></div><div class=series-header><h2 class=series-title>Apache Spark 배우기</h2></div><input type=checkbox id=series-toggle class=series-toggle-input hidden><div class=series-content><ol class=series-list><li class="series-item active"><span class=series-item-index>1.</span>
<a href=/blog/spark-study-1/#series-anchor>스파크의 기본 개념과 아키텍처</a></li><li class=series-item><span class=series-item-index>2.</span>
<a href=/blog/spark-study-2/#series-anchor>로컬 환경에서 설치하고 PySpark 실행하기</a></li><li class=series-item><span class=series-item-index>3.</span>
<a href=/blog/spark-study-3/#series-anchor>스파크 애플리케이션 구조와 RDD 이해하기</a></li><li class=series-item><span class=series-item-index>4.</span>
<a href=/blog/spark-study-4/#series-anchor>DataFrame과 Dataset API 활용하기</a></li><li class=series-item><span class=series-item-index>5.</span>
<a href=/blog/spark-study-5/#series-anchor>스파크 SQL과 테이블/뷰 관리</a></li><li class=series-item><span class=series-item-index>6.</span>
<a href=/blog/spark-study-6/#series-anchor>다양한 데이터 소스 읽기/쓰기 (Parquet, JSON, CSV, Avro)</a></li><li class=series-item><span class=series-item-index>7.</span>
<a href=/blog/spark-study-7/#series-anchor>외부 데이터베이스 연동 (PostgreSQL, MySQL)</a></li><li class=series-item><span class=series-item-index>8.</span>
<a href=/blog/spark-study-8/#series-anchor>사용자 정의 함수(UDF)와 고차 함수 활용하기</a></li></ol></div><div class=series-footer><label for=series-toggle class=series-toggle-label><span class=series-toggle-icon><i class="fas fa-caret-up"></i></span>
<span class=series-toggle-text-hide>숨기기</span>
<span class=series-toggle-text-show>목록 보기</span></label><div class=series-nav><span class=series-nav-info>1/8</span><div class=series-nav-buttons><span class="series-nav-button disabled"><i class="fas fa-chevron-left"></i></span>
<a href=/blog/spark-study-2/#series-anchor class=series-nav-button><i class="fas fa-chevron-right"></i></a></div></div></div></div><script>(function(){const e=document.getElementById("series-toggle"),t="series-expanded",n=localStorage.getItem(t)??"true";n==="true"&&(e.checked=!0),e.addEventListener("change",function(){localStorage.setItem(t,this.checked)})})()</script><h2 id=study-overview>Study Overview
<a class=anchor href=#study-overview>#</a></h2><p><a href="https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=296379664" target=_blank rel="noopener noreferrer">러닝 스파크 2nd 개정판</a> 과정을 따릅니다.</p><h3 id=목적>목적
<a class=anchor href=#%eb%aa%a9%ec%a0%81>#</a></h3><ul><li>대용량 데이터 처리를 위한 아파치 스파크를 이론적으로 학습</li><li>책에서 대상으로 하는 스파크 3.x 버전과 25년 5월 출시된 Spark 4.0 버전을 비교</li><li>각 챕터에서 배운 것으로 실습할만한 것이 있다면 추가로 시도하기</li><li>실습은 PySpark API를 사용하며, 최신화된
<a href=https://spark.apache.org/docs/4.0.0/api/python/index.html target=_blank rel="noopener noreferrer">PySpark 4.0.0 문서</a>를 참조</li></ul><h3 id=챕터>챕터
<a class=anchor href=#%ec%b1%95%ed%84%b0>#</a></h3><blockquote class=sc-hint><ol><li>아파치 스파크 소개: 통합 분석 엔진</li><li>아파치 스파크 다운로드 및 시작</li><li>아파치 스파크의 정형화 API</li><li>스파크 SQL과 데이터 프레임: 내장 데이터 소스 소개</li><li>스파크 SQL과 데이터 프레임: 외부 데이터 소스와 소통하기</li><li>스파크 SQL과 데이터세트</li><li>스파크 애플리케이션의 최적화 및 튜닝</li><li>정형화 스트리밍</li><li>아파치 스파크를 통한 안정적인 데이터 레이크 구축</li><li>MLlib을 사용한 머신러닝</li><li>아파치 스파크로 머신러닝 파이프라인 관리, 배포 및 확장</li><li>에필로그: 아파치 스파크 3.0</li></ol></blockquote><h2 id=spark-overview>Spark Overview
<a class=anchor href=#spark-overview>#</a></h2><h3 id=스파크의-시작>스파크의 시작
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac%ec%9d%98-%ec%8b%9c%ec%9e%91>#</a></h3><p>RDBMS 같은 전통적인 저장 시스템으로는 구글이 방대한 규모의 인터넷 문서를 다룰 수 없어
구글 파일 시스템(GFS), 맵리듀스(MapReduce), 빅테이블(BigTable) 등을 만들어 냈다.
GFS는 클러스터 환경에서 분산 파일시스템을 제공하고, 빅테이블은 GFS를 기반으로 대규모 데이터 저장 수단을 제공한다.
맵리듀스는 함수형 프로그래밍 기반으로 대규모 데이터 분산 처리를 구현했다. 클러스터의 워커 노드들이
분산된 데이터에 연산을 하고(Map), 그 결과를 하나로 합쳐(Reduce) 최종 결과를 생성해낸다.
이러한 접근 방식은 네트워크 트래픽을 크게 감소시키면서 로컬 디스크에 대한 I/O를 극대화한다.</p><p>GFS는 하둡 파일 시스템과 맵리듀스 구현에 영향을 주었다. HDFS의 맵리듀스에는 몇 가지 단점이 있었다.
첫째, 운영이 복잡해 관리가 쉽지 않았다. 둘째, 배치 처리를 위한 맵리듀스 API의 기본 설정 코드가 너무 많이 필요했다.
셋째, 맵리듀스 태스크가 필요해질 때마다 중간 과정의 데이터를 로컬 디스크에 써야 했다.
반복적인 I/O 작업에 의해 거대한 맵리듀스 작업에 며칠이 걸리기도 했다.</p><p><label class=md-image for=md-image-toggle-0><input class="hidden toggle" type=checkbox id=md-image-toggle-0>
<img src="https://dl.dropboxusercontent.com/scl/fi/pg3qcymue8h7z8h8n8cau/spark-01-map-reduce.webp?rlkey=6bnfs4bxy1haa8e52335qv24a&amp;raw=1" alt="Big Data -> Split -> Map -> Reduce -> Output" loading=lazy decoding=async></label></p><p>UC 버클리 연구원들은 동적이고 반복적인 작업에서 비효율적인 맵리듀스를 개선하여 단순하고 빠르고 쉬운 스파크를 만들기로 했다.
구체적으로는 더 높은 장애 내구성을 갖고, 병렬성을 높이면서, 맵리듀스 연산을 위한 중간 결과를 메모리에 저장하고,
간편한 API를 다양한 언어로 제공하고자 했다.</p><h3 id=아파치-스파크란>아파치 스파크란?
<a class=anchor href=#%ec%95%84%ed%8c%8c%ec%b9%98-%ec%8a%a4%ed%8c%8c%ed%81%ac%eb%9e%80>#</a></h3><p>아파치 스파크는 데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 위한 통합형 엔진이다.
중간 연산을 메모리에 저장하고 머신러닝, SQL, 스트리밍 처리, 그래프 처리 등을 간편하게 API로 지원한다.</p><p>스파크의 설계 철학에는 속도, 사용 편리성, 모듈성, 확장성이 있다.</p><ol><li><p>속도
스파크는 하드웨어 산업의 발전으로 메모리 성능 향상에 많은 이득을 얻었는데, 모든 중간 결과를 메모리에 저장해
I/O 작업을 제한하고 속도를 향상시켰다. 또한, 질의 연산을 DAG로 구성해 효율적인 연산 그래프를 만들고 병렬 수행을 지원한다.</p></li><li><p>사용 편리성
데이터프레임이나 데이터세트 같이 고수준으로 추상화된 자료 구조를 사용해 단순성을 실현시켰다.
다양한 언어로 연산을 지원하여 사용자들이 편한 언어로 빅데이터를 처리할 수 있다.</p></li><li><p>모듈성
문서화가 잘된 API를 제공하며, 스파크 SQL이나 정형화 스트리밍 등의
핵심 컴포넌트를 하나의 엔진 안에서 연동된 상태로 사용할 수 있다.</p></li><li><p>확장성
스파크는 저장보다는 빠른 병렬 연산 엔진에 초점을 맞춰, 수많은 데이터 소스에서 데이터를 읽어 들여
메모리에서 처리하는 것이 가능하다. 서드파티 패키지 목록에는 다양한 외부 데이터 소스가 포함되어 있다.</p></li></ol><h3 id=아파치-컴포넌트>아파치 컴포넌트
<a class=anchor href=#%ec%95%84%ed%8c%8c%ec%b9%98-%ec%bb%b4%ed%8f%ac%eb%84%8c%ed%8a%b8>#</a></h3><p>다양한 워크로드를 위해 스파크 SQL, 스파크 MLlib, 스파크 정형화 스트리밍, GraphX를 제공한다.
자바, R, 스칼라, SQL, 파이썬 중 어느 것으로 스파크 코드를 작성해도 바이트 코드로 변환되어 워커 노드의 JVM에서 실행된다.</p><ol><li><p>스파크 SQL
RDBMS 테이블이나 CSV와 같은 구조화된 데이터 파일 포맷에서 데이터를 읽어 들여 영구적이거나
임시적인 테이블을 생성한다. SQL 계통의 질의를 써서 데이터를 데이터프레임으로 읽어 들일 수 있다.</p></li><li><p>스파크 MLlib
범용 머신러닝 알고리즘들이 들어 있다. 특성을 추출 및 가공하고 학습/검증 파이프라인을 구축하는 기능을
지원하며, 경사 하강법 최적화를 포함한 저수준 ML 기능을 포함한다.</p></li><li><p>스파크 정형화 스트리밍
실시간으로 연결하고 반응하기 위한 데이터 모델은 스트림을 연속적으로 증가하는 테이블이자,
끝에 새로운 레코드가 추가되는 형태이다. 단순히 정형화 테이블로 보고 쿼리를 날리면 된다.
정형화 스트리밍 모델의 하부에는 스파크 SQL 엔진이 장애 복구와 지연 데이터의 모든 측면을 관리한다.</p></li><li><p>GraphX
그래프를 조작하고 그래프 병렬 연산을 수행하기 위한 라이브러리다. 분석, 연결 탐색 등
표준적인 그래프 알고리즘과 커뮤니티 사용자들이 기여한 알고리즘을 포함한다.</p></li></ol><h2 id=spark-architecture>Spark Architecture
<a class=anchor href=#spark-architecture>#</a></h2><label class=sc-image for=sc-image-toggle-1 style=text-align:center><input class="hidden toggle" type=checkbox id=sc-image-toggle-1><img src="https://dl.dropboxusercontent.com/scl/fi/hhpp6o2d6m6grww5vz6t8/spark-02-architecture.webp?rlkey=mzdwo2l947nuead3shu2xeodz&amp;raw=1" alt="The Architecture of Apache Spark" loading=lazy decoding=async style=zgotmplz></label><h3 id=spark-driver>Spark Driver
<a class=anchor href=#spark-driver>#</a></h3><p>SparkSession 객체를 초기화하는 책임을 가진 Spark Application의 일부이다.
Spark Driver는 여러 가지 역할을 한다.</p><ol><li>Cluster Manager와 통신하며 Spark Executor들을 위해 필요한 자원을 요청한다.</li><li>모든 스파크 작업을 DAG 연산 형태로 변환해 스케줄링한다.</li><li>각 실행 단위를 태스크로 나누어 Spark Executor들에게 분배한다.</li><li>자원이 한번 할당되면 그 다음부터는 Driver가 Executor와 직접 통신한다.</li></ol><h3 id=sparksession>SparkSession
<a class=anchor href=#sparksession>#</a></h3><p>스파크 2.0에서 모든 스파크 연산과 데이터에 대한 통합 연결 채널이 만들어졌다.</p><ol><li>SparkContext, SQLContext, HiveContext, SparkConf, StreamingContext 등이 합쳐졌다.</li><li>일원화된 연결 채널을 통해 JVM 실행 파라미터들을 만들고 데이터프레임이나 데이터세트를 정의한다.</li><li>데이터 소스에서 데이터를 읽고 메타데이터에 접근해 스파크 SQL 질의를 실행할 수 있다.</li></ol><p>SparkSession은 모든 스파크 기능을 한 군데에서 접근할 수 있는 시작점을 제공한다.</p><blockquote class=sc-hint><p><a href=https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html target=_blank rel="noopener noreferrer">pyspark.sql.SparkSession</a>
문서를 참조해 SparkSession 생성</p></blockquote><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>master</span><span class=p>(</span><span class=s2>&#34;local&#34;</span><span class=p>)</span> <span class=c1># 원격 접속의 경우 .remote(&#34;sc://localhost&#34;)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&#34;LearnSpark&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&#34;spark.sql.shuffle.partitions&#34;</span><span class=p>,</span> <span class=mi>6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div></div><h3 id=cluster-manager>Cluster Manager
<a class=anchor href=#cluster-manager>#</a></h3><p>Spark Application이 실행되는 클러스터에서 자원을 관리 및 할당하는 책임을 가진다.
Standalone, Hadoop YARN, Apache Mesos, Kubernetes 네 종류의 Cluster Manager를 지원한다.</p><h3 id=spark-executor>Spark Executor
<a class=anchor href=#spark-executor>#</a></h3><p>클러스터의 각 워커 노드에서 동작하며, Driver와 통신하며 Task를 실행하는 역할을 한다.
대부분의 배포 모드에서 노드당 하나의 Executor만 실행한다.</p><h3 id=배포-모드>배포 모드
<a class=anchor href=#%eb%b0%b0%ed%8f%ac-%eb%aa%a8%eb%93%9c>#</a></h3><p>스파크가 여러 환경에서 돌아갈 수 있도록 다양한 배포 모드를 지원한다. 추상화되어 있어 Cluster Manager는 실행 환경에 대한 정보가 필요없고, YARN이나 Kubernetes 같은 인기 있는 환경에 배포가 가능하다.</p><table><thead><tr><th>Mode</th><th>Spark Driver</th><th>Spark Executor</th><th>Cluster Manager</th></tr></thead><tbody><tr><td>Local</td><td>단일 서버 같은 머신에서 단일 JVM 위에서 실행</td><td>Driver와 동일한 JVM 위에서 동작</td><td>동일한 호스트에서 실행</td></tr><tr><td>Standalone</td><td>Cluster의 아무 노드에서나 실행</td><td>Cluster의 각 노드가 자체적인 Executor를 실행</td><td>Cluster의 아무 호스트에나 할당</td></tr><tr><td>YARN(Client)</td><td>Cluster 외부의 Client에서 동작</td><td>YARM의 노드 매니저의 컨테이너</td><td>YARN의 리소스 매니저가 노드 매니저에 컨테이너 할당</td></tr><tr><td>YARN(Cluster)</td><td>YARN 애플리케이션 마스터에서 동작</td><td>YARN(Client)와 동일</td><td>YARN(Client)와 동일</td></tr><tr><td>Kubernetes</td><td>Kubernetes Pod에서 동작</td><td>각 워커가 자신의 Pod 내에서 실행</td><td>Kubernetes 마스터</td></tr></tbody></table><h3 id=분산-데이터>분산 데이터
<a class=anchor href=#%eb%b6%84%ec%82%b0-%eb%8d%b0%ec%9d%b4%ed%84%b0>#</a></h3><p>물리적인 데이터는 HDFS나 클라우드 저장소에 존재한다. 데이터는 파티션으로 물리적인 수준에서 분산되고, 스파크는 파티션을 추상화하여 메모리의 데이터프레임 객체를 바라본다.</p><p>파티셔닝은 효과적인 병렬 처리를 가능하게 해준다. 데이터를 조각내 청크나 파티션 단위로 분산해 Spark Executor가 네트워크 사용을 최소화하고 가까이 있는 데이터만 처리한다.</p><h2 id=스파크-활용사례>스파크 활용사례
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac-%ed%99%9c%ec%9a%a9%ec%82%ac%eb%a1%80>#</a></h2><h3 id=데이터-사이언스>데이터 사이언스
<a class=anchor href=#%eb%8d%b0%ec%9d%b4%ed%84%b0-%ec%82%ac%ec%9d%b4%ec%96%b8%ec%8a%a4>#</a></h3><p>데이터 사이언티스트들은 데이터를 정제하고 패턴을 발견하기 위해 데이터를 살펴본다. 대부분은 SQL에 능하고, NumPy나 pandas 같은 라이브러리를 편하게 사용한다. 모델 구축을 위해 분류, 회귀, 클러스터링 알고리즘을 어떻게 사용할지도 알아야 한다.</p><p>스파크는 MLlib은 모델 파이프라인을 구축할 수 있는 일반적인 머신러닝 알고리즘들을 제공한다. 또한, 스파크 SQL로 일회성 데이터 탐색을 가능하게 해준다.</p><h3 id=데이터-엔지니어링>데이터 엔지니어링
<a class=anchor href=#%eb%8d%b0%ec%9d%b4%ed%84%b0-%ec%97%94%ec%a7%80%eb%8b%88%ec%96%b4%eb%a7%81>#</a></h3><p>클러스터링 모델은 독립적으로 존재하지 않고 아파치 카프카 같은 스트리밍 엔진과 연계해 동작한다. 데이터 파이프라인은 다양한 소스에서 오는 원본 데이터를 최종 단계로까지 변형해주며, 그런 데이터는 NoSQL이나 RDBMS 등에 저장된다.</p><p>스파크의 정형화 스트리밍 API를 써서 실시간 또는 정적인 데이터 소스에 대한 ETL 파이프라인을 구축할 수 있게 해준다. 또한, 스파크가 연산을 쉽게 병렬화 해주어 고수준 언어에만 집중해 ETL을 수행할 수 있게 지원한다.</p><h3 id=스파크-사용-사례>스파크 사용 사례
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac-%ec%82%ac%ec%9a%a9-%ec%82%ac%eb%a1%80>#</a></h3><ol><li>클러스터 전체에 걸쳐 분산된 대규모 데이터세트의 병렬 처리</li><li>데이터 탐색이나 시각화를 위한 일회성이나 대화형 질의 수행</li><li>MLlib을 이용해 머신러닝 모델을 구축, 훈련, 평가</li></ol></article><footer class=site-footer><div class=tags-wrap><a href="/search/?tags=Apache%20Spark" class=tag>#Apache Spark</a>
<a href="/search/?tags=Spark%20Architecture" class=tag>#Spark Architecture</a>
<a href="/search/?tags=SparkSession" class=tag>#SparkSession</a>
<a href="/search/?tags=Cluster%20Manager" class=tag>#Cluster Manager</a>
<a href="/search/?tags=PySpark" class=tag>#PySpark</a>
<a href="/search/?tags=%eb%8d%b0%ec%9d%b4%ed%84%b0%20%ec%97%94%ec%a7%80%eb%8b%88%ec%96%b4%eb%a7%81" class=tag>#데이터 엔지니어링</a>
<a href="/search/?tags=%ec%8a%a4%ed%8c%8c%ed%81%ac" class=tag>#스파크</a>
<a href="/search/?tags=Study" class=tag>#Study</a></div><div class=prev-next-wrap><a href=/blog/airflow-study-7/ class=prev-link><span class=prev-next-label><i class="fa-solid fa-backward"></i> PREV</span>
<span class=prev-next-title>Apache Airflow - 외부 시스템 연동 (Connection, Hook, PostgreSQL)</span>
</a><a href=/blog/spark-study-2/ class=next-link><span class=prev-next-label>NEXT <i class="fa-solid fa-forward"></i></span>
<span class=prev-next-title>Apache Spark - 로컬 환경에서 설치하고 PySpark 실행하기</span></a></div><div class=comments-wrap><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://minyeamer.github.io/blog/spark-study-1/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-1/"};(function(){var e=document,t=e.createElement("script");t.src="https://minyeamer.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})();function reloadDisqus(){if(window.DISQUS){DISQUS.reset({reload:!0,config:function(){this.page.url="https://minyeamer.github.io/blog/spark-study-1/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-1/"}});const e=setInterval(()=>{const t=document.getElementById(atob(atob("WkdsemNYVnpYM1JvY21WaFpBPT0=")));var n=!1;if(t){const e=t.querySelector(atob(atob("VzNOeVl5bzlKMkZrY3lkZA==")));e&&(t.appendChild(e),n=!0)}n&&clearInterval(e)},1e3)}}</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div><div class="copyright-wrap flex justify-center"><small>Minystory - <a href=https://creativecommons.org/licenses/by/4.0/legalcode target=_blank rel="noopener noreferrer">© CC BY 4.0</a></small></div></footer><label for=menu-control class="hidden site-menu-overlay"></label></div><aside class=site-toc aria-label=목차><div class=toc-content><nav id=TableOfContents><ul><li><a href=#study-overview>Study Overview</a><ul><li><a href=#목적>목적</a></li><li><a href=#챕터>챕터</a></li></ul></li><li><a href=#spark-overview>Spark Overview</a><ul><li><a href=#스파크의-시작>스파크의 시작</a></li><li><a href=#아파치-스파크란>아파치 스파크란?</a></li><li><a href=#아파치-컴포넌트>아파치 컴포넌트</a></li></ul></li><li><a href=#spark-architecture>Spark Architecture</a><ul><li><a href=#spark-driver>Spark Driver</a></li><li><a href=#sparksession>SparkSession</a></li><li><a href=#cluster-manager>Cluster Manager</a></li><li><a href=#spark-executor>Spark Executor</a></li><li><a href=#배포-모드>배포 모드</a></li><li><a href=#분산-데이터>분산 데이터</a></li></ul></li><li><a href=#스파크-활용사례>스파크 활용사례</a><ul><li><a href=#데이터-사이언스>데이터 사이언스</a></li><li><a href=#데이터-엔지니어링>데이터 엔지니어링</a></li><li><a href=#스파크-사용-사례>스파크 사용 사례</a></li></ul></li></ul></nav></div><div class=hidden id=toc-config data-start=2 data-end=3></div></aside><div class=site-toolbar role=toolbar aria-label="툴바'"><input type=checkbox id=toolbar-toggle class="hidden toggle"><div class=toolbar-items><button class=toolbar-button onclick='window.scrollTo({top:0,behavior:"smooth"})' title="Go to top">
<i class="fa fa-chevron-up"></i>
</button>
<button class=toolbar-button onclick='window.scrollTo({top:document.body.scrollHeight,behavior:"smooth"})' title="Go to bottom">
<i class="fa fa-chevron-down"></i>
</button>
<button class=toolbar-button onclick=history.back() title="Go back">
<i class="fa-solid fa-arrow-left"></i></button></div><label for=toolbar-toggle class="toolbar-button toolbar-toggle-label"><i class="fa-solid fa-plus icon-expand"></i>
<i class="fa-solid fa-xmark icon-collapse"></i></label></div></main></body></html>