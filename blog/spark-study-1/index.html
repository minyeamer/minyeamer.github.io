<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=keywords content="Apache Spark,Spark Architecture,SparkSession,Cluster Manager,PySpark,데이터 엔지니어링,스파크,Study"><meta name=description content="Apache Spark의 기본 개념과 아키텍처를 다루며, 스파크의 시작부터 컴포넌트, Spark Driver, SparkSession, Cluster Manager, …"><meta name=author content="minyeamer"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-1/><link rel=icon href=https://minyeamer.github.io/images/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://minyeamer.github.io/images/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://minyeamer.github.io/images/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><link rel=mask-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><meta name=google-site-verification content="u1tWcHmHUZWfFT1cHaku6sqU-bK40N3WLR-C-4VUWN0"><meta name=naver-site-verification content="6eaf8e9da1a6104780f056f1a7797fe5a3a5a0da"><meta property="og:title" content="Apache Spark - 스파크의 기본 개념과 아키텍처"><meta property="og:description" content="Apache Spark의 기본 개념과 아키텍처를 다루며, 스파크의 시작부터 컴포넌트, Spark Driver, SparkSession, Cluster Manager, …"><meta property="og:type" content="article"><meta property="og:url" content="https://minyeamer.github.io/blog/spark-study-1/"><meta property="og:image" content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-22T18:42:10+09:00"><meta property="article:modified_time" content="2025-06-22T18:42:10+09:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0"><meta name=twitter:title content="Apache Spark - 스파크의 기본 개념과 아키텍처"><meta name=twitter:description content="Apache Spark의 기본 개념과 아키텍처를 다루며, 스파크의 시작부터 컴포넌트, Spark Driver, SparkSession, Cluster Manager, …"><meta name=twitter:site content="@https://x.com/minyeamer"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://minyeamer.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Apache Spark - 스파크의 기본 개념과 아키텍처","item":"https://minyeamer.github.io/blog/spark-study-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Spark - 스파크의 기본 개념과 아키텍처","name":"Apache Spark - 스파크의 기본 개념과 아키텍처","description":"Apache Spark의 기본 개념과 아키텍처를 다루며, 스파크의 시작부터 컴포넌트, Spark Driver, SparkSession, Cluster Manager, 배포 모드까지 단계별로 안내합니다. 데이터 엔지니어링과 빅데이터 처리를 위한 필수 지식을 습득하고 실무에 적용하세요.\n","keywords":["Apache Spark","Spark Architecture","SparkSession","Cluster Manager","PySpark","데이터 엔지니어링","스파크","Study"],"articleBody":"Study Overview # 러닝 스파크 2nd 개정판 과정을 따릅니다.\n목적 # 대용량 데이터 처리를 위한 아파치 스파크를 이론적으로 학습 책에서 대상으로 하는 스파크 3.x 버전과 25년 5월 출시된 Spark 4.0 버전을 비교 각 챕터에서 배운 것으로 실습할만한 것이 있다면 추가로 시도하기 실습은 PySpark API를 사용하며, 최신화된 PySpark 4.0.0 문서를 참조 챕터 # 아파치 스파크 소개: 통합 분석 엔진 아파치 스파크 다운로드 및 시작 아파치 스파크의 정형화 API 스파크 SQL과 데이터 프레임: 내장 데이터 소스 소개 스파크 SQL과 데이터 프레임: 외부 데이터 소스와 소통하기 스파크 SQL과 데이터세트 스파크 애플리케이션의 최적화 및 튜닝 정형화 스트리밍 아파치 스파크를 통한 안정적인 데이터 레이크 구축 MLlib을 사용한 머신러닝 아파치 스파크로 머신러닝 파이프라인 관리, 배포 및 확장 에필로그: 아파치 스파크 3.0 Spark Overview # 스파크의 시작 # RDBMS 같은 전통적인 저장 시스템으로는 구글이 방대한 규모의 인터넷 문서를 다룰 수 없어 구글 파일 시스템(GFS), 맵리듀스(MapReduce), 빅테이블(BigTable) 등을 만들어 냈다. GFS는 클러스터 환경에서 분산 파일시스템을 제공하고, 빅테이블은 GFS를 기반으로 대규모 데이터 저장 수단을 제공한다. 맵리듀스는 함수형 프로그래밍 기반으로 대규모 데이터 분산 처리를 구현했다. 클러스터의 워커 노드들이 분산된 데이터에 연산을 하고(Map), 그 결과를 하나로 합쳐(Reduce) 최종 결과를 생성해낸다. 이러한 접근 방식은 네트워크 트래픽을 크게 감소시키면서 로컬 디스크에 대한 I/O를 극대화한다.\nGFS는 하둡 파일 시스템과 맵리듀스 구현에 영향을 주었다. HDFS의 맵리듀스에는 몇 가지 단점이 있었다. 첫째, 운영이 복잡해 관리가 쉽지 않았다. 둘째, 배치 처리를 위한 맵리듀스 API의 기본 설정 코드가 너무 많이 필요했다. 셋째, 맵리듀스 태스크가 필요해질 때마다 중간 과정의 데이터를 로컬 디스크에 써야 했다. 반복적인 I/O 작업에 의해 거대한 맵리듀스 작업에 며칠이 걸리기도 했다.\nUC 버클리 연구원들은 동적이고 반복적인 작업에서 비효율적인 맵리듀스를 개선하여 단순하고 빠르고 쉬운 스파크를 만들기로 했다. 구체적으로는 더 높은 장애 내구성을 갖고, 병렬성을 높이면서, 맵리듀스 연산을 위한 중간 결과를 메모리에 저장하고, 간편한 API를 다양한 언어로 제공하고자 했다.\n아파치 스파크란? # 아파치 스파크는 데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 위한 통합형 엔진이다. 중간 연산을 메모리에 저장하고 머신러닝, SQL, 스트리밍 처리, 그래프 처리 등을 간편하게 API로 지원한다.\n스파크의 설계 철학에는 속도, 사용 편리성, 모듈성, 확장성이 있다.\n속도 스파크는 하드웨어 산업의 발전으로 메모리 성능 향상에 많은 이득을 얻었는데, 모든 중간 결과를 메모리에 저장해 I/O 작업을 제한하고 속도를 향상시켰다. 또한, 질의 연산을 DAG로 구성해 효율적인 연산 그래프를 만들고 병렬 수행을 지원한다.\n사용 편리성 데이터프레임이나 데이터세트 같이 고수준으로 추상화된 자료 구조를 사용해 단순성을 실현시켰다. 다양한 언어로 연산을 지원하여 사용자들이 편한 언어로 빅데이터를 처리할 수 있다.\n모듈성 문서화가 잘된 API를 제공하며, 스파크 SQL이나 정형화 스트리밍 등의 핵심 컴포넌트를 하나의 엔진 안에서 연동된 상태로 사용할 수 있다.\n확장성 스파크는 저장보다는 빠른 병렬 연산 엔진에 초점을 맞춰, 수많은 데이터 소스에서 데이터를 읽어 들여 메모리에서 처리하는 것이 가능하다. 서드파티 패키지 목록에는 다양한 외부 데이터 소스가 포함되어 있다.\n아파치 컴포넌트 # 다양한 워크로드를 위해 스파크 SQL, 스파크 MLlib, 스파크 정형화 스트리밍, GraphX를 제공한다. 자바, R, 스칼라, SQL, 파이썬 중 어느 것으로 스파크 코드를 작성해도 바이트 코드로 변환되어 워커 노드의 JVM에서 실행된다.\n스파크 SQL RDBMS 테이블이나 CSV와 같은 구조화된 데이터 파일 포맷에서 데이터를 읽어 들여 영구적이거나 임시적인 테이블을 생성한다. SQL 계통의 질의를 써서 데이터를 데이터프레임으로 읽어 들일 수 있다.\n스파크 MLlib 범용 머신러닝 알고리즘들이 들어 있다. 특성을 추출 및 가공하고 학습/검증 파이프라인을 구축하는 기능을 지원하며, 경사 하강법 최적화를 포함한 저수준 ML 기능을 포함한다.\n스파크 정형화 스트리밍 실시간으로 연결하고 반응하기 위한 데이터 모델은 스트림을 연속적으로 증가하는 테이블이자, 끝에 새로운 레코드가 추가되는 형태이다. 단순히 정형화 테이블로 보고 쿼리를 날리면 된다. 정형화 스트리밍 모델의 하부에는 스파크 SQL 엔진이 장애 복구와 지연 데이터의 모든 측면을 관리한다.\nGraphX 그래프를 조작하고 그래프 병렬 연산을 수행하기 위한 라이브러리다. 분석, 연결 탐색 등 표준적인 그래프 알고리즘과 커뮤니티 사용자들이 기여한 알고리즘을 포함한다.\nSpark Architecture # Spark Driver # SparkSession 객체를 초기화하는 책임을 가진 Spark Application의 일부이다. Spark Driver는 여러 가지 역할을 한다.\nCluster Manager와 통신하며 Spark Executor들을 위해 필요한 자원을 요청한다. 모든 스파크 작업을 DAG 연산 형태로 변환해 스케줄링한다. 각 실행 단위를 태스크로 나누어 Spark Executor들에게 분배한다. 자원이 한번 할당되면 그 다음부터는 Driver가 Executor와 직접 통신한다. SparkSession # 스파크 2.0에서 모든 스파크 연산과 데이터에 대한 통합 연결 채널이 만들어졌다.\nSparkContext, SQLContext, HiveContext, SparkConf, StreamingContext 등이 합쳐졌다. 일원화된 연결 채널을 통해 JVM 실행 파라미터들을 만들고 데이터프레임이나 데이터세트를 정의한다. 데이터 소스에서 데이터를 읽고 메타데이터에 접근해 스파크 SQL 질의를 실행할 수 있다. SparkSession은 모든 스파크 기능을 한 군데에서 접근할 수 있는 시작점을 제공한다.\npyspark.sql.SparkSession 문서를 참조해 SparkSession 생성\nCopy python spark = ( SparkSession.builder .master(\"local\") # 원격 접속의 경우 .remote(\"sc://localhost\") .appName(\"LearnSpark\") .config(\"spark.sql.shuffle.partitions\", 6) .getOrCreate() ) Cluster Manager # Spark Application이 실행되는 클러스터에서 자원을 관리 및 할당하는 책임을 가진다. Standalone, Hadoop YARN, Apache Mesos, Kubernetes 네 종류의 Cluster Manager를 지원한다.\nSpark Executor # 클러스터의 각 워커 노드에서 동작하며, Driver와 통신하며 Task를 실행하는 역할을 한다. 대부분의 배포 모드에서 노드당 하나의 Executor만 실행한다.\n배포 모드 # 스파크가 여러 환경에서 돌아갈 수 있도록 다양한 배포 모드를 지원한다. 추상화되어 있어 Cluster Manager는 실행 환경에 대한 정보가 필요없고, YARN이나 Kubernetes 같은 인기 있는 환경에 배포가 가능하다.\nMode Spark Driver Spark Executor Cluster Manager Local 단일 서버 같은 머신에서 단일 JVM 위에서 실행 Driver와 동일한 JVM 위에서 동작 동일한 호스트에서 실행 Standalone Cluster의 아무 노드에서나 실행 Cluster의 각 노드가 자체적인 Executor를 실행 Cluster의 아무 호스트에나 할당 YARN(Client) Cluster 외부의 Client에서 동작 YARM의 노드 매니저의 컨테이너 YARN의 리소스 매니저가 노드 매니저에 컨테이너 할당 YARN(Cluster) YARN 애플리케이션 마스터에서 동작 YARN(Client)와 동일 YARN(Client)와 동일 Kubernetes Kubernetes Pod에서 동작 각 워커가 자신의 Pod 내에서 실행 Kubernetes 마스터 분산 데이터 # 물리적인 데이터는 HDFS나 클라우드 저장소에 존재한다. 데이터는 파티션으로 물리적인 수준에서 분산되고, 스파크는 파티션을 추상화하여 메모리의 데이터프레임 객체를 바라본다.\n파티셔닝은 효과적인 병렬 처리를 가능하게 해준다. 데이터를 조각내 청크나 파티션 단위로 분산해 Spark Executor가 네트워크 사용을 최소화하고 가까이 있는 데이터만 처리한다.\n스파크 활용사례 # 데이터 사이언스 # 데이터 사이언티스트들은 데이터를 정제하고 패턴을 발견하기 위해 데이터를 살펴본다. 대부분은 SQL에 능하고, NumPy나 pandas 같은 라이브러리를 편하게 사용한다. 모델 구축을 위해 분류, 회귀, 클러스터링 알고리즘을 어떻게 사용할지도 알아야 한다.\n스파크는 MLlib은 모델 파이프라인을 구축할 수 있는 일반적인 머신러닝 알고리즘들을 제공한다. 또한, 스파크 SQL로 일회성 데이터 탐색을 가능하게 해준다.\n데이터 엔지니어링 # 클러스터링 모델은 독립적으로 존재하지 않고 아파치 카프카 같은 스트리밍 엔진과 연계해 동작한다. 데이터 파이프라인은 다양한 소스에서 오는 원본 데이터를 최종 단계로까지 변형해주며, 그런 데이터는 NoSQL이나 RDBMS 등에 저장된다.\n스파크의 정형화 스트리밍 API를 써서 실시간 또는 정적인 데이터 소스에 대한 ETL 파이프라인을 구축할 수 있게 해준다. 또한, 스파크가 연산을 쉽게 병렬화 해주어 고수준 언어에만 집중해 ETL을 수행할 수 있게 지원한다.\n스파크 사용 사례 # 클러스터 전체에 걸쳐 분산된 대규모 데이터세트의 병렬 처리 데이터 탐색이나 시각화를 위한 일회성이나 대화형 질의 수행 MLlib을 이용해 머신러닝 모델을 구축, 훈련, 평가 ","wordCount":"1033","inLanguage":"en","image":"https:\/\/dl.dropboxusercontent.com\/scl\/fi\/iafnblb6k95kbw7bwn2xj\/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6\u0026dl=0","datePublished":"2025-06-22T18:42:10+09:00","dateModified":"2025-06-22T18:42:10+09:00","author":{"@type":"Person","name":"minyeamer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://minyeamer.github.io/blog/spark-study-1/"},"publisher":{"@type":"Person","name":"Minystory","logo":{"@type":"ImageObject","url":"https://minyeamer.github.io/images/favicons/favicon.ico"}}}</script><title>Apache Spark - 스파크의 기본 개념과 아키텍처 | Minystory</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-1/><link rel=stylesheet href=/book.min.2e720c942dee933711365c3172eaed31e9904eaa0270fb5bb4f72da9a9495921.css integrity="sha256-LnIMlC3ukzcRNlwxcurtMemQTqoCcPtbtPctqalJWSE=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/search-input.min.91691c381073ff8f49253402c51ea4e91135f957e926e54679a27a3c2710994c.js integrity="sha256-kWkcOBBz/49JJTQCxR6k6RE1+VfpJuVGeaJ6PCcQmUw=" crossorigin=anonymous></script><link rel=preload href=/search-data.min.c5cac37e79fd2b2153ad6517d4fe3a12ee1e11d80262f8740cd1b6c7787501af.json as=fetch crossorigin><script>window.SEARCH_DATA_URL="/search-data.min.c5cac37e79fd2b2153ad6517d4fe3a12ee1e11d80262f8740cd1b6c7787501af.json"</script><script defer src=/search.min.f30f9834d4764fd9751da64098c954d01085f648ba9ca421a3c97582f8c47253.js integrity="sha256-8w+YNNR2T9l1HaZAmMlU0BCF9ki6nKQho8l1gvjEclM=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-BJ8Z9RMBPJ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BJ8Z9RMBPJ")</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css crossorigin=anonymous><script defer src=/scroll-progress.min.841ade7e507a5f6d59c4e7bf2fe2b2ca034070677ff7957eec55610a024dd776.js integrity="sha256-hBreflB6X21ZxOe/L+KyygNAcGd/95V+7FVhCgJN13Y=" crossorigin=anonymous></script><script defer src=/dark-mode.min.e41c6440ffd9967d6f6a419ff3ce09b862009fe1646ab265f5cb2817d2a508e3.js integrity="sha256-5BxkQP/Zln1vakGf884JuGIAn+FkarJl9csoF9KlCOM=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.9.0/highlightjs-line-numbers.min.js></script><script defer src=/copy-code.min.aaeef965f0b4992e55f976edaecb34a89d414e1791caa18c3f4f4376c6d8b5a8.js integrity="sha256-qu75ZfC0mS5V+Xbtrss0qJ1BTheRyqGMP09DdsbYtag=" crossorigin=anonymous></script><script defer src=/toc-highlightjs.093016f0ef312174ad862fdcf5792e88ab5442bd39beecc38d15643f71ab5c31.min integrity="sha256-CTAW8O8xIXSthi/c9XkuiKtUQr05vuzDjRVkP3GrXDE=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-posts book-layout-post"><div class=scroll-progress><div class=scroll-progress-bar></div></div><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><div class=sidebar-profile><div class=profile-img-wrap><a href=https://minyeamer.github.io/><img src=/images/profile/menu.jpg alt=Profile class=profile-img></a></div><div class=sidebar-social><a href=https://github.com/minyeamer target=_blank title=GitHub><i class="fa-brands fa-github"></i>
</a><a href=/categories/ title=Categories><i class="fa-solid fa-folder"></i>
</a><a href=/tags/ title=Tags><i class="fa-solid fa-tags"></i>
</a><button id=dark-mode-toggle class=dark-mode-toggle aria-label="Toggle dark mode">
<i class="fa-solid fa-circle-half-stroke"></i></button></div></div><h2 class=book-brand><a class="flex align-center" href=/><span>Minystory</span></a></h2><div class="book-search hidden"><div class=search-input-container><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/ onkeydown='event.key==="Enter"&&goToSearchPage()'>
<button type=button id=book-search-button class=book-search-btn onclick=goToSearchPage()>
<i class="fa-solid fa-magnifying-glass"></i></button></div><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden");function goToSearchPage(){const t=document.getElementById("book-search-input"),e=t.value.trim();e&&(window.location.href="/search/?q="+encodeURIComponent(e))}</script><div class=book-categories><input type=checkbox class="hidden toggle" id=categories-control checked>
<label for=categories-control class="categories-toggle categories-link"><a href=/categories/><i class="fa-solid fa-folder"></i>
<span>전체</span>
<span class=category-count>(28)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul class=categories-menu id=categories-menu><li><input type=checkbox class="hidden toggle" id=cat-algorithm>
<label for=cat-algorithm class="categories-toggle categories-link"><a href=/categories/algorithm/><i class="fa-solid fa-folder"></i>
Algorithm
<span class=category-count>(1)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/algorithm/sql/><i class="fa-solid fa-file"></i>
SQL
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-engineering>
<label for=cat-data-engineering class="categories-toggle categories-link"><a href=/categories/data-engineering/><i class="fa-solid fa-folder"></i>
Data Engineering
<span class=category-count>(19)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-engineering/apache-airflow/><i class="fa-solid fa-file"></i>
Apache Airflow
<span class=category-count>(7)</span></a></li><li class=categories-link><a href=/categories/data-engineering/apache-spark/><i class="fa-solid fa-file"></i>
Apache Spark
<span class=category-count>(8)</span></a></li><li class=categories-link><a href=/categories/data-engineering/crawling/><i class="fa-solid fa-file"></i>
Crawling
<span class=category-count>(4)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-frontend>
<label for=cat-frontend class="categories-toggle categories-link"><a href=/categories/frontend/><i class="fa-solid fa-folder"></i>
Frontend
<span class=category-count>(7)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/frontend/blog/><i class="fa-solid fa-file"></i>
Blog
<span class=category-count>(7)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-project>
<label for=cat-project class="categories-toggle categories-link"><a href=/categories/project/><i class="fa-solid fa-folder"></i>
Project
<span class=category-count>(1)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/project/open-source/><i class="fa-solid fa-file"></i>
Open Source
<span class=category-count>(1)</span></a></li></ul></li></ul></div><div class=recent-posts><div class=recent-posts-header><i class="fa-solid fa-clock"></i>
<span>최신글</span></div><ul class=recent-posts-list><li class=recent-post-item><a href=/blog/hugo-blog-3/ title="Hugo 블로그 만들기 (3) - 태그, 카테고리 페이지 추가"><div class=recent-post-title>Hugo 블로그 만들기 (3) - 태그, 카테고리 페이지 추가</div><div class=recent-post-date><time datetime=2025-11-22>2025.11.22</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-2/ title="Hugo 블로그 만들기 (2) - 메인 레이아웃 개선"><div class=recent-post-title>Hugo 블로그 만들기 (2) - 메인 레이아웃 개선</div><div class=recent-post-date><time datetime=2025-11-04>2025.11.04</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-1/ title="Hugo 블로그 만들기 (1) - 프로젝트 기획 및 구조 설계"><div class=recent-post-title>Hugo 블로그 만들기 (1) - 프로젝트 기획 및 구조 설계</div><div class=recent-post-date><time datetime=2025-11-01>2025.11.01</time></div></a></li><li class=recent-post-item><a href=/blog/openup-handson/ title="[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기"><div class=recent-post-title>[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기</div><div class=recent-post-date><time datetime=2025-10-28>2025.10.28</time></div></a></li><li class=recent-post-item><a href=/blog/spark-study-8/ title="Apache Spark - 고차함수(Higher-Order Functions)"><div class=recent-post-title>Apache Spark - 고차함수(Higher-Order Functions)</div><div class=recent-post-date><time datetime=2025-07-19>2025.07.19</time></div></a></li></ul></div></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><i class="fa-solid fa-bars book-icon" id=menu-icon></i></label><h3><a href=https://minyeamer.github.io/ class=site-title>Minystory</a></h3><label for=toc-control><i class="fa-solid fa-list book-icon" id=toc-icon></i></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#study-overview>Study Overview</a><ul><li><a href=#목적>목적</a></li><li><a href=#챕터>챕터</a></li></ul></li><li><a href=#spark-overview>Spark Overview</a><ul><li><a href=#스파크의-시작>스파크의 시작</a></li><li><a href=#아파치-스파크란>아파치 스파크란?</a></li><li><a href=#아파치-컴포넌트>아파치 컴포넌트</a></li></ul></li><li><a href=#spark-architecture>Spark Architecture</a><ul><li><a href=#spark-driver>Spark Driver</a></li><li><a href=#sparksession>SparkSession</a></li><li><a href=#cluster-manager>Cluster Manager</a></li><li><a href=#spark-executor>Spark Executor</a></li><li><a href=#배포-모드>배포 모드</a></li><li><a href=#분산-데이터>분산 데이터</a></li></ul></li><li><a href=#스파크-활용사례>스파크 활용사례</a><ul><li><a href=#데이터-사이언스>데이터 사이언스</a></li><li><a href=#데이터-엔지니어링>데이터 엔지니어링</a></li><li><a href=#스파크-사용-사례>스파크 사용 사례</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><header class=post-header><div class=post-header-category><a href=/categories/data-engineering/apache-spark/ class=post-header-category-link>Data Engineering/Apache Spark</a></div><h1 class=post-header-title>Apache Spark - 스파크의 기본 개념과 아키텍처</h1><div class=post-header-date><time datetime=2025-06-22T18:42:10+09:00>2025. 6. 22. 18:42</time></div></header><div class=book-cover><img src="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0" alt="Cover Image" class=book-cover-img></div><h2 id=study-overview>Study Overview
<a class=anchor href=#study-overview>#</a></h2><p><a href="https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=296379664" target=_blank rel="noopener noreferrer">러닝 스파크 2nd 개정판</a> 과정을 따릅니다.</p><h3 id=목적>목적
<a class=anchor href=#%eb%aa%a9%ec%a0%81>#</a></h3><ul><li>대용량 데이터 처리를 위한 아파치 스파크를 이론적으로 학습</li><li>책에서 대상으로 하는 스파크 3.x 버전과 25년 5월 출시된 Spark 4.0 버전을 비교</li><li>각 챕터에서 배운 것으로 실습할만한 것이 있다면 추가로 시도하기</li><li>실습은 PySpark API를 사용하며, 최신화된
<a href=https://spark.apache.org/docs/4.0.0/api/python/index.html target=_blank rel="noopener noreferrer">PySpark 4.0.0 문서</a>를 참조</li></ul><h3 id=챕터>챕터
<a class=anchor href=#%ec%b1%95%ed%84%b0>#</a></h3><blockquote class=book-hint><ol><li>아파치 스파크 소개: 통합 분석 엔진</li><li>아파치 스파크 다운로드 및 시작</li><li>아파치 스파크의 정형화 API</li><li>스파크 SQL과 데이터 프레임: 내장 데이터 소스 소개</li><li>스파크 SQL과 데이터 프레임: 외부 데이터 소스와 소통하기</li><li>스파크 SQL과 데이터세트</li><li>스파크 애플리케이션의 최적화 및 튜닝</li><li>정형화 스트리밍</li><li>아파치 스파크를 통한 안정적인 데이터 레이크 구축</li><li>MLlib을 사용한 머신러닝</li><li>아파치 스파크로 머신러닝 파이프라인 관리, 배포 및 확장</li><li>에필로그: 아파치 스파크 3.0</li></ol></blockquote><h2 id=spark-overview>Spark Overview
<a class=anchor href=#spark-overview>#</a></h2><h3 id=스파크의-시작>스파크의 시작
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac%ec%9d%98-%ec%8b%9c%ec%9e%91>#</a></h3><p>RDBMS 같은 전통적인 저장 시스템으로는 구글이 방대한 규모의 인터넷 문서를 다룰 수 없어
구글 파일 시스템(GFS), 맵리듀스(MapReduce), 빅테이블(BigTable) 등을 만들어 냈다.
GFS는 클러스터 환경에서 분산 파일시스템을 제공하고, 빅테이블은 GFS를 기반으로 대규모 데이터 저장 수단을 제공한다.
맵리듀스는 함수형 프로그래밍 기반으로 대규모 데이터 분산 처리를 구현했다. 클러스터의 워커 노드들이
분산된 데이터에 연산을 하고(Map), 그 결과를 하나로 합쳐(Reduce) 최종 결과를 생성해낸다.
이러한 접근 방식은 네트워크 트래픽을 크게 감소시키면서 로컬 디스크에 대한 I/O를 극대화한다.</p><p>GFS는 하둡 파일 시스템과 맵리듀스 구현에 영향을 주었다. HDFS의 맵리듀스에는 몇 가지 단점이 있었다.
첫째, 운영이 복잡해 관리가 쉽지 않았다. 둘째, 배치 처리를 위한 맵리듀스 API의 기본 설정 코드가 너무 많이 필요했다.
셋째, 맵리듀스 태스크가 필요해질 때마다 중간 과정의 데이터를 로컬 디스크에 써야 했다.
반복적인 I/O 작업에 의해 거대한 맵리듀스 작업에 며칠이 걸리기도 했다.</p><p><img src="https://dl.dropboxusercontent.com/scl/fi/pg3qcymue8h7z8h8n8cau/spark-01-map-reduce.webp?rlkey=6bnfs4bxy1haa8e52335qv24a&amp;dl=0" alt="Big Data -> Split -> Map -> Reduce -> Output"></p><p>UC 버클리 연구원들은 동적이고 반복적인 작업에서 비효율적인 맵리듀스를 개선하여 단순하고 빠르고 쉬운 스파크를 만들기로 했다.
구체적으로는 더 높은 장애 내구성을 갖고, 병렬성을 높이면서, 맵리듀스 연산을 위한 중간 결과를 메모리에 저장하고,
간편한 API를 다양한 언어로 제공하고자 했다.</p><h3 id=아파치-스파크란>아파치 스파크란?
<a class=anchor href=#%ec%95%84%ed%8c%8c%ec%b9%98-%ec%8a%a4%ed%8c%8c%ed%81%ac%eb%9e%80>#</a></h3><p>아파치 스파크는 데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 위한 통합형 엔진이다.
중간 연산을 메모리에 저장하고 머신러닝, SQL, 스트리밍 처리, 그래프 처리 등을 간편하게 API로 지원한다.</p><p>스파크의 설계 철학에는 속도, 사용 편리성, 모듈성, 확장성이 있다.</p><ol><li><p>속도
스파크는 하드웨어 산업의 발전으로 메모리 성능 향상에 많은 이득을 얻었는데, 모든 중간 결과를 메모리에 저장해
I/O 작업을 제한하고 속도를 향상시켰다. 또한, 질의 연산을 DAG로 구성해 효율적인 연산 그래프를 만들고 병렬 수행을 지원한다.</p></li><li><p>사용 편리성
데이터프레임이나 데이터세트 같이 고수준으로 추상화된 자료 구조를 사용해 단순성을 실현시켰다.
다양한 언어로 연산을 지원하여 사용자들이 편한 언어로 빅데이터를 처리할 수 있다.</p></li><li><p>모듈성
문서화가 잘된 API를 제공하며, 스파크 SQL이나 정형화 스트리밍 등의
핵심 컴포넌트를 하나의 엔진 안에서 연동된 상태로 사용할 수 있다.</p></li><li><p>확장성
스파크는 저장보다는 빠른 병렬 연산 엔진에 초점을 맞춰, 수많은 데이터 소스에서 데이터를 읽어 들여
메모리에서 처리하는 것이 가능하다. 서드파티 패키지 목록에는 다양한 외부 데이터 소스가 포함되어 있다.</p></li></ol><h3 id=아파치-컴포넌트>아파치 컴포넌트
<a class=anchor href=#%ec%95%84%ed%8c%8c%ec%b9%98-%ec%bb%b4%ed%8f%ac%eb%84%8c%ed%8a%b8>#</a></h3><p>다양한 워크로드를 위해 스파크 SQL, 스파크 MLlib, 스파크 정형화 스트리밍, GraphX를 제공한다.
자바, R, 스칼라, SQL, 파이썬 중 어느 것으로 스파크 코드를 작성해도 바이트 코드로 변환되어 워커 노드의 JVM에서 실행된다.</p><ol><li><p>스파크 SQL
RDBMS 테이블이나 CSV와 같은 구조화된 데이터 파일 포맷에서 데이터를 읽어 들여 영구적이거나
임시적인 테이블을 생성한다. SQL 계통의 질의를 써서 데이터를 데이터프레임으로 읽어 들일 수 있다.</p></li><li><p>스파크 MLlib
범용 머신러닝 알고리즘들이 들어 있다. 특성을 추출 및 가공하고 학습/검증 파이프라인을 구축하는 기능을
지원하며, 경사 하강법 최적화를 포함한 저수준 ML 기능을 포함한다.</p></li><li><p>스파크 정형화 스트리밍
실시간으로 연결하고 반응하기 위한 데이터 모델은 스트림을 연속적으로 증가하는 테이블이자,
끝에 새로운 레코드가 추가되는 형태이다. 단순히 정형화 테이블로 보고 쿼리를 날리면 된다.
정형화 스트리밍 모델의 하부에는 스파크 SQL 엔진이 장애 복구와 지연 데이터의 모든 측면을 관리한다.</p></li><li><p>GraphX
그래프를 조작하고 그래프 병렬 연산을 수행하기 위한 라이브러리다. 분석, 연결 탐색 등
표준적인 그래프 알고리즘과 커뮤니티 사용자들이 기여한 알고리즘을 포함한다.</p></li></ol><h2 id=spark-architecture>Spark Architecture
<a class=anchor href=#spark-architecture>#</a></h2><div style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/hhpp6o2d6m6grww5vz6t8/spark-02-architecture.webp?rlkey=mzdwo2l947nuead3shu2xeodz&amp;dl=0" alt="The Architecture of Apache Spark" style=width:100%;max-width:691px></div><h3 id=spark-driver>Spark Driver
<a class=anchor href=#spark-driver>#</a></h3><p>SparkSession 객체를 초기화하는 책임을 가진 Spark Application의 일부이다.
Spark Driver는 여러 가지 역할을 한다.</p><ol><li>Cluster Manager와 통신하며 Spark Executor들을 위해 필요한 자원을 요청한다.</li><li>모든 스파크 작업을 DAG 연산 형태로 변환해 스케줄링한다.</li><li>각 실행 단위를 태스크로 나누어 Spark Executor들에게 분배한다.</li><li>자원이 한번 할당되면 그 다음부터는 Driver가 Executor와 직접 통신한다.</li></ol><h3 id=sparksession>SparkSession
<a class=anchor href=#sparksession>#</a></h3><p>스파크 2.0에서 모든 스파크 연산과 데이터에 대한 통합 연결 채널이 만들어졌다.</p><ol><li>SparkContext, SQLContext, HiveContext, SparkConf, StreamingContext 등이 합쳐졌다.</li><li>일원화된 연결 채널을 통해 JVM 실행 파라미터들을 만들고 데이터프레임이나 데이터세트를 정의한다.</li><li>데이터 소스에서 데이터를 읽고 메타데이터에 접근해 스파크 SQL 질의를 실행할 수 있다.</li></ol><p>SparkSession은 모든 스파크 기능을 한 군데에서 접근할 수 있는 시작점을 제공한다.</p><blockquote class=book-hint><p><a href=https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html target=_blank rel="noopener noreferrer">pyspark.sql.SparkSession</a>
문서를 참조해 SparkSession 생성</p></blockquote><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>master</span><span class=p>(</span><span class=s2>&#34;local&#34;</span><span class=p>)</span> <span class=c1># 원격 접속의 경우 .remote(&#34;sc://localhost&#34;)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&#34;LearnSpark&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&#34;spark.sql.shuffle.partitions&#34;</span><span class=p>,</span> <span class=mi>6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div></div><h3 id=cluster-manager>Cluster Manager
<a class=anchor href=#cluster-manager>#</a></h3><p>Spark Application이 실행되는 클러스터에서 자원을 관리 및 할당하는 책임을 가진다.
Standalone, Hadoop YARN, Apache Mesos, Kubernetes 네 종류의 Cluster Manager를 지원한다.</p><h3 id=spark-executor>Spark Executor
<a class=anchor href=#spark-executor>#</a></h3><p>클러스터의 각 워커 노드에서 동작하며, Driver와 통신하며 Task를 실행하는 역할을 한다.
대부분의 배포 모드에서 노드당 하나의 Executor만 실행한다.</p><h3 id=배포-모드>배포 모드
<a class=anchor href=#%eb%b0%b0%ed%8f%ac-%eb%aa%a8%eb%93%9c>#</a></h3><p>스파크가 여러 환경에서 돌아갈 수 있도록 다양한 배포 모드를 지원한다. 추상화되어 있어 Cluster Manager는 실행 환경에 대한 정보가 필요없고, YARN이나 Kubernetes 같은 인기 있는 환경에 배포가 가능하다.</p><table><thead><tr><th>Mode</th><th>Spark Driver</th><th>Spark Executor</th><th>Cluster Manager</th></tr></thead><tbody><tr><td>Local</td><td>단일 서버 같은 머신에서 단일 JVM 위에서 실행</td><td>Driver와 동일한 JVM 위에서 동작</td><td>동일한 호스트에서 실행</td></tr><tr><td>Standalone</td><td>Cluster의 아무 노드에서나 실행</td><td>Cluster의 각 노드가 자체적인 Executor를 실행</td><td>Cluster의 아무 호스트에나 할당</td></tr><tr><td>YARN(Client)</td><td>Cluster 외부의 Client에서 동작</td><td>YARM의 노드 매니저의 컨테이너</td><td>YARN의 리소스 매니저가 노드 매니저에 컨테이너 할당</td></tr><tr><td>YARN(Cluster)</td><td>YARN 애플리케이션 마스터에서 동작</td><td>YARN(Client)와 동일</td><td>YARN(Client)와 동일</td></tr><tr><td>Kubernetes</td><td>Kubernetes Pod에서 동작</td><td>각 워커가 자신의 Pod 내에서 실행</td><td>Kubernetes 마스터</td></tr></tbody></table><h3 id=분산-데이터>분산 데이터
<a class=anchor href=#%eb%b6%84%ec%82%b0-%eb%8d%b0%ec%9d%b4%ed%84%b0>#</a></h3><p>물리적인 데이터는 HDFS나 클라우드 저장소에 존재한다. 데이터는 파티션으로 물리적인 수준에서 분산되고, 스파크는 파티션을 추상화하여 메모리의 데이터프레임 객체를 바라본다.</p><p>파티셔닝은 효과적인 병렬 처리를 가능하게 해준다. 데이터를 조각내 청크나 파티션 단위로 분산해 Spark Executor가 네트워크 사용을 최소화하고 가까이 있는 데이터만 처리한다.</p><h2 id=스파크-활용사례>스파크 활용사례
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac-%ed%99%9c%ec%9a%a9%ec%82%ac%eb%a1%80>#</a></h2><h3 id=데이터-사이언스>데이터 사이언스
<a class=anchor href=#%eb%8d%b0%ec%9d%b4%ed%84%b0-%ec%82%ac%ec%9d%b4%ec%96%b8%ec%8a%a4>#</a></h3><p>데이터 사이언티스트들은 데이터를 정제하고 패턴을 발견하기 위해 데이터를 살펴본다. 대부분은 SQL에 능하고, NumPy나 pandas 같은 라이브러리를 편하게 사용한다. 모델 구축을 위해 분류, 회귀, 클러스터링 알고리즘을 어떻게 사용할지도 알아야 한다.</p><p>스파크는 MLlib은 모델 파이프라인을 구축할 수 있는 일반적인 머신러닝 알고리즘들을 제공한다. 또한, 스파크 SQL로 일회성 데이터 탐색을 가능하게 해준다.</p><h3 id=데이터-엔지니어링>데이터 엔지니어링
<a class=anchor href=#%eb%8d%b0%ec%9d%b4%ed%84%b0-%ec%97%94%ec%a7%80%eb%8b%88%ec%96%b4%eb%a7%81>#</a></h3><p>클러스터링 모델은 독립적으로 존재하지 않고 아파치 카프카 같은 스트리밍 엔진과 연계해 동작한다. 데이터 파이프라인은 다양한 소스에서 오는 원본 데이터를 최종 단계로까지 변형해주며, 그런 데이터는 NoSQL이나 RDBMS 등에 저장된다.</p><p>스파크의 정형화 스트리밍 API를 써서 실시간 또는 정적인 데이터 소스에 대한 ETL 파이프라인을 구축할 수 있게 해준다. 또한, 스파크가 연산을 쉽게 병렬화 해주어 고수준 언어에만 집중해 ETL을 수행할 수 있게 지원한다.</p><h3 id=스파크-사용-사례>스파크 사용 사례
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac-%ec%82%ac%ec%9a%a9-%ec%82%ac%eb%a1%80>#</a></h3><ol><li>클러스터 전체에 걸쳐 분산된 대규모 데이터세트의 병렬 처리</li><li>데이터 탐색이나 시각화를 위한 일회성이나 대화형 질의 수행</li><li>MLlib을 이용해 머신러닝 모델을 구축, 훈련, 평가</li></ol></article><div class=book-nav><button class=book-nav-btn3 onclick='window.scrollTo({top:0,behavior:"smooth"})' title="Go to top">
<i class="fa fa-chevron-up"></i>
</button>
<button class=book-nav-btn3 onclick='window.scrollTo({top:document.body.scrollHeight,behavior:"smooth"})' title="Go to bottom">
<i class="fa fa-chevron-down"></i>
<button class=book-nav-btn3 onclick=history.back() title="Go back">
<i class="fa-solid fa-arrow-left"></i></button></div><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class=post-tags><a href=/tags/apache-spark/ class=tag>#Apache Spark</a>
<a href=/tags/spark-architecture/ class=tag>#Spark Architecture</a>
<a href=/tags/sparksession/ class=tag>#SparkSession</a>
<a href=/tags/cluster-manager/ class=tag>#Cluster Manager</a>
<a href=/tags/pyspark/ class=tag>#PySpark</a>
<a href=/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81/ class=tag>#데이터 엔지니어링</a>
<a href=/tags/%EC%8A%A4%ED%8C%8C%ED%81%AC/ class=tag>#스파크</a>
<a href=/tags/study/ class=tag>#Study</a></div><div class=post-navigation><a href class="post-nav-link post-nav-prev post-nav-disabled"><span class=post-nav-direction><i class="fa-solid fa-backward"></i> PREV</span>
<span class=post-nav-title>이전 게시글이 없습니다</span>
</a><a href=/blog/spark-study-2/ class="post-nav-link post-nav-next"><span class=post-nav-direction>NEXT <i class="fa-solid fa-forward"></i></span>
<span class=post-nav-title>Apache Spark - 설치하고 PySpark 실행하기</span></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script><div class=book-comments><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://minyeamer.github.io/blog/spark-study-1/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-1/"};(function(){var e=document,t=e.createElement("script");t.src="https://minyeamer.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})();function reloadDisqus(){window.DISQUS&&DISQUS.reset({reload:!0,config:function(){this.page.url="https://minyeamer.github.io/blog/spark-study-1/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-1/"}})}</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#study-overview>Study Overview</a><ul><li><a href=#목적>목적</a></li><li><a href=#챕터>챕터</a></li></ul></li><li><a href=#spark-overview>Spark Overview</a><ul><li><a href=#스파크의-시작>스파크의 시작</a></li><li><a href=#아파치-스파크란>아파치 스파크란?</a></li><li><a href=#아파치-컴포넌트>아파치 컴포넌트</a></li></ul></li><li><a href=#spark-architecture>Spark Architecture</a><ul><li><a href=#spark-driver>Spark Driver</a></li><li><a href=#sparksession>SparkSession</a></li><li><a href=#cluster-manager>Cluster Manager</a></li><li><a href=#spark-executor>Spark Executor</a></li><li><a href=#배포-모드>배포 모드</a></li><li><a href=#분산-데이터>분산 데이터</a></li></ul></li><li><a href=#스파크-활용사례>스파크 활용사례</a><ul><li><a href=#데이터-사이언스>데이터 사이언스</a></li><li><a href=#데이터-엔지니어링>데이터 엔지니어링</a></li><li><a href=#스파크-사용-사례>스파크 사용 사례</a></li></ul></li></ul></nav></div></aside></main></body></html>