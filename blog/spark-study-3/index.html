<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=keywords content="Apache Spark,Spark Application,RDD,Spark Shell,Spark Web UI,데이터 엔지니어링,스파크,Study"><meta name=description content="Apache Spark의 애플리케이션 구조와 RDD 개념을 다루며, Driver Process, Executor, Job, Stage, Task부터 Transformation과 …"><meta name=author content="minyeamer"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-3/><link rel=icon href=https://minyeamer.github.io/images/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://minyeamer.github.io/images/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://minyeamer.github.io/images/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><link rel=mask-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><meta name=google-site-verification content="u1tWcHmHUZWfFT1cHaku6sqU-bK40N3WLR-C-4VUWN0"><meta name=naver-site-verification content="6eaf8e9da1a6104780f056f1a7797fe5a3a5a0da"><meta property="og:title" content="Apache Spark - 스파크 애플리케이션 구조와 RDD 이해하기"><meta property="og:description" content="Apache Spark의 애플리케이션 구조와 RDD 개념을 다루며, Driver Process, Executor, Job, Stage, Task부터 Transformation과 …"><meta property="og:type" content="article"><meta property="og:url" content="https://minyeamer.github.io/blog/spark-study-3/"><meta property="og:image" content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-29T12:50:06+09:00"><meta property="article:modified_time" content="2025-06-29T12:50:06+09:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0"><meta name=twitter:title content="Apache Spark - 스파크 애플리케이션 구조와 RDD 이해하기"><meta name=twitter:description content="Apache Spark의 애플리케이션 구조와 RDD 개념을 다루며, Driver Process, Executor, Job, Stage, Task부터 Transformation과 …"><meta name=twitter:site content="@https://x.com/minyeamer"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://minyeamer.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Apache Spark - 스파크 애플리케이션 구조와 RDD 이해하기","item":"https://minyeamer.github.io/blog/spark-study-3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Spark - 스파크 애플리케이션 구조와 RDD 이해하기","name":"Apache Spark - 스파크 애플리케이션 구조와 RDD 이해하기","description":"Apache Spark의 애플리케이션 구조와 RDD 개념을 다루며, Driver Process, Executor, Job, Stage, Task부터 Transformation과 Action까지 단계별로 안내합니다.\n","keywords":["Apache Spark","Spark Application","RDD","Spark Shell","Spark Web UI","데이터 엔지니어링","스파크","Study"],"articleBody":"Spark Application # Spark Application은 Driver Process 하나와 일련의 일련의 Executors로 구성된다.\nDriver Process # Driver Process는 main() 함수를 실행하고 클러스터 내 노드에서 세 가지 작업을 담당한다.\nSpark Application 관련 정보를 유지한다. 사용자의 프로그램이나 입력에 대응한다. Executor 작업을 분석, 배포, 예약한다. Executor # Executor는 Driver가 할당한 작업을 실제로 실행하는 역할을 하는데, 두 가지 작업을 담당한다.\nDriver가 할당한 Task를 실행한다. Task의 상태와 결과를 Driver 노드에 보고한다. Cluster Manager # 실물 시스템을 제어하고 Spark Application에 리소스를 할당하는 작업은 Cluster Manager가 맡는다. Spark Application의 실행 과정에서 Cluster Manager는 Application이 실행되는 물리적인 머신을 관리한다. Spark Application은 클러스터에서 독립적인 프로세스로 실행되며, SparkContext 객체에 의해 조정된다.\nSparkContext는 여러 유형의 Cluster Manager(Standalone, YARN, Kubernetes)에 연결될 수 있으며, Application 간에 리소스를 할당한다. Spark가 연결되어 클러스터의 노드에서 Executor가 확보되면, SparkContext에 전달된 Application 코드가 Executor에게 전달된다.\nJob # Spark Driver는 Spark Application을 하나 이상의 Spark Job으로 변환한다. 각 Job은 DAG로 변환되며, DAG 그래프에서 각각의 노드는 하나 이상의 Spark Stage에 해당한다.\nStage # 어떤 작업이 연속적으로 또는 병렬적으로 수행되는지에 맞춰 Stage에 해당하는 DAG 노드가 생성된다. Spark 연산은 하나의 Stage 안에서 실행되지 않고 여러 Stage로 나뉘어 실행된다.\nTask # 각 Stage는 최소 실행 단위이며 Executor들 위에서 실행되는 Spark Task들로 이루어진다. 각 Task는 개별적인 CPU 코어에 할당되어 개별적인 파티션을 갖고 작업하기 때문에, 철저하게 병렬 처리가 이루어진다.\nRDD(Resilient Distributed Data) # RDD는 탄력적인 분산 데이터셋이란 의미로, 분산 데이터를 병렬로 처리하고 장애가 발생할 경우 스스로 복구될 수 있는 내성을 가지고 있다. RDD는 Spark에서 정의한 분산 데이터 모델로, 여러 서버에 나누어 저장되어 각 서버에서 저장된 데이터를 동시에 병렬로 처리할 수 있다.\nRDD 특징 # RDD는 5가지 특징을 가지고 있다.\nDistributed Collection\n데이터는 클러스터에 흩어져 있지만 하나의 파일인 것처럼 사용이 가능한다. 즉, 여러 군데의 데이터를 하나의 객체로 사용할 수 있다.\nResilient \u0026 Immutable\n데이터는 탄력적이고 불변하는 성질이 있다. RDD의 변환 과정은 DAG로 그릴 수 있기 때문에 문제가 생길 경우 쉽게 이전의 RDD로 돌아갈 수 있다. 연산 중 문제가 생겨도 다시 복원해서 연산하면 되기 때문에 탄력적인 성질을 가진다고 볼 수 있다. 또한, 여러 노드 중 하나의 노드에서 장애가 발생해도 복원이 가능하기 때문에 불변하다는 성질을 가진다고도 볼 수 있다.\nType-Safe\nRDD는 컴파일 시 타입을 판별할 수 있다. Integer RDD, String RDD, Double RDD 등으로 미리 판단할 수 있기 때문에 문제를 일찍 발견할 수 있다.\nStructured \u0026 Unstructured Data\n정형 데이터인 테이블, RDB, DataFrame과 비정형 데이터인 텍스트, 로그, 자연어 등을 모두 담을 수 있다.\nLazy Evaluation\n분산 데이터의 Spark 연산은 Transformation과 Action으로 구분된다. Action을 할 때까지 Transformation을 실행하지 않는다. Action을 하게 되면 Transformation을 실행하는 게으른 연산 방식을 가진다.\nTransformation # Transformation은 불변성의 특징을 가진 원본 데이터를 수정하지 않고 하나의 Spark DataFrame을 새로운 DataFrame으로 변형(Transform)한다. select() 나 filter() 같은 연산은 원본 DataFrame을 수정하지 않는다.\nTransformation은 즉시 계산되지 않고 Lineage라 불리는 형태로 기록된다. 기록된 Lineage는 더 효율적으로 연산할 수 있도록 Transformation들끼리 재배열하거나 합치도록 최적화된다. Lazy Evaluation은 Action이 실행되는 시점이나 데이터에 실제 접근하는 시점까지 실제 실행을 미루는 전략이다.\nLazy Evaluation이 일련의 Transformation들을 최적화한다면, Lineage는 데이터 불변성 및 장애에 대한 내구성을 제공한다. Lineage에는 Transformation들이 기록되어 있고 실행 전까지 DataFrame이 변하지 않기 때문에, 단순히 기록된 Lineage를 재실행하는 것만으로 원래 상태를 다시 만들어낼 수 있다.\nTransformation은 Narrow Transformation과 Wide Transformation으로 구분된다.\nNarrow Transformation # Narrow Transformation은 하나의 입력 파티션을 연산하여 하나의 출력 파티션을 내놓는 경우다. 입력 파티션에 대한 연산이 독립적으로 이루어지며, 연산의 결과인 출력 파티션은 입력 파티션의 데이터에만 의존한다. 즉, 다른 파티션의 데이터를 참조할 필요가 없다는 것을 의미한다. filter() 와 contains() 등의 연산이 여기에 해당된다.\nNarrow Transformation은 실행 비용이 상대적으로 낮고, 성능이 좋아 빠른 처리가 가능하다.\nWide Transformation # Wide Transformation은 입력 데이터의 여러 파티션 간에 데이터가 재분배되어야 하는 경우다. 다른 파티션으로부터 데이터를 읽어들여서 Shuffle(데이터 재분배)하는 과정이 필요하며, groupBy() 나 orderBy() 등의 연산이 여기에 해당된다.\nWide Transformation은 네트워크를 통한 대량의 데이터 이동을 발생시켜 실행 시간이 오래 걸리고 리소스 사용량이 많다.\nAction # Action은 RDD로 결과 값을 계산하고, 연산 결과를 반환하거나 외부 스토리지(HDFS 등)에 저장한다. count() 나 show() 함수는 연산 결과를 반환하거나 출력하고, saveAsTextFile() 과 같은 함수로 연산 결과를 스토리지에 저장할 수 있다.\nAction을 호출할 때마다 RDD가 처음부터 계산되는데, 반복적인 연산에 의한 비효율성을 피하기 위해 cache() 와 persist() 를 사용해 데이터를 메모리에 보관할 수 있다.\nWeb UI # 스파크는 클러스터 상태와 리소스 사용을 모니터링하기 위해 Web UI를 제공한다. 기본적으로 4040 포트를 사용하는데 다음과 같은 내용을 볼 수 있다.\n스케줄러의 Stage와 Task 목록 RDD 크기와 메모리 사용의 요약 환경 정보 실행 중인 Executor 정보 모든 스파크 SQL 쿼리 아래는 AWS 문서에서 제공하는 화면이다. Web UI를 통해 Job, Stage, Task들이 어떻게 구성되는지 DAG 형태로 시각화해서 볼 수 있다. Stage 안에서 각각의 Task는 파란 박스로 표시되는데, 아래 예시에서 Stage 2는 2개의 Task로 구성되어 있음을 알 수 있다. Task가 여러 개라면 모두 병렬로 실행된다.\nspark-submit # databricks/LearningSparkV2/chapter2 에서 각 주별로 학생들이 어떤 색깔의 M\u0026M을 좋아하는지 알려주는 스파크 프로그램을 작성한 예제 mnmcount.py 를 가져온다. 동일한 위치의 data/ 경로에서 M\u0026M 데이터셋 mnm_dataset.csv 을 확인할 수 있다.\nM\u0026M 개수 집계 (Python) # Copy python # src/mnmcount.py from pyspark.sql import SparkSession import sys if __name__ == \"__main__\": if len(sys.argv) != 2: print(\"Usage: mnmcount \", file=sys.stderr) sys.exit(-1) # SparkSession 객체를 만든다. spark = (SparkSession .builder .appName(\"PythonMnMCount\") .getOrCreate()) # 인자에서 M\u0026M 데이터가 들어있는 파일 이름을 얻는다. mnm_file = sys.argv[1] # 데이터가 CSV 형식이며 헤더가 있음을 알리고 스키마를 추론하도록 한다. mnm_df = (spark.read.format(\"csv\") .option(\"header\", \"true\") .option(\"inferSchema\", \"true\") .load(mnm_file)) mnm_df.show(n=5, truncate=False) # State, Color, Count 필드를 선택하고 State, Color를 기준으로 Count를 sum 집계한다. # select, groupBy, sum, orderBy 메서드를 연결하여 연속적으로 호출한다. count_mnm_df = (mnm_df.select(\"State\", \"Color\", \"Count\") .groupBy(\"State\", \"Color\") .sum(\"Count\") .orderBy(\"sum(Count)\", ascending=False)) # 상위 60개 결과를 보여주고, 모든 행 개수를 count 집계해 출력한다. count_mnm_df.show(n=60, truncate=False) print(\"Total Rows = %d\" % (count_mnm_df.count())) # 위 집계 과정에서 중간에 where 메서드를 추가해 캘리포니아(CA) 주에 대해서만 집계한다. ca_count_mnm_df = (mnm_df.select(\"*\") .where(mnm_df.State == 'CA') .groupBy(\"State\", \"Color\") .sum(\"Count\") .orderBy(\"sum(Count)\", ascending=False)) # 상위 10개 결과를 보여준다. ca_count_mnm_df.show(n=10, truncate=False) # SparkSession을 멈춘다. spark.stop() Application 실행 # spark-submit 스크립트에 파이썬 코드를 첫 번째 인자로, CSV 파일을 두 번째 인자로 전달한다.\n실행 과정에서 불필요한 INFO 로그를 무시하고 싶다면, $SPARK_HOME/conf/ 경로에서 log4j2.properties.template 파일의 이름을 log4j2.properties 로 변경하고 파일 내용에서 rootLogger.level = info 부분의 값을 warn 으로 변경하면 된다.\nCopy bash (spark) % $SPARK_HOME/bin/spark-submit src/mnmcount.py data/mnm_dataset.csv +-----+------+-----+ |State|Color |Count| +-----+------+-----+ |TX |Red |20 | |NV |Blue |66 | |CO |Blue |79 | |OR |Blue |71 | |WA |Yellow|93 | +-----+------+-----+ only showing top 5 rows +-----+------+----------+ |State|Color |sum(Count)| +-----+------+----------+ |CA |Yellow|100956 | |WA |Green |96486 | |CA |Brown |95762 | |TX |Green |95753 | |TX |Red |95404 | |CO |Yellow|95038 | |NM |Red |94699 | |OR |Orange|94514 | |WY |Green |94339 | |NV |Orange|93929 | |TX |Yellow|93819 | |CO |Green |93724 | |CO |Brown |93692 | |CA |Green |93505 | |NM |Brown |93447 | |CO |Blue |93412 | |WA |Red |93332 | |WA |Brown |93082 | |WA |Yellow|92920 | |NM |Yellow|92747 | |NV |Brown |92478 | |TX |Orange|92315 | |AZ |Brown |92287 | |AZ |Green |91882 | |WY |Red |91768 | |AZ |Orange|91684 | |CA |Red |91527 | |WA |Orange|91521 | |NV |Yellow|91390 | |UT |Orange|91341 | |NV |Green |91331 | |NM |Orange|91251 | |NM |Green |91160 | |WY |Blue |91002 | |UT |Red |90995 | |CO |Orange|90971 | |AZ |Yellow|90946 | |TX |Brown |90736 | |OR |Blue |90526 | |CA |Orange|90311 | |OR |Red |90286 | |NM |Blue |90150 | |AZ |Red |90042 | |NV |Blue |90003 | |UT |Blue |89977 | |AZ |Blue |89971 | |WA |Blue |89886 | |OR |Green |89578 | |CO |Red |89465 | |NV |Red |89346 | |UT |Yellow|89264 | |OR |Brown |89136 | |CA |Blue |89123 | |UT |Brown |88973 | |TX |Blue |88466 | |UT |Green |88392 | |OR |Yellow|88129 | |WY |Orange|87956 | |WY |Yellow|87800 | |WY |Brown |86110 | +-----+------+----------+ Total Rows = 60 +-----+------+----------+ |State|Color |sum(Count)| +-----+------+----------+ |CA |Yellow|100956 | |CA |Brown |95762 | |CA |Green |93505 | |CA |Red |91527 | |CA |Orange|90311 | |CA |Blue |89123 | +-----+------+----------+ 처음에는 mnm_dataset.csv 의 상위 5개 행을 보여주고, 이어서 각 주별, 색깔별 합계를 출력한다. 그리고, 캘리포니아(CA)에 대한 결과만 별도로 출력한다.\nReferences # https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/ https://www.databricks.com/en/glossary/what-are-spark-applications https://spark.apache.org/docs/latest/cluster-overview.html https://velog.io/@dbgpwl34/Spark-스파크-애플리케이션의-아키텍처-스파크-애플리케이션의-생애-주기 https://spark.apache.org/docs/latest/rdd-programming-guide.html https://6mini.github.io/data%20engineering/2021/12/12/rdd/ https://mengu.tistory.com/27 https://sunrise-min.tistory.com/entry/Apache-Spark-RDD https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui.html https://github.com/databricks/LearningSparkV2 ","wordCount":"1281","inLanguage":"en","image":"https:\/\/dl.dropboxusercontent.com\/scl\/fi\/iafnblb6k95kbw7bwn2xj\/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6\u0026dl=0","datePublished":"2025-06-29T12:50:06+09:00","dateModified":"2025-06-29T12:50:06+09:00","author":{"@type":"Person","name":"minyeamer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://minyeamer.github.io/blog/spark-study-3/"},"publisher":{"@type":"Person","name":"Minystory","logo":{"@type":"ImageObject","url":"https://minyeamer.github.io/images/favicons/favicon.ico"}}}</script><title>Apache Spark - 스파크 애플리케이션 구조와 RDD 이해하기 | Minystory</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-3/><link rel=stylesheet href=/book.min.da9f864e1bccfac13510edef0c8dbe217c58d1ba58855d698051f162d9101fc5.css integrity="sha256-2p+GThvM+sE1EO3vDI2+IXxY0bpYhV1pgFHxYtkQH8U=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/search-input.min.0130ffd8d0f9261d369e3f8a1dd27f53e6c9c68d6a3121caf40d774553d01302.js integrity="sha256-ATD/2ND5Jh02nj+KHdJ/U+bJxo1qMSHK9A13RVPQEwI=" crossorigin=anonymous></script><link rel=preload href=/search-data.min.14c2e862a75e3567d64cfdaf05de47fe2ba8c95205bee1199ef71c8bc0695673.json as=fetch crossorigin><script>window.SEARCH_DATA_URL="/search-data.min.14c2e862a75e3567d64cfdaf05de47fe2ba8c95205bee1199ef71c8bc0695673.json"</script><script defer src=/search.min.f30f9834d4764fd9751da64098c954d01085f648ba9ca421a3c97582f8c47253.js integrity="sha256-8w+YNNR2T9l1HaZAmMlU0BCF9ki6nKQho8l1gvjEclM=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-BJ8Z9RMBPJ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BJ8Z9RMBPJ")</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css crossorigin=anonymous><script defer src=/scroll-progress.min.841ade7e507a5f6d59c4e7bf2fe2b2ca034070677ff7957eec55610a024dd776.js integrity="sha256-hBreflB6X21ZxOe/L+KyygNAcGd/95V+7FVhCgJN13Y=" crossorigin=anonymous></script><script defer src=/dark-mode.min.e41c6440ffd9967d6f6a419ff3ce09b862009fe1646ab265f5cb2817d2a508e3.js integrity="sha256-5BxkQP/Zln1vakGf884JuGIAn+FkarJl9csoF9KlCOM=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.9.0/highlightjs-line-numbers.min.js></script><script defer src=/copy-code.min.aaeef965f0b4992e55f976edaecb34a89d414e1791caa18c3f4f4376c6d8b5a8.js integrity="sha256-qu75ZfC0mS5V+Xbtrss0qJ1BTheRyqGMP09DdsbYtag=" crossorigin=anonymous></script><script defer src=/toc-highlightjs.093016f0ef312174ad862fdcf5792e88ab5442bd39beecc38d15643f71ab5c31.min integrity="sha256-CTAW8O8xIXSthi/c9XkuiKtUQr05vuzDjRVkP3GrXDE=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-posts book-layout-post"><div class=scroll-progress><div class=scroll-progress-bar></div></div><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><div class=sidebar-profile><div class=profile-img-wrap><a href=https://minyeamer.github.io/><img src=/images/profile/menu.jpg alt=Profile class=profile-img></a></div><div class=sidebar-social><a href=https://github.com/minyeamer target=_blank title=GitHub><i class="fa-brands fa-github"></i>
</a><a href=/categories/ title=Categories><i class="fa-solid fa-folder"></i>
</a><a href=/tags/ title=Tags><i class="fa-solid fa-tags"></i>
</a><button id=dark-mode-toggle class=dark-mode-toggle aria-label="Toggle dark mode">
<i class="fa-solid fa-circle-half-stroke"></i></button></div></div><h2 class=book-brand><a class="flex align-center" href=/><span>Minystory</span></a></h2><div class="book-search hidden"><div class=search-input-container><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/ onkeydown='event.key==="Enter"&&goToSearchPage()'>
<button type=button id=book-search-button class=book-search-btn onclick=goToSearchPage()>
<i class="fa-solid fa-magnifying-glass"></i></button></div><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden");function goToSearchPage(){const t=document.getElementById("book-search-input"),e=t.value.trim();e&&(window.location.href="/search/?q="+encodeURIComponent(e))}</script><div class=book-categories><input type=checkbox class="hidden toggle" id=categories-control checked>
<label for=categories-control class="categories-toggle categories-link"><a href=/categories/><i class="fa-solid fa-folder"></i>
<span>전체</span>
<span class=category-count>(38)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul class=categories-menu id=categories-menu><li><input type=checkbox class="hidden toggle" id=cat-algorithm>
<label for=cat-algorithm class="categories-toggle categories-link"><a href=/categories/algorithm/><i class="fa-solid fa-folder"></i>
Algorithm
<span class=category-count>(4)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/algorithm/graph/><i class="fa-solid fa-file"></i>
Graph
<span class=category-count>(1)</span></a></li><li class=categories-link><a href=/categories/algorithm/python/><i class="fa-solid fa-file"></i>
Python
<span class=category-count>(2)</span></a></li><li class=categories-link><a href=/categories/algorithm/sql/><i class="fa-solid fa-file"></i>
SQL
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-cloud>
<label for=cat-cloud class="categories-toggle categories-link"><a href=/categories/cloud/><i class="fa-solid fa-folder"></i>
Cloud
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/cloud/kubernetes/><i class="fa-solid fa-file"></i>
Kubernetes
<span class=category-count>(2)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-analysis>
<label for=cat-data-analysis class="categories-toggle categories-link"><a href=/categories/data-analysis/><i class="fa-solid fa-folder"></i>
Data Analysis
<span class=category-count>(3)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-analysis/dacon/><i class="fa-solid fa-file"></i>
Dacon
<span class=category-count>(3)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-engineering>
<label for=cat-data-engineering class="categories-toggle categories-link"><a href=/categories/data-engineering/><i class="fa-solid fa-folder"></i>
Data Engineering
<span class=category-count>(19)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-engineering/apache-airflow/><i class="fa-solid fa-file"></i>
Apache Airflow
<span class=category-count>(7)</span></a></li><li class=categories-link><a href=/categories/data-engineering/apache-spark/><i class="fa-solid fa-file"></i>
Apache Spark
<span class=category-count>(8)</span></a></li><li class=categories-link><a href=/categories/data-engineering/crawling/><i class="fa-solid fa-file"></i>
Crawling
<span class=category-count>(4)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-frontend>
<label for=cat-frontend class="categories-toggle categories-link"><a href=/categories/frontend/><i class="fa-solid fa-folder"></i>
Frontend
<span class=category-count>(7)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/frontend/blog/><i class="fa-solid fa-file"></i>
Blog
<span class=category-count>(7)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-linux>
<label for=cat-linux class="categories-toggle categories-link"><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
<span class=category-count>(1)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/linux/ubuntu/><i class="fa-solid fa-file"></i>
Ubuntu
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-project>
<label for=cat-project class="categories-toggle categories-link"><a href=/categories/project/><i class="fa-solid fa-folder"></i>
Project
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/project/open-source/><i class="fa-solid fa-file"></i>
Open Source
<span class=category-count>(1)</span></a></li><li class=categories-link><a href=/categories/project/tools/><i class="fa-solid fa-file"></i>
Tools
<span class=category-count>(1)</span></a></li></ul></li></ul></div><div class=recent-posts><div class=recent-posts-header><i class="fa-solid fa-clock"></i>
<span>최신글</span></div><ul class=recent-posts-list><li class=recent-post-item><a href=/blog/hugo-blog-3/ title="Hugo 블로그 만들기 (3) - Taxonomies로 태그/카테고리 페이지 커스터마이징"><div class=recent-post-title>Hugo 블로그 만들기 (3) - Taxonomies로 태그/카테고리 페이지 커스터마이징</div><div class=recent-post-date><time datetime=2025-11-22>2025.11.22</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-2/ title="Hugo 블로그 만들기 (2) - 메인 레이아웃 커스터마이징 (메뉴, 목차, 헤더)"><div class=recent-post-title>Hugo 블로그 만들기 (2) - 메인 레이아웃 커스터마이징 (메뉴, 목차, 헤더)</div><div class=recent-post-date><time datetime=2025-11-04>2025.11.04</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-1/ title="Hugo 블로그 만들기 (1) - 프로젝트 구성과 GitHub Pages 배포 (Submodule 활용)"><div class=recent-post-title>Hugo 블로그 만들기 (1) - 프로젝트 구성과 GitHub Pages 배포 (Submodule 활용)</div><div class=recent-post-date><time datetime=2025-11-01>2025.11.01</time></div></a></li><li class=recent-post-item><a href=/blog/openup-handson/ title="[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기"><div class=recent-post-title>[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기</div><div class=recent-post-date><time datetime=2025-10-28>2025.10.28</time></div></a></li><li class=recent-post-item><a href=/blog/uv-project/ title="[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리"><div class=recent-post-title>[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리</div><div class=recent-post-date><time datetime=2025-07-23>2025.07.23</time></div></a></li></ul></div></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><i class="fa-solid fa-bars book-icon" id=menu-icon></i></label><h3><a href=https://minyeamer.github.io/ class=site-title>Minystory</a></h3><label for=toc-control><i class="fa-solid fa-list book-icon" id=toc-icon></i></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#spark-application>Spark Application</a><ul><li><a href=#driver-process>Driver Process</a></li><li><a href=#executor>Executor</a></li><li><a href=#cluster-manager>Cluster Manager</a></li><li><a href=#job>Job</a></li><li><a href=#stage>Stage</a></li><li><a href=#task>Task</a></li></ul></li><li><a href=#rddresilient-distributed-data>RDD(Resilient Distributed Data)</a><ul><li><a href=#rdd-특징>RDD 특징</a></li><li><a href=#transformation>Transformation</a></li><li><a href=#narrow-transformation>Narrow Transformation</a></li><li><a href=#wide-transformation>Wide Transformation</a></li><li><a href=#action>Action</a></li></ul></li><li><a href=#web-ui>Web UI</a></li><li><a href=#spark-submit>spark-submit</a><ul><li><a href=#mm-개수-집계-python>M&amp;M 개수 집계 (Python)</a></li><li><a href=#application-실행>Application 실행</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></aside></header><article class="markdown book-article"><header class=post-header><div class=post-header-category><a href=/categories/data-engineering/apache-spark/ class=post-header-category-link>Data Engineering/Apache Spark</a></div><h1 class=post-header-title>Apache Spark - 스파크 애플리케이션 구조와 RDD 이해하기</h1><div class=post-header-date><time datetime=2025-06-29T12:50:06+09:00>2025. 6. 29. 12:50</time></div></header><div class=book-cover><img src="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0" alt="Cover Image" class=book-cover-img></div><h2 id=spark-application>Spark Application
<a class=anchor href=#spark-application>#</a></h2><p>Spark Application은 Driver Process 하나와 일련의 일련의 Executors로 구성된다.</p><p><img src="https://dl.dropboxusercontent.com/scl/fi/efpu71pb72iioxddwha2y/spark-09-spark-applications.webp?rlkey=p9badhgpaaylfwocm4hq7mpsg&amp;dl=0" alt="Spark Applications Explained | Databricks"></p><h3 id=driver-process>Driver Process
<a class=anchor href=#driver-process>#</a></h3><p>Driver Process는 main() 함수를 실행하고 클러스터 내 노드에서 세 가지 작업을 담당한다.</p><ol><li>Spark Application 관련 정보를 유지한다.</li><li>사용자의 프로그램이나 입력에 대응한다.</li><li>Executor 작업을 분석, 배포, 예약한다.</li></ol><h3 id=executor>Executor
<a class=anchor href=#executor>#</a></h3><p>Executor는 Driver가 할당한 작업을 실제로 실행하는 역할을 하는데, 두 가지 작업을 담당한다.</p><ol><li>Driver가 할당한 Task를 실행한다.</li><li>Task의 상태와 결과를 Driver 노드에 보고한다.</li></ol><h3 id=cluster-manager>Cluster Manager
<a class=anchor href=#cluster-manager>#</a></h3><p>실물 시스템을 제어하고 Spark Application에 리소스를 할당하는 작업은 Cluster Manager가 맡는다.
Spark Application의 실행 과정에서 Cluster Manager는 Application이 실행되는 물리적인 머신을 관리한다.
Spark Application은 클러스터에서 독립적인 프로세스로 실행되며, SparkContext 객체에 의해 조정된다.</p><p><img src="https://dl.dropboxusercontent.com/scl/fi/idzpu1q4qtd235bz2j6zd/spark-10-cluster-overview.webp?rlkey=ta8wmac7rx1ekmuh5ts6lca7w&amp;dl=0" alt="Cluster Mode Overview - Spark 4.0.0 Documentation"></p><p>SparkContext는 여러 유형의 Cluster Manager(Standalone, YARN, Kubernetes)에 연결될 수 있으며,
Application 간에 리소스를 할당한다. Spark가 연결되어 클러스터의 노드에서 Executor가 확보되면,
SparkContext에 전달된 Application 코드가 Executor에게 전달된다.</p><p><img src="https://dl.dropboxusercontent.com/scl/fi/jqawdvvxozxxs5e5mta5q/spark-11-execution-flow.webp?rlkey=qsjvuasvudjkugo7j54jylt6w&amp;dl=0" alt="Driver -> Job -> Stage -> Tasks"></p><h3 id=job>Job
<a class=anchor href=#job>#</a></h3><p>Spark Driver는 Spark Application을 하나 이상의 Spark Job으로 변환한다.
각 Job은 DAG로 변환되며, DAG 그래프에서 각각의 노드는 하나 이상의 Spark Stage에 해당한다.</p><h3 id=stage>Stage
<a class=anchor href=#stage>#</a></h3><p>어떤 작업이 연속적으로 또는 병렬적으로 수행되는지에 맞춰 Stage에 해당하는 DAG 노드가 생성된다.
Spark 연산은 하나의 Stage 안에서 실행되지 않고 여러 Stage로 나뉘어 실행된다.</p><h3 id=task>Task
<a class=anchor href=#task>#</a></h3><p>각 Stage는 최소 실행 단위이며 Executor들 위에서 실행되는 Spark Task들로 이루어진다.
각 Task는 개별적인 CPU 코어에 할당되어 개별적인 파티션을 갖고 작업하기 때문에, 철저하게 병렬 처리가 이루어진다.</p><h2 id=rddresilient-distributed-data>RDD(Resilient Distributed Data)
<a class=anchor href=#rddresilient-distributed-data>#</a></h2><p>RDD는 탄력적인 분산 데이터셋이란 의미로, 분산 데이터를 병렬로 처리하고 장애가 발생할 경우 스스로
복구될 수 있는 내성을 가지고 있다. RDD는 Spark에서 정의한 분산 데이터 모델로,
여러 서버에 나누어 저장되어 각 서버에서 저장된 데이터를 동시에 병렬로 처리할 수 있다.</p><h3 id=rdd-특징>RDD 특징
<a class=anchor href=#rdd-%ed%8a%b9%ec%a7%95>#</a></h3><p>RDD는 5가지 특징을 가지고 있다.</p><ol><li><p>Distributed Collection<br>데이터는 클러스터에 흩어져 있지만 하나의 파일인 것처럼 사용이 가능한다.
즉, 여러 군데의 데이터를 하나의 객체로 사용할 수 있다.</p></li><li><p>Resilient & Immutable<br>데이터는 탄력적이고 불변하는 성질이 있다. RDD의 변환 과정은 DAG로 그릴 수 있기 때문에 문제가 생길 경우
쉽게 이전의 RDD로 돌아갈 수 있다. 연산 중 문제가 생겨도 다시 복원해서 연산하면 되기 때문에
탄력적인 성질을 가진다고 볼 수 있다. 또한, 여러 노드 중 하나의 노드에서 장애가 발생해도
복원이 가능하기 때문에 불변하다는 성질을 가진다고도 볼 수 있다.</p></li><li><p>Type-Safe<br>RDD는 컴파일 시 타입을 판별할 수 있다. Integer RDD, String RDD, Double RDD 등으로
미리 판단할 수 있기 때문에 문제를 일찍 발견할 수 있다.</p></li><li><p>Structured & Unstructured Data<br>정형 데이터인 테이블, RDB, DataFrame과 비정형 데이터인 텍스트, 로그, 자연어 등을 모두 담을 수 있다.</p></li><li><p>Lazy Evaluation<br>분산 데이터의 Spark 연산은 Transformation과 Action으로 구분된다. Action을 할 때까지
Transformation을 실행하지 않는다. Action을 하게 되면 Transformation을 실행하는 게으른 연산 방식을 가진다.</p></li></ol><h3 id=transformation>Transformation
<a class=anchor href=#transformation>#</a></h3><p>Transformation은 불변성의 특징을 가진 원본 데이터를 수정하지 않고 하나의 Spark DataFrame을
새로운 DataFrame으로 변형(Transform)한다. <code>select()</code> 나 <code>filter()</code> 같은 연산은 원본 DataFrame을 수정하지 않는다.</p><p>Transformation은 즉시 계산되지 않고 Lineage라 불리는 형태로 기록된다.
기록된 Lineage는 더 효율적으로 연산할 수 있도록 Transformation들끼리 재배열하거나 합치도록 최적화된다.
Lazy Evaluation은 Action이 실행되는 시점이나 데이터에 실제 접근하는 시점까지 실제 실행을 미루는 전략이다.</p><p>Lazy Evaluation이 일련의 Transformation들을 최적화한다면, Lineage는 데이터 불변성 및
장애에 대한 내구성을 제공한다. Lineage에는 Transformation들이 기록되어 있고 실행 전까지
DataFrame이 변하지 않기 때문에, 단순히 기록된 Lineage를 재실행하는 것만으로 원래 상태를 다시 만들어낼 수 있다.</p><p>Transformation은 Narrow Transformation과 Wide Transformation으로 구분된다.</p><h3 id=narrow-transformation>Narrow Transformation
<a class=anchor href=#narrow-transformation>#</a></h3><p>Narrow Transformation은 하나의 입력 파티션을 연산하여 하나의 출력 파티션을 내놓는 경우다.
입력 파티션에 대한 연산이 독립적으로 이루어지며, 연산의 결과인 출력 파티션은 입력 파티션의 데이터에만 의존한다.
즉, 다른 파티션의 데이터를 참조할 필요가 없다는 것을 의미한다. <code>filter()</code> 와 <code>contains()</code> 등의 연산이 여기에 해당된다.</p><p>Narrow Transformation은 실행 비용이 상대적으로 낮고, 성능이 좋아 빠른 처리가 가능하다.</p><h3 id=wide-transformation>Wide Transformation
<a class=anchor href=#wide-transformation>#</a></h3><p>Wide Transformation은 입력 데이터의 여러 파티션 간에 데이터가 재분배되어야 하는 경우다.
다른 파티션으로부터 데이터를 읽어들여서 Shuffle(데이터 재분배)하는 과정이 필요하며,
<code>groupBy()</code> 나 <code>orderBy()</code> 등의 연산이 여기에 해당된다.</p><p>Wide Transformation은 네트워크를 통한 대량의 데이터 이동을 발생시켜 실행 시간이 오래 걸리고 리소스 사용량이 많다.</p><h3 id=action>Action
<a class=anchor href=#action>#</a></h3><p>Action은 RDD로 결과 값을 계산하고, 연산 결과를 반환하거나 외부 스토리지(HDFS 등)에 저장한다.
<code>count()</code> 나 <code>show()</code> 함수는 연산 결과를 반환하거나 출력하고,
<code>saveAsTextFile()</code> 과 같은 함수로 연산 결과를 스토리지에 저장할 수 있다.</p><p>Action을 호출할 때마다 RDD가 처음부터 계산되는데, 반복적인 연산에 의한 비효율성을 피하기 위해
<code>cache()</code> 와 <code>persist()</code> 를 사용해 데이터를 메모리에 보관할 수 있다.</p><h2 id=web-ui>Web UI
<a class=anchor href=#web-ui>#</a></h2><p>스파크는 클러스터 상태와 리소스 사용을 모니터링하기 위해 Web UI를 제공한다.
기본적으로 4040 포트를 사용하는데 다음과 같은 내용을 볼 수 있다.</p><ul><li>스케줄러의 Stage와 Task 목록</li><li>RDD 크기와 메모리 사용의 요약</li><li>환경 정보</li><li>실행 중인 Executor 정보</li><li>모든 스파크 SQL 쿼리</li></ul><p>아래는 <a href=https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui.html target=_blank rel="noopener noreferrer">AWS 문서</a>에서
제공하는 화면이다. Web UI를 통해 Job, Stage, Task들이 어떻게 구성되는지 DAG 형태로 시각화해서 볼 수 있다.
Stage 안에서 각각의 Task는 파란 박스로 표시되는데, 아래 예시에서 Stage 2는 2개의
Task로 구성되어 있음을 알 수 있다. Task가 여러 개라면 모두 병렬로 실행된다.</p><p><img src="https://dl.dropboxusercontent.com/scl/fi/34b0fd6v1ovfsezjbu7qc/spark-12-dag-visualization.webp?rlkey=sk8l6qo20z319bctwc4fr70op&amp;dl=0" alt="Detail for Job 2 > [Stage 2 -> Stage 3 -> Stage 4]"></p><h2 id=spark-submit>spark-submit
<a class=anchor href=#spark-submit>#</a></h2><p><a href=https://github.com/databricks/LearningSparkV2/tree/master/chapter2/py/src target=_blank rel="noopener noreferrer">databricks/LearningSparkV2/chapter2</a>
에서 각 주별로 학생들이 어떤 색깔의 M&amp;M을 좋아하는지 알려주는 스파크 프로그램을 작성한 예제 <code>mnmcount.py</code> 를 가져온다.
동일한 위치의 <code>data/</code> 경로에서 M&amp;M 데이터셋 <code>mnm_dataset.csv</code> 을 확인할 수 있다.</p><h3 id=mm-개수-집계-python>M&amp;M 개수 집계 (Python)
<a class=anchor href=#mm-%ea%b0%9c%ec%88%98-%ec%a7%91%ea%b3%84-python>#</a></h3><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># src/mnmcount.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>SparkSession</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>sys</span><span class=o>.</span><span class=n>argv</span><span class=p>)</span> <span class=o>!=</span> <span class=mi>2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Usage: mnmcount &lt;file&gt;&#34;</span><span class=p>,</span> <span class=n>file</span><span class=o>=</span><span class=n>sys</span><span class=o>.</span><span class=n>stderr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>sys</span><span class=o>.</span><span class=n>exit</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># SparkSession 객체를 만든다.</span>
</span></span><span class=line><span class=cl>    <span class=n>spark</span> <span class=o>=</span> <span class=p>(</span><span class=n>SparkSession</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>builder</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&#34;PythonMnMCount&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>getOrCreate</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 인자에서 M&amp;M 데이터가 들어있는 파일 이름을 얻는다.</span>
</span></span><span class=line><span class=cl>    <span class=n>mnm_file</span> <span class=o>=</span> <span class=n>sys</span><span class=o>.</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 데이터가 CSV 형식이며 헤더가 있음을 알리고 스키마를 추론하도록 한다.</span>
</span></span><span class=line><span class=cl>    <span class=n>mnm_df</span> <span class=o>=</span> <span class=p>(</span><span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&#34;csv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>option</span><span class=p>(</span><span class=s2>&#34;header&#34;</span><span class=p>,</span> <span class=s2>&#34;true&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>option</span><span class=p>(</span><span class=s2>&#34;inferSchema&#34;</span><span class=p>,</span> <span class=s2>&#34;true&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>mnm_file</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>mnm_df</span><span class=o>.</span><span class=n>show</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>truncate</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># State, Color, Count 필드를 선택하고 State, Color를 기준으로 Count를 sum 집계한다.</span>
</span></span><span class=line><span class=cl>    <span class=c1># select, groupBy, sum, orderBy 메서드를 연결하여 연속적으로 호출한다.</span>
</span></span><span class=line><span class=cl>    <span class=n>count_mnm_df</span> <span class=o>=</span> <span class=p>(</span><span class=n>mnm_df</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;State&#34;</span><span class=p>,</span> <span class=s2>&#34;Color&#34;</span><span class=p>,</span> <span class=s2>&#34;Count&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=o>.</span><span class=n>groupBy</span><span class=p>(</span><span class=s2>&#34;State&#34;</span><span class=p>,</span> <span class=s2>&#34;Color&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=s2>&#34;Count&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=s2>&#34;sum(Count)&#34;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 상위 60개 결과를 보여주고, 모든 행 개수를 count 집계해 출력한다.</span>
</span></span><span class=line><span class=cl>    <span class=n>count_mnm_df</span><span class=o>.</span><span class=n>show</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>60</span><span class=p>,</span> <span class=n>truncate</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Total Rows = </span><span class=si>%d</span><span class=s2>&#34;</span> <span class=o>%</span> <span class=p>(</span><span class=n>count_mnm_df</span><span class=o>.</span><span class=n>count</span><span class=p>()))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 위 집계 과정에서 중간에 where 메서드를 추가해 캘리포니아(CA) 주에 대해서만 집계한다.</span>
</span></span><span class=line><span class=cl>    <span class=n>ca_count_mnm_df</span> <span class=o>=</span> <span class=p>(</span><span class=n>mnm_df</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;*&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>mnm_df</span><span class=o>.</span><span class=n>State</span> <span class=o>==</span> <span class=s1>&#39;CA&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=o>.</span><span class=n>groupBy</span><span class=p>(</span><span class=s2>&#34;State&#34;</span><span class=p>,</span> <span class=s2>&#34;Color&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=s2>&#34;Count&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=s2>&#34;sum(Count)&#34;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 상위 10개 결과를 보여준다.</span>
</span></span><span class=line><span class=cl>    <span class=n>ca_count_mnm_df</span><span class=o>.</span><span class=n>show</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>truncate</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># SparkSession을 멈춘다.</span>
</span></span><span class=line><span class=cl>    <span class=n>spark</span><span class=o>.</span><span class=n>stop</span><span class=p>()</span></span></span></code></pre></div></div><h3 id=application-실행>Application 실행
<a class=anchor href=#application-%ec%8b%a4%ed%96%89>#</a></h3><p><code>spark-submit</code> 스크립트에 파이썬 코드를 첫 번째 인자로, CSV 파일을 두 번째 인자로 전달한다.</p><p>실행 과정에서 불필요한 INFO 로그를 무시하고 싶다면, <code>$SPARK_HOME/conf/</code> 경로에서
<code>log4j2.properties.template</code> 파일의 이름을 <code>log4j2.properties</code> 로 변경하고
파일 내용에서 <code>rootLogger.level = info</code> 부분의 값을 <code>warn</code> 으로 변경하면 된다.</p><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>(</span>spark<span class=o>)</span> % <span class=nv>$SPARK_HOME</span>/bin/spark-submit src/mnmcount.py data/mnm_dataset.csv
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>+-----+------+-----+
</span></span><span class=line><span class=cl><span class=p>|</span>State<span class=p>|</span>Color <span class=p>|</span>Count<span class=p>|</span>
</span></span><span class=line><span class=cl>+-----+------+-----+
</span></span><span class=line><span class=cl><span class=p>|</span>TX   <span class=p>|</span>Red   <span class=p>|</span><span class=m>20</span>   <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NV   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>66</span>   <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CO   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>79</span>   <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>OR   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>71</span>   <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WA   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>93</span>   <span class=p>|</span>
</span></span><span class=line><span class=cl>+-----+------+-----+
</span></span><span class=line><span class=cl>only showing top <span class=m>5</span> rows
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>+-----+------+----------+
</span></span><span class=line><span class=cl><span class=p>|</span>State<span class=p>|</span>Color <span class=p>|</span>sum<span class=o>(</span>Count<span class=o>)</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+-----+------+----------+
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>100956</span>    <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WA   <span class=p>|</span>Green <span class=p>|</span><span class=m>96486</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Brown <span class=p>|</span><span class=m>95762</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>TX   <span class=p>|</span>Green <span class=p>|</span><span class=m>95753</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>TX   <span class=p>|</span>Red   <span class=p>|</span><span class=m>95404</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CO   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>95038</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NM   <span class=p>|</span>Red   <span class=p>|</span><span class=m>94699</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>OR   <span class=p>|</span>Orange<span class=p>|</span><span class=m>94514</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WY   <span class=p>|</span>Green <span class=p>|</span><span class=m>94339</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NV   <span class=p>|</span>Orange<span class=p>|</span><span class=m>93929</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>TX   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>93819</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CO   <span class=p>|</span>Green <span class=p>|</span><span class=m>93724</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CO   <span class=p>|</span>Brown <span class=p>|</span><span class=m>93692</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Green <span class=p>|</span><span class=m>93505</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NM   <span class=p>|</span>Brown <span class=p>|</span><span class=m>93447</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CO   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>93412</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WA   <span class=p>|</span>Red   <span class=p>|</span><span class=m>93332</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WA   <span class=p>|</span>Brown <span class=p>|</span><span class=m>93082</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WA   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>92920</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NM   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>92747</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NV   <span class=p>|</span>Brown <span class=p>|</span><span class=m>92478</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>TX   <span class=p>|</span>Orange<span class=p>|</span><span class=m>92315</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>AZ   <span class=p>|</span>Brown <span class=p>|</span><span class=m>92287</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>AZ   <span class=p>|</span>Green <span class=p>|</span><span class=m>91882</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WY   <span class=p>|</span>Red   <span class=p>|</span><span class=m>91768</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>AZ   <span class=p>|</span>Orange<span class=p>|</span><span class=m>91684</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Red   <span class=p>|</span><span class=m>91527</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WA   <span class=p>|</span>Orange<span class=p>|</span><span class=m>91521</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NV   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>91390</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>UT   <span class=p>|</span>Orange<span class=p>|</span><span class=m>91341</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NV   <span class=p>|</span>Green <span class=p>|</span><span class=m>91331</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NM   <span class=p>|</span>Orange<span class=p>|</span><span class=m>91251</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NM   <span class=p>|</span>Green <span class=p>|</span><span class=m>91160</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WY   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>91002</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>UT   <span class=p>|</span>Red   <span class=p>|</span><span class=m>90995</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CO   <span class=p>|</span>Orange<span class=p>|</span><span class=m>90971</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>AZ   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>90946</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>TX   <span class=p>|</span>Brown <span class=p>|</span><span class=m>90736</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>OR   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>90526</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Orange<span class=p>|</span><span class=m>90311</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>OR   <span class=p>|</span>Red   <span class=p>|</span><span class=m>90286</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NM   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>90150</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>AZ   <span class=p>|</span>Red   <span class=p>|</span><span class=m>90042</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NV   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>90003</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>UT   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>89977</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>AZ   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>89971</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WA   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>89886</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>OR   <span class=p>|</span>Green <span class=p>|</span><span class=m>89578</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CO   <span class=p>|</span>Red   <span class=p>|</span><span class=m>89465</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>NV   <span class=p>|</span>Red   <span class=p>|</span><span class=m>89346</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>UT   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>89264</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>OR   <span class=p>|</span>Brown <span class=p>|</span><span class=m>89136</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>89123</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>UT   <span class=p>|</span>Brown <span class=p>|</span><span class=m>88973</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>TX   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>88466</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>UT   <span class=p>|</span>Green <span class=p>|</span><span class=m>88392</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>OR   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>88129</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WY   <span class=p>|</span>Orange<span class=p>|</span><span class=m>87956</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WY   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>87800</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>WY   <span class=p>|</span>Brown <span class=p>|</span><span class=m>86110</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl>+-----+------+----------+
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Total <span class=nv>Rows</span> <span class=o>=</span> <span class=m>60</span>
</span></span><span class=line><span class=cl>+-----+------+----------+
</span></span><span class=line><span class=cl><span class=p>|</span>State<span class=p>|</span>Color <span class=p>|</span>sum<span class=o>(</span>Count<span class=o>)</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+-----+------+----------+
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Yellow<span class=p>|</span><span class=m>100956</span>    <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Brown <span class=p>|</span><span class=m>95762</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Green <span class=p>|</span><span class=m>93505</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Red   <span class=p>|</span><span class=m>91527</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Orange<span class=p>|</span><span class=m>90311</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>CA   <span class=p>|</span>Blue  <span class=p>|</span><span class=m>89123</span>     <span class=p>|</span>
</span></span><span class=line><span class=cl>+-----+------+----------+</span></span></code></pre></div></div><p>처음에는 <code>mnm_dataset.csv</code> 의 상위 5개 행을 보여주고, 이어서 각 주별, 색깔별 합계를 출력한다.
그리고, 캘리포니아(CA)에 대한 결과만 별도로 출력한다.</p><h2 id=references>References
<a class=anchor href=#references>#</a></h2><ul><li><a href=https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/ target=_blank rel="noopener noreferrer">https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/</a></li><li><a href=https://www.databricks.com/en/glossary/what-are-spark-applications target=_blank rel="noopener noreferrer">https://www.databricks.com/en/glossary/what-are-spark-applications</a></li><li><a href=https://spark.apache.org/docs/latest/cluster-overview.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/cluster-overview.html</a></li><li><a href=https://velog.io/@dbgpwl34/Spark-%ec%8a%a4%ed%8c%8c%ed%81%ac-%ec%95%a0%ed%94%8c%eb%a6%ac%ec%bc%80%ec%9d%b4%ec%85%98%ec%9d%98-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98-%ec%8a%a4%ed%8c%8c%ed%81%ac-%ec%95%a0%ed%94%8c%eb%a6%ac%ec%bc%80%ec%9d%b4%ec%85%98%ec%9d%98-%ec%83%9d%ec%95%a0-%ec%a3%bc%ea%b8%b0 target=_blank rel="noopener noreferrer">https://velog.io/@dbgpwl34/Spark-스파크-애플리케이션의-아키텍처-스파크-애플리케이션의-생애-주기</a></li><li><a href=https://spark.apache.org/docs/latest/rdd-programming-guide.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/rdd-programming-guide.html</a></li><li><a href=https://6mini.github.io/data%20engineering/2021/12/12/rdd/ target=_blank rel="noopener noreferrer">https://6mini.github.io/data%20engineering/2021/12/12/rdd/</a></li><li><a href=https://mengu.tistory.com/27 target=_blank rel="noopener noreferrer">https://mengu.tistory.com/27</a></li><li><a href=https://sunrise-min.tistory.com/entry/Apache-Spark-RDD target=_blank rel="noopener noreferrer">https://sunrise-min.tistory.com/entry/Apache-Spark-RDD</a></li><li><a href=https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui.html target=_blank rel="noopener noreferrer">https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui.html</a></li><li><a href=https://github.com/databricks/LearningSparkV2 target=_blank rel="noopener noreferrer">https://github.com/databricks/LearningSparkV2</a></li></ul></article><div class=book-nav><button class=book-nav-btn3 onclick='window.scrollTo({top:0,behavior:"smooth"})' title="Go to top">
<i class="fa fa-chevron-up"></i>
</button>
<button class=book-nav-btn3 onclick='window.scrollTo({top:document.body.scrollHeight,behavior:"smooth"})' title="Go to bottom">
<i class="fa fa-chevron-down"></i>
<button class=book-nav-btn3 onclick=history.back() title="Go back">
<i class="fa-solid fa-arrow-left"></i></button></div><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class=post-tags><a href=/tags/apache-spark/ class=tag>#Apache Spark</a>
<a href=/tags/spark-application/ class=tag>#Spark Application</a>
<a href=/tags/rdd/ class=tag>#RDD</a>
<a href=/tags/spark-shell/ class=tag>#Spark Shell</a>
<a href=/tags/spark-web-ui/ class=tag>#Spark Web UI</a>
<a href=/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81/ class=tag>#데이터 엔지니어링</a>
<a href=/tags/%EC%8A%A4%ED%8C%8C%ED%81%AC/ class=tag>#스파크</a>
<a href=/tags/study/ class=tag>#Study</a></div><div class=post-navigation><a href=/blog/spark-study-2/ class="post-nav-link post-nav-prev"><span class=post-nav-direction><i class="fa-solid fa-backward"></i> PREV</span>
<span class=post-nav-title>Apache Spark - 로컬 환경에서 설치하고 PySpark 실행하기</span>
</a><a href=/blog/spark-study-4/ class="post-nav-link post-nav-next"><span class=post-nav-direction>NEXT <i class="fa-solid fa-forward"></i></span>
<span class=post-nav-title>Apache Spark - DataFrame과 Dataset API 활용하기</span></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script><div class=book-comments><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://minyeamer.github.io/blog/spark-study-3/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-3/"};(function(){var e=document,t=e.createElement("script");t.src="https://minyeamer.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})();function reloadDisqus(){window.DISQUS&&DISQUS.reset({reload:!0,config:function(){this.page.url="https://minyeamer.github.io/blog/spark-study-3/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-3/"}})}</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#spark-application>Spark Application</a><ul><li><a href=#driver-process>Driver Process</a></li><li><a href=#executor>Executor</a></li><li><a href=#cluster-manager>Cluster Manager</a></li><li><a href=#job>Job</a></li><li><a href=#stage>Stage</a></li><li><a href=#task>Task</a></li></ul></li><li><a href=#rddresilient-distributed-data>RDD(Resilient Distributed Data)</a><ul><li><a href=#rdd-특징>RDD 특징</a></li><li><a href=#transformation>Transformation</a></li><li><a href=#narrow-transformation>Narrow Transformation</a></li><li><a href=#wide-transformation>Wide Transformation</a></li><li><a href=#action>Action</a></li></ul></li><li><a href=#web-ui>Web UI</a></li><li><a href=#spark-submit>spark-submit</a><ul><li><a href=#mm-개수-집계-python>M&amp;M 개수 집계 (Python)</a></li><li><a href=#application-실행>Application 실행</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></div></aside></main></body></html>