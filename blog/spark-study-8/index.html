<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content><meta name=keywords content="Apache Spark,고차 함수,UDF,Pandas UDF,Spark SQL,PySpark,데이터 엔지니어링,스파크,Study"><meta name=description content="Apache Spark의 고차 함수와 사용자 정의 함수를 다루며, UDF 생성부터 Pandas UDF, transform, filter 등 고차 함수 활용까지 단계별로 안내합니다. …"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><link rel=icon href=https://minyeamer.github.io/images/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://minyeamer.github.io/images/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://minyeamer.github.io/images/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><link rel=mask-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><meta name=google-site-verification content="u1tWcHmHUZWfFT1cHaku6sqU-bK40N3WLR-C-4VUWN0"><meta name=naver-site-verification content="6eaf8e9da1a6104780f056f1a7797fe5a3a5a0da"><meta property="og:title" content="Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기"><meta property="og:description" content="Apache Spark의 고차 함수와 사용자 정의 함수를 다루며, UDF 생성부터 Pandas UDF, transform, filter 등 고차 함수 활용까지 단계별로 안내합니다. …"><meta property="og:type" content="article"><meta property="og:url" content="https://minyeamer.github.io/blog/spark-study-8/"><meta property="og:image" content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;raw=1"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-19T23:53:45+09:00"><meta property="article:modified_time" content="2025-07-19T23:53:45+09:00"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-7/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-6/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-5/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-4/"><meta property="og:see_also" content="https://minyeamer.github.io/blog/spark-study-3/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;raw=1"><meta name=twitter:title content="Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기"><meta name=twitter:description content="Apache Spark의 고차 함수와 사용자 정의 함수를 다루며, UDF 생성부터 Pandas UDF, transform, filter 등 고차 함수 활용까지 단계별로 안내합니다. …"><meta name=twitter:site content="@https://x.com/minyeamer"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://minyeamer.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기","item":"https://minyeamer.github.io/blog/spark-study-8/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기","name":"Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기","description":"Apache Spark의 고차 함수와 사용자 정의 함수를 다루며, UDF 생성부터 Pandas UDF, transform, filter 등 고차 함수 활용까지 단계별로 안내합니다. 빅데이터 분석과 데이터 엔지니어링을 위한 강력한 도구를 습득하고 실무에 적용하세요.\n","keywords":["Apache Spark, 고차 함수, UDF, Pandas UDF, Spark SQL, PySpark, 데이터 엔지니어링, 스파크, Study"],"articleBody":" Apache Spark 배우기 1. 스파크의 기본 개념과 아키텍처 2. 로컬 환경에서 설치하고 PySpark 실행하기 3. 스파크 애플리케이션 구조와 RDD 이해하기 4. DataFrame과 Dataset API 활용하기 5. 스파크 SQL과 테이블/뷰 관리 6. 다양한 데이터 소스 읽기/쓰기 (Parquet, JSON, CSV, Avro) 7. 외부 데이터베이스 연동 (PostgreSQL, MySQL) 8. 사용자 정의 함수(UDF)와 고차 함수 활용하기 숨기기 목록 보기 8/8 User-Defined Functions #스파크는 자신의 기능을 정의할 수 있는 유연성을 제공한다. 이를 사용자 정의 함수(User-Defined Function, UDF)라고 한다.\nUDF를 생성하는 이점은 스파크 SQL 안에서 이를 사용할 수 있다는 것이다.\nSpark SQL UDF 활용 #다음은 스파크 SQL UDF를 만드는 예시로, 인수를 세제곱하는 함수 cubed() 를 생성한다.\nCopy python from pyspark.sql.types import LongType # 큐브 함수 생성 def cubed(s): return s * s * s # UDF로 등록 spark.udf.register(\"cubed\", cubed, LongType())스파크 SQL을 사용하여 cubed() 함수를 실행할 수 있다.\nCopy python # 임시 뷰 생성 spark.range(1, 9).createOrReplaceTempView(\"udf_test\") # 큐브 UDF를 사용하여 쿼리 spark.sql(\"SELECT id, cubed(id) AS id_cubed FROM udf_test\").show() Copy bash +---+--------+ | id|id_cubed| +---+--------+ | 1| 1| | 2| 8| | 3| 27| | 4| 64| | 5| 125| | 6| 216| | 7| 343| | 8| 512| +---+--------+스파크 SQL 평가 순서 #스파크 SQL은 하위 표현식의 평가 순서를 보장하지 않는다. 예를 들어, 다음 쿼리에서 s IS NOT NULL 절이 strlen(s) \u003e 1 절 이전에 실행된다는 것을 보장할 수 없다.\nCopy python spark.sql(\"SELECT s FROM test1 WHERE s IS NOT NULL AND strlen(s) \u003e 1\")따라서, 다음 두 가지 null 검사 방식을 수행하는 것이 좋다.\nUDF 안에서 null 을 인식하고 null 검사를 수행할 필요가 있다. SQL문에서 IF 또는 CASE WHEN 식을 사용하여 null 검사를 수행하고 조건에 맞으면 UDF를 호출한다. Pandas UDF #PySpark UDF는 JVM과 파이썬 사이의 데이터 이동을 필요로 해서 Scala UDF보다 성능이 느렸다.\n이 문제를 해결하기 위해 Pandas UDF가 스파크 2.3 버전부터 도입되었다. Pandas UDF는 Apache Arrow를 사용하여 Pandas UDF를 정의하거나 함수 자체를 래핑할 수 있다. Apache Arrow 형식에 포함된 데이터라면 더이상 JVM으로 데이터를 전달하기 위해 직렬화나 피클할 필요가 없다.\nPandas UDF는 pandas.Series, pandas.DataFrame 과 같은 파이썬 유형 힌트로 유추한다. 예시로, 앞에서 정의한 큐브 함수를 Pandas UDF로 만들면 아래와 같다.\nCopy python import pandas as pd from pyspark.sql.functions import col, pandas_udf from pyspark.sql.types import LongType # 큐브 함수 생성 def cubed(a: pd.Series) -\u003e pd.Series: return a * a * a # 큐브 함수에 대한 Pandas UDF 생성 cubed_udf = pandas_udf(cubed, returnType=LongType())Pandas UDF는 아래와 같이 실행할 수 있다.\nCopy python # 스파크 데이터프레임 생성 df = spark.range(1, 4) # Pandas UDF를 실행 df.select(\"id\", cubed_udf(col(\"id\"))).show() Copy bash +---+---------+ | id|cubed(id)| +---+---------+ | 1| 1| | 2| 8| | 3| 27| +---+---------+스파크 UI에서 시각화된 pandas_udf 함수의 실행 단계에 대한 DAG을 조회할 수 있다. Stage 0에서 ArrowEvalPython 연산이 Pandas UDF를 평가하는 단계이다.\n고차 함수 #복잡한 데이터 유형은 단순한 데이터 유형의 결합이기 때문에 다음과 같이 조작할 수 있다.\n중첩된 구조를 개별 행으로 분해하고 각각에 함수를 적용한 후 중첩된 구조를 다시 만드는 방법 사용자 정의 함수를 사용하는 방법 하지만 배열과 같은 중첩된 구조를 분해하고 다시 만든다고 가정할 때, 셔플 작업이 발생해 결과 배열의 순서가 원래 배열의 순서와 동일하지 않을 수 있다.\n사용자 정의 함수를 사용할 경우에는 정렬 문제는 해결할 수 있지만, 직렬화 및 역직렬화 과정을 거치면서 발생하는 비용이 크다는 문제가 있다.\n내장 함수 #복잡한 데이터 유형에 대해 스파크 2.4 이상 버전에 포함된 내장 함수를 사용할 수 있다. 자세한 건 공식 문서를 참고해볼 수 있는데, 그 중에서 배열과 맵에 대해서 일부를 알아본다.\n배열과 관련된 함수는 공식 문서에서 array 문단부터 시작하는 함수들을 참고하면 된다. 대표적으로 array_distinct 함수는 배열 내 중복을 제거하고, array_sort 함수는 배열을 오름차순으로 정렬한다. array로 시작하지 않는 함수 중에서도 concat 함수는 복수 개의 배열을 받아 하나의 배열로 합쳐주고, flatten 함수는 2차원 이상 중첩된 배열을 단일 배열로 플랫화한다. sequence 함수로 시작과 끝에 대한 배열을 생성할 수 있고, slice 함수로 배열의 특정 부분만 잘라낼 수도 있다.\n맵과 관련된 함수는 공식 문서에서 map 문단부터 시작하는 함수들을 참고하면 된다. 대표적으로 map_concat 함수는 복수 개의 맵을 하나의 맵으로 합쳐주고, map_keys 함수로 맵에서 키 배열만 추출할 수도 있다. map으로 시작하지 않는 함수 중에서도 element_at 함수는 주어진 키에 대한 값을 반환하고, cardinality 함수는 맵의 크기를 반환한다.\ntransform() #내장 함수 외에도 익명 람다 함수를 인수로 사용하는 고차 함수 transform() 이 있다.\n고차 함수를 실행해보기 위해 아래와 같이 샘플 데이터 tC 를 만들어본다.\nCopy python from pyspark.sql.types import * schema = StructType([StructField(\"celsius\", ArrayType(IntegerType()))]) t_list = [[35, 36, 32, 30, 40, 42, 38]], [[31, 32, 34, 55, 56]] t_c = spark.createDataFrame(t_list, schema) t_c.createOrReplaceTempView(\"tC\") t_c.show() Copy bash +--------------------+ | celsius| +--------------------+ |[35, 36, 32, 30, ...| |[31, 32, 34, 55, 56]| +--------------------+Celsius 단위를 Fahrenheit 단위로 바꾸는 transform() 함수를 사용해, celsius 열로부터 fahrenheit 열을 계산했다. 출력 결과는 아래와 같다.\nCopy python spark.sql(\"\"\" SELECT celsius, transform(celsius, t -\u003e ((t * 9) div 5) + 32) AS fahrenheit FROM tc \"\"\").show() Copy bash +--------------------+--------------------+ | celsius| fahrenheit| +--------------------+--------------------+ |[35, 36, 32, 30, ...|[95, 96, 89, 86, ...| |[31, 32, 34, 55, 56]|[87, 89, 93, 131,...| +--------------------+--------------------+filter() #filter() 함수는 입력한 배열의 요소 중 부울 함수가 참인 요소만으로 구성된 배열을 생성한다.\nCopy python spark.sql(\"\"\" SELECT celsius, filter(celsius, t -\u003e t \u003e 38) AS high FROM tc \"\"\").show() Copy bash +--------------------+--------+ | celsius| high| +--------------------+--------+ |[35, 36, 32, 30, ...|[40, 42]| |[31, 32, 34, 55, 56]|[55, 56]| +--------------------+--------+exists() #exists() 함수는 입력한 배열의 요소 중 불린 함수를 만족시키는 것이 존재할 때 참을 반환한다.\nCopy python spark.sql(\"\"\" SELECT celsius, exists(celsius, t -\u003e t = 38) AS threshold FROM tc \"\"\").show() Copy bash +--------------------+---------+ | celsius|threshold| +--------------------+---------+ |[35, 36, 32, 30, ...| true| |[31, 32, 34, 55, 56]| false| +--------------------+---------+스파크 SQL 작업 #스파크 SQL의 기능 중 일부는 DataFrame의 다양한 기능에서 유래된다. 이용가능한 작업에는 집계 함수, 수집 함수, 날짜 함수, 수학 함수, 정렬 함수, 문자열 함수, 윈도우 함수 등 매우 광범위하다.\nUnion #Union은 동일한 스키마를 가진 두 개의 서로 다른 DataFrame을 하나로 합치는 작업이다.\nSQL문으로 다음과 같이 표현할 수 있다.\nCopy sql (SELECT * FROM first_half) UNION ALL (SELECT * FROM second_half);파이썬으로는 다음과 같이 표현할 수 있다.\nCopy python result = first_half.union(second_half)Join #Join은 두 개 이상의 DataFrame을 특정 조건을 기준으로 결합하여 하나로 합치는 작업이다.\nSQL문으로 다음과 같이 표현할 수 있다.\nCopy sql SELECT p.id AS productId, p.storeId, s.name AS storeName, p.name AS productName FROM product AS p LEFT JOIN store AS s ON p.storeId = s.id;파이썬으로는 다음과 같이 표현할 수 있다.\nCopy python from pyspark.sql.functions import col product.join( store, product.storeId == store.id, how = \"left\" ).select( col(\"p.id\").alias(\"productId\"), \"p.storeId\", col(\"s.name\").alias(\"storeName\"), col(\"p.name\").alias(\"productName\") ).show()윈도우 #윈도우 함수를 사용하면 모든 입력 행에 대해 단일값을 반환하면서 행 그룹에 대해 작업할 수 있다.\n순위를 매기는 작업과 관련해서는 RANK, DENSE_RANK, PERCENT_RANK, NTILE, ROW_NUMBER 함수가 있고, 집계와 관련해서는 MAX, MIN, COUNT, SUM, AVG 등의 함수가 있다.\nSQL문으로 다음과 같이 표현할 수 있다.\nCopy sql SELECT name, dept, salary, RANK() OVER (PARTITION BY dept ORDER BY salary) AS rank FROM employees;파이썬으로는 다음과 같이 표현할 수 있다.\nCopy python from pyspark.sql.functions import rank from pyspark.sql import Window window = rank().over(Window.partitionBy(\"dept\").orderBy(\"salary\")).alias(\"rank\") employees.select(\"name\", \"dept\", \"salary\", window).show()수정 #DataFrame 자체는 변경할 수 없지만, 열을 가공하여 새로운 DataFrame을 만드는 것과 같은 작업을 통해 수정할 수 있다.\n파이썬으로 활용 가능한 다음과 같은 예시가 있다.\nCopy python from pyspark.sql.functions import expr # 열 추가 foo2 = foo.withColumn( \"status\", expr(\"CASE WHEN delay \u003c= 10 THEN 'On-time' ELSE 'Delayed' END\")) # 열 삭제 foo3 = foo2.drop(\"delay\") # 칼럼명 바꾸기 foo4 = foo3.withColumnRenamed(\"status\", \"flight_status\")피벗 #로우와 칼럼을 바꿔야 하는 경우가 있다. 이 경우에 pivot 함수를 지원한다.\n피벗을 실행해보기 위해 아래와 같이 샘플 데이터를 만들어본다.\nCopy python from pyspark.sql import Row df1 = spark.createDataFrame([ Row(course=\"dotNET\", year=2012, earnings=10000), Row(course=\"Java\", year=2012, earnings=20000), Row(course=\"dotNET\", year=2012, earnings=5000), Row(course=\"dotNET\", year=2013, earnings=48000), Row(course=\"Java\", year=2013, earnings=30000),]) df1.show() Copy bash +------+----+--------+ |course|year|earnings| +------+----+--------+ |dotNET|2012| 10000| | Java|2012| 20000| |dotNET|2012| 5000| |dotNET|2013| 48000| | Java|2013| 30000| +------+----+--------+위 데이터에서 course 를 열로, year 를 행으로, earnings 를 값으로 sum 집계해 구성한 피벗 테이블을 아래와 같이 만들 수 있다.\nCopy python df1.groupBy(\"year\").pivot( \"course\", [\"dotNET\", \"Java\"]).sum(\"earnings\").sort(\"year\").show() Copy bash +----+------+-----+ |year|dotNET| Java| +----+------+-----+ |2012| 15000|20000| |2013| 48000|30000| +----+------+-----+References # https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html https://books.japila.pl/pyspark-internals/sql/ArrowEvalPython/#evalType https://spark.apache.org/docs/latest/api/sql/index.html https://docs.databricks.com/aws/en/semi-structured/higher-order-functions https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rank.html https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.pivot.html ","wordCount":"1264","inLanguage":"ko","image":"https:\/\/dl.dropboxusercontent.com\/scl\/fi\/iafnblb6k95kbw7bwn2xj\/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6\u0026raw=1","datePublished":"2025-07-19T23:53:45+09:00","dateModified":"2025-07-19T23:53:45+09:00","author":{"@type":"Person","name":"minyeamer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://minyeamer.github.io/blog/spark-study-8/"},"publisher":{"@type":"Person","name":"Minystory","logo":{"@type":"ImageObject","url":"https://minyeamer.github.io/images/favicons/favicon.ico"}}}</script><script>(function(){const e=256+768*1.3;window.innerWidth>e&&localStorage.getItem("menu-expanded")==="false"&&document.documentElement.classList.add("menu-initial-collapsed")})()</script><title>Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기</title><link rel=manifest href=/data/manifest.json><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-8/><link rel=stylesheet href=/main.min.2645a7d9c5a4e6ec4130cf335d83b7bd6ecc4ea05e244abe01938a765c99d8b7.css integrity="sha256-JkWn2cWk5uxBMM8zXYO3vW7MTqBeJEq+AZOKdlyZ2Lc=" crossorigin=anonymous><script async src="https://www.googletagmanager.com/gtag/js?id=G-BJ8Z9RMBPJ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BJ8Z9RMBPJ")</script><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script><script>(function(){const e=console.warn;console.warn=function(...n){const t=(new Error).stack||"";if(t.includes("highlight.min.js")||t.includes("highlightjs-line-numbers"))return;e.apply(console,n)}})()</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.9.0/highlightjs-line-numbers.min.js crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){typeof hljs!="undefined"&&(hljs.highlightAll(),typeof hljs.initLineNumbersOnLoad=="function"&&hljs.initLineNumbersOnLoad())})</script><script>window.siteI18n=window.siteI18n||{},window.siteI18n.defaultLang="en"</script><script>window.siteI18n.dataUrl="/data/i18n.min.a69d97976d04e681499d74d71f0019de3d6ed9f29a55bc606a9459d1454b3b65.json"</script><script>window.siteI18n.initData=function(){return window.siteI18n.data?Promise.resolve(window.siteI18n.data):fetch(window.siteI18n.dataUrl).then(e=>{if(!e.ok)throw new Error(`HTTP error! status: ${e.status}`);return e.json()}).then(e=>(window.siteI18n.data=e,window.siteI18n.data))},window.siteI18n.getLanguage=function(e={}){const s="site-language",t=localStorage.getItem(s);if(t)return t;const n=(navigator.language||navigator.userLanguage).split("-")[0];return!e||e[n]?n:window.siteI18n.defaultLang},window.siteI18n.translate=function(e,t=""){if(window.siteI18n.data){const n=window.siteI18n.getLanguage(),t=window.siteI18n.data[n];if(t&&e in t)return t[e]}return t},void window.siteI18n.initData().catch(()=>{})</script><script defer src=/js/core/i18n.min.c076e5ad51c454cca138121312827bfde8c5526a930ce57cea2207f501fea0d7.js integrity="sha256-wHblrVHEVMyhOBITEoJ7/ejFUmqTDOV86iIH9QH+oNc=" crossorigin=anonymous></script><script defer src=/js/partials/scroll-progress.min.841ade7e507a5f6d59c4e7bf2fe2b2ca034070677ff7957eec55610a024dd776.js integrity="sha256-hBreflB6X21ZxOe/L+KyygNAcGd/95V+7FVhCgJN13Y=" crossorigin=anonymous></script><script defer src=/js/partials/menu-toggle.min.e4c6c0cbf938a3d475fffe81471742bb460a77af62c865617af554b992375da9.js integrity="sha256-5MbAy/k4o9R1//6BRxdCu0YKd69iyGVhevVUuZI3Xak=" crossorigin=anonymous></script><script defer src=/js/partials/toc-toggle.min.eb96c48129742c9454fd93d56aed2e6c2d69bf4853d82204b2e53662e92f02cc.js integrity="sha256-65bEgSl0LJRU/ZPVau0ubC1pv0hT2CIEsuU2YukvAsw=" crossorigin=anonymous></script><script defer src=/js/core/set-theme.min.3ffcf0a1423dfbec7dc2da84e7cd18933d2a4ebc1efd4058f2f3da1c4e6d10c3.js integrity="sha256-P/zwoUI9++x9wtqE580Ykz0qTrwe/UBY8vPaHE5tEMM=" crossorigin=anonymous></script><script defer src=/js/shortcodes/copy-code.min.68a0c392faa93e1c6ebb981074928a99da92c62b203f5d43120539057e9e299e.js integrity="sha256-aKDDkvqpPhxuu5gQdJKKmdqSxisgP11DEgU5BX6eKZ4=" crossorigin=anonymous></script><script defer src=/js/partials/toc-highlight.min.7917ead4ecb7378779bfbf3f988251ac76bd55ca7f12fd5919870777dbcd6095.js integrity="sha256-eRfq1Oy3N4d5v78/mIJRrHa9Vcp/Ev1ZGYcHd9vNYJU=" crossorigin=anonymous></script><script defer src=/js/partials/reading-time.min.1063c3a4b82c1c1f36f88704c4544b75c39c2707d86c09aa7098d2963e6d3835.js integrity="sha256-EGPDpLgsHB82+IcExFRLdcOcJwfYbAmqcJjSlj5tODU=" crossorigin=anonymous></script><script defer src=/js/shortcodes/image-zoom.min.bb446c50cbec91f1b4fdfbb9f695d753ef4811f43de0a9411201c8466ffe204a.js integrity="sha256-u0RsUMvskfG0/fu59pXXU+9IEfQ94KlBEgHIRm/+IEo=" crossorigin=anonymous></script><script defer src=/js/shortcodes/data-table.min.d20aaf7f506ee989f91746098231f979e58b8435513de0d4f05eefb9c45743e7.js integrity="sha256-0gqvf1Bu6Yn5F0YJgjH5eeWLhDVRPeDU8F7vucRXQ+c=" crossorigin=anonymous></script><script>window.siteSearch=window.siteSearch||{}</script><script>window.siteSearch.contentUrl="/data/content.min.2139dbc8d9c6a32a3911208fc83c2318f1506e5b4ff3c811888f5a38f634284f.json"</script><script>window.siteSearch.categoriesUrl="/data/categories.min.e5ad81c31794748a54e2582c1615444e4e8e3354bfda1a0ea76f869cebee36d7.json"</script><script>window.siteSearch.tagsUrl="/data/tags.min.e6d3eb3deec95a87346243a2e36efdf24c16f6b62180a48785e3781c41afb2f7.json"</script><script defer src=/fuse.min.js></script><script defer src=/js/search/init.min.ee793e2de351fef268c6642567b4af23bd3763c2cb74f767e7240807e394417d.js integrity="sha256-7nk+LeNR/vJoxmQlZ7SvI703Y8LLdPdn5yQIB+OUQX0=" crossorigin=anonymous></script><script defer src=/js/search/input.min.c66bcb412051f2f9c3c6b5fa330c41ca187bd4e9a91447b672d8cbe1468bcfc9.js integrity="sha256-xmvLQSBR8vnDxrX6MwxByhh71OmpFEe2ctjL4UaLz8k=" crossorigin=anonymous></script><script defer src=/js/search/list.min.dd79e8831a4de031882d789f0ccdd204cc68a7481011c4cfc62f541eda286077.js integrity="sha256-3XnogxpN4DGILXifDM3SBMxop0gQEcTPxi9UHtooYHc=" crossorigin=anonymous></script></head><body class="site-kind-page site-type-posts site-layout-post" dir=ltr><div class=scroll-progress><div class=scroll-progress-bar></div></div><label class=image-overlay-wrap for=image-overlay-toggle><input class="hidden toggle" type=checkbox id=image-overlay-toggle><div class=image-overlay></div></label><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><div class=menu-overlay></div><main class=container><aside class=site-menu aria-label=메뉴 data-i18n-id=menu.aside.tooltip data-i18n-attrs=aira-label><div class=menu-content><nav><div class=menu-profile><div class=profile-image-wrap><a href=https://minyeamer.github.io/><img src=/images/profile/menu.jpg alt=Profile class=profile-image decoding=async></a></div><h2 class=profile-title><a class="flex align-center" href=https://minyeamer.github.io/><span>Minystory</span></a></h2></div><div class=menu-links><a href=https://github.com/minyeamer target=_blank id=github-link title=GitHub><i class=icon-github></i>
</a><a href=/categories/ id=categories-link title=Categories><i class=icon-folder></i>
</a><a href=/tags/ id=tags-link title=Tags><i class=icon-tags></i>
</a><button class=dark-mode-toggle id=theme-toggle-button aria-label="Toggle color scheme">
<i class=icon-moon></i></button></div><div class=menu-search id=search-input data-hotkeys=s/ role=button tabindex=0 aria-label=검색 data-i18n-id=search.action.label data-i18n-attrs=aira-label><i class="icon-search search-icon"></i>
<span class=search-placeholder data-i18n-id=search.input.label data-i18n-text='{"`/`": "$code"}'><code>/</code> 를 눌러 검색하세요</span></div><div class=menu-categories><input type=checkbox class="hidden toggle" id=categories-control checked>
<label for=categories-control class="categories-label categories-toggle"><a href=/categories/ class=categories-root><i class=icon-folder></i>
<span data-i18n-id=categories.root.label data-i18n-text>전체
</span><span class=category-count>(42)</span>
</a><i class="icon-chevron-down categories-arrow"></i></label><ul><li><input type=checkbox class="hidden toggle" id=cat-algorithm>
<label for=cat-algorithm class="categories-label categories-toggle"><a href="/search/?category1=Algorithm"><i class=icon-folder></i>Algorithm<span class=category-count>(4)</span>
</a><i class="icon-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Algorithm&category2=Graph"><i class=icon-file></i>Graph<span class=category-count>(1)</span></a></li><li class=categories-label><a href="/search/?category1=Algorithm&category2=Python"><i class=icon-file></i>Python<span class=category-count>(2)</span></a></li><li class=categories-label><a href="/search/?category1=Algorithm&category2=SQL"><i class=icon-file></i>SQL<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-cloud>
<label for=cat-cloud class="categories-label categories-toggle"><a href="/search/?category1=Cloud"><i class=icon-folder></i>Cloud<span class=category-count>(2)</span>
</a><i class="icon-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Cloud&category2=Kubernetes"><i class=icon-file></i>Kubernetes<span class=category-count>(2)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-analysis>
<label for=cat-data-analysis class="categories-label categories-toggle"><a href="/search/?category1=Data%20Analysis"><i class=icon-folder></i>Data Analysis<span class=category-count>(3)</span>
</a><i class="icon-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Data%20Analysis&category2=Dacon"><i class=icon-file></i>Dacon<span class=category-count>(3)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-engineering>
<label for=cat-data-engineering class="categories-label categories-toggle"><a href="/search/?category1=Data%20Engineering"><i class=icon-folder></i>Data Engineering<span class=category-count>(19)</span>
</a><i class="icon-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Data%20Engineering&category2=Apache%20Airflow"><i class=icon-file></i>Apache Airflow<span class=category-count>(7)</span></a></li><li class=categories-label><a href="/search/?category1=Data%20Engineering&category2=Apache%20Spark"><i class=icon-file></i>Apache Spark<span class=category-count>(8)</span></a></li><li class=categories-label><a href="/search/?category1=Data%20Engineering&category2=Crawling"><i class=icon-file></i>Crawling<span class=category-count>(4)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-frontend>
<label for=cat-frontend class="categories-label categories-toggle"><a href="/search/?category1=Frontend"><i class=icon-folder></i>Frontend<span class=category-count>(11)</span>
</a><i class="icon-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Frontend&category2=Blog"><i class=icon-file></i>Blog<span class=category-count>(11)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-linux>
<label for=cat-linux class="categories-label categories-toggle"><a href="/search/?category1=Linux"><i class=icon-folder></i>Linux<span class=category-count>(1)</span>
</a><i class="icon-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Linux&category2=Ubuntu"><i class=icon-file></i>Ubuntu<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-project>
<label for=cat-project class="categories-label categories-toggle"><a href="/search/?category1=Project"><i class=icon-folder></i>Project<span class=category-count>(2)</span>
</a><i class="icon-chevron-down categories-arrow"></i></label><ul><li class=categories-label><a href="/search/?category1=Project&category2=Open%20Source"><i class=icon-file></i>Open Source<span class=category-count>(1)</span></a></li><li class=categories-label><a href="/search/?category1=Project&category2=Tools"><i class=icon-file></i>Tools<span class=category-count>(1)</span></a></li></ul></li></ul></div><div class=recent-posts><div class=recent-post-label><i class=icon-clock></i>
<span data-i18n-id=menu.recent.posts data-i18n-text>최신글</span></div><ul class=recent-post-list><li class=recent-post-item><a href=/blog/hugo-seotax-2/ title="Hugo 정적 페이지 경량화 - JS 기반 동적 렌더링 검색 구현"><div class=recent-post-title>Hugo 정적 페이지 경량화 - JS 기반 동적 렌더링 검색 구현</div><div class=recent-post-date><time datetime=2026-02-15>2026.02.15</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-seotax-1/ title="Hugo 서택스(SeoTax) 테마 제작기 - 동적 렌더링으로 확장된 검색"><div class=recent-post-title>Hugo 서택스(SeoTax) 테마 제작기 - 동적 렌더링으로 확장된 검색</div><div class=recent-post-date><time datetime=2026-01-25>2026.01.25</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-5/ title="Hugo Disqus 댓글 연동 - 본문 레이아웃 개선하기 (헤더/푸터)"><div class=recent-post-title>Hugo Disqus 댓글 연동 - 본문 레이아웃 개선하기 (헤더/푸터)</div><div class=recent-post-date><time datetime=2025-12-15>2025.12.15</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-4/ title="Hugo 검색 기능 구현 - Fuse.js로 검색 인덱스 최적화하기"><div class=recent-post-title>Hugo 검색 기능 구현 - Fuse.js로 검색 인덱스 최적화하기</div><div class=recent-post-date><time datetime=2025-12-14>2025.12.14</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-3/ title="Hugo 분류(Taxonomies) 커스터마이징 - 태그/카테고리 템플릿 구현"><div class=recent-post-title>Hugo 분류(Taxonomies) 커스터마이징 - 태그/카테고리 템플릿 구현</div><div class=recent-post-date><time datetime=2025-11-22>2025.11.22</time></div></a></li></ul></div></nav><script>(function(){var e=document.querySelector("aside .menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=main-wrap><header class=site-header><div class="flex align-center justify-between"><label for=menu-control aria-label="메뉴 접기/펼치기" title="메뉴 접기/펼치기" data-i18n-id=menu.toggle.tooltip data-i18n-attrs=aria-label,title><i class="icon-bars menu-icon" id=menu-icon></i></label><div class=mobile-search id=mobile-search-input role=button tabindex=0 aria-label=검색 data-i18n-id=search.action.label data-i18n-attrs=aria-label><i class="icon-search search-icon"></i>
<span class=mobile-title>Minystory</span>
<i class=mobile-title-pad></i></div><label for=toc-control aria-label="목차 접기/펼치기" title="목차 접기/펼치기" data-i18n-id=toc.toggle.tooltip data-i18n-attrs=aria-label,title><i class="icon-list menu-icon" id=toc-icon></i></label></div></header><article class="content-wrap markdown" id=content-wrap><header class=content-header><div class=content-category><a href="/search/?category1=Data%20Engineering&category2=Apache%20Spark" class=content-category-link>Data Engineering/Apache Spark</a></div><h1 class=content-title>Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기</h1><div class=content-datetime><time datetime=2025-07-19T23:53:45+09:00>2025. 07. 19. 23:53
</time><span>• </span><span id=reading-time>읽는데 19분</span></div></header><div class=content-cover-wrap><img src="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;raw=1" class=content-cover alt="Cover Image" width=1280 height=665 decoding=async></div><div id=series-anchor></div><div class=sc-series><div class=series-bookmark><svg width="32" height="48" fill="currentColor" viewBox="0 0 32 48" class="series-corner-image"><path fill="currentColor" d="M32 0H0v48h.163l16-16L32 47.836V0z"/></svg></div><div class=series-header><h2 class=series-title>Apache Spark 배우기</h2></div><input type=checkbox id=series-toggle class=series-toggle-input hidden><div class=series-content><ol class=series-list><li class=series-item><span class=series-item-index>1.</span>
<a href=/blog/spark-study-1/#series-anchor>스파크의 기본 개념과 아키텍처</a></li><li class=series-item><span class=series-item-index>2.</span>
<a href=/blog/spark-study-2/#series-anchor>로컬 환경에서 설치하고 PySpark 실행하기</a></li><li class=series-item><span class=series-item-index>3.</span>
<a href=/blog/spark-study-3/#series-anchor>스파크 애플리케이션 구조와 RDD 이해하기</a></li><li class=series-item><span class=series-item-index>4.</span>
<a href=/blog/spark-study-4/#series-anchor>DataFrame과 Dataset API 활용하기</a></li><li class=series-item><span class=series-item-index>5.</span>
<a href=/blog/spark-study-5/#series-anchor>스파크 SQL과 테이블/뷰 관리</a></li><li class=series-item><span class=series-item-index>6.</span>
<a href=/blog/spark-study-6/#series-anchor>다양한 데이터 소스 읽기/쓰기 (Parquet, JSON, CSV, Avro)</a></li><li class=series-item><span class=series-item-index>7.</span>
<a href=/blog/spark-study-7/#series-anchor>외부 데이터베이스 연동 (PostgreSQL, MySQL)</a></li><li class="series-item active"><span class=series-item-index>8.</span>
<a href=/blog/spark-study-8/#series-anchor>사용자 정의 함수(UDF)와 고차 함수 활용하기</a></li></ol></div><div class=series-footer><label for=series-toggle class=series-toggle-label><span class=series-toggle-icon><i class=icon-caret-up></i></span>
<span class=series-toggle-text-hide data-i18n-id=series.hide.label data-i18n-text>숨기기</span>
<span class=series-toggle-text-show data-i18n-id=series.show.label data-i18n-text>목록 보기</span></label><div class=series-nav><span class=series-nav-info>8/8</span><div class=series-nav-buttons><a href=/blog/spark-study-7/#series-anchor class=series-nav-button><i class=icon-chevron-left></i></a>
<span class="series-nav-button disabled"><i class=icon-chevron-right></i></span></div></div></div></div><script>(function(){const e=document.getElementById("series-toggle"),t="series-expanded",n=localStorage.getItem(t)??"true";n==="true"&&(e.checked=!0),e.addEventListener("change",function(){localStorage.setItem(t,this.checked)})})()</script><h2 id=user-defined-functions>User-Defined Functions
<a class=anchor href=#user-defined-functions>#</a></h2><p>스파크는 자신의 기능을 정의할 수 있는 유연성을 제공한다.
이를 사용자 정의 함수(User-Defined Function, UDF)라고 한다.</p><p>UDF를 생성하는 이점은 스파크 SQL 안에서 이를 사용할 수 있다는 것이다.</p><h3 id=spark-sql-udf-활용>Spark SQL UDF 활용
<a class=anchor href=#spark-sql-udf-%ed%99%9c%ec%9a%a9>#</a></h3><p>다음은 스파크 SQL UDF를 만드는 예시로, 인수를 세제곱하는 함수 <code>cubed()</code> 를 생성한다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.types</span> <span class=kn>import</span> <span class=n>LongType</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 큐브 함수 생성</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cubed</span><span class=p>(</span><span class=n>s</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>s</span> <span class=o>*</span> <span class=n>s</span> <span class=o>*</span> <span class=n>s</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># UDF로 등록</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>udf</span><span class=o>.</span><span class=n>register</span><span class=p>(</span><span class=s2>&#34;cubed&#34;</span><span class=p>,</span> <span class=n>cubed</span><span class=p>,</span> <span class=n>LongType</span><span class=p>())</span></span></span></code></pre></div></div><p>스파크 SQL을 사용하여 <code>cubed()</code> 함수를 실행할 수 있다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 임시 뷰 생성</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>)</span><span class=o>.</span><span class=n>createOrReplaceTempView</span><span class=p>(</span><span class=s2>&#34;udf_test&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 큐브 UDF를 사용하여 쿼리</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT id, cubed(id) AS id_cubed FROM udf_test&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=sc-codeblock data-lang=bash><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+---+--------+
</span></span><span class=line><span class=cl><span class=p>|</span> id<span class=p>|</span>id_cubed<span class=p>|</span>
</span></span><span class=line><span class=cl>+---+--------+
</span></span><span class=line><span class=cl><span class=p>|</span>  1<span class=p>|</span>       1<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  2<span class=p>|</span>       8<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  3<span class=p>|</span>      27<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  4<span class=p>|</span>      64<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  5<span class=p>|</span>     125<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  6<span class=p>|</span>     216<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  7<span class=p>|</span>     343<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  8<span class=p>|</span>     512<span class=p>|</span>
</span></span><span class=line><span class=cl>+---+--------+</span></span></code></pre></div></div><h3 id=스파크-sql-평가-순서>스파크 SQL 평가 순서
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac-sql-%ed%8f%89%ea%b0%80-%ec%88%9c%ec%84%9c>#</a></h3><p>스파크 SQL은 하위 표현식의 평가 순서를 보장하지 않는다.
예를 들어, 다음 쿼리에서 <code>s IS NOT NULL</code> 절이 <code>strlen(s) > 1</code> 절 이전에 실행된다는 것을 보장할 수 없다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT s FROM test1 WHERE s IS NOT NULL AND strlen(s) &gt; 1&#34;</span><span class=p>)</span></span></span></code></pre></div></div><p>따라서, 다음 두 가지 <code>null</code> 검사 방식을 수행하는 것이 좋다.</p><ol><li>UDF 안에서 <code>null</code> 을 인식하고 <code>null</code> 검사를 수행할 필요가 있다.</li><li>SQL문에서 <code>IF</code> 또는 <code>CASE WHEN</code> 식을 사용하여 <code>null</code> 검사를 수행하고 조건에 맞으면 UDF를 호출한다.</li></ol><h3 id=pandas-udf>Pandas UDF
<a class=anchor href=#pandas-udf>#</a></h3><p>PySpark UDF는 JVM과 파이썬 사이의 데이터 이동을 필요로 해서 Scala UDF보다 성능이 느렸다.</p><p>이 문제를 해결하기 위해 Pandas UDF가 스파크 2.3 버전부터 도입되었다.
Pandas UDF는 Apache Arrow를 사용하여 Pandas UDF를 정의하거나 함수 자체를 래핑할 수 있다.
Apache Arrow 형식에 포함된 데이터라면 더이상 JVM으로 데이터를 전달하기 위해 직렬화나 피클할 필요가 없다.</p><p>Pandas UDF는 <code>pandas.Series</code>, <code>pandas.DataFrame</code> 과 같은 파이썬 유형 힌트로 유추한다.
예시로, 앞에서 정의한 큐브 함수를 Pandas UDF로 만들면 아래와 같다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>col</span><span class=p>,</span> <span class=n>pandas_udf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.types</span> <span class=kn>import</span> <span class=n>LongType</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 큐브 함수 생성</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cubed</span><span class=p>(</span><span class=n>a</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>a</span> <span class=o>*</span> <span class=n>a</span> <span class=o>*</span> <span class=n>a</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 큐브 함수에 대한 Pandas UDF 생성</span>
</span></span><span class=line><span class=cl><span class=n>cubed_udf</span> <span class=o>=</span> <span class=n>pandas_udf</span><span class=p>(</span><span class=n>cubed</span><span class=p>,</span> <span class=n>returnType</span><span class=o>=</span><span class=n>LongType</span><span class=p>())</span></span></span></code></pre></div></div><p>Pandas UDF는 아래와 같이 실행할 수 있다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 스파크 데이터프레임 생성</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Pandas UDF를 실행</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;id&#34;</span><span class=p>,</span> <span class=n>cubed_udf</span><span class=p>(</span><span class=n>col</span><span class=p>(</span><span class=s2>&#34;id&#34;</span><span class=p>)))</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=sc-codeblock data-lang=bash><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+---+---------+
</span></span><span class=line><span class=cl><span class=p>|</span> id<span class=p>|</span>cubed<span class=o>(</span>id<span class=o>)</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+---+---------+
</span></span><span class=line><span class=cl><span class=p>|</span>  1<span class=p>|</span>        1<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  2<span class=p>|</span>        8<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  3<span class=p>|</span>       27<span class=p>|</span>
</span></span><span class=line><span class=cl>+---+---------+</span></span></code></pre></div></div><p>스파크 UI에서 시각화된 <code>pandas_udf</code> 함수의 실행 단계에 대한 DAG을 조회할 수 있다.
Stage 0에서 <code>ArrowEvalPython</code> 연산이 Pandas UDF를 평가하는 단계이다.</p><label class=sc-image for=sc-image-toggle-1 style=text-align:center><input class="hidden toggle" type=checkbox id=sc-image-toggle-1><img src="https://dl.dropboxusercontent.com/scl/fi/kn9ih42tqsbxfskwq5vj4/spark-19-pandas-udf.webp?rlkey=f1yvfjog5fvxjyhcvjugsd1id&amp;raw=1" alt="WholeStageCodegen (1) -> ArrowEvalPython -> WholeStageCodeGen (2) -> mapPartitionsInternal" id=sc-image-1 width=852 height=1626 loading=lazy decoding=async style=max-width:432px></label><h2 id=고차-함수>고차 함수
<a class=anchor href=#%ea%b3%a0%ec%b0%a8-%ed%95%a8%ec%88%98>#</a></h2><p>복잡한 데이터 유형은 단순한 데이터 유형의 결합이기 때문에 다음과 같이 조작할 수 있다.</p><ol><li>중첩된 구조를 개별 행으로 분해하고 각각에 함수를 적용한 후 중첩된 구조를 다시 만드는 방법</li><li>사용자 정의 함수를 사용하는 방법</li></ol><p>하지만 배열과 같은 중첩된 구조를 분해하고 다시 만든다고 가정할 때, 셔플 작업이 발생해 결과 배열의 순서가 원래 배열의 순서와 동일하지 않을 수 있다.</p><p>사용자 정의 함수를 사용할 경우에는 정렬 문제는 해결할 수 있지만, 직렬화 및 역직렬화 과정을 거치면서 발생하는 비용이 크다는 문제가 있다.</p><h3 id=내장-함수>내장 함수
<a class=anchor href=#%eb%82%b4%ec%9e%a5-%ed%95%a8%ec%88%98>#</a></h3><p>복잡한 데이터 유형에 대해 스파크 2.4 이상 버전에 포함된 내장 함수를 사용할 수 있다.
자세한 건 <a href=https://spark.apache.org/docs/latest/api/sql/index.html target=_blank rel="noopener noreferrer">공식 문서</a>를 참고해볼 수 있는데,
그 중에서 배열과 맵에 대해서 일부를 알아본다.</p><p>배열과 관련된 함수는 공식 문서에서
<a href=https://spark.apache.org/docs/latest/api/sql/index.html#array target=_blank rel="noopener noreferrer">array 문단</a>부터 시작하는 함수들을 참고하면 된다.
대표적으로 <code>array_distinct</code> 함수는 배열 내 중복을 제거하고, <code>array_sort</code> 함수는 배열을 오름차순으로 정렬한다.
array로 시작하지 않는 함수 중에서도 <code>concat</code> 함수는 복수 개의 배열을 받아 하나의 배열로 합쳐주고,
<code>flatten</code> 함수는 2차원 이상 중첩된 배열을 단일 배열로 플랫화한다. <code>sequence</code> 함수로
시작과 끝에 대한 배열을 생성할 수 있고, <code>slice</code> 함수로 배열의 특정 부분만 잘라낼 수도 있다.</p><p>맵과 관련된 함수는 공식 문서에서
<a href=https://spark.apache.org/docs/latest/api/sql/index.html#map target=_blank rel="noopener noreferrer">map 문단</a>부터
시작하는 함수들을 참고하면 된다.
대표적으로 <code>map_concat</code> 함수는 복수 개의 맵을 하나의 맵으로 합쳐주고,
<code>map_keys</code> 함수로 맵에서 키 배열만 추출할 수도 있다. map으로 시작하지 않는 함수 중에서도
<code>element_at</code> 함수는 주어진 키에 대한 값을 반환하고, <code>cardinality</code> 함수는 맵의 크기를 반환한다.</p><h3 id=transform>transform()
<a class=anchor href=#transform>#</a></h3><p>내장 함수 외에도 익명 람다 함수를 인수로 사용하는 고차 함수 <code>transform()</code> 이 있다.</p><p>고차 함수를 실행해보기 위해 아래와 같이 샘플 데이터 <code>tC</code> 를 만들어본다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.types</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>schema</span> <span class=o>=</span> <span class=n>StructType</span><span class=p>([</span><span class=n>StructField</span><span class=p>(</span><span class=s2>&#34;celsius&#34;</span><span class=p>,</span> <span class=n>ArrayType</span><span class=p>(</span><span class=n>IntegerType</span><span class=p>()))])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>t_list</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>38</span><span class=p>]],</span> <span class=p>[[</span><span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>55</span><span class=p>,</span> <span class=mi>56</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=n>t_c</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>createDataFrame</span><span class=p>(</span><span class=n>t_list</span><span class=p>,</span> <span class=n>schema</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>t_c</span><span class=o>.</span><span class=n>createOrReplaceTempView</span><span class=p>(</span><span class=s2>&#34;tC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>t_c</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=sc-codeblock data-lang=bash><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span>             celsius<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>35, 36, 32, 30, ...<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>31, 32, 34, 55, 56<span class=o>]</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+</span></span></code></pre></div></div><p>Celsius 단위를 Fahrenheit 단위로 바꾸는 <code>transform()</code> 함수를 사용해,
<code>celsius</code> 열로부터 <code>fahrenheit</code> 열을 계산했다. 출력 결과는 아래와 같다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>SELECT
</span></span></span><span class=line><span class=cl><span class=s2>  celsius,
</span></span></span><span class=line><span class=cl><span class=s2>  transform(celsius, t -&gt; ((t * 9) div 5) + 32) AS fahrenheit
</span></span></span><span class=line><span class=cl><span class=s2>FROM tc
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=sc-codeblock data-lang=bash><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------------------+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span>             celsius<span class=p>|</span>          fahrenheit<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>35, 36, 32, 30, ...<span class=p>|</span><span class=o>[</span>95, 96, 89, 86, ...<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>31, 32, 34, 55, 56<span class=o>]</span><span class=p>|</span><span class=o>[</span>87, 89, 93, 131,...<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+--------------------+</span></span></code></pre></div></div><h3 id=filter>filter()
<a class=anchor href=#filter>#</a></h3><p><code>filter()</code> 함수는 입력한 배열의 요소 중 부울 함수가 참인 요소만으로 구성된 배열을 생성한다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>SELECT
</span></span></span><span class=line><span class=cl><span class=s2>  celsius,
</span></span></span><span class=line><span class=cl><span class=s2>  filter(celsius, t -&gt; t &gt; 38) AS high
</span></span></span><span class=line><span class=cl><span class=s2>FROM tc
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=sc-codeblock data-lang=bash><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------------------+--------+
</span></span><span class=line><span class=cl><span class=p>|</span>             celsius<span class=p>|</span>    high<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+--------+
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>35, 36, 32, 30, ...<span class=p>|</span><span class=o>[</span>40, 42<span class=o>]</span><span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>31, 32, 34, 55, 56<span class=o>]</span><span class=p>|</span><span class=o>[</span>55, 56<span class=o>]</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+--------+</span></span></code></pre></div></div><h3 id=exists>exists()
<a class=anchor href=#exists>#</a></h3><p><code>exists()</code> 함수는 입력한 배열의 요소 중 불린 함수를 만족시키는 것이 존재할 때 참을 반환한다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>SELECT
</span></span></span><span class=line><span class=cl><span class=s2>  celsius,
</span></span></span><span class=line><span class=cl><span class=s2>  exists(celsius, t -&gt; t = 38) AS threshold
</span></span></span><span class=line><span class=cl><span class=s2>FROM tc
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=sc-codeblock data-lang=bash><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------------------+---------+
</span></span><span class=line><span class=cl><span class=p>|</span>             celsius<span class=p>|</span>threshold<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+---------+
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>35, 36, 32, 30, ...<span class=p>|</span>     true<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>31, 32, 34, 55, 56<span class=o>]</span><span class=p>|</span>    false<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+---------+</span></span></code></pre></div></div><h2 id=스파크-sql-작업>스파크 SQL 작업
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac-sql-%ec%9e%91%ec%97%85>#</a></h2><p>스파크 SQL의 기능 중 일부는 DataFrame의 다양한 기능에서 유래된다.
이용가능한 작업에는 집계 함수, 수집 함수, 날짜 함수, 수학 함수, 정렬 함수,
문자열 함수, 윈도우 함수 등 매우 광범위하다.</p><h3 id=union>Union
<a class=anchor href=#union>#</a></h3><p>Union은 동일한 스키마를 가진 두 개의 서로 다른 DataFrame을 하나로 합치는 작업이다.</p><p>SQL문으로 다음과 같이 표현할 수 있다.</p><div class=sc-codeblock data-lang=sql><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">sql</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=p>(</span><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>first_half</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=k>UNION</span><span class=w> </span><span class=k>ALL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=p>(</span><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>second_half</span><span class=p>);</span></span></span></code></pre></div></div><p>파이썬으로는 다음과 같이 표현할 수 있다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>first_half</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>second_half</span><span class=p>)</span></span></span></code></pre></div></div><h3 id=join>Join
<a class=anchor href=#join>#</a></h3><p>Join은 두 개 이상의 DataFrame을 특정 조건을 기준으로 결합하여 하나로 합치는 작업이다.</p><p>SQL문으로 다음과 같이 표현할 수 있다.</p><div class=sc-codeblock data-lang=sql><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">sql</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>p</span><span class=p>.</span><span class=n>id</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>productId</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>p</span><span class=p>.</span><span class=n>storeId</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>s</span><span class=p>.</span><span class=n>name</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>storeName</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>p</span><span class=p>.</span><span class=n>name</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>productName</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=k>FROM</span><span class=w> </span><span class=n>product</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>p</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>LEFT</span><span class=w> </span><span class=k>JOIN</span><span class=w> </span><span class=n>store</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>ON</span><span class=w> </span><span class=n>p</span><span class=p>.</span><span class=n>storeId</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>s</span><span class=p>.</span><span class=n>id</span><span class=p>;</span></span></span></code></pre></div></div><p>파이썬으로는 다음과 같이 표현할 수 있다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>col</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>product</span><span class=o>.</span><span class=n>join</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>store</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>product</span><span class=o>.</span><span class=n>storeId</span> <span class=o>==</span> <span class=n>store</span><span class=o>.</span><span class=n>id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>how</span> <span class=o>=</span> <span class=s2>&#34;left&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>select</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>col</span><span class=p>(</span><span class=s2>&#34;p.id&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s2>&#34;productId&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;p.storeId&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>col</span><span class=p>(</span><span class=s2>&#34;s.name&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s2>&#34;storeName&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>col</span><span class=p>(</span><span class=s2>&#34;p.name&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s2>&#34;productName&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><h3 id=윈도우>윈도우
<a class=anchor href=#%ec%9c%88%eb%8f%84%ec%9a%b0>#</a></h3><p>윈도우 함수를 사용하면 모든 입력 행에 대해 단일값을 반환하면서 행 그룹에 대해 작업할 수 있다.</p><p>순위를 매기는 작업과 관련해서는 <code>RANK</code>, <code>DENSE_RANK</code>, <code>PERCENT_RANK</code>, <code>NTILE</code>, <code>ROW_NUMBER</code>
함수가 있고, 집계와 관련해서는 <code>MAX</code>, <code>MIN</code>, <code>COUNT</code>, <code>SUM</code>, <code>AVG</code> 등의 함수가 있다.</p><p>SQL문으로 다음과 같이 표현할 수 있다.</p><div class=sc-codeblock data-lang=sql><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">sql</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>name</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>dept</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>salary</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>RANK</span><span class=p>()</span><span class=w> </span><span class=n>OVER</span><span class=w> </span><span class=p>(</span><span class=n>PARTITION</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>dept</span><span class=w> </span><span class=k>ORDER</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>salary</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>rank</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=k>FROM</span><span class=w> </span><span class=n>employees</span><span class=p>;</span></span></span></code></pre></div></div><p>파이썬으로는 다음과 같이 표현할 수 있다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>rank</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>Window</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>window</span> <span class=o>=</span> <span class=n>rank</span><span class=p>()</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>Window</span><span class=o>.</span><span class=n>partitionBy</span><span class=p>(</span><span class=s2>&#34;dept&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=s2>&#34;salary&#34;</span><span class=p>))</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s2>&#34;rank&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>employees</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;name&#34;</span><span class=p>,</span> <span class=s2>&#34;dept&#34;</span><span class=p>,</span> <span class=s2>&#34;salary&#34;</span><span class=p>,</span> <span class=n>window</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><h3 id=수정>수정
<a class=anchor href=#%ec%88%98%ec%a0%95>#</a></h3><p>DataFrame 자체는 변경할 수 없지만, 열을 가공하여 새로운 DataFrame을 만드는 것과 같은 작업을 통해 수정할 수 있다.</p><p>파이썬으로 활용 가능한 다음과 같은 예시가 있다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>expr</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 열 추가</span>
</span></span><span class=line><span class=cl><span class=n>foo2</span> <span class=o>=</span> <span class=n>foo</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;status&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=n>expr</span><span class=p>(</span><span class=s2>&#34;CASE WHEN delay &lt;= 10 THEN &#39;On-time&#39; ELSE &#39;Delayed&#39; END&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 열 삭제</span>
</span></span><span class=line><span class=cl><span class=n>foo3</span> <span class=o>=</span> <span class=n>foo2</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&#34;delay&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 칼럼명 바꾸기</span>
</span></span><span class=line><span class=cl><span class=n>foo4</span> <span class=o>=</span> <span class=n>foo3</span><span class=o>.</span><span class=n>withColumnRenamed</span><span class=p>(</span><span class=s2>&#34;status&#34;</span><span class=p>,</span> <span class=s2>&#34;flight_status&#34;</span><span class=p>)</span></span></span></code></pre></div></div><h3 id=피벗>피벗
<a class=anchor href=#%ed%94%bc%eb%b2%97>#</a></h3><p>로우와 칼럼을 바꿔야 하는 경우가 있다. 이 경우에 <code>pivot</code> 함수를 지원한다.</p><p>피벗을 실행해보기 위해 아래와 같이 샘플 데이터를 만들어본다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>Row</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>df1</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>createDataFrame</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;dotNET&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2012</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>10000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;Java&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2012</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>20000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;dotNET&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2012</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>5000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;dotNET&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2013</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>48000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;Java&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2013</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>30000</span><span class=p>),])</span>
</span></span><span class=line><span class=cl><span class=n>df1</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=sc-codeblock data-lang=bash><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+------+----+--------+
</span></span><span class=line><span class=cl><span class=p>|</span>course<span class=p>|</span>year<span class=p>|</span>earnings<span class=p>|</span>
</span></span><span class=line><span class=cl>+------+----+--------+
</span></span><span class=line><span class=cl><span class=p>|</span>dotNET<span class=p>|</span>2012<span class=p>|</span>   10000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  Java<span class=p>|</span>2012<span class=p>|</span>   20000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>dotNET<span class=p>|</span>2012<span class=p>|</span>    5000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>dotNET<span class=p>|</span>2013<span class=p>|</span>   48000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  Java<span class=p>|</span>2013<span class=p>|</span>   30000<span class=p>|</span>
</span></span><span class=line><span class=cl>+------+----+--------+</span></span></code></pre></div></div><p>위 데이터에서 <code>course</code> 를 열로, <code>year</code> 를 행으로, <code>earnings</code> 를 값으로
<code>sum</code> 집계해 구성한 피벗 테이블을 아래와 같이 만들 수 있다.</p><div class=sc-codeblock data-lang=python><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>df1</span><span class=o>.</span><span class=n>groupBy</span><span class=p>(</span><span class=s2>&#34;year&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>pivot</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;course&#34;</span><span class=p>,</span> <span class=p>[</span><span class=s2>&#34;dotNET&#34;</span><span class=p>,</span> <span class=s2>&#34;Java&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=s2>&#34;earnings&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=s2>&#34;year&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=sc-codeblock data-lang=bash><div class=code-actions><button class="code-copy-button code-action" onclick=copyCode(this)>
<i class=icon-file-copy></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+----+------+-----+
</span></span><span class=line><span class=cl><span class=p>|</span>year<span class=p>|</span>dotNET<span class=p>|</span> Java<span class=p>|</span>
</span></span><span class=line><span class=cl>+----+------+-----+
</span></span><span class=line><span class=cl><span class=p>|</span>2012<span class=p>|</span> 15000<span class=p>|</span>20000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>2013<span class=p>|</span> 48000<span class=p>|</span>30000<span class=p>|</span>
</span></span><span class=line><span class=cl>+----+------+-----+</span></span></code></pre></div></div><h2 id=references>References
<a class=anchor href=#references>#</a></h2><ul><li><a href=https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html</a></li><li><a href=https://books.japila.pl/pyspark-internals/sql/ArrowEvalPython/#evalType target=_blank rel="noopener noreferrer">https://books.japila.pl/pyspark-internals/sql/ArrowEvalPython/#evalType</a></li><li><a href=https://spark.apache.org/docs/latest/api/sql/index.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/api/sql/index.html</a></li><li><a href=https://docs.databricks.com/aws/en/semi-structured/higher-order-functions target=_blank rel="noopener noreferrer">https://docs.databricks.com/aws/en/semi-structured/higher-order-functions</a></li><li><a href=https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rank.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rank.html</a></li><li><a href=https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.pivot.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.pivot.html</a></li></ul></article><footer class=site-footer><div class=tags-wrap><a href="/search/?tags=Apache%20Spark" class=tag>#Apache Spark</a>
<a href="/search/?tags=%ea%b3%a0%ec%b0%a8%20%ed%95%a8%ec%88%98" class=tag>#고차 함수</a>
<a href="/search/?tags=UDF" class=tag>#UDF</a>
<a href="/search/?tags=Pandas%20UDF" class=tag>#Pandas UDF</a>
<a href="/search/?tags=Spark%20SQL" class=tag>#Spark SQL</a>
<a href="/search/?tags=PySpark" class=tag>#PySpark</a>
<a href="/search/?tags=%eb%8d%b0%ec%9d%b4%ed%84%b0%20%ec%97%94%ec%a7%80%eb%8b%88%ec%96%b4%eb%a7%81" class=tag>#데이터 엔지니어링</a>
<a href="/search/?tags=%ec%8a%a4%ed%8c%8c%ed%81%ac" class=tag>#스파크</a>
<a href="/search/?tags=Study" class=tag>#Study</a></div><div class=prev-next-wrap><a href=/blog/spark-study-7/ class=prev-link><span class=prev-next-label><i class=icon-backward></i>
<span data-i18n-id=post.prev.link data-i18n-text>이전</span>
</span><span class=prev-next-title>Apache Spark - 외부 데이터베이스 연동 (PostgreSQL, MySQL)</span>
</a><a href=/blog/uv-project/ class=next-link><span class=prev-next-label><span data-i18n-id=post.next.link data-i18n-text>다음</span>
<i class=icon-forward></i>
</span><span class=prev-next-title>[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리</span></a></div><div class=comments-wrap><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://minyeamer.github.io/blog/spark-study-8/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-8/"};window.relocateDisqus=()=>{let e=0;const t=20,n=setInterval(()=>{e++;const s=document.getElementById(atob(atob("WkdsemNYVnpYM1JvY21WaFpBPT0=")));var o=!1;if(s){const e=s.querySelector(atob(atob("VzNOeVl5bzlKMkZrY3lkZA==")));e&&(s.appendChild(e),o=!0)}(o||e>t)&&clearInterval(n)},1e3)},function(){var e=document,t=e.createElement("script");t.src="https://minyeamer.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)}(),window.relocateDisqus();function reloadDisqus(){window.DISQUS&&(DISQUS.reset({reload:!0,config:function(){this.page.url="https://minyeamer.github.io/blog/spark-study-8/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-8/"}}),window.relocateDisqus())}</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div><div class="copyright-wrap flex justify-center"><small>Minystory - <a href=https://creativecommons.org/licenses/by/4.0/legalcode target=_blank rel="noopener noreferrer">© CC BY 4.0</a></small></div></footer><label for=menu-control class="hidden site-menu-overlay"></label></div><aside class=site-toc aria-label=목차 data-i18n-id=toc.aside.tooltip data-i18n-attrs=aira-label><div class=toc-content><nav id=TableOfContents><ul><li><a href=#user-defined-functions>User-Defined Functions</a><ul><li><a href=#spark-sql-udf-활용>Spark SQL UDF 활용</a></li><li><a href=#스파크-sql-평가-순서>스파크 SQL 평가 순서</a></li><li><a href=#pandas-udf>Pandas UDF</a></li></ul></li><li><a href=#고차-함수>고차 함수</a><ul><li><a href=#내장-함수>내장 함수</a></li><li><a href=#transform>transform()</a></li><li><a href=#filter>filter()</a></li><li><a href=#exists>exists()</a></li></ul></li><li><a href=#스파크-sql-작업>스파크 SQL 작업</a><ul><li><a href=#union>Union</a></li><li><a href=#join>Join</a></li><li><a href=#윈도우>윈도우</a></li><li><a href=#수정>수정</a></li><li><a href=#피벗>피벗</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></div><div class=hidden id=toc-config data-start=2 data-end=3></div></aside><div class=site-toolbar role=toolbar aria-label="툴바'" data-i18n-id=toolbar.wrap.tooltip data-i18n-attrs=aira-label><input type=checkbox id=toolbar-toggle class="hidden toggle"><div class=toolbar-items><div class="toolbar-button i18n-button"><i class=icon-globe></i>
<select class=i18n-selector id=i18n-selector aria-label="i18n `toolbar.i18n.tooltip` | default `Select language`" title="i18n `toolbar.i18n.tooltip` | default `Select language`" data-i18n-id=toolbar.i18n.tooltip data-i18n-attrs=aria-label,title><option value=ko>한국어</option><option value=en>English</option><option value=ja>日本語</option><option value=zh>中文</option><option value=es>Español</option><option value=fr>Français</option><option value=de>Deutsch</option><option value=it>Italiano</option><option value=pt>Português</option><option value=ru>Русский</option><option value=am>አማርኛ</option><option value=bg>Български</option><option value=bn>বাংলা</option><option value=cn>简体中文</option><option value=cs>Čeština</option><option value=fa>فارسی</option><option value=he>עברית</option><option value=nb>Norsk</option><option value=nl>Nederlands</option><option value=oc>Occitan</option><option value=pl>Polski</option><option value=pt-BR>Português (BR)</option><option value=sv>Svenska</option><option value=sw>Kiswahili</option><option value=tr>Türkçe</option><option value=uk>Українська</option><option value=zh-TW>繁體中文</option></select></div><button class=toolbar-button onclick='window.scrollTo({top:0,behavior:"smooth"})' aria-label="i18n `toolbar.top.tooltip` | default `Go to top`" title="i18n `toolbar.top.tooltip` | default `Go to top`" data-i18n-id=toolbar.top.tooltip data-i18n-attrs=aria-label,title>
<i class=icon-chevron-up></i>
</button>
<button class=toolbar-button onclick='window.scrollTo({top:document.body.scrollHeight,behavior:"smooth"})' aria-label="i18n `toolbar.bottom.tooltip` | default `Go to bottom`" title="i18n `toolbar.bottom.tooltip` | default `Go to bottom`" data-i18n-id=toolbar.bottom.tooltip data-i18n-attrs=aria-label,title>
<i class=icon-chevron-down></i>
</button>
<button class=toolbar-button onclick=history.back() aria-label="i18n `toolbar.back.tooltip` | default `Go back`" title="i18n `toolbar.back.tooltip` | default `Go back`" data-i18n-id=toolbar.back.tooltip data-i18n-attrs=aria-label,title>
<i class=icon-arrow-left></i></button></div><label for=toolbar-toggle class="toolbar-button toolbar-toggle-label"><i class="icon-plus icon-expand"></i>
<i class="icon-xmark icon-collapse"></i></label></div></main></body></html>