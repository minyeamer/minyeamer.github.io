<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=keywords content="Apache Spark,고차 함수,UDF,Pandas UDF,Spark SQL,PySpark,데이터 엔지니어링,스파크,Study"><meta name=description content="Apache Spark의 고차 함수와 사용자 정의 함수를 다루며, UDF 생성부터 Pandas UDF, transform, filter 등 고차 함수 활용까지 단계별로 안내합니다. …"><meta name=author content="minyeamer"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-8/><link rel=icon href=https://minyeamer.github.io/images/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://minyeamer.github.io/images/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://minyeamer.github.io/images/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><link rel=mask-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><meta name=google-site-verification content="u1tWcHmHUZWfFT1cHaku6sqU-bK40N3WLR-C-4VUWN0"><meta name=naver-site-verification content="6eaf8e9da1a6104780f056f1a7797fe5a3a5a0da"><meta property="og:title" content="Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기"><meta property="og:description" content="Apache Spark의 고차 함수와 사용자 정의 함수를 다루며, UDF 생성부터 Pandas UDF, transform, filter 등 고차 함수 활용까지 단계별로 안내합니다. …"><meta property="og:type" content="article"><meta property="og:url" content="https://minyeamer.github.io/blog/spark-study-8/"><meta property="og:image" content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-19T23:53:45+09:00"><meta property="article:modified_time" content="2025-07-19T23:53:45+09:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0"><meta name=twitter:title content="Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기"><meta name=twitter:description content="Apache Spark의 고차 함수와 사용자 정의 함수를 다루며, UDF 생성부터 Pandas UDF, transform, filter 등 고차 함수 활용까지 단계별로 안내합니다. …"><meta name=twitter:site content="@https://x.com/minyeamer"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://minyeamer.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기","item":"https://minyeamer.github.io/blog/spark-study-8/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기","name":"Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기","description":"Apache Spark의 고차 함수와 사용자 정의 함수를 다루며, UDF 생성부터 Pandas UDF, transform, filter 등 고차 함수 활용까지 단계별로 안내합니다. 빅데이터 분석과 데이터 엔지니어링을 위한 강력한 도구를 습득하고 실무에 적용하세요.\n","keywords":["Apache Spark","고차 함수","UDF","Pandas UDF","Spark SQL","PySpark","데이터 엔지니어링","스파크","Study"],"articleBody":"User-Defined Functions # 스파크는 자신의 기능을 정의할 수 있는 유연성을 제공한다. 이를 사용자 정의 함수(User-Defined Function, UDF)라고 한다.\nUDF를 생성하는 이점은 스파크 SQL 안에서 이를 사용할 수 있다는 것이다.\nSpark SQL UDF 활용 # 다음은 스파크 SQL UDF를 만드는 예시로, 인수를 세제곱하는 함수 cubed() 를 생성한다.\nCopy python from pyspark.sql.types import LongType # 큐브 함수 생성 def cubed(s): return s * s * s # UDF로 등록 spark.udf.register(\"cubed\", cubed, LongType()) 스파크 SQL을 사용하여 cubed() 함수를 실행할 수 있다.\nCopy python # 임시 뷰 생성 spark.range(1, 9).createOrReplaceTempView(\"udf_test\") # 큐브 UDF를 사용하여 쿼리 spark.sql(\"SELECT id, cubed(id) AS id_cubed FROM udf_test\").show() Copy bash +---+--------+ | id|id_cubed| +---+--------+ | 1| 1| | 2| 8| | 3| 27| | 4| 64| | 5| 125| | 6| 216| | 7| 343| | 8| 512| +---+--------+ 스파크 SQL 평가 순서 # 스파크 SQL은 하위 표현식의 평가 순서를 보장하지 않는다. 예를 들어, 다음 쿼리에서 s IS NOT NULL 절이 strlen(s) \u003e 1 절 이전에 실행된다는 것을 보장할 수 없다.\nCopy python spark.sql(\"SELECT s FROM test1 WHERE s IS NOT NULL AND strlen(s) \u003e 1\") 따라서, 다음 두 가지 null 검사 방식을 수행하는 것이 좋다.\nUDF 안에서 null 을 인식하고 null 검사를 수행할 필요가 있다. SQL문에서 IF 또는 CASE WHEN 식을 사용하여 null 검사를 수행하고 조건에 맞으면 UDF를 호출한다. Pandas UDF # PySpark UDF는 JVM과 파이썬 사이의 데이터 이동을 필요로 해서 Scala UDF보다 성능이 느렸다.\n이 문제를 해결하기 위해 Pandas UDF가 스파크 2.3 버전부터 도입되었다. Pandas UDF는 Apache Arrow를 사용하여 Pandas UDF를 정의하거나 함수 자체를 래핑할 수 있다. Apache Arrow 형식에 포함된 데이터라면 더이상 JVM으로 데이터를 전달하기 위해 직렬화나 피클할 필요가 없다.\nPandas UDF는 pandas.Series, pandas.DataFrame 과 같은 파이썬 유형 힌트로 유추한다. 예시로, 앞에서 정의한 큐브 함수를 Pandas UDF로 만들면 아래와 같다.\nCopy python import pandas as pd from pyspark.sql.functions import col, pandas_udf from pyspark.sql.types import LongType # 큐브 함수 생성 def cubed(a: pd.Series) -\u003e pd.Series: return a * a * a # 큐브 함수에 대한 Pandas UDF 생성 cubed_udf = pandas_udf(cubed, returnType=LongType()) Pandas UDF는 아래와 같이 실행할 수 있다.\nCopy python # 스파크 데이터프레임 생성 df = spark.range(1, 4) # Pandas UDF를 실행 df.select(\"id\", cubed_udf(col(\"id\"))).show() Copy bash +---+---------+ | id|cubed(id)| +---+---------+ | 1| 1| | 2| 8| | 3| 27| +---+---------+ 스파크 UI에서 시각화된 pandas_udf 함수의 실행 단계에 대한 DAG을 조회할 수 있다. Stage 0에서 ArrowEvalPython 연산이 Pandas UDF를 평가하는 단계이다.\n고차 함수 # 복잡한 데이터 유형은 단순한 데이터 유형의 결합이기 때문에 다음과 같이 조작할 수 있다.\n중첩된 구조를 개별 행으로 분해하고 각각에 함수를 적용한 후 중첩된 구조를 다시 만드는 방법 사용자 정의 함수를 사용하는 방법 하지만 배열과 같은 중첩된 구조를 분해하고 다시 만든다고 가정할 때, 셔플 작업이 발생해 결과 배열의 순서가 원래 배열의 순서와 동일하지 않을 수 있다.\n사용자 정의 함수를 사용할 경우에는 정렬 문제는 해결할 수 있지만, 직렬화 및 역직렬화 과정을 거치면서 발생하는 비용이 크다는 문제가 있다.\n내장 함수 # 복잡한 데이터 유형에 대해 스파크 2.4 이상 버전에 포함된 내장 함수를 사용할 수 있다. 자세한 건 공식 문서를 참고해볼 수 있는데, 그 중에서 배열과 맵에 대해서 일부를 알아본다.\n배열과 관련된 함수는 공식 문서에서 array 문단부터 시작하는 함수들을 참고하면 된다. 대표적으로 array_distinct 함수는 배열 내 중복을 제거하고, array_sort 함수는 배열을 오름차순으로 정렬한다. array로 시작하지 않는 함수 중에서도 concat 함수는 복수 개의 배열을 받아 하나의 배열로 합쳐주고, flatten 함수는 2차원 이상 중첩된 배열을 단일 배열로 플랫화한다. sequence 함수로 시작과 끝에 대한 배열을 생성할 수 있고, slice 함수로 배열의 특정 부분만 잘라낼 수도 있다.\n맵과 관련된 함수는 공식 문서에서 map 문단부터 시작하는 함수들을 참고하면 된다. 대표적으로 map_concat 함수는 복수 개의 맵을 하나의 맵으로 합쳐주고, map_keys 함수로 맵에서 키 배열만 추출할 수도 있다. map으로 시작하지 않는 함수 중에서도 element_at 함수는 주어진 키에 대한 값을 반환하고, cardinality 함수는 맵의 크기를 반환한다.\ntransform() # 내장 함수 외에도 익명 람다 함수를 인수로 사용하는 고차 함수 transform() 이 있다.\n고차 함수를 실행해보기 위해 아래와 같이 샘플 데이터 tC 를 만들어본다.\nCopy python from pyspark.sql.types import * schema = StructType([StructField(\"celsius\", ArrayType(IntegerType()))]) t_list = [[35, 36, 32, 30, 40, 42, 38]], [[31, 32, 34, 55, 56]] t_c = spark.createDataFrame(t_list, schema) t_c.createOrReplaceTempView(\"tC\") t_c.show() Copy bash +--------------------+ | celsius| +--------------------+ |[35, 36, 32, 30, ...| |[31, 32, 34, 55, 56]| +--------------------+ Celsius 단위를 Fahrenheit 단위로 바꾸는 transform() 함수를 사용해, celsius 열로부터 fahrenheit 열을 계산했다. 출력 결과는 아래와 같다.\nCopy python spark.sql(\"\"\" SELECT celsius, transform(celsius, t -\u003e ((t * 9) div 5) + 32) AS fahrenheit FROM tc \"\"\").show() Copy bash +--------------------+--------------------+ | celsius| fahrenheit| +--------------------+--------------------+ |[35, 36, 32, 30, ...|[95, 96, 89, 86, ...| |[31, 32, 34, 55, 56]|[87, 89, 93, 131,...| +--------------------+--------------------+ filter() # filter() 함수는 입력한 배열의 요소 중 부울 함수가 참인 요소만으로 구성된 배열을 생성한다.\nCopy python spark.sql(\"\"\" SELECT celsius, filter(celsius, t -\u003e t \u003e 38) AS high FROM tc \"\"\").show() Copy bash +--------------------+--------+ | celsius| high| +--------------------+--------+ |[35, 36, 32, 30, ...|[40, 42]| |[31, 32, 34, 55, 56]|[55, 56]| +--------------------+--------+ exists() # exists() 함수는 입력한 배열의 요소 중 불린 함수를 만족시키는 것이 존재할 때 참을 반환한다.\nCopy python spark.sql(\"\"\" SELECT celsius, exists(celsius, t -\u003e t = 38) AS threshold FROM tc \"\"\").show() Copy bash +--------------------+---------+ | celsius|threshold| +--------------------+---------+ |[35, 36, 32, 30, ...| true| |[31, 32, 34, 55, 56]| false| +--------------------+---------+ 스파크 SQL 작업 # 스파크 SQL의 기능 중 일부는 DataFrame의 다양한 기능에서 유래된다. 이용가능한 작업에는 집계 함수, 수집 함수, 날짜 함수, 수학 함수, 정렬 함수, 문자열 함수, 윈도우 함수 등 매우 광범위하다.\nUnion # Union은 동일한 스키마를 가진 두 개의 서로 다른 DataFrame을 하나로 합치는 작업이다.\nSQL문으로 다음과 같이 표현할 수 있다.\nCopy sql (SELECT * FROM first_half) UNION ALL (SELECT * FROM second_half); 파이썬으로는 다음과 같이 표현할 수 있다.\nCopy python result = first_half.union(second_half) Join # Join은 두 개 이상의 DataFrame을 특정 조건을 기준으로 결합하여 하나로 합치는 작업이다.\nSQL문으로 다음과 같이 표현할 수 있다.\nCopy sql SELECT p.id AS productId, p.storeId, s.name AS storeName, p.name AS productName FROM product AS p LEFT JOIN store AS s ON p.storeId = s.id; 파이썬으로는 다음과 같이 표현할 수 있다.\nCopy python from pyspark.sql.functions import col product.join( store, product.storeId == store.id, how = \"left\" ).select( col(\"p.id\").alias(\"productId\"), \"p.storeId\", col(\"s.name\").alias(\"storeName\"), col(\"p.name\").alias(\"productName\") ).show() 윈도우 # 윈도우 함수를 사용하면 모든 입력 행에 대해 단일값을 반환하면서 행 그룹에 대해 작업할 수 있다.\n순위를 매기는 작업과 관련해서는 RANK, DENSE_RANK, PERCENT_RANK, NTILE, ROW_NUMBER 함수가 있고, 집계와 관련해서는 MAX, MIN, COUNT, SUM, AVG 등의 함수가 있다.\nSQL문으로 다음과 같이 표현할 수 있다.\nCopy sql SELECT name, dept, salary, RANK() OVER (PARTITION BY dept ORDER BY salary) AS rank FROM employees; 파이썬으로는 다음과 같이 표현할 수 있다.\nCopy python from pyspark.sql.functions import rank from pyspark.sql import Window window = rank().over(Window.partitionBy(\"dept\").orderBy(\"salary\")).alias(\"rank\") employees.select(\"name\", \"dept\", \"salary\", window).show() 수정 # DataFrame 자체는 변경할 수 없지만, 열을 가공하여 새로운 DataFrame을 만드는 것과 같은 작업을 통해 수정할 수 있다.\n파이썬으로 활용 가능한 다음과 같은 예시가 있다.\nCopy python from pyspark.sql.functions import expr # 열 추가 foo2 = foo.withColumn( \"status\", expr(\"CASE WHEN delay \u003c= 10 THEN 'On-time' ELSE 'Delayed' END\")) # 열 삭제 foo3 = foo2.drop(\"delay\") # 칼럼명 바꾸기 foo4 = foo3.withColumnRenamed(\"status\", \"flight_status\") 피벗 # 로우와 칼럼을 바꿔야 하는 경우가 있다. 이 경우에 pivot 함수를 지원한다.\n피벗을 실행해보기 위해 아래와 같이 샘플 데이터를 만들어본다.\nCopy python from pyspark.sql import Row df1 = spark.createDataFrame([ Row(course=\"dotNET\", year=2012, earnings=10000), Row(course=\"Java\", year=2012, earnings=20000), Row(course=\"dotNET\", year=2012, earnings=5000), Row(course=\"dotNET\", year=2013, earnings=48000), Row(course=\"Java\", year=2013, earnings=30000),]) df1.show() Copy bash +------+----+--------+ |course|year|earnings| +------+----+--------+ |dotNET|2012| 10000| | Java|2012| 20000| |dotNET|2012| 5000| |dotNET|2013| 48000| | Java|2013| 30000| +------+----+--------+ 위 데이터에서 course 를 열로, year 를 행으로, earnings 를 값으로 sum 집계해 구성한 피벗 테이블을 아래와 같이 만들 수 있다.\nCopy python df1.groupBy(\"year\").pivot( \"course\", [\"dotNET\", \"Java\"]).sum(\"earnings\").sort(\"year\").show() Copy bash +----+------+-----+ |year|dotNET| Java| +----+------+-----+ |2012| 15000|20000| |2013| 48000|30000| +----+------+-----+ References # https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html https://books.japila.pl/pyspark-internals/sql/ArrowEvalPython/#evalType https://spark.apache.org/docs/latest/api/sql/index.html https://docs.databricks.com/aws/en/semi-structured/higher-order-functions https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rank.html https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.pivot.html ","wordCount":"1241","inLanguage":"en","image":"https:\/\/dl.dropboxusercontent.com\/scl\/fi\/iafnblb6k95kbw7bwn2xj\/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6\u0026dl=0","datePublished":"2025-07-19T23:53:45+09:00","dateModified":"2025-07-19T23:53:45+09:00","author":{"@type":"Person","name":"minyeamer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://minyeamer.github.io/blog/spark-study-8/"},"publisher":{"@type":"Person","name":"Minystory","logo":{"@type":"ImageObject","url":"https://minyeamer.github.io/images/favicons/favicon.ico"}}}</script><title>Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기 | Minystory</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://minyeamer.github.io/blog/spark-study-8/><link rel=stylesheet href=/book.min.da9f864e1bccfac13510edef0c8dbe217c58d1ba58855d698051f162d9101fc5.css integrity="sha256-2p+GThvM+sE1EO3vDI2+IXxY0bpYhV1pgFHxYtkQH8U=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/search-input.min.001a2de4432bf89598db2196086b6547f20e393567b4b1b3a77de6490593f192.js integrity="sha256-ABot5EMr+JWY2yGWCGtlR/IOOTVntLGzp33mSQWT8ZI=" crossorigin=anonymous></script><link rel=preload href=/search-data.min.b5fc1c1b32ff60714603f9f856445cfd05f75b2319514d42e837b0ce77aa76dc.json as=fetch crossorigin><script>window.SEARCH_DATA_URL="/search-data.min.b5fc1c1b32ff60714603f9f856445cfd05f75b2319514d42e837b0ce77aa76dc.json"</script><script defer src=/search.min.f30f9834d4764fd9751da64098c954d01085f648ba9ca421a3c97582f8c47253.js integrity="sha256-8w+YNNR2T9l1HaZAmMlU0BCF9ki6nKQho8l1gvjEclM=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-BJ8Z9RMBPJ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BJ8Z9RMBPJ")</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css crossorigin=anonymous><script defer src=/scroll-progress.min.841ade7e507a5f6d59c4e7bf2fe2b2ca034070677ff7957eec55610a024dd776.js integrity="sha256-hBreflB6X21ZxOe/L+KyygNAcGd/95V+7FVhCgJN13Y=" crossorigin=anonymous></script><script defer src=/dark-mode.min.e41c6440ffd9967d6f6a419ff3ce09b862009fe1646ab265f5cb2817d2a508e3.js integrity="sha256-5BxkQP/Zln1vakGf884JuGIAn+FkarJl9csoF9KlCOM=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.9.0/highlightjs-line-numbers.min.js></script><script defer src=/copy-code.min.aaeef965f0b4992e55f976edaecb34a89d414e1791caa18c3f4f4376c6d8b5a8.js integrity="sha256-qu75ZfC0mS5V+Xbtrss0qJ1BTheRyqGMP09DdsbYtag=" crossorigin=anonymous></script><script defer src=/toc-highlightjs.093016f0ef312174ad862fdcf5792e88ab5442bd39beecc38d15643f71ab5c31.min integrity="sha256-CTAW8O8xIXSthi/c9XkuiKtUQr05vuzDjRVkP3GrXDE=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-posts book-layout-post"><div class=scroll-progress><div class=scroll-progress-bar></div></div><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><div class=sidebar-profile><div class=profile-img-wrap><a href=https://minyeamer.github.io/><img src=/images/profile/menu.jpg alt=Profile class=profile-img></a></div><div class=sidebar-social><a href=https://github.com/minyeamer target=_blank title=GitHub><i class="fa-brands fa-github"></i>
</a><a href=/categories/ title=Categories><i class="fa-solid fa-folder"></i>
</a><a href=/tags/ title=Tags><i class="fa-solid fa-tags"></i>
</a><button id=dark-mode-toggle class=dark-mode-toggle aria-label="Toggle dark mode">
<i class="fa-solid fa-circle-half-stroke"></i></button></div></div><h2 class=book-brand><a class="flex align-center" href=/><span>Minystory</span></a></h2><div class="book-search hidden"><div class=search-input-container><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/ onkeydown='event.key==="Enter"&&goToSearchPage()'>
<button type=button id=book-search-button class=book-search-btn onclick=goToSearchPage()>
<i class="fa-solid fa-magnifying-glass"></i></button></div><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden");function goToSearchPage(){const t=document.getElementById("book-search-input"),e=t.value.trim();e&&(window.location.href="/search/?q="+encodeURIComponent(e))}</script><div class=book-categories><input type=checkbox class="hidden toggle" id=categories-control checked>
<label for=categories-control class="categories-toggle categories-link"><a href=/categories/><i class="fa-solid fa-folder"></i>
<span>전체</span>
<span class=category-count>(37)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul class=categories-menu id=categories-menu><li><input type=checkbox class="hidden toggle" id=cat-algorithm>
<label for=cat-algorithm class="categories-toggle categories-link"><a href=/categories/algorithm/><i class="fa-solid fa-folder"></i>
Algorithm
<span class=category-count>(4)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/algorithm/graph/><i class="fa-solid fa-file"></i>
Graph
<span class=category-count>(1)</span></a></li><li class=categories-link><a href=/categories/algorithm/python/><i class="fa-solid fa-file"></i>
Python
<span class=category-count>(2)</span></a></li><li class=categories-link><a href=/categories/algorithm/sql/><i class="fa-solid fa-file"></i>
SQL
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-cloud>
<label for=cat-cloud class="categories-toggle categories-link"><a href=/categories/cloud/><i class="fa-solid fa-folder"></i>
Cloud
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/cloud/kubernetes/><i class="fa-solid fa-file"></i>
Kubernetes
<span class=category-count>(2)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-analysis>
<label for=cat-data-analysis class="categories-toggle categories-link"><a href=/categories/data-analysis/><i class="fa-solid fa-folder"></i>
Data Analysis
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-analysis/dacon/><i class="fa-solid fa-file"></i>
Dacon
<span class=category-count>(2)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-engineering>
<label for=cat-data-engineering class="categories-toggle categories-link"><a href=/categories/data-engineering/><i class="fa-solid fa-folder"></i>
Data Engineering
<span class=category-count>(19)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-engineering/apache-airflow/><i class="fa-solid fa-file"></i>
Apache Airflow
<span class=category-count>(7)</span></a></li><li class=categories-link><a href=/categories/data-engineering/apache-spark/><i class="fa-solid fa-file"></i>
Apache Spark
<span class=category-count>(8)</span></a></li><li class=categories-link><a href=/categories/data-engineering/crawling/><i class="fa-solid fa-file"></i>
Crawling
<span class=category-count>(4)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-frontend>
<label for=cat-frontend class="categories-toggle categories-link"><a href=/categories/frontend/><i class="fa-solid fa-folder"></i>
Frontend
<span class=category-count>(7)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/frontend/blog/><i class="fa-solid fa-file"></i>
Blog
<span class=category-count>(7)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-linux>
<label for=cat-linux class="categories-toggle categories-link"><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
<span class=category-count>(1)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/linux/ubuntu/><i class="fa-solid fa-file"></i>
Ubuntu
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-project>
<label for=cat-project class="categories-toggle categories-link"><a href=/categories/project/><i class="fa-solid fa-folder"></i>
Project
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/project/open-source/><i class="fa-solid fa-file"></i>
Open Source
<span class=category-count>(1)</span></a></li><li class=categories-link><a href=/categories/project/tools/><i class="fa-solid fa-file"></i>
Tools
<span class=category-count>(1)</span></a></li></ul></li></ul></div><div class=recent-posts><div class=recent-posts-header><i class="fa-solid fa-clock"></i>
<span>최신글</span></div><ul class=recent-posts-list><li class=recent-post-item><a href=/blog/hugo-blog-3/ title="Hugo 블로그 만들기 (3) - Taxonomies로 태그/카테고리 페이지 커스터마이징"><div class=recent-post-title>Hugo 블로그 만들기 (3) - Taxonomies로 태그/카테고리 페이지 커스터마이징</div><div class=recent-post-date><time datetime=2025-11-22>2025.11.22</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-2/ title="Hugo 블로그 만들기 (2) - 메인 레이아웃 커스터마이징 (메뉴, 목차, 헤더)"><div class=recent-post-title>Hugo 블로그 만들기 (2) - 메인 레이아웃 커스터마이징 (메뉴, 목차, 헤더)</div><div class=recent-post-date><time datetime=2025-11-04>2025.11.04</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-1/ title="Hugo 블로그 만들기 (1) - 프로젝트 구성과 GitHub Pages 배포 (Submodule 활용)"><div class=recent-post-title>Hugo 블로그 만들기 (1) - 프로젝트 구성과 GitHub Pages 배포 (Submodule 활용)</div><div class=recent-post-date><time datetime=2025-11-01>2025.11.01</time></div></a></li><li class=recent-post-item><a href=/blog/openup-handson/ title="[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기"><div class=recent-post-title>[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기</div><div class=recent-post-date><time datetime=2025-10-28>2025.10.28</time></div></a></li><li class=recent-post-item><a href=/blog/uv-project/ title="[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리"><div class=recent-post-title>[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리</div><div class=recent-post-date><time datetime=2025-07-23>2025.07.23</time></div></a></li></ul></div></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><i class="fa-solid fa-bars book-icon" id=menu-icon></i></label><h3><a href=https://minyeamer.github.io/ class=site-title>Minystory</a></h3><label for=toc-control><i class="fa-solid fa-list book-icon" id=toc-icon></i></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#user-defined-functions>User-Defined Functions</a><ul><li><a href=#spark-sql-udf-활용>Spark SQL UDF 활용</a></li><li><a href=#스파크-sql-평가-순서>스파크 SQL 평가 순서</a></li><li><a href=#pandas-udf>Pandas UDF</a></li></ul></li><li><a href=#고차-함수>고차 함수</a><ul><li><a href=#내장-함수>내장 함수</a></li><li><a href=#transform>transform()</a></li><li><a href=#filter>filter()</a></li><li><a href=#exists>exists()</a></li></ul></li><li><a href=#스파크-sql-작업>스파크 SQL 작업</a><ul><li><a href=#union>Union</a></li><li><a href=#join>Join</a></li><li><a href=#윈도우>윈도우</a></li><li><a href=#수정>수정</a></li><li><a href=#피벗>피벗</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></aside></header><article class="markdown book-article"><header class=post-header><div class=post-header-category><a href=/categories/data-engineering/apache-spark/ class=post-header-category-link>Data Engineering/Apache Spark</a></div><h1 class=post-header-title>Apache Spark - 사용자 정의 함수(UDF)와 고차 함수 활용하기</h1><div class=post-header-date><time datetime=2025-07-19T23:53:45+09:00>2025. 7. 19. 23:53</time></div></header><div class=book-cover><img src="https://dl.dropboxusercontent.com/scl/fi/iafnblb6k95kbw7bwn2xj/spark-00-cover.webp?rlkey=6995tacnu3mvr7s31akl5sca6&amp;dl=0" alt="Cover Image" class=book-cover-img></div><h2 id=user-defined-functions>User-Defined Functions
<a class=anchor href=#user-defined-functions>#</a></h2><p>스파크는 자신의 기능을 정의할 수 있는 유연성을 제공한다.
이를 사용자 정의 함수(User-Defined Function, UDF)라고 한다.</p><p>UDF를 생성하는 이점은 스파크 SQL 안에서 이를 사용할 수 있다는 것이다.</p><h3 id=spark-sql-udf-활용>Spark SQL UDF 활용
<a class=anchor href=#spark-sql-udf-%ed%99%9c%ec%9a%a9>#</a></h3><p>다음은 스파크 SQL UDF를 만드는 예시로, 인수를 세제곱하는 함수 <code>cubed()</code> 를 생성한다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.types</span> <span class=kn>import</span> <span class=n>LongType</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 큐브 함수 생성</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cubed</span><span class=p>(</span><span class=n>s</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>s</span> <span class=o>*</span> <span class=n>s</span> <span class=o>*</span> <span class=n>s</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># UDF로 등록</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>udf</span><span class=o>.</span><span class=n>register</span><span class=p>(</span><span class=s2>&#34;cubed&#34;</span><span class=p>,</span> <span class=n>cubed</span><span class=p>,</span> <span class=n>LongType</span><span class=p>())</span></span></span></code></pre></div></div><p>스파크 SQL을 사용하여 <code>cubed()</code> 함수를 실행할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 임시 뷰 생성</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>)</span><span class=o>.</span><span class=n>createOrReplaceTempView</span><span class=p>(</span><span class=s2>&#34;udf_test&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 큐브 UDF를 사용하여 쿼리</span>
</span></span><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT id, cubed(id) AS id_cubed FROM udf_test&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+---+--------+
</span></span><span class=line><span class=cl><span class=p>|</span> id<span class=p>|</span>id_cubed<span class=p>|</span>
</span></span><span class=line><span class=cl>+---+--------+
</span></span><span class=line><span class=cl><span class=p>|</span>  1<span class=p>|</span>       1<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  2<span class=p>|</span>       8<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  3<span class=p>|</span>      27<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  4<span class=p>|</span>      64<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  5<span class=p>|</span>     125<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  6<span class=p>|</span>     216<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  7<span class=p>|</span>     343<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  8<span class=p>|</span>     512<span class=p>|</span>
</span></span><span class=line><span class=cl>+---+--------+</span></span></code></pre></div></div><h3 id=스파크-sql-평가-순서>스파크 SQL 평가 순서
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac-sql-%ed%8f%89%ea%b0%80-%ec%88%9c%ec%84%9c>#</a></h3><p>스파크 SQL은 하위 표현식의 평가 순서를 보장하지 않는다.
예를 들어, 다음 쿼리에서 <code>s IS NOT NULL</code> 절이 <code>strlen(s) > 1</code> 절 이전에 실행된다는 것을 보장할 수 없다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;SELECT s FROM test1 WHERE s IS NOT NULL AND strlen(s) &gt; 1&#34;</span><span class=p>)</span></span></span></code></pre></div></div><p>따라서, 다음 두 가지 <code>null</code> 검사 방식을 수행하는 것이 좋다.</p><ol><li>UDF 안에서 <code>null</code> 을 인식하고 <code>null</code> 검사를 수행할 필요가 있다.</li><li>SQL문에서 <code>IF</code> 또는 <code>CASE WHEN</code> 식을 사용하여 <code>null</code> 검사를 수행하고 조건에 맞으면 UDF를 호출한다.</li></ol><h3 id=pandas-udf>Pandas UDF
<a class=anchor href=#pandas-udf>#</a></h3><p>PySpark UDF는 JVM과 파이썬 사이의 데이터 이동을 필요로 해서 Scala UDF보다 성능이 느렸다.</p><p>이 문제를 해결하기 위해 Pandas UDF가 스파크 2.3 버전부터 도입되었다.
Pandas UDF는 Apache Arrow를 사용하여 Pandas UDF를 정의하거나 함수 자체를 래핑할 수 있다.
Apache Arrow 형식에 포함된 데이터라면 더이상 JVM으로 데이터를 전달하기 위해 직렬화나 피클할 필요가 없다.</p><p>Pandas UDF는 <code>pandas.Series</code>, <code>pandas.DataFrame</code> 과 같은 파이썬 유형 힌트로 유추한다.
예시로, 앞에서 정의한 큐브 함수를 Pandas UDF로 만들면 아래와 같다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>col</span><span class=p>,</span> <span class=n>pandas_udf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.types</span> <span class=kn>import</span> <span class=n>LongType</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 큐브 함수 생성</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cubed</span><span class=p>(</span><span class=n>a</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>a</span> <span class=o>*</span> <span class=n>a</span> <span class=o>*</span> <span class=n>a</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 큐브 함수에 대한 Pandas UDF 생성</span>
</span></span><span class=line><span class=cl><span class=n>cubed_udf</span> <span class=o>=</span> <span class=n>pandas_udf</span><span class=p>(</span><span class=n>cubed</span><span class=p>,</span> <span class=n>returnType</span><span class=o>=</span><span class=n>LongType</span><span class=p>())</span></span></span></code></pre></div></div><p>Pandas UDF는 아래와 같이 실행할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 스파크 데이터프레임 생성</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Pandas UDF를 실행</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;id&#34;</span><span class=p>,</span> <span class=n>cubed_udf</span><span class=p>(</span><span class=n>col</span><span class=p>(</span><span class=s2>&#34;id&#34;</span><span class=p>)))</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+---+---------+
</span></span><span class=line><span class=cl><span class=p>|</span> id<span class=p>|</span>cubed<span class=o>(</span>id<span class=o>)</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+---+---------+
</span></span><span class=line><span class=cl><span class=p>|</span>  1<span class=p>|</span>        1<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  2<span class=p>|</span>        8<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  3<span class=p>|</span>       27<span class=p>|</span>
</span></span><span class=line><span class=cl>+---+---------+</span></span></code></pre></div></div><p>스파크 UI에서 시각화된 <code>pandas_udf</code> 함수의 실행 단계에 대한 DAG을 조회할 수 있다.
Stage 0에서 <code>ArrowEvalPython</code> 연산이 Pandas UDF를 평가하는 단계이다.</p><div style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/kn9ih42tqsbxfskwq5vj4/spark-19-pandas-udf.webp?rlkey=f1yvfjog5fvxjyhcvjugsd1id&amp;dl=0" alt="WholeStageCodegen (1) -> ArrowEvalPython -> WholeStageCodeGen (2) -> mapPartitionsInternal" style=width:100%;max-width:432px></div><h2 id=고차-함수>고차 함수
<a class=anchor href=#%ea%b3%a0%ec%b0%a8-%ed%95%a8%ec%88%98>#</a></h2><p>복잡한 데이터 유형은 단순한 데이터 유형의 결합이기 때문에 다음과 같이 조작할 수 있다.</p><ol><li>중첩된 구조를 개별 행으로 분해하고 각각에 함수를 적용한 후 중첩된 구조를 다시 만드는 방법</li><li>사용자 정의 함수를 사용하는 방법</li></ol><p>하지만 배열과 같은 중첩된 구조를 분해하고 다시 만든다고 가정할 때, 셔플 작업이 발생해 결과 배열의 순서가 원래 배열의 순서와 동일하지 않을 수 있다.</p><p>사용자 정의 함수를 사용할 경우에는 정렬 문제는 해결할 수 있지만, 직렬화 및 역직렬화 과정을 거치면서 발생하는 비용이 크다는 문제가 있다.</p><h3 id=내장-함수>내장 함수
<a class=anchor href=#%eb%82%b4%ec%9e%a5-%ed%95%a8%ec%88%98>#</a></h3><p>복잡한 데이터 유형에 대해 스파크 2.4 이상 버전에 포함된 내장 함수를 사용할 수 있다.
자세한 건 <a href=https://spark.apache.org/docs/latest/api/sql/index.html target=_blank rel="noopener noreferrer">공식 문서</a>를 참고해볼 수 있는데,
그 중에서 배열과 맵에 대해서 일부를 알아본다.</p><p>배열과 관련된 함수는 공식 문서에서
<a href=https://spark.apache.org/docs/latest/api/sql/index.html#array target=_blank rel="noopener noreferrer">array 문단</a>부터 시작하는 함수들을 참고하면 된다.
대표적으로 <code>array_distinct</code> 함수는 배열 내 중복을 제거하고, <code>array_sort</code> 함수는 배열을 오름차순으로 정렬한다.
array로 시작하지 않는 함수 중에서도 <code>concat</code> 함수는 복수 개의 배열을 받아 하나의 배열로 합쳐주고,
<code>flatten</code> 함수는 2차원 이상 중첩된 배열을 단일 배열로 플랫화한다. <code>sequence</code> 함수로
시작과 끝에 대한 배열을 생성할 수 있고, <code>slice</code> 함수로 배열의 특정 부분만 잘라낼 수도 있다.</p><p>맵과 관련된 함수는 공식 문서에서
<a href=https://spark.apache.org/docs/latest/api/sql/index.html#map target=_blank rel="noopener noreferrer">map 문단</a>부터
시작하는 함수들을 참고하면 된다.
대표적으로 <code>map_concat</code> 함수는 복수 개의 맵을 하나의 맵으로 합쳐주고,
<code>map_keys</code> 함수로 맵에서 키 배열만 추출할 수도 있다. map으로 시작하지 않는 함수 중에서도
<code>element_at</code> 함수는 주어진 키에 대한 값을 반환하고, <code>cardinality</code> 함수는 맵의 크기를 반환한다.</p><h3 id=transform>transform()
<a class=anchor href=#transform>#</a></h3><p>내장 함수 외에도 익명 람다 함수를 인수로 사용하는 고차 함수 <code>transform()</code> 이 있다.</p><p>고차 함수를 실행해보기 위해 아래와 같이 샘플 데이터 <code>tC</code> 를 만들어본다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.types</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>schema</span> <span class=o>=</span> <span class=n>StructType</span><span class=p>([</span><span class=n>StructField</span><span class=p>(</span><span class=s2>&#34;celsius&#34;</span><span class=p>,</span> <span class=n>ArrayType</span><span class=p>(</span><span class=n>IntegerType</span><span class=p>()))])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>t_list</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>38</span><span class=p>]],</span> <span class=p>[[</span><span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>55</span><span class=p>,</span> <span class=mi>56</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=n>t_c</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>createDataFrame</span><span class=p>(</span><span class=n>t_list</span><span class=p>,</span> <span class=n>schema</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>t_c</span><span class=o>.</span><span class=n>createOrReplaceTempView</span><span class=p>(</span><span class=s2>&#34;tC&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>t_c</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span>             celsius<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>35, 36, 32, 30, ...<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>31, 32, 34, 55, 56<span class=o>]</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+</span></span></code></pre></div></div><p>Celsius 단위를 Fahrenheit 단위로 바꾸는 <code>transform()</code> 함수를 사용해,
<code>celsius</code> 열로부터 <code>fahrenheit</code> 열을 계산했다. 출력 결과는 아래와 같다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>SELECT
</span></span></span><span class=line><span class=cl><span class=s2>  celsius,
</span></span></span><span class=line><span class=cl><span class=s2>  transform(celsius, t -&gt; ((t * 9) div 5) + 32) AS fahrenheit
</span></span></span><span class=line><span class=cl><span class=s2>FROM tc
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------------------+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span>             celsius<span class=p>|</span>          fahrenheit<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>35, 36, 32, 30, ...<span class=p>|</span><span class=o>[</span>95, 96, 89, 86, ...<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>31, 32, 34, 55, 56<span class=o>]</span><span class=p>|</span><span class=o>[</span>87, 89, 93, 131,...<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+--------------------+</span></span></code></pre></div></div><h3 id=filter>filter()
<a class=anchor href=#filter>#</a></h3><p><code>filter()</code> 함수는 입력한 배열의 요소 중 부울 함수가 참인 요소만으로 구성된 배열을 생성한다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>SELECT
</span></span></span><span class=line><span class=cl><span class=s2>  celsius,
</span></span></span><span class=line><span class=cl><span class=s2>  filter(celsius, t -&gt; t &gt; 38) AS high
</span></span></span><span class=line><span class=cl><span class=s2>FROM tc
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------------------+--------+
</span></span><span class=line><span class=cl><span class=p>|</span>             celsius<span class=p>|</span>    high<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+--------+
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>35, 36, 32, 30, ...<span class=p>|</span><span class=o>[</span>40, 42<span class=o>]</span><span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>31, 32, 34, 55, 56<span class=o>]</span><span class=p>|</span><span class=o>[</span>55, 56<span class=o>]</span><span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+--------+</span></span></code></pre></div></div><h3 id=exists>exists()
<a class=anchor href=#exists>#</a></h3><p><code>exists()</code> 함수는 입력한 배열의 요소 중 불린 함수를 만족시키는 것이 존재할 때 참을 반환한다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>SELECT
</span></span></span><span class=line><span class=cl><span class=s2>  celsius,
</span></span></span><span class=line><span class=cl><span class=s2>  exists(celsius, t -&gt; t = 38) AS threshold
</span></span></span><span class=line><span class=cl><span class=s2>FROM tc
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+--------------------+---------+
</span></span><span class=line><span class=cl><span class=p>|</span>             celsius<span class=p>|</span>threshold<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+---------+
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>35, 36, 32, 30, ...<span class=p>|</span>     true<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span><span class=o>[</span>31, 32, 34, 55, 56<span class=o>]</span><span class=p>|</span>    false<span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------------+---------+</span></span></code></pre></div></div><h2 id=스파크-sql-작업>스파크 SQL 작업
<a class=anchor href=#%ec%8a%a4%ed%8c%8c%ed%81%ac-sql-%ec%9e%91%ec%97%85>#</a></h2><p>스파크 SQL의 기능 중 일부는 DataFrame의 다양한 기능에서 유래된다.
이용가능한 작업에는 집계 함수, 수집 함수, 날짜 함수, 수학 함수, 정렬 함수,
문자열 함수, 윈도우 함수 등 매우 광범위하다.</p><h3 id=union>Union
<a class=anchor href=#union>#</a></h3><p>Union은 동일한 스키마를 가진 두 개의 서로 다른 DataFrame을 하나로 합치는 작업이다.</p><p>SQL문으로 다음과 같이 표현할 수 있다.</p><div class=book-codeblock data-lang=sql><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">sql</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=p>(</span><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>first_half</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>UNION</span><span class=w> </span><span class=k>ALL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>(</span><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>second_half</span><span class=p>);</span></span></span></code></pre></div></div><p>파이썬으로는 다음과 같이 표현할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>first_half</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>second_half</span><span class=p>)</span></span></span></code></pre></div></div><h3 id=join>Join
<a class=anchor href=#join>#</a></h3><p>Join은 두 개 이상의 DataFrame을 특정 조건을 기준으로 결합하여 하나로 합치는 작업이다.</p><p>SQL문으로 다음과 같이 표현할 수 있다.</p><div class=book-codeblock data-lang=sql><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">sql</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>p</span><span class=p>.</span><span class=n>id</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>productId</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>p</span><span class=p>.</span><span class=n>storeId</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>s</span><span class=p>.</span><span class=n>name</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>storeName</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>p</span><span class=p>.</span><span class=n>name</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>productName</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w> </span><span class=n>product</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>p</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>LEFT</span><span class=w> </span><span class=k>JOIN</span><span class=w> </span><span class=n>store</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>ON</span><span class=w> </span><span class=n>p</span><span class=p>.</span><span class=n>storeId</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>s</span><span class=p>.</span><span class=n>id</span><span class=p>;</span></span></span></code></pre></div></div><p>파이썬으로는 다음과 같이 표현할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>col</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>product</span><span class=o>.</span><span class=n>join</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>store</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>product</span><span class=o>.</span><span class=n>storeId</span> <span class=o>==</span> <span class=n>store</span><span class=o>.</span><span class=n>id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>how</span> <span class=o>=</span> <span class=s2>&#34;left&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>select</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>col</span><span class=p>(</span><span class=s2>&#34;p.id&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s2>&#34;productId&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;p.storeId&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>col</span><span class=p>(</span><span class=s2>&#34;s.name&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s2>&#34;storeName&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>col</span><span class=p>(</span><span class=s2>&#34;p.name&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s2>&#34;productName&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><h3 id=윈도우>윈도우
<a class=anchor href=#%ec%9c%88%eb%8f%84%ec%9a%b0>#</a></h3><p>윈도우 함수를 사용하면 모든 입력 행에 대해 단일값을 반환하면서 행 그룹에 대해 작업할 수 있다.</p><p>순위를 매기는 작업과 관련해서는 <code>RANK</code>, <code>DENSE_RANK</code>, <code>PERCENT_RANK</code>, <code>NTILE</code>, <code>ROW_NUMBER</code>
함수가 있고, 집계와 관련해서는 <code>MAX</code>, <code>MIN</code>, <code>COUNT</code>, <code>SUM</code>, <code>AVG</code> 등의 함수가 있다.</p><p>SQL문으로 다음과 같이 표현할 수 있다.</p><div class=book-codeblock data-lang=sql><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">sql</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>name</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>dept</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>salary</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>RANK</span><span class=p>()</span><span class=w> </span><span class=n>OVER</span><span class=w> </span><span class=p>(</span><span class=n>PARTITION</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>dept</span><span class=w> </span><span class=k>ORDER</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>salary</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>rank</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w> </span><span class=n>employees</span><span class=p>;</span></span></span></code></pre></div></div><p>파이썬으로는 다음과 같이 표현할 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>rank</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>Window</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>window</span> <span class=o>=</span> <span class=n>rank</span><span class=p>()</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>Window</span><span class=o>.</span><span class=n>partitionBy</span><span class=p>(</span><span class=s2>&#34;dept&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=s2>&#34;salary&#34;</span><span class=p>))</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s2>&#34;rank&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>employees</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;name&#34;</span><span class=p>,</span> <span class=s2>&#34;dept&#34;</span><span class=p>,</span> <span class=s2>&#34;salary&#34;</span><span class=p>,</span> <span class=n>window</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><h3 id=수정>수정
<a class=anchor href=#%ec%88%98%ec%a0%95>#</a></h3><p>DataFrame 자체는 변경할 수 없지만, 열을 가공하여 새로운 DataFrame을 만드는 것과 같은 작업을 통해 수정할 수 있다.</p><p>파이썬으로 활용 가능한 다음과 같은 예시가 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql.functions</span> <span class=kn>import</span> <span class=n>expr</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 열 추가</span>
</span></span><span class=line><span class=cl><span class=n>foo2</span> <span class=o>=</span> <span class=n>foo</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;status&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=n>expr</span><span class=p>(</span><span class=s2>&#34;CASE WHEN delay &lt;= 10 THEN &#39;On-time&#39; ELSE &#39;Delayed&#39; END&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 열 삭제</span>
</span></span><span class=line><span class=cl><span class=n>foo3</span> <span class=o>=</span> <span class=n>foo2</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&#34;delay&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 칼럼명 바꾸기</span>
</span></span><span class=line><span class=cl><span class=n>foo4</span> <span class=o>=</span> <span class=n>foo3</span><span class=o>.</span><span class=n>withColumnRenamed</span><span class=p>(</span><span class=s2>&#34;status&#34;</span><span class=p>,</span> <span class=s2>&#34;flight_status&#34;</span><span class=p>)</span></span></span></code></pre></div></div><h3 id=피벗>피벗
<a class=anchor href=#%ed%94%bc%eb%b2%97>#</a></h3><p>로우와 칼럼을 바꿔야 하는 경우가 있다. 이 경우에 <code>pivot</code> 함수를 지원한다.</p><p>피벗을 실행해보기 위해 아래와 같이 샘플 데이터를 만들어본다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>Row</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>df1</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>createDataFrame</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;dotNET&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2012</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>10000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;Java&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2012</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>20000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;dotNET&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2012</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>5000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;dotNET&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2013</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>48000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Row</span><span class=p>(</span><span class=n>course</span><span class=o>=</span><span class=s2>&#34;Java&#34;</span><span class=p>,</span> <span class=n>year</span><span class=o>=</span><span class=mi>2013</span><span class=p>,</span> <span class=n>earnings</span><span class=o>=</span><span class=mi>30000</span><span class=p>),])</span>
</span></span><span class=line><span class=cl><span class=n>df1</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+------+----+--------+
</span></span><span class=line><span class=cl><span class=p>|</span>course<span class=p>|</span>year<span class=p>|</span>earnings<span class=p>|</span>
</span></span><span class=line><span class=cl>+------+----+--------+
</span></span><span class=line><span class=cl><span class=p>|</span>dotNET<span class=p>|</span>2012<span class=p>|</span>   10000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  Java<span class=p>|</span>2012<span class=p>|</span>   20000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>dotNET<span class=p>|</span>2012<span class=p>|</span>    5000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>dotNET<span class=p>|</span>2013<span class=p>|</span>   48000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>  Java<span class=p>|</span>2013<span class=p>|</span>   30000<span class=p>|</span>
</span></span><span class=line><span class=cl>+------+----+--------+</span></span></code></pre></div></div><p>위 데이터에서 <code>course</code> 를 열로, <code>year</code> 를 행으로, <code>earnings</code> 를 값으로
<code>sum</code> 집계해 구성한 피벗 테이블을 아래와 같이 만들 수 있다.</p><div class=book-codeblock data-lang=python><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">python</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>df1</span><span class=o>.</span><span class=n>groupBy</span><span class=p>(</span><span class=s2>&#34;year&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>pivot</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;course&#34;</span><span class=p>,</span> <span class=p>[</span><span class=s2>&#34;dotNET&#34;</span><span class=p>,</span> <span class=s2>&#34;Java&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=s2>&#34;earnings&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=s2>&#34;year&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div></div><div class=book-codeblock data-lang=bash><div class=code-actions><button class="code-copy-btn code-action" onclick=copyCode(this)>
<i class="fa-solid fa-copy"></i>Copy
</button>
<span class="code-language code-action">bash</span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+----+------+-----+
</span></span><span class=line><span class=cl><span class=p>|</span>year<span class=p>|</span>dotNET<span class=p>|</span> Java<span class=p>|</span>
</span></span><span class=line><span class=cl>+----+------+-----+
</span></span><span class=line><span class=cl><span class=p>|</span>2012<span class=p>|</span> 15000<span class=p>|</span>20000<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>2013<span class=p>|</span> 48000<span class=p>|</span>30000<span class=p>|</span>
</span></span><span class=line><span class=cl>+----+------+-----+</span></span></code></pre></div></div><h2 id=references>References
<a class=anchor href=#references>#</a></h2><ul><li><a href=https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html</a></li><li><a href=https://books.japila.pl/pyspark-internals/sql/ArrowEvalPython/#evalType target=_blank rel="noopener noreferrer">https://books.japila.pl/pyspark-internals/sql/ArrowEvalPython/#evalType</a></li><li><a href=https://spark.apache.org/docs/latest/api/sql/index.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/api/sql/index.html</a></li><li><a href=https://docs.databricks.com/aws/en/semi-structured/higher-order-functions target=_blank rel="noopener noreferrer">https://docs.databricks.com/aws/en/semi-structured/higher-order-functions</a></li><li><a href=https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rank.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rank.html</a></li><li><a href=https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.pivot.html target=_blank rel="noopener noreferrer">https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.pivot.html</a></li></ul></article><div class=book-nav><button class=book-nav-btn3 onclick='window.scrollTo({top:0,behavior:"smooth"})' title="Go to top">
<i class="fa fa-chevron-up"></i>
</button>
<button class=book-nav-btn3 onclick='window.scrollTo({top:document.body.scrollHeight,behavior:"smooth"})' title="Go to bottom">
<i class="fa fa-chevron-down"></i>
<button class=book-nav-btn3 onclick=history.back() title="Go back">
<i class="fa-solid fa-arrow-left"></i></button></div><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class=post-tags><a href=/tags/apache-spark/ class=tag>#Apache Spark</a>
<a href=/tags/%EA%B3%A0%EC%B0%A8-%ED%95%A8%EC%88%98/ class=tag>#고차 함수</a>
<a href=/tags/udf/ class=tag>#UDF</a>
<a href=/tags/pandas-udf/ class=tag>#Pandas UDF</a>
<a href=/tags/spark-sql/ class=tag>#Spark SQL</a>
<a href=/tags/pyspark/ class=tag>#PySpark</a>
<a href=/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81/ class=tag>#데이터 엔지니어링</a>
<a href=/tags/%EC%8A%A4%ED%8C%8C%ED%81%AC/ class=tag>#스파크</a>
<a href=/tags/study/ class=tag>#Study</a></div><div class=post-navigation><a href=/blog/spark-study-7/ class="post-nav-link post-nav-prev"><span class=post-nav-direction><i class="fa-solid fa-backward"></i> PREV</span>
<span class=post-nav-title>Apache Spark - 외부 데이터베이스 연동 (PostgreSQL, MySQL)</span>
</a><a href class="post-nav-link post-nav-next post-nav-disabled"><span class=post-nav-direction>NEXT <i class="fa-solid fa-forward"></i></span>
<span class=post-nav-title>다음 게시글이 없습니다</span></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script><div class=book-comments><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://minyeamer.github.io/blog/spark-study-8/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-8/"};(function(){var e=document,t=e.createElement("script");t.src="https://minyeamer.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})();function reloadDisqus(){window.DISQUS&&DISQUS.reset({reload:!0,config:function(){this.page.url="https://minyeamer.github.io/blog/spark-study-8/",this.page.identifier="https://minyeamer.github.io/blog/spark-study-8/"}})}</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#user-defined-functions>User-Defined Functions</a><ul><li><a href=#spark-sql-udf-활용>Spark SQL UDF 활용</a></li><li><a href=#스파크-sql-평가-순서>스파크 SQL 평가 순서</a></li><li><a href=#pandas-udf>Pandas UDF</a></li></ul></li><li><a href=#고차-함수>고차 함수</a><ul><li><a href=#내장-함수>내장 함수</a></li><li><a href=#transform>transform()</a></li><li><a href=#filter>filter()</a></li><li><a href=#exists>exists()</a></li></ul></li><li><a href=#스파크-sql-작업>스파크 SQL 작업</a><ul><li><a href=#union>Union</a></li><li><a href=#join>Join</a></li><li><a href=#윈도우>윈도우</a></li><li><a href=#수정>수정</a></li><li><a href=#피벗>피벗</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></div></aside></main></body></html>