<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[AI SCHOOL 5기] 머신 러닝 | Minystory</title><meta name=keywords content="AI SCHOOL,멋쟁이사자처럼,코드라이언,Machine Learning"><meta name=description content="인공지능 Intelligent Agents를 만드는 것 주변 환경들을 인식하고 원하는 행동을 취하여 목표를 성취하는 것 Artificial Narrow Intelligence 제한된 기능만 수행할 수 있는 인공지능 weak AI Artificial General Intelligence 사람만큼 다양한 분야에서 기능을 수행할 수 있는 인공지능 strong AI Artificial Super Intelligence 모든 분야에서 사람보다 뛰어난 인공지능 모델 데이터를 가장 잘 설명할 수 있는 함수 (y = ax + b) 모델에서 θ는 Parameter(가중치, Weight) 의미 모델에서 h(x)는 Hypotheses(가설) 의미 모델에서 b는 Bias(편향, 보정치) 의미 머신러닝 어떠한 과제를 해결하는 과정에서 특정한 평가 기준을 바탕으로 학습의 경험을 쌓는 프로그램 머신러닝 분류 Supervised 입력값에 대한 정답을 예측하기 위해 학습 데이터와 정답이 같이 존재 회귀(Regression): 결과가 실수 영역 전체에서 나타남 분류(Classification): 결과가 특정 분류에 해당하는 불연속값으로 나타남 ex) 주식 가격 예측, 이미지 인식 등 Unsupervised 입력값 속에 숨어있는 규칙성을 찾기 위해 학습 정답이 없는 데이터를 주고 비슷한 집단을 분류 ex) 고객군 분류, 장바구니 분석(Association Rule) 등 Reinforcement Trial & Error를 통한 학습 최종적으로 얻게 될 기대 보상을 최대화하기 위한 행동 선택 정책 학습 각 상태에 대해 결정한 행동을 통해 환경으로부터 받는 보상을 학습 ex) 로봇 제어, 공정 최적화 등 Automated ML 어떤 모델(함수, 알고리즘)을 써야할지를 컴퓨터가 알아서 정하게 함 인공신경망 레이어의 범위, 후보 등을 정해놓고 그 안에서 가장 좋은 조합을 찾음 ex) AutoML Tables (행의 수가 1000건이 넘어야하는 제약) 학습 데이터를 가장 잘 설명하는 방법을 찾는 과정 데이터에 맞는 모델을 찾는 과정 (= Model Fitting) 실제 정답과 예측 결과 사이의 오차(Loss, Cost, Error)를 줄여나가는 최적화 과정 학습 과정 초기 모델에 데이터를 입력 결과를 평가 (예측/분류의 정확도 등) 결과를 개선하기 위해 모델을 수정 (모델 내부 Parameter 수정 등) Model&rsquo;s Capacity 2번 모델은 3번 모델보다 오차가 크지만 새로운 데이터가 생겼을 때 비슷하게 예측 가능 3번 모델은 오차가 가장 적지만 새로운 데이터가 생겼을 때 오차가 매우 커질 수 있음 3번 모델과 같은 Overfitting(과적합)이 발생하기 전에 학습을 멈춤 Cross Validation 새로운 데이터들에 대해서도 좋은 결과를 내게 하기 위해 데이터를 3개 그룹으로 나눠 학습 60%의 Training Data로 모델을 학습 20%의 Validation Data로 모델을 최적화/선택 20%의 Test Data로 모델을 평가 데이터를 분리하는 비율은 모델에 따라 달라짐 K-Fold Cross Validation 후보 모델 간 비교 및 선택을 위한 알고리즘 Training Data를 K 등분하고 그 중 하나를 Validation Data로 설정 K 값은 자체적으로 결정하며 보통 10-Fold 사용 (시간이 없으면 5-Fold) 머신러닝에서 K는 주로 사용자가 결정하는 상수 Stratified: 층화 표집 방법, 데이터의 분류 별 비율이 다르면 K-Fold 조각 안에서 비율을 유지시킴 10-Fold 학습 과정 데이터를 80%의 Training Data와 20%의 Test Data로 나누고 Training Data를 10등분"><meta name=author content="minyeamer"><link rel=canonical href=https://minyeamer.github.io/blog/aischool-06-00-machine-learning/><meta name=google-site-verification content="u1tWcHmHUZWfFT1cHaku6sqU-bK40N3WLR-C-4VUWN0"><meta name=naver-site-verification content="6eaf8e9da1a6104780f056f1a7797fe5a3a5a0da"><link crossorigin=anonymous href=/assets/css/stylesheet.78a14cf8249250820b49e9dc59e58b846a9beea6d16d50612c68b121ddf02146.css integrity="sha256-eKFM+CSSUIILSencWeWLhGqb7qbRbVBhLGixId3wIUY=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://minyeamer.github.io/img/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://minyeamer.github.io/img/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://minyeamer.github.io/img/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://minyeamer.github.io/img/favicons/apple-touch-icon.png><link rel=mask-icon href=https://minyeamer.github.io/img/favicons/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-BWECRMSX3V"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BWECRMSX3V")</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-BWECRMSX3V"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BWECRMSX3V",{anonymize_ip:!1})}</script><meta property="og:title" content="[AI SCHOOL 5기] 머신 러닝"><meta property="og:description" content="인공지능 Intelligent Agents를 만드는 것 주변 환경들을 인식하고 원하는 행동을 취하여 목표를 성취하는 것 Artificial Narrow Intelligence 제한된 기능만 수행할 수 있는 인공지능 weak AI Artificial General Intelligence 사람만큼 다양한 분야에서 기능을 수행할 수 있는 인공지능 strong AI Artificial Super Intelligence 모든 분야에서 사람보다 뛰어난 인공지능 모델 데이터를 가장 잘 설명할 수 있는 함수 (y = ax + b) 모델에서 θ는 Parameter(가중치, Weight) 의미 모델에서 h(x)는 Hypotheses(가설) 의미 모델에서 b는 Bias(편향, 보정치) 의미 머신러닝 어떠한 과제를 해결하는 과정에서 특정한 평가 기준을 바탕으로 학습의 경험을 쌓는 프로그램 머신러닝 분류 Supervised 입력값에 대한 정답을 예측하기 위해 학습 데이터와 정답이 같이 존재 회귀(Regression): 결과가 실수 영역 전체에서 나타남 분류(Classification): 결과가 특정 분류에 해당하는 불연속값으로 나타남 ex) 주식 가격 예측, 이미지 인식 등 Unsupervised 입력값 속에 숨어있는 규칙성을 찾기 위해 학습 정답이 없는 데이터를 주고 비슷한 집단을 분류 ex) 고객군 분류, 장바구니 분석(Association Rule) 등 Reinforcement Trial & Error를 통한 학습 최종적으로 얻게 될 기대 보상을 최대화하기 위한 행동 선택 정책 학습 각 상태에 대해 결정한 행동을 통해 환경으로부터 받는 보상을 학습 ex) 로봇 제어, 공정 최적화 등 Automated ML 어떤 모델(함수, 알고리즘)을 써야할지를 컴퓨터가 알아서 정하게 함 인공신경망 레이어의 범위, 후보 등을 정해놓고 그 안에서 가장 좋은 조합을 찾음 ex) AutoML Tables (행의 수가 1000건이 넘어야하는 제약) 학습 데이터를 가장 잘 설명하는 방법을 찾는 과정 데이터에 맞는 모델을 찾는 과정 (= Model Fitting) 실제 정답과 예측 결과 사이의 오차(Loss, Cost, Error)를 줄여나가는 최적화 과정 학습 과정 초기 모델에 데이터를 입력 결과를 평가 (예측/분류의 정확도 등) 결과를 개선하기 위해 모델을 수정 (모델 내부 Parameter 수정 등) Model&rsquo;s Capacity 2번 모델은 3번 모델보다 오차가 크지만 새로운 데이터가 생겼을 때 비슷하게 예측 가능 3번 모델은 오차가 가장 적지만 새로운 데이터가 생겼을 때 오차가 매우 커질 수 있음 3번 모델과 같은 Overfitting(과적합)이 발생하기 전에 학습을 멈춤 Cross Validation 새로운 데이터들에 대해서도 좋은 결과를 내게 하기 위해 데이터를 3개 그룹으로 나눠 학습 60%의 Training Data로 모델을 학습 20%의 Validation Data로 모델을 최적화/선택 20%의 Test Data로 모델을 평가 데이터를 분리하는 비율은 모델에 따라 달라짐 K-Fold Cross Validation 후보 모델 간 비교 및 선택을 위한 알고리즘 Training Data를 K 등분하고 그 중 하나를 Validation Data로 설정 K 값은 자체적으로 결정하며 보통 10-Fold 사용 (시간이 없으면 5-Fold) 머신러닝에서 K는 주로 사용자가 결정하는 상수 Stratified: 층화 표집 방법, 데이터의 분류 별 비율이 다르면 K-Fold 조각 안에서 비율을 유지시킴 10-Fold 학습 과정 데이터를 80%의 Training Data와 20%의 Test Data로 나누고 Training Data를 10등분"><meta property="og:type" content="article"><meta property="og:url" content="https://minyeamer.github.io/blog/aischool-06-00-machine-learning/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-04-13T16:31:00+09:00"><meta property="article:modified_time" content="2022-04-13T16:31:00+09:00"><meta property="og:site_name" content="Minystory"><meta name=twitter:card content="summary"><meta name=twitter:title content="[AI SCHOOL 5기] 머신 러닝"><meta name=twitter:description content="인공지능 Intelligent Agents를 만드는 것 주변 환경들을 인식하고 원하는 행동을 취하여 목표를 성취하는 것 Artificial Narrow Intelligence 제한된 기능만 수행할 수 있는 인공지능 weak AI Artificial General Intelligence 사람만큼 다양한 분야에서 기능을 수행할 수 있는 인공지능 strong AI Artificial Super Intelligence 모든 분야에서 사람보다 뛰어난 인공지능 모델 데이터를 가장 잘 설명할 수 있는 함수 (y = ax + b) 모델에서 θ는 Parameter(가중치, Weight) 의미 모델에서 h(x)는 Hypotheses(가설) 의미 모델에서 b는 Bias(편향, 보정치) 의미 머신러닝 어떠한 과제를 해결하는 과정에서 특정한 평가 기준을 바탕으로 학습의 경험을 쌓는 프로그램 머신러닝 분류 Supervised 입력값에 대한 정답을 예측하기 위해 학습 데이터와 정답이 같이 존재 회귀(Regression): 결과가 실수 영역 전체에서 나타남 분류(Classification): 결과가 특정 분류에 해당하는 불연속값으로 나타남 ex) 주식 가격 예측, 이미지 인식 등 Unsupervised 입력값 속에 숨어있는 규칙성을 찾기 위해 학습 정답이 없는 데이터를 주고 비슷한 집단을 분류 ex) 고객군 분류, 장바구니 분석(Association Rule) 등 Reinforcement Trial & Error를 통한 학습 최종적으로 얻게 될 기대 보상을 최대화하기 위한 행동 선택 정책 학습 각 상태에 대해 결정한 행동을 통해 환경으로부터 받는 보상을 학습 ex) 로봇 제어, 공정 최적화 등 Automated ML 어떤 모델(함수, 알고리즘)을 써야할지를 컴퓨터가 알아서 정하게 함 인공신경망 레이어의 범위, 후보 등을 정해놓고 그 안에서 가장 좋은 조합을 찾음 ex) AutoML Tables (행의 수가 1000건이 넘어야하는 제약) 학습 데이터를 가장 잘 설명하는 방법을 찾는 과정 데이터에 맞는 모델을 찾는 과정 (= Model Fitting) 실제 정답과 예측 결과 사이의 오차(Loss, Cost, Error)를 줄여나가는 최적화 과정 학습 과정 초기 모델에 데이터를 입력 결과를 평가 (예측/분류의 정확도 등) 결과를 개선하기 위해 모델을 수정 (모델 내부 Parameter 수정 등) Model&rsquo;s Capacity 2번 모델은 3번 모델보다 오차가 크지만 새로운 데이터가 생겼을 때 비슷하게 예측 가능 3번 모델은 오차가 가장 적지만 새로운 데이터가 생겼을 때 오차가 매우 커질 수 있음 3번 모델과 같은 Overfitting(과적합)이 발생하기 전에 학습을 멈춤 Cross Validation 새로운 데이터들에 대해서도 좋은 결과를 내게 하기 위해 데이터를 3개 그룹으로 나눠 학습 60%의 Training Data로 모델을 학습 20%의 Validation Data로 모델을 최적화/선택 20%의 Test Data로 모델을 평가 데이터를 분리하는 비율은 모델에 따라 달라짐 K-Fold Cross Validation 후보 모델 간 비교 및 선택을 위한 알고리즘 Training Data를 K 등분하고 그 중 하나를 Validation Data로 설정 K 값은 자체적으로 결정하며 보통 10-Fold 사용 (시간이 없으면 5-Fold) 머신러닝에서 K는 주로 사용자가 결정하는 상수 Stratified: 층화 표집 방법, 데이터의 분류 별 비율이 다르면 K-Fold 조각 안에서 비율을 유지시킴 10-Fold 학습 과정 데이터를 80%의 Training Data와 20%의 Test Data로 나누고 Training Data를 10등분"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://minyeamer.github.io/post/"},{"@type":"ListItem","position":2,"name":"[AI SCHOOL 5기] 머신 러닝","item":"https://minyeamer.github.io/blog/aischool-06-00-machine-learning/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[AI SCHOOL 5기] 머신 러닝","name":"[AI SCHOOL 5기] 머신 러닝","description":"인공지능 Intelligent Agents를 만드는 것 주변 환경들을 인식하고 원하는 행동을 취하여 목표를 성취하는 것 Artificial Narrow Intelligence 제한된 기능만 수행할 수 있는 인공지능 weak AI Artificial General Intelligence 사람만큼 다양한 분야에서 기능을 수행할 수 있는 인공지능 strong AI Artificial Super Intelligence 모든 분야에서 사람보다 뛰어난 인공지능 모델 데이터를 가장 잘 설명할 수 있는 함수 (y = ax + b) 모델에서 θ는 Parameter(가중치, Weight) 의미 모델에서 h(x)는 Hypotheses(가설) 의미 모델에서 b는 Bias(편향, 보정치) 의미 머신러닝 어떠한 과제를 해결하는 과정에서 특정한 평가 기준을 바탕으로 학습의 경험을 쌓는 프로그램 머신러닝 분류 Supervised 입력값에 대한 정답을 예측하기 위해 학습 데이터와 정답이 같이 존재 회귀(Regression): 결과가 실수 영역 전체에서 나타남 분류(Classification): 결과가 특정 분류에 해당하는 불연속값으로 나타남 ex) 주식 가격 예측, 이미지 인식 등 Unsupervised 입력값 속에 숨어있는 규칙성을 찾기 위해 학습 정답이 없는 데이터를 주고 비슷한 집단을 분류 ex) 고객군 분류, 장바구니 분석(Association Rule) 등 Reinforcement Trial \u0026amp; Error를 통한 학습 최종적으로 얻게 될 기대 보상을 최대화하기 위한 행동 선택 정책 학습 각 상태에 대해 결정한 행동을 통해 환경으로부터 받는 보상을 학습 ex) 로봇 제어, 공정 최적화 등 Automated ML 어떤 모델(함수, 알고리즘)을 써야할지를 컴퓨터가 알아서 정하게 함 인공신경망 레이어의 범위, 후보 등을 정해놓고 그 안에서 가장 좋은 조합을 찾음 ex) AutoML Tables (행의 수가 1000건이 넘어야하는 제약) 학습 데이터를 가장 잘 설명하는 방법을 찾는 과정 데이터에 맞는 모델을 찾는 과정 (= Model Fitting) 실제 정답과 예측 결과 사이의 오차(Loss, Cost, Error)를 줄여나가는 최적화 과정 학습 과정 초기 모델에 데이터를 입력 결과를 평가 (예측/분류의 정확도 등) 결과를 개선하기 위해 모델을 수정 (모델 내부 Parameter 수정 등) Model\u0026rsquo;s Capacity 2번 모델은 3번 모델보다 오차가 크지만 새로운 데이터가 생겼을 때 비슷하게 예측 가능 3번 모델은 오차가 가장 적지만 새로운 데이터가 생겼을 때 오차가 매우 커질 수 있음 3번 모델과 같은 Overfitting(과적합)이 발생하기 전에 학습을 멈춤 Cross Validation 새로운 데이터들에 대해서도 좋은 결과를 내게 하기 위해 데이터를 3개 그룹으로 나눠 학습 60%의 Training Data로 모델을 학습 20%의 Validation Data로 모델을 최적화/선택 20%의 Test Data로 모델을 평가 데이터를 분리하는 비율은 모델에 따라 달라짐 K-Fold Cross Validation 후보 모델 간 비교 및 선택을 위한 알고리즘 Training Data를 K 등분하고 그 중 하나를 Validation Data로 설정 K 값은 자체적으로 결정하며 보통 10-Fold 사용 (시간이 없으면 5-Fold) 머신러닝에서 K는 주로 사용자가 결정하는 상수 Stratified: 층화 표집 방법, 데이터의 분류 별 비율이 다르면 K-Fold 조각 안에서 비율을 유지시킴 10-Fold 학습 과정 데이터를 80%의 Training Data와 20%의 Test Data로 나누고 Training Data를 10등분","keywords":["AI SCHOOL","멋쟁이사자처럼","코드라이언","Machine Learning"],"articleBody":"인공지능 Intelligent Agents를 만드는 것 주변 환경들을 인식하고 원하는 행동을 취하여 목표를 성취하는 것 Artificial Narrow Intelligence 제한된 기능만 수행할 수 있는 인공지능 weak AI Artificial General Intelligence 사람만큼 다양한 분야에서 기능을 수행할 수 있는 인공지능 strong AI Artificial Super Intelligence 모든 분야에서 사람보다 뛰어난 인공지능 모델 데이터를 가장 잘 설명할 수 있는 함수 (y = ax + b) 모델에서 θ는 Parameter(가중치, Weight) 의미 모델에서 h(x)는 Hypotheses(가설) 의미 모델에서 b는 Bias(편향, 보정치) 의미 머신러닝 어떠한 과제를 해결하는 과정에서 특정한 평가 기준을 바탕으로 학습의 경험을 쌓는 프로그램 머신러닝 분류 Supervised 입력값에 대한 정답을 예측하기 위해 학습 데이터와 정답이 같이 존재 회귀(Regression): 결과가 실수 영역 전체에서 나타남 분류(Classification): 결과가 특정 분류에 해당하는 불연속값으로 나타남 ex) 주식 가격 예측, 이미지 인식 등 Unsupervised 입력값 속에 숨어있는 규칙성을 찾기 위해 학습 정답이 없는 데이터를 주고 비슷한 집단을 분류 ex) 고객군 분류, 장바구니 분석(Association Rule) 등 Reinforcement Trial \u0026 Error를 통한 학습 최종적으로 얻게 될 기대 보상을 최대화하기 위한 행동 선택 정책 학습 각 상태에 대해 결정한 행동을 통해 환경으로부터 받는 보상을 학습 ex) 로봇 제어, 공정 최적화 등 Automated ML 어떤 모델(함수, 알고리즘)을 써야할지를 컴퓨터가 알아서 정하게 함 인공신경망 레이어의 범위, 후보 등을 정해놓고 그 안에서 가장 좋은 조합을 찾음 ex) AutoML Tables (행의 수가 1000건이 넘어야하는 제약) 학습 데이터를 가장 잘 설명하는 방법을 찾는 과정 데이터에 맞는 모델을 찾는 과정 (= Model Fitting) 실제 정답과 예측 결과 사이의 오차(Loss, Cost, Error)를 줄여나가는 최적화 과정 학습 과정 초기 모델에 데이터를 입력 결과를 평가 (예측/분류의 정확도 등) 결과를 개선하기 위해 모델을 수정 (모델 내부 Parameter 수정 등) Model’s Capacity 2번 모델은 3번 모델보다 오차가 크지만 새로운 데이터가 생겼을 때 비슷하게 예측 가능 3번 모델은 오차가 가장 적지만 새로운 데이터가 생겼을 때 오차가 매우 커질 수 있음 3번 모델과 같은 Overfitting(과적합)이 발생하기 전에 학습을 멈춤 Cross Validation 새로운 데이터들에 대해서도 좋은 결과를 내게 하기 위해 데이터를 3개 그룹으로 나눠 학습 60%의 Training Data로 모델을 학습 20%의 Validation Data로 모델을 최적화/선택 20%의 Test Data로 모델을 평가 데이터를 분리하는 비율은 모델에 따라 달라짐 K-Fold Cross Validation 후보 모델 간 비교 및 선택을 위한 알고리즘 Training Data를 K 등분하고 그 중 하나를 Validation Data로 설정 K 값은 자체적으로 결정하며 보통 10-Fold 사용 (시간이 없으면 5-Fold) 머신러닝에서 K는 주로 사용자가 결정하는 상수 Stratified: 층화 표집 방법, 데이터의 분류 별 비율이 다르면 K-Fold 조각 안에서 비율을 유지시킴 10-Fold 학습 과정 데이터를 80%의 Training Data와 20%의 Test Data로 나누고 Training Data를 10등분\nPhase 1. Training Data(0:9) + Validation Data(TD 9)를 사용해 점수 측정\nPhase 2. Training Data(0:8,9) + Validation Data(TD 8)를 사용해 점수 측정\n. . .\nPhase 10. Training Data(1:10) + Validation Data(TD 0)를 사용해 점수 측정\n마지막으로 Training Data 전체를 학습하고 Test Data로 검증\nScikit-learn 파이썬으로 전통적인 머신 러닝 알고리즘들을 구현한 오픈 소스 라이브러리 다른 라이브러리들과의 호환성이 좋음 (Numpy, Pandas, Matplotlib 등) 머신러닝 학습 과정 데이터셋 불러오기 1 sklearn.load_[DATA]() Train/Test set으로 데이터 나눔 1 sklearn.model_selection.train_test_split(X, Y, test_size) 모델 객체 생성 1 2 3 4 5 6 sklearn.linear_model.LinearRegression() sklearn.linear_model.LogisticRegression() sklearn.neighbors.KNeighborsClassifier(n_neighbors) sklearn.cluster.KMeans(n_clusters) sklearn.decomposition.PCA(n_components) sklearn.svm.SVC(kernel, C, gamma) 모델 학습 시키기 1 model.fit(train_X, train_Y) 모델로 새로운 데이터 예측 (Scaler를 적용했으면 새로운 데이터에도 적용) 1 2 3 4 5 6 model.predict(test_X) model.predict_proba(test_X) sklearn.metrics.mean_squared_error(predicted_Y, test_Y) sklearn.metrics.accuracy_score(predicted_Y, test_Y) sklearn.metrics.precision_score sklearn.metrics.recall_score 머신러닝 분류 기준 Choosing the right estimator Feature Normalization Numeric Column Min-Max Algorithm Standardization Categorical Column One-Hot Encoding, One-Hot Vector 열과 목록 개수만큼 0으로 채워진 행렬을 만들고 값이 해당하는 위치에 1을 표시 범주형 데이터(카테고리)의 숫자가 크고 작음에 관계없이 카테고리의 위치값만을 판단 Supervised Algorithm Linear Regression (선형 회귀) 종속 변수 y와 독립 변수 x 사이의 선형 상관 관계를 모델링하는 회귀분석 기법 Logistic Regression (로지스틱 회귀) 이진 분류(0 또는 1) 문제를 해결하기 위한 모델 ex) 스팸 메일 분류, 질병 양성/음성 분류 등 Gradient Boosting Regression (XG Boost) 대용량 분산 처리를 위한 Gradient Boosting 라이브러리 ex) 테니스를 쳤던 과거 데이터를 보고 날씨 정보를 이용해 의사결정 K-Nearest Neightbor Algorithm (KNN) 기존의 가까운 이웃 데이터를 살펴 새로운 데이터를 분류하는 알고리즘 Kernel Support Vector Machine (KSVM) 데이터를 분류하는 Margin을 최대화하는 결정 경계를 찾는 기법 Unsupervised Algorithm K-Means Algorithm 데이터를 K개의 클러스터로 분류하는 알고리즘 Principal Component Analysis 차원 축소를 통해 최소 차원의 정보로 원래 차원의 정보를 모사하는 알고리즘 Model Saving \u0026 Loading Model Saving 1 2 3 import joblib joblib.dump(model, 'model_v1.pkl', compress=True) Model Loading 1 2 3 import joblib model_loaded = joblib.load('model_v1.pkl') ","wordCount":"688","inLanguage":"en","datePublished":"2022-04-13T16:31:00+09:00","dateModified":"2022-04-13T16:31:00+09:00","author":{"@type":"Person","name":"minyeamer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://minyeamer.github.io/blog/aischool-06-00-machine-learning/"},"publisher":{"@type":"Organization","name":"Minystory","logo":{"@type":"ImageObject","url":"https://minyeamer.github.io/img/favicons/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://minyeamer.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://minyeamer.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://minyeamer.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://minyeamer.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://minyeamer.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://minyeamer.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://minyeamer.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://minyeamer.github.io/post/>Posts</a></div><h1 class=post-title>[AI SCHOOL 5기] 머신 러닝</h1><div class=post-meta><span title='2022-04-13 16:31:00 +0900 KST'>April 13, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;688 words&nbsp;·&nbsp;minyeamer&nbsp;|&nbsp;<a href=https://github.com/minyeamer/til/edit/main/study/ai-school/06-machine-learning/00-machine-learning.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>&nbsp;Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#인공지능>인공지능</a><ul><li><a href=#artificial-narrow-intelligence>Artificial Narrow Intelligence</a></li><li><a href=#artificial-general-intelligence>Artificial General Intelligence</a></li><li><a href=#artificial-super-intelligence>Artificial Super Intelligence</a></li></ul></li><li><a href=#모델>모델</a></li><li><a href=#머신러닝>머신러닝</a><ul><li><a href=#머신러닝-분류>머신러닝 분류</a></li><li><a href=#supervised>Supervised</a></li><li><a href=#unsupervised>Unsupervised</a></li><li><a href=#reinforcement>Reinforcement</a></li><li><a href=#automated-ml>Automated ML</a></li></ul></li><li><a href=#학습>학습</a><ul><li><a href=#학습-과정>학습 과정</a></li><li><a href=#models-capacity>Model&rsquo;s Capacity</a></li><li><a href=#cross-validation>Cross Validation</a></li><li><a href=#k-fold-cross-validation>K-Fold Cross Validation</a></li><li><a href=#10-fold-학습-과정>10-Fold 학습 과정</a></li></ul></li><li><a href=#scikit-learn>Scikit-learn</a><ul><li><a href=#머신러닝-학습-과정>머신러닝 학습 과정</a></li><li><a href=#머신러닝-분류-기준>머신러닝 분류 기준</a></li></ul></li><li><a href=#feature-normalization>Feature Normalization</a><ul><li><a href=#numeric-column>Numeric Column</a></li><li><a href=#categorical-column>Categorical Column</a></li></ul></li><li><a href=#supervised-algorithm>Supervised Algorithm</a><ul><li><a href=#linear-regression-선형-회귀httpsminyeamergithubioblogaischool-06-01-linear-regression><a href=https://minyeamer.github.io/blog/aischool-06-01-linear-regression/>Linear Regression (선형 회귀)</a></a></li><li><a href=#logistic-regression-로지스틱-회귀httpsminyeamergithubioblogaishcool-06-02-logistic-regression><a href=https://minyeamer.github.io/blog/aishcool-06-02-logistic-regression/>Logistic Regression (로지스틱 회귀)</a></a></li><li><a href=#gradient-boosting-regression-xg-boosthttpsminyeamergithubioblogaishcool-06-03-gradient-boosting><a href=https://minyeamer.github.io/blog/aishcool-06-03-gradient-boosting/>Gradient Boosting Regression (XG Boost)</a></a></li><li><a href=#k-nearest-neightbor-algorithm-knnhttpsminyeamergithubioblogaishcool-06-04-knn><a href=https://minyeamer.github.io/blog/aishcool-06-04-knn/>K-Nearest Neightbor Algorithm (KNN)</a></a></li><li><a href=#kernel-support-vector-machine-ksvmhttpsminyeamergithubioblogaishcool-06-05-kernelized-svm><a href=https://minyeamer.github.io/blog/aishcool-06-05-kernelized-svm/>Kernel Support Vector Machine (KSVM)</a></a></li></ul></li><li><a href=#unsupervised-algorithm>Unsupervised Algorithm</a><ul><li><a href=#k-means-algorithmhttpsminyeamergithubioblogaishcool-06-06-k-means><a href=https://minyeamer.github.io/blog/aishcool-06-06-k-means/>K-Means Algorithm</a></a></li><li><a href=#principal-component-analysishttpsminyeamergithubioblogaishcool-06-07-pca><a href=https://minyeamer.github.io/blog/aishcool-06-07-pca/>Principal Component Analysis</a></a></li></ul></li><li><a href=#model-saving--loading>Model Saving & Loading</a><ul><li><a href=#model-saving>Model Saving</a></li><li><a href=#model-loading>Model Loading</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h1 id=인공지능>인공지능<a hidden class=anchor aria-hidden=true href=#인공지능>#</a></h1><ul><li>Intelligent Agents를 만드는 것</li><li>주변 환경들을 인식하고 원하는 행동을 취하여 목표를 성취하는 것</li></ul><h2 id=artificial-narrow-intelligence>Artificial Narrow Intelligence<a hidden class=anchor aria-hidden=true href=#artificial-narrow-intelligence>#</a></h2><ul><li>제한된 기능만 수행할 수 있는 인공지능</li><li>weak AI</li></ul><h2 id=artificial-general-intelligence>Artificial General Intelligence<a hidden class=anchor aria-hidden=true href=#artificial-general-intelligence>#</a></h2><ul><li>사람만큼 다양한 분야에서 기능을 수행할 수 있는 인공지능</li><li>strong AI</li></ul><h2 id=artificial-super-intelligence>Artificial Super Intelligence<a hidden class=anchor aria-hidden=true href=#artificial-super-intelligence>#</a></h2><ul><li>모든 분야에서 사람보다 뛰어난 인공지능</li></ul><hr><h1 id=모델>모델<a hidden class=anchor aria-hidden=true href=#모델>#</a></h1><ul><li>데이터를 가장 잘 설명할 수 있는 함수 (<code>y = ax + b</code>)</li><li>모델에서 <code>θ</code>는 Parameter(가중치, Weight) 의미</li><li>모델에서 <code>h(x)</code>는 Hypotheses(가설) 의미</li><li>모델에서 <code>b</code>는 Bias(편향, 보정치) 의미</li></ul><hr><h1 id=머신러닝>머신러닝<a hidden class=anchor aria-hidden=true href=#머신러닝>#</a></h1><ul><li>어떠한 과제를 해결하는 과정에서 특정한 평가 기준을 바탕으로 학습의 경험을 쌓는 프로그램</li></ul><h2 id=머신러닝-분류>머신러닝 분류<a hidden class=anchor aria-hidden=true href=#머신러닝-분류>#</a></h2><p><img loading=lazy src="https://github.com/minyeamer/til/blob/main/.media/study/ai-school/06-machine-learning/00-machine-learning/51p.png?raw=true" alt=51p></p><h2 id=supervised>Supervised<a hidden class=anchor aria-hidden=true href=#supervised>#</a></h2><ul><li>입력값에 대한 정답을 예측하기 위해 학습</li><li>데이터와 정답이 같이 존재</li><li><strong>회귀(Regression)</strong>: 결과가 실수 영역 전체에서 나타남</li><li><strong>분류(Classification)</strong>: 결과가 특정 분류에 해당하는 불연속값으로 나타남</li><li>ex) 주식 가격 예측, 이미지 인식 등</li></ul><h2 id=unsupervised>Unsupervised<a hidden class=anchor aria-hidden=true href=#unsupervised>#</a></h2><ul><li>입력값 속에 숨어있는 규칙성을 찾기 위해 학습</li><li>정답이 없는 데이터를 주고 비슷한 집단을 분류</li><li>ex) 고객군 분류, 장바구니 분석(Association Rule) 등</li></ul><h2 id=reinforcement>Reinforcement<a hidden class=anchor aria-hidden=true href=#reinforcement>#</a></h2><ul><li>Trial & Error를 통한 학습</li><li>최종적으로 얻게 될 기대 보상을 최대화하기 위한 행동 선택 정책 학습</li><li>각 상태에 대해 결정한 행동을 통해 환경으로부터 받는 보상을 학습</li><li>ex) 로봇 제어, 공정 최적화 등</li></ul><h2 id=automated-ml>Automated ML<a hidden class=anchor aria-hidden=true href=#automated-ml>#</a></h2><ul><li>어떤 모델(함수, 알고리즘)을 써야할지를 컴퓨터가 알아서 정하게 함</li><li>인공신경망 레이어의 범위, 후보 등을 정해놓고 그 안에서 가장 좋은 조합을 찾음</li><li>ex) AutoML Tables (행의 수가 1000건이 넘어야하는 제약)</li></ul><hr><h1 id=학습>학습<a hidden class=anchor aria-hidden=true href=#학습>#</a></h1><ul><li>데이터를 가장 잘 설명하는 방법을 찾는 과정</li><li>데이터에 맞는 모델을 찾는 과정 (= Model Fitting)</li><li>실제 정답과 예측 결과 사이의 오차(Loss, Cost, Error)를 줄여나가는 최적화 과정</li></ul><h2 id=학습-과정>학습 과정<a hidden class=anchor aria-hidden=true href=#학습-과정>#</a></h2><ol><li>초기 모델에 데이터를 입력</li><li>결과를 평가 (예측/분류의 정확도 등)</li><li>결과를 개선하기 위해 모델을 수정 (모델 내부 Parameter 수정 등)</li></ol><h2 id=models-capacity>Model&rsquo;s Capacity<a hidden class=anchor aria-hidden=true href=#models-capacity>#</a></h2><p><img loading=lazy src="https://github.com/minyeamer/til/blob/main/.media/study/ai-school/06-machine-learning/00-machine-learning/44p.png?raw=true" alt=44p></p><ul><li>2번 모델은 3번 모델보다 오차가 크지만 새로운 데이터가 생겼을 때 비슷하게 예측 가능</li><li>3번 모델은 오차가 가장 적지만 새로운 데이터가 생겼을 때 오차가 매우 커질 수 있음</li><li>3번 모델과 같은 Overfitting(과적합)이 발생하기 전에 학습을 멈춤</li></ul><h2 id=cross-validation>Cross Validation<a hidden class=anchor aria-hidden=true href=#cross-validation>#</a></h2><ul><li>새로운 데이터들에 대해서도 좋은 결과를 내게 하기 위해 데이터를 3개 그룹으로 나눠 학습</li><li>60%의 Training Data로 모델을 학습</li><li>20%의 Validation Data로 모델을 최적화/선택</li><li>20%의 Test Data로 모델을 평가</li><li>데이터를 분리하는 비율은 모델에 따라 달라짐</li></ul><h2 id=k-fold-cross-validation>K-Fold Cross Validation<a hidden class=anchor aria-hidden=true href=#k-fold-cross-validation>#</a></h2><ul><li>후보 모델 간 비교 및 선택을 위한 알고리즘</li><li>Training Data를 <strong>K</strong> 등분하고 그 중 하나를 Validation Data로 설정</li><li><strong>K</strong> 값은 자체적으로 결정하며 보통 10-Fold 사용 (시간이 없으면 5-Fold)</li><li>머신러닝에서 <strong>K</strong>는 주로 사용자가 결정하는 상수</li><li><strong>Stratified</strong>: 층화 표집 방법, 데이터의 분류 별 비율이 다르면 K-Fold 조각 안에서 비율을 유지시킴</li></ul><h2 id=10-fold-학습-과정>10-Fold 학습 과정<a hidden class=anchor aria-hidden=true href=#10-fold-학습-과정>#</a></h2><blockquote><p>데이터를 80%의 Training Data와 20%의 Test Data로 나누고 Training Data를 10등분<br>Phase 1. Training Data(0:9) + Validation Data(TD 9)를 사용해 점수 측정<br>Phase 2. Training Data(0:8,9) + Validation Data(TD 8)를 사용해 점수 측정<br>. . .<br>Phase 10. Training Data(1:10) + Validation Data(TD 0)를 사용해 점수 측정<br>마지막으로 Training Data 전체를 학습하고 Test Data로 검증</p></blockquote><hr><h1 id=scikit-learn>Scikit-learn<a hidden class=anchor aria-hidden=true href=#scikit-learn>#</a></h1><ul><li>파이썬으로 전통적인 머신 러닝 알고리즘들을 구현한 오픈 소스 라이브러리</li><li>다른 라이브러리들과의 호환성이 좋음 (Numpy, Pandas, Matplotlib 등)</li></ul><h2 id=머신러닝-학습-과정>머신러닝 학습 과정<a hidden class=anchor aria-hidden=true href=#머신러닝-학습-과정>#</a></h2><ol><li>데이터셋 불러오기</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>load_</span><span class=p>[</span><span class=n>DATA</span><span class=p>]()</span>
</span></span></code></pre></td></tr></table></div></div><ol start=2><li>Train/Test set으로 데이터 나눔</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>model_selection</span><span class=o>.</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ol start=3><li>모델 객체 생성</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>linear_model</span><span class=o>.</span><span class=n>LinearRegression</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>linear_model</span><span class=o>.</span><span class=n>LogisticRegression</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>neighbors</span><span class=o>.</span><span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>cluster</span><span class=o>.</span><span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>decomposition</span><span class=o>.</span><span class=n>PCA</span><span class=p>(</span><span class=n>n_components</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=p>,</span> <span class=n>C</span><span class=p>,</span> <span class=n>gamma</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ol start=4><li>모델 학습 시키기</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_X</span><span class=p>,</span> <span class=n>train_Y</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ol start=5><li>모델로 새로운 데이터 예측 (Scaler를 적용했으면 새로운 데이터에도 적용)</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>test_X</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>test_X</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>predicted_Y</span><span class=p>,</span> <span class=n>test_Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>accuracy_score</span><span class=p>(</span><span class=n>predicted_Y</span><span class=p>,</span> <span class=n>test_Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>precision_score</span>
</span></span><span class=line><span class=cl><span class=n>sklearn</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>recall_score</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=머신러닝-분류-기준>머신러닝 분류 기준<a hidden class=anchor aria-hidden=true href=#머신러닝-분류-기준>#</a></h2><ul><li><a href=https://scikit-learn.org/stable/tutorial/machine_learning_map/ target=_blank rel=noopener>Choosing the right estimator</a></li></ul><p><img loading=lazy src="https://github.com/minyeamer/til/blob/main/.media/study/ai-school/06-machine-learning/00-machine-learning/estimator.png?raw=true" alt=estimator></p><hr><h1 id=feature-normalization>Feature Normalization<a hidden class=anchor aria-hidden=true href=#feature-normalization>#</a></h1><h2 id=numeric-column>Numeric Column<a hidden class=anchor aria-hidden=true href=#numeric-column>#</a></h2><ul><li>Min-Max Algorithm</li><li>Standardization</li></ul><h2 id=categorical-column>Categorical Column<a hidden class=anchor aria-hidden=true href=#categorical-column>#</a></h2><ul><li>One-Hot Encoding, One-Hot Vector</li><li>열과 목록 개수만큼 0으로 채워진 행렬을 만들고 값이 해당하는 위치에 1을 표시</li><li>범주형 데이터(카테고리)의 숫자가 크고 작음에 관계없이 카테고리의 위치값만을 판단</li></ul><hr><h1 id=supervised-algorithm>Supervised Algorithm<a hidden class=anchor aria-hidden=true href=#supervised-algorithm>#</a></h1><h2 id=linear-regression-선형-회귀httpsminyeamergithubioblogaischool-06-01-linear-regression><a href=https://minyeamer.github.io/blog/aischool-06-01-linear-regression/ target=_blank rel=noopener>Linear Regression (선형 회귀)</a><a hidden class=anchor aria-hidden=true href=#linear-regression-선형-회귀httpsminyeamergithubioblogaischool-06-01-linear-regression>#</a></h2><ul><li>종속 변수 y와 독립 변수 x 사이의 선형 상관 관계를 모델링하는 회귀분석 기법</li></ul><h2 id=logistic-regression-로지스틱-회귀httpsminyeamergithubioblogaishcool-06-02-logistic-regression><a href=https://minyeamer.github.io/blog/aishcool-06-02-logistic-regression/ target=_blank rel=noopener>Logistic Regression (로지스틱 회귀)</a><a hidden class=anchor aria-hidden=true href=#logistic-regression-로지스틱-회귀httpsminyeamergithubioblogaishcool-06-02-logistic-regression>#</a></h2><ul><li>이진 분류(0 또는 1) 문제를 해결하기 위한 모델</li><li>ex) 스팸 메일 분류, 질병 양성/음성 분류 등</li></ul><h2 id=gradient-boosting-regression-xg-boosthttpsminyeamergithubioblogaishcool-06-03-gradient-boosting><a href=https://minyeamer.github.io/blog/aishcool-06-03-gradient-boosting/ target=_blank rel=noopener>Gradient Boosting Regression (XG Boost)</a><a hidden class=anchor aria-hidden=true href=#gradient-boosting-regression-xg-boosthttpsminyeamergithubioblogaishcool-06-03-gradient-boosting>#</a></h2><ul><li>대용량 분산 처리를 위한 Gradient Boosting 라이브러리</li><li>ex) 테니스를 쳤던 과거 데이터를 보고 날씨 정보를 이용해 의사결정</li></ul><h2 id=k-nearest-neightbor-algorithm-knnhttpsminyeamergithubioblogaishcool-06-04-knn><a href=https://minyeamer.github.io/blog/aishcool-06-04-knn/ target=_blank rel=noopener>K-Nearest Neightbor Algorithm (KNN)</a><a hidden class=anchor aria-hidden=true href=#k-nearest-neightbor-algorithm-knnhttpsminyeamergithubioblogaishcool-06-04-knn>#</a></h2><ul><li>기존의 가까운 이웃 데이터를 살펴 새로운 데이터를 분류하는 알고리즘</li></ul><h2 id=kernel-support-vector-machine-ksvmhttpsminyeamergithubioblogaishcool-06-05-kernelized-svm><a href=https://minyeamer.github.io/blog/aishcool-06-05-kernelized-svm/ target=_blank rel=noopener>Kernel Support Vector Machine (KSVM)</a><a hidden class=anchor aria-hidden=true href=#kernel-support-vector-machine-ksvmhttpsminyeamergithubioblogaishcool-06-05-kernelized-svm>#</a></h2><ul><li>데이터를 분류하는 Margin을 최대화하는 결정 경계를 찾는 기법</li></ul><hr><h1 id=unsupervised-algorithm>Unsupervised Algorithm<a hidden class=anchor aria-hidden=true href=#unsupervised-algorithm>#</a></h1><h2 id=k-means-algorithmhttpsminyeamergithubioblogaishcool-06-06-k-means><a href=https://minyeamer.github.io/blog/aishcool-06-06-k-means/ target=_blank rel=noopener>K-Means Algorithm</a><a hidden class=anchor aria-hidden=true href=#k-means-algorithmhttpsminyeamergithubioblogaishcool-06-06-k-means>#</a></h2><ul><li>데이터를 K개의 클러스터로 분류하는 알고리즘</li></ul><h2 id=principal-component-analysishttpsminyeamergithubioblogaishcool-06-07-pca><a href=https://minyeamer.github.io/blog/aishcool-06-07-pca/ target=_blank rel=noopener>Principal Component Analysis</a><a hidden class=anchor aria-hidden=true href=#principal-component-analysishttpsminyeamergithubioblogaishcool-06-07-pca>#</a></h2><ul><li>차원 축소를 통해 최소 차원의 정보로 원래 차원의 정보를 모사하는 알고리즘</li></ul><hr><h1 id=model-saving--loading>Model Saving & Loading<a hidden class=anchor aria-hidden=true href=#model-saving--loading>#</a></h1><h2 id=model-saving>Model Saving<a hidden class=anchor aria-hidden=true href=#model-saving>#</a></h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s1>&#39;model_v1.pkl&#39;</span><span class=p>,</span> <span class=n>compress</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=model-loading>Model Loading<a hidden class=anchor aria-hidden=true href=#model-loading>#</a></h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_loaded</span> <span class=o>=</span> <span class=n>joblib</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;model_v1.pkl&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://minyeamer.github.io/tags/ai-school/>AI SCHOOL</a></li><li><a href=https://minyeamer.github.io/tags/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/>멋쟁이사자처럼</a></li><li><a href=https://minyeamer.github.io/tags/%EC%BD%94%EB%93%9C%EB%9D%BC%EC%9D%B4%EC%96%B8/>코드라이언</a></li><li><a href=https://minyeamer.github.io/tags/machine-learning/>Machine Learning</a></li></ul><nav class=paginav><a class=prev href=https://minyeamer.github.io/blog/aischool-06-02-logistic-regression/><span class=title>« Prev</span><br><span>[AI SCHOOL 5기] 머신 러닝 실습 - 로지스틱 회귀</span></a>
<a class=next href=https://minyeamer.github.io/blog/aischool-06-01-linear-regression/><span class=title>Next »</span><br><span>[AI SCHOOL 5기] 머신 러닝 실습 - 선형 회귀</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share [AI SCHOOL 5기] 머신 러닝 on twitter" href="https://twitter.com/intent/tweet/?text=%5bAI%20SCHOOL%205%ea%b8%b0%5d%20%eb%a8%b8%ec%8b%a0%20%eb%9f%ac%eb%8b%9d&url=https%3a%2f%2fminyeamer.github.io%2fblog%2faischool-06-00-machine-learning%2f&hashtags=AISCHOOL%2c%eb%a9%8b%ec%9f%81%ec%9d%b4%ec%82%ac%ec%9e%90%ec%b2%98%eb%9f%bc%2c%ec%bd%94%eb%93%9c%eb%9d%bc%ec%9d%b4%ec%96%b8%2cMachineLearning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [AI SCHOOL 5기] 머신 러닝 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fminyeamer.github.io%2fblog%2faischool-06-00-machine-learning%2f&title=%5bAI%20SCHOOL%205%ea%b8%b0%5d%20%eb%a8%b8%ec%8b%a0%20%eb%9f%ac%eb%8b%9d&summary=%5bAI%20SCHOOL%205%ea%b8%b0%5d%20%eb%a8%b8%ec%8b%a0%20%eb%9f%ac%eb%8b%9d&source=https%3a%2f%2fminyeamer.github.io%2fblog%2faischool-06-00-machine-learning%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [AI SCHOOL 5기] 머신 러닝 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fminyeamer.github.io%2fblog%2faischool-06-00-machine-learning%2f&title=%5bAI%20SCHOOL%205%ea%b8%b0%5d%20%eb%a8%b8%ec%8b%a0%20%eb%9f%ac%eb%8b%9d"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [AI SCHOOL 5기] 머신 러닝 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fminyeamer.github.io%2fblog%2faischool-06-00-machine-learning%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [AI SCHOOL 5기] 머신 러닝 on whatsapp" href="https://api.whatsapp.com/send?text=%5bAI%20SCHOOL%205%ea%b8%b0%5d%20%eb%a8%b8%ec%8b%a0%20%eb%9f%ac%eb%8b%9d%20-%20https%3a%2f%2fminyeamer.github.io%2fblog%2faischool-06-00-machine-learning%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [AI SCHOOL 5기] 머신 러닝 on telegram" href="https://telegram.me/share/url?text=%5bAI%20SCHOOL%205%ea%b8%b0%5d%20%eb%a8%b8%ec%8b%a0%20%eb%9f%ac%eb%8b%9d&url=https%3a%2f%2fminyeamer.github.io%2fblog%2faischool-06-00-machine-learning%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=minyeamer/til issue-term=pathname label=comments theme=preferred-color-scheme crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2022 <a href=https://minyeamer.github.io/>Minystory</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>