<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=keywords content="DACON,NLP,텍스트 분류,감정 분석,KoELECTRA,RoBERTa,데이터 증강,앙상블,역번역,NLPAUG,쇼핑몰 리뷰"><meta name=description content="쇼핑몰 리뷰 텍스트로 평점을 예측하는 NLP 대회 참가 후기. 역번역과 NLPAUG를 활용한 데이터 증강, KoELECTRA와 RoBERTa 모델 비교 실험, 그리고 …"><meta name=author content="minyeamer"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><link rel=canonical href=https://minyeamer.github.io/blog/dacon-shop-review/><link rel=icon href=https://minyeamer.github.io/images/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://minyeamer.github.io/images/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://minyeamer.github.io/images/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><link rel=mask-icon href=https://minyeamer.github.io/images/favicons/apple-touch-icon.png><meta name=google-site-verification content="u1tWcHmHUZWfFT1cHaku6sqU-bK40N3WLR-C-4VUWN0"><meta name=naver-site-verification content="6eaf8e9da1a6104780f056f1a7797fe5a3a5a0da"><meta property="og:title" content="DACON 쇼핑몰 리뷰 평점 분류 - KoELECTRA와 RoBERTa 앙상블로 2위 달성"><meta property="og:description" content="쇼핑몰 리뷰 텍스트로 평점을 예측하는 NLP 대회 참가 후기. 역번역과 NLPAUG를 활용한 데이터 증강, KoELECTRA와 RoBERTa 모델 비교 실험, 그리고 …"><meta property="og:type" content="article"><meta property="og:url" content="https://minyeamer.github.io/blog/dacon-shop-review/"><meta property="og:image" content="https://dl.dropboxusercontent.com/scl/fi/ur1r3hzxm11trh1p63y4o/shop-review-00-cover.webp?rlkey=f2nnfvwif6byhu0lbvb6bd0sh&amp;dl=0"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-08-22T15:06:20+09:00"><meta property="article:modified_time" content="2022-08-22T15:06:20+09:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dl.dropboxusercontent.com/scl/fi/ur1r3hzxm11trh1p63y4o/shop-review-00-cover.webp?rlkey=f2nnfvwif6byhu0lbvb6bd0sh&amp;dl=0"><meta name=twitter:title content="DACON 쇼핑몰 리뷰 평점 분류 - KoELECTRA와 RoBERTa 앙상블로 2위 달성"><meta name=twitter:description content="쇼핑몰 리뷰 텍스트로 평점을 예측하는 NLP 대회 참가 후기. 역번역과 NLPAUG를 활용한 데이터 증강, KoELECTRA와 RoBERTa 모델 비교 실험, 그리고 …"><meta name=twitter:site content="@https://x.com/minyeamer"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://minyeamer.github.io/posts/"},{"@type":"ListItem","position":2,"name":"DACON 쇼핑몰 리뷰 평점 분류 - KoELECTRA와 RoBERTa 앙상블로 2위 달성","item":"https://minyeamer.github.io/blog/dacon-shop-review/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"DACON 쇼핑몰 리뷰 평점 분류 - KoELECTRA와 RoBERTa 앙상블로 2위 달성","name":"DACON 쇼핑몰 리뷰 평점 분류 - KoELECTRA와 RoBERTa 앙상블로 2위 달성","description":"쇼핑몰 리뷰 텍스트로 평점을 예측하는 NLP 대회 참가 후기. 역번역과 NLPAUG를 활용한 데이터 증강, KoELECTRA와 RoBERTa 모델 비교 실험, 그리고 hard-voting 앙상블을 통해 accuracy 0.7116으로 550팀 중 2위를 달성한 과정을 공유합니다.\n","keywords":["DACON","NLP","텍스트 분류","감정 분석","KoELECTRA","RoBERTa","데이터 증강","앙상블","역번역","NLPAUG","쇼핑몰 리뷰"],"articleBody":" 쇼핑몰 리뷰 평점 분류 AI 해커톤 출처 : DACON - Data Science Competition dacon.io Introduction # 쇼핑몰에서 상품을 고르는데 있어서 다른 사람들의 리뷰와 평점을 참고하게 되는데, 상품 리뷰 텍스트와 평점 사이에 어떤 관계가 있는지, 리뷰 텍스트만으로 평점을 예측가능한지에 대해 실험합니다. 1점, 2점, 4점, 5점으로 분류된 평점 별로 워드 클라우드를 활용해 빈도수가 많은 단어를 시각화해보고, 다중 분류 작업을 수행하는 언어 모델을 학습시킨 결과를 비교할 계획으로 프로젝트 진행합니다. 평점 별 불균형이 존재해 F1-Score로 평가하는 것이 이상적이라 판단하지만, 대회의 판단 기준에 맞게 Accuracy를 활용하고, 전체 테스트 데이터 중 50%에 대한 점수를 지표로 활용합니다. Fine-tuning된 KoELECTRA 및 RoBERTa 모델에 대한 예측 결과를 hard-voting하여 accuracy 기준 0.7116 점으로 550팀 중 2위에 위치했습니다. Private 2nd | 0.7116 | KoELECTAR+RoBERTa | Hard-Voting 알고리즘 | NLP | 분류 | 리뷰 | Accuracy dacon.io Data # 쇼핑몰 리뷰 데이터 샘플 아이디(id), 쇼핑몰 리뷰 텍스트(reviews), 상품 평점(target)으로 구성됩니다. 총 25000개의 행에 대해서, 각각의 리뷰 텍스트에 1, 2, 4, 5 중 하나의 평점이 라벨링된 구조입니다. EDA # 토큰화된 단어를 워드 클라우드로 시각화 했을 때, 낮은 평점의 리뷰에서는 '안'과 같은 부정적인 단어가, 높은 평점의 리뷰에서는 '잘', '좋아요'와 같은 긍정적인 단어가 자주 언급됨이 확인됩니다. '재구매' 단어 역시 높은 평점의 리뷰에서 더욱 많은 비중을 가지고 있으며, '배송' 단어의 경우 모든 평점의 리뷰에서 유사한 비중을 가집니다. 평점 1점 리뷰에서 빈도수가 많은 단어 평점 2점 리뷰에서 빈도수가 많은 단어 평점 4점 리뷰에서 빈도수가 많은 단어 평점 5점 리뷰에서 빈도수가 많은 단어 평점 별 리뷰 수를 시각화 했을 때, 최대 4배에 달하는 불균형이 존재함이 확인됩니다. 데이터 증강을 통해 각 평점 간 비율을 맞춰야할 것이라 판단됩니다. 원본 데이터의 불균형적인 평점 별 리뷰 수 이상적인 평점 별 리뷰 수 Data Augmentation # Reverse Translation # 한글 리뷰를 영어로 번역하고 다시 한글로 역번역하여 의미의 변질없이 문장의 표현만을 변환했습니다. 초기엔 구글 번역 API를 구현한 googletrans 라이브러리로 번역을 시도했지만, '별로'를 'good'으로 변환하는 등 핵심 키워드에 대한 번역이 올바르지 못해 다른 방안을 탐색했습니다. 다음으로, 파파고 크롤링을 활용했을 때, 구글 번역보다 상대적으로 정확도가 높았지만, 단어 번역을 시도하고 결과를 수집하는데 평균 3초의 딜레이가 요구되어 시간적 손실이 컸습니다. 결과적으로, 요청 비용이 발생하는 파파고 API를 통해 역번역을 수행하지만, 크레딧을 활용해 비용을 최소화하고, 크레딧을 초과하는 데이터에 한해 파파고 크롤링을 적용했습니다. NLPAUG # 역번역을 통한 2배의 증가로도 평점 별 리뷰 비율을 맞출 수 없기 때문에, 추가적인 텍스트 증강 기법으로 NLPAUG의 동의어 변환 함수를 활용했습니다. 'red apple'을 'ruby apple'로 대체하는 식으로 문장의 표현을 변환했습니다. 하지만, NLPAUG에서 지원되는 WordNet에 한국어 동의어 데이터가 존재하지 않기 때문에, 해당 기법을 적용하기 위해선 영어로 번역된 문장을 활용해야 했습니다. 평점 5점과 2배 이상의 차이를 보이는 1점과 4점 리뷰에 한해 역번역 전에 NLPAUG를 적용했습니다. hanspell # 데이터에 정규 표현식과 hanspell 맞춤법 검사를 적용해 텍스트 정규화 작업 수행했습니다. 최종적으로 원본 데이터, 증강된 데이터, 각각에 대해 정규화된 데이터의 4가지 학습 데이터를 생성했습니다. Experiments # 서로 다른 모델 간 비교 # 학습 시간의 단축을 위해 ELECTRA 모델을 중심적으로 비교를 시도하였으며, 대회에서 레퍼런스로 공유된 RoBERTa 모델을 비교 대상에 추가했습니다. 한국어를 지원하는 KoELECTRA 모델 중에서 가장 기본적인 v3 모델과 NER 작업에 사용되는 ner 모델, 다른 제작자가 감정 분석에 맞게 fine-tuning한 jaehyeong 모델, 마지막으로 RoBERTa Large 모델을 선정하였고, 동일한 설정으로 2 epoch를 학습한 결과를 비교했습니다. Base 모델은 64, Large 모델엔 32 batch size를 적용하였고(Colab RAM 제한), valid size 0.1, learning rate 1e-5 설정에 대해 2 epochs를 수행하여 accuracy를 평가했습니다. 파라미터 수 때문이지 검증 데이터에 대한 평가 점수에서는 RoBERTa 모델이 앞섰지만, 대회용 테스트 데이터에 대해서는 KoELECTRA jaehyeong 모델과 RoBERTa 모델의 성능이 유사했습니다. 학습 데이터 간 비교 # 앞선 작업에서 KoELECTRA 모델과 RoBERTa 모델 간 성능 차이가 극심하지 않은 것을 확인하고, KoELECTRA 모델 중 가장 성능이 높은 jaehyeong 모델을 기준으로 학습 데이터 간 비교를 수행했습니다. 원본 데이터(vanilla), 증강된 데이터(aug), 정규화된 원본 데이터(cleaned_vanilla), 정규화된 증강 데이터(cleaned_aug)를 각각 활용해 학습한 결과를 비교했습니다. 하이퍼파라미터는 앞선 작업과 동일하며, 2 epochs를 수행하여 accuracy를 평가했습니다. 검증 데이터에 대한 평가 점수는 aug 데이터가 앞섰지만, 대회용 테스트 데이터에 대해서는 aug 데이터의 예측 성능이 가장 낮고 vanilla 데이터가 가장 높았습니다. 테스트 데이터 간 비교 # 서로 다른 학습 데이터에 대해 최적화된 모델 간에 테스트 데이터 별 예측 성능을 비교했습니다. 테스트 데이터는 원본 데이터(vanilla)와 정규화된 데이터(cleaned)로 정의했습니다. 전체 테스트 데이터 중 50%에 대한 점수를 기록하는 대회의 평가 기준을 활용해 각각의 예측 결과 간에 점수를 비교했을 때, 오히려 원본 데이터가 높은 성능을 보이는 것을 확인했습니다. 이러한 결과가 발생한 원인을 파악하기 위해 각각의 데이터에 대해 EDA를 다시 수행했을 때, 가장 많은 데이터 증강이 발생한 평점 4점 리뷰의 단어 비율이 크게 변화함을 확인했습니다. 원본 데이터에서 평점 4점 리뷰의 단어 비율 증강/정규화된 데이터에서 평점 4점 리뷰의 단어 비율 NLPAUG의 동의어 변환이 원인인 것으로 추정되어 다른 증강법을 적용할 필요가 있지만, 데이터 전처리부터 다시 수행하는 것과 모델링을 개선하는 것을 병행할만한 여유가 없다고 판단해 더이상의 데이터 변환 없이 다음 단계인 앙상블로 전환했습니다. Ensemble # KoELECTRA, RoBERTa 모델과 다양한 종류의 데이터를 활용해 예측한 결과를 통해 hard-voting 및 soft-voting 수행했습니다. 원본 데이터를 활용해 학습한 KoELECTRA, RoBERTa 모델의 예측값에 hard-voting을 적용한 결과가 가장 높은 점수를 보였으며, soft-voting은 상대적으로 낮은 점수를 보였습니다. Conclusion # 라벨 간 불균형을 극복하기 위해 역번역, 동의어 변환 등의 다양한 자연어 데이터 증강 기법을 적용했습니다. 각각의 ELECTRA 모델과 RoBERTa Large 모델을 비교했을 때, 파라미터의 수가 가장 많은 RoBERTa 모델의 성능이 앞섰지만 ELECTRA 모델과의 차이가 크지 않았습니다. 모델 경량화를 고려할 경우엔 ELECTRA를 활용하는게 더 유리할 것입니다. 데이터에 따른 성능 변화를 비교하는 과정에서 전처리된 데이터가 원본 데이터보다 낮은 성능을 발생시키는 것을 인지하고 두 데이터를 비교하였을 때 잘못된 전처리로 인해 노이즈가 발생한 것을 확인했습니다. 텍스트 정규화를 수행한 경우가 그렇지 않은 경우보다 낮은 성능을 보이는 경향이 있었고, 이를 통해 비정규화된 텍스트에서 나타나는 말투나 이모티콘 등의 표현이 감정 분석 작업에 적지 않은 영향을 주는 것이라 추측합니다. Post-Project # 자연어 처리에서 활용되는 데이터 증강 기법에 대해 알아볼 수 있는 좋은 기회가 되었습니다. ELECTRA 모델을 활용한 덕분에 짧은 시간 안에 다양한 조건에서 성능을 평가할 수 있었고, 분류 작업 파이프라인을 만드는 과정에서 HuggingFace의 활용법에 대해서도 익힐 수 있게 되었습니다. 하지만, HuggingFace의 경우 너무 간략화된 부분이 많아 PyTorch를 배운다는 목적에는 부합하지 않았고, Dropout과 같은 과적합 방지 기법들을 적용하는데도 어려움을 겪었습니다. 고수준의 라이브러리는 사용하기엔 편리하지만 작업의 복잡도가 증가할수록 제약이 많아짐을 느꼈고, 이를 극복하기 위해 바닥부터 모델링 코드를 짜는 경험의 중요성을 다시 한번 인식합니다. ","wordCount":"961","inLanguage":"en","image":"https:\/\/dl.dropboxusercontent.com\/scl\/fi\/ur1r3hzxm11trh1p63y4o\/shop-review-00-cover.webp?rlkey=f2nnfvwif6byhu0lbvb6bd0sh\u0026dl=0","datePublished":"2022-08-22T15:06:20+09:00","dateModified":"2022-08-22T15:06:20+09:00","author":{"@type":"Person","name":"minyeamer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://minyeamer.github.io/blog/dacon-shop-review/"},"publisher":{"@type":"Person","name":"Minystory","logo":{"@type":"ImageObject","url":"https://minyeamer.github.io/images/favicons/favicon.ico"}}}</script><title>DACON 쇼핑몰 리뷰 평점 분류 - KoELECTRA와 RoBERTa 앙상블로 2위 달성 | Minystory</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://minyeamer.github.io/blog/dacon-shop-review/><link rel=stylesheet href=/book.min.da9f864e1bccfac13510edef0c8dbe217c58d1ba58855d698051f162d9101fc5.css integrity="sha256-2p+GThvM+sE1EO3vDI2+IXxY0bpYhV1pgFHxYtkQH8U=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/search-input.min.428bcd7e442f65fd5910061533a2a4b195358eb46c2b7fd98046f38a3c588934.js integrity="sha256-QovNfkQvZf1ZEAYVM6KksZU1jrRsK3/ZgEbzijxYiTQ=" crossorigin=anonymous></script><link rel=preload href=/search-data.min.abaa44e712e0b03ceed61a2da1d37ba7833b8bbfd4dcfadb9e45df8f0785682d.json as=fetch crossorigin><script>window.SEARCH_DATA_URL="/search-data.min.abaa44e712e0b03ceed61a2da1d37ba7833b8bbfd4dcfadb9e45df8f0785682d.json"</script><script defer src=/search.min.f30f9834d4764fd9751da64098c954d01085f648ba9ca421a3c97582f8c47253.js integrity="sha256-8w+YNNR2T9l1HaZAmMlU0BCF9ki6nKQho8l1gvjEclM=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-BJ8Z9RMBPJ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-BJ8Z9RMBPJ")</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css crossorigin=anonymous><script defer src=/scroll-progress.min.841ade7e507a5f6d59c4e7bf2fe2b2ca034070677ff7957eec55610a024dd776.js integrity="sha256-hBreflB6X21ZxOe/L+KyygNAcGd/95V+7FVhCgJN13Y=" crossorigin=anonymous></script><script defer src=/dark-mode.min.e41c6440ffd9967d6f6a419ff3ce09b862009fe1646ab265f5cb2817d2a508e3.js integrity="sha256-5BxkQP/Zln1vakGf884JuGIAn+FkarJl9csoF9KlCOM=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.9.0/highlightjs-line-numbers.min.js></script><script defer src=/copy-code.min.aaeef965f0b4992e55f976edaecb34a89d414e1791caa18c3f4f4376c6d8b5a8.js integrity="sha256-qu75ZfC0mS5V+Xbtrss0qJ1BTheRyqGMP09DdsbYtag=" crossorigin=anonymous></script><script defer src=/toc-highlightjs.093016f0ef312174ad862fdcf5792e88ab5442bd39beecc38d15643f71ab5c31.min integrity="sha256-CTAW8O8xIXSthi/c9XkuiKtUQr05vuzDjRVkP3GrXDE=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-posts book-layout-post"><div class=scroll-progress><div class=scroll-progress-bar></div></div><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><div class=sidebar-profile><div class=profile-img-wrap><a href=https://minyeamer.github.io/><img src=/images/profile/menu.jpg alt=Profile class=profile-img></a></div><div class=sidebar-social><a href=https://github.com/minyeamer target=_blank title=GitHub><i class="fa-brands fa-github"></i>
</a><a href=/categories/ title=Categories><i class="fa-solid fa-folder"></i>
</a><a href=/tags/ title=Tags><i class="fa-solid fa-tags"></i>
</a><button id=dark-mode-toggle class=dark-mode-toggle aria-label="Toggle dark mode">
<i class="fa-solid fa-circle-half-stroke"></i></button></div></div><h2 class=book-brand><a class="flex align-center" href=/><span>Minystory</span></a></h2><div class="book-search hidden"><div class=search-input-container><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/ onkeydown='event.key==="Enter"&&goToSearchPage()'>
<button type=button id=book-search-button class=book-search-btn onclick=goToSearchPage()>
<i class="fa-solid fa-magnifying-glass"></i></button></div><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden");function goToSearchPage(){const t=document.getElementById("book-search-input"),e=t.value.trim();e&&(window.location.href="/search/?q="+encodeURIComponent(e))}</script><div class=book-categories><input type=checkbox class="hidden toggle" id=categories-control checked>
<label for=categories-control class="categories-toggle categories-link"><a href=/categories/><i class="fa-solid fa-folder"></i>
<span>전체</span>
<span class=category-count>(38)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul class=categories-menu id=categories-menu><li><input type=checkbox class="hidden toggle" id=cat-algorithm>
<label for=cat-algorithm class="categories-toggle categories-link"><a href=/categories/algorithm/><i class="fa-solid fa-folder"></i>
Algorithm
<span class=category-count>(4)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/algorithm/graph/><i class="fa-solid fa-file"></i>
Graph
<span class=category-count>(1)</span></a></li><li class=categories-link><a href=/categories/algorithm/python/><i class="fa-solid fa-file"></i>
Python
<span class=category-count>(2)</span></a></li><li class=categories-link><a href=/categories/algorithm/sql/><i class="fa-solid fa-file"></i>
SQL
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-cloud>
<label for=cat-cloud class="categories-toggle categories-link"><a href=/categories/cloud/><i class="fa-solid fa-folder"></i>
Cloud
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/cloud/kubernetes/><i class="fa-solid fa-file"></i>
Kubernetes
<span class=category-count>(2)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-analysis>
<label for=cat-data-analysis class="categories-toggle categories-link"><a href=/categories/data-analysis/><i class="fa-solid fa-folder"></i>
Data Analysis
<span class=category-count>(3)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-analysis/dacon/><i class="fa-solid fa-file"></i>
Dacon
<span class=category-count>(3)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-data-engineering>
<label for=cat-data-engineering class="categories-toggle categories-link"><a href=/categories/data-engineering/><i class="fa-solid fa-folder"></i>
Data Engineering
<span class=category-count>(19)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/data-engineering/apache-airflow/><i class="fa-solid fa-file"></i>
Apache Airflow
<span class=category-count>(7)</span></a></li><li class=categories-link><a href=/categories/data-engineering/apache-spark/><i class="fa-solid fa-file"></i>
Apache Spark
<span class=category-count>(8)</span></a></li><li class=categories-link><a href=/categories/data-engineering/crawling/><i class="fa-solid fa-file"></i>
Crawling
<span class=category-count>(4)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-frontend>
<label for=cat-frontend class="categories-toggle categories-link"><a href=/categories/frontend/><i class="fa-solid fa-folder"></i>
Frontend
<span class=category-count>(7)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/frontend/blog/><i class="fa-solid fa-file"></i>
Blog
<span class=category-count>(7)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-linux>
<label for=cat-linux class="categories-toggle categories-link"><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
<span class=category-count>(1)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/linux/ubuntu/><i class="fa-solid fa-file"></i>
Ubuntu
<span class=category-count>(1)</span></a></li></ul></li><li><input type=checkbox class="hidden toggle" id=cat-project>
<label for=cat-project class="categories-toggle categories-link"><a href=/categories/project/><i class="fa-solid fa-folder"></i>
Project
<span class=category-count>(2)</span>
</a><i class="fa-solid fa-chevron-down categories-arrow"></i></label><ul><li class=categories-link><a href=/categories/project/open-source/><i class="fa-solid fa-file"></i>
Open Source
<span class=category-count>(1)</span></a></li><li class=categories-link><a href=/categories/project/tools/><i class="fa-solid fa-file"></i>
Tools
<span class=category-count>(1)</span></a></li></ul></li></ul></div><div class=recent-posts><div class=recent-posts-header><i class="fa-solid fa-clock"></i>
<span>최신글</span></div><ul class=recent-posts-list><li class=recent-post-item><a href=/blog/hugo-blog-3/ title="Hugo 블로그 만들기 (3) - Taxonomies로 태그/카테고리 페이지 커스터마이징"><div class=recent-post-title>Hugo 블로그 만들기 (3) - Taxonomies로 태그/카테고리 페이지 커스터마이징</div><div class=recent-post-date><time datetime=2025-11-22>2025.11.22</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-2/ title="Hugo 블로그 만들기 (2) - 메인 레이아웃 커스터마이징 (메뉴, 목차, 헤더)"><div class=recent-post-title>Hugo 블로그 만들기 (2) - 메인 레이아웃 커스터마이징 (메뉴, 목차, 헤더)</div><div class=recent-post-date><time datetime=2025-11-04>2025.11.04</time></div></a></li><li class=recent-post-item><a href=/blog/hugo-blog-1/ title="Hugo 블로그 만들기 (1) - 프로젝트 구성과 GitHub Pages 배포 (Submodule 활용)"><div class=recent-post-title>Hugo 블로그 만들기 (1) - 프로젝트 구성과 GitHub Pages 배포 (Submodule 활용)</div><div class=recent-post-date><time datetime=2025-11-01>2025.11.01</time></div></a></li><li class=recent-post-item><a href=/blog/openup-handson/ title="[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기"><div class=recent-post-title>[OSSCA] 2025 오픈소스 컨트리뷰션 아카데미 - PyTorch 문서 한글화 참여 후기</div><div class=recent-post-date><time datetime=2025-10-28>2025.10.28</time></div></a></li><li class=recent-post-item><a href=/blog/uv-project/ title="[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리"><div class=recent-post-title>[Python] uv로 프로젝트 구성하고 PyPI 배포하기 - Rust 기반 고속 패키지 관리</div><div class=recent-post-date><time datetime=2025-07-23>2025.07.23</time></div></a></li></ul></div></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><i class="fa-solid fa-bars book-icon" id=menu-icon></i></label><h3><a href=https://minyeamer.github.io/ class=site-title>Minystory</a></h3><label for=toc-control><i class="fa-solid fa-list book-icon" id=toc-icon></i></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#data>Data</a></li><li><a href=#eda>EDA</a></li><li><a href=#data-augmentation>Data Augmentation</a><ul><li><a href=#reverse-translation>Reverse Translation</a></li><li><a href=#nlpaug>NLPAUG</a></li><li><a href=#hanspell>hanspell</a></li></ul></li><li><a href=#experiments>Experiments</a><ul><li><a href=#서로-다른-모델-간-비교>서로 다른 모델 간 비교</a></li><li><a href=#학습-데이터-간-비교>학습 데이터 간 비교</a></li><li><a href=#테스트-데이터-간-비교>테스트 데이터 간 비교</a></li><li><a href=#ensemble>Ensemble</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#post-project>Post-Project</a></li></ul></nav></aside></header><article class="markdown book-article"><header class=post-header><div class=post-header-category><a href=/categories/data-analysis/dacon/ class=post-header-category-link>Data Analysis/Dacon</a></div><h1 class=post-header-title>DACON 쇼핑몰 리뷰 평점 분류 - KoELECTRA와 RoBERTa 앙상블로 2위 달성</h1><div class=post-header-date><time datetime=2022-08-22T15:06:20+09:00>2022. 8. 22. 15:06</time></div></header><div class=book-cover><img src="https://dl.dropboxusercontent.com/scl/fi/ur1r3hzxm11trh1p63y4o/shop-review-00-cover.webp?rlkey=f2nnfvwif6byhu0lbvb6bd0sh&amp;dl=0" alt="Cover Image" class=book-cover-img></div><a href=https://dacon.io/competitions/official/235938/overview/description target=_blank class=bookmark-card><div class=bookmark-image><img src=https://dacon.s3.ap-northeast-2.amazonaws.com/competition/235938/meta_cpt.jpeg alt="쇼핑몰 리뷰 평점 분류 AI 해커톤"></div><div class=bookmark-content><h3 class=bookmark-title>쇼핑몰 리뷰 평점 분류 AI 해커톤</h3><p class=bookmark-description>출처 : DACON - Data Science Competition</p><small class=bookmark-url>dacon.io</small></div></a><h2 id=introduction>Introduction
<a class=anchor href=#introduction>#</a></h2><ul><li>쇼핑몰에서 상품을 고르는데 있어서 다른 사람들의 리뷰와 평점을 참고하게 되는데,
상품 리뷰 텍스트와 평점 사이에 어떤 관계가 있는지, 리뷰 텍스트만으로 평점을 예측가능한지에 대해 실험합니다.</li><li>1점, 2점, 4점, 5점으로 분류된 평점 별로 워드 클라우드를 활용해 빈도수가 많은 단어를 시각화해보고,
다중 분류 작업을 수행하는 언어 모델을 학습시킨 결과를 비교할 계획으로 프로젝트 진행합니다.</li><li>평점 별 불균형이 존재해 F1-Score로 평가하는 것이 이상적이라 판단하지만,
대회의 판단 기준에 맞게 Accuracy를 활용하고, 전체 테스트 데이터 중 50%에 대한 점수를 지표로 활용합니다.</li><li>Fine-tuning된 KoELECTRA 및 RoBERTa 모델에 대한 예측 결과를 hard-voting하여
accuracy 기준 <code>0.7116</code> 점으로 550팀 중 2위에 위치했습니다.</li></ul><a href=https://dacon.io/competitions/official/235938/codeshare/5932 target=_blank class=bookmark-card><div class=bookmark-image><img src=https://dacon.s3.ap-northeast-2.amazonaws.com/competition/235938/meta_cpt.jpeg alt=" Private 2nd | 0.7116 | KoELECTAR+RoBERTa | Hard-Voting"></div><div class=bookmark-content><h3 class=bookmark-title>Private 2nd | 0.7116 | KoELECTAR+RoBERTa | Hard-Voting</h3><p class=bookmark-description>알고리즘 | NLP | 분류 | 리뷰 | Accuracy</p><small class=bookmark-url>dacon.io</small></div></a><h2 id=data>Data
<a class=anchor href=#data>#</a></h2><ul><li><a href=https://dacon.io/competitions/official/235938/data target=_blank rel="noopener noreferrer">쇼핑몰 리뷰 데이터</a></li><li>샘플 아이디(id), 쇼핑몰 리뷰 텍스트(reviews), 상품 평점(target)으로 구성됩니다.</li><li>총 25000개의 행에 대해서, 각각의 리뷰 텍스트에 1, 2, 4, 5 중 하나의 평점이 라벨링된 구조입니다.</li></ul><h2 id=eda>EDA
<a class=anchor href=#eda>#</a></h2><ul><li>토큰화된 단어를 워드 클라우드로 시각화 했을 때, 낮은 평점의 리뷰에서는 '안'과 같은 부정적인 단어가,
높은 평점의 리뷰에서는 '잘', '좋아요'와 같은 긍정적인 단어가 자주 언급됨이 확인됩니다.</li><li>'재구매' 단어 역시 높은 평점의 리뷰에서 더욱 많은 비중을 가지고 있으며,
'배송' 단어의 경우 모든 평점의 리뷰에서 유사한 비중을 가집니다.</li></ul><table><thead><tr><th style=text-align:center>평점 1점 리뷰에서 빈도수가 많은 단어</th><th style=text-align:center>평점 2점 리뷰에서 빈도수가 많은 단어</th></tr></thead><tbody><tr><td style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/so6oe23rvnqake6lk966z/shop-review-01-wc-score-1.webp?rlkey=3quh8mb05d9yi8qvy7mn1bapw&amp;dl=0" alt="워드클라우드 평점 1점 - 너무, 안, 배송, 그냥, 잘, 못"></td><td style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/nemetg0aeo27bbbpvct2f/shop-review-02-wc-score-2.webp?rlkey=0miz5qqbixlhlx6eaw00qyjod&amp;dl=0" alt="워드클라우드 평점 2점 - 너무, 안, 배송, 잘, 그냥, 생각"></td></tr></tbody></table><table><thead><tr><th style=text-align:center>평점 4점 리뷰에서 빈도수가 많은 단어</th><th style=text-align:center>평점 5점 리뷰에서 빈도수가 많은 단어</th></tr></thead><tbody><tr><td style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/mg197ah0insbj3rk97i7m/shop-review-03-wc-score-4.webp?rlkey=t134xfyr6x1385mc2j8zhd6jo&amp;dl=0" alt="워드클라우드 평점 4점 - 좋아요, 잘, 배송, 재구매, 사용, 가격"></td><td style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/gycpg3eo9vrku624zymi6/shop-review-04-wc-score-5.webp?rlkey=l5xkad3dyijwhtamtexs9c3ob&amp;dl=0" alt="워드클라우드 평점 5점 - 좋아요, 잘, 배송, 너무, 재구매, 사용"></td></tr></tbody></table><ul><li>평점 별 리뷰 수를 시각화 했을 때, 최대 4배에 달하는 불균형이 존재함이 확인됩니다.</li><li>데이터 증강을 통해 각 평점 간 비율을 맞춰야할 것이라 판단됩니다.</li></ul><table><thead><tr><th style=text-align:center>원본 데이터의 불균형적인 평점 별 리뷰 수</th><th style=text-align:center>이상적인 평점 별 리뷰 수</th></tr></thead><tbody><tr><td style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/jrdany6421ugvya02lnkf/shop-review-05-bar-original.webp?rlkey=mqcc8qf97jsd7lvq145x9bnu2&amp;dl=0" alt="원본 데이터의 불균형적인 평점 별 리뷰 수"></td><td style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/mlafgphr8bkllod7yxdsw/shop-review-06-bar-balanced.webp?rlkey=axnz2ml9fmrrtmt5t6dvhk2dm&amp;dl=0" alt="이상적인 평점 별 리뷰 수"></td></tr></tbody></table><h2 id=data-augmentation>Data Augmentation
<a class=anchor href=#data-augmentation>#</a></h2><h3 id=reverse-translation>Reverse Translation
<a class=anchor href=#reverse-translation>#</a></h3><ul><li>한글 리뷰를 영어로 번역하고 다시 한글로 역번역하여 의미의 변질없이 문장의 표현만을 변환했습니다.</li><li>초기엔 구글 번역 API를 구현한 googletrans 라이브러리로 번역을 시도했지만,
'별로'를 'good'으로 변환하는 등 핵심 키워드에 대한 번역이 올바르지 못해 다른 방안을 탐색했습니다.</li><li>다음으로, 파파고 크롤링을 활용했을 때, 구글 번역보다 상대적으로 정확도가 높았지만,
단어 번역을 시도하고 결과를 수집하는데 평균 3초의 딜레이가 요구되어 시간적 손실이 컸습니다.</li><li>결과적으로, 요청 비용이 발생하는 파파고 API를 통해 역번역을 수행하지만,
크레딧을 활용해 비용을 최소화하고, 크레딧을 초과하는 데이터에 한해 파파고 크롤링을 적용했습니다.</li></ul><h3 id=nlpaug>NLPAUG
<a class=anchor href=#nlpaug>#</a></h3><ul><li>역번역을 통한 2배의 증가로도 평점 별 리뷰 비율을 맞출 수 없기 때문에,
추가적인 텍스트 증강 기법으로 NLPAUG의 동의어 변환 함수를 활용했습니다.</li><li>'red apple'을 'ruby apple'로 대체하는 식으로 문장의 표현을 변환했습니다.</li><li>하지만, NLPAUG에서 지원되는 WordNet에 한국어 동의어 데이터가 존재하지 않기 때문에,
해당 기법을 적용하기 위해선 영어로 번역된 문장을 활용해야 했습니다.</li><li>평점 5점과 2배 이상의 차이를 보이는 1점과 4점 리뷰에 한해 역번역 전에 NLPAUG를 적용했습니다.</li></ul><h3 id=hanspell>hanspell
<a class=anchor href=#hanspell>#</a></h3><ul><li>데이터에 정규 표현식과 hanspell 맞춤법 검사를 적용해 텍스트 정규화 작업 수행했습니다.</li><li>최종적으로 원본 데이터, 증강된 데이터, 각각에 대해 정규화된 데이터의 4가지 학습 데이터를 생성했습니다.</li></ul><h2 id=experiments>Experiments
<a class=anchor href=#experiments>#</a></h2><h3 id=서로-다른-모델-간-비교>서로 다른 모델 간 비교
<a class=anchor href=#%ec%84%9c%eb%a1%9c-%eb%8b%a4%eb%a5%b8-%eb%aa%a8%eb%8d%b8-%ea%b0%84-%eb%b9%84%ea%b5%90>#</a></h3><ul><li>학습 시간의 단축을 위해 ELECTRA 모델을 중심적으로 비교를 시도하였으며,
대회에서 레퍼런스로 공유된 RoBERTa 모델을 비교 대상에 추가했습니다.</li><li>한국어를 지원하는 KoELECTRA 모델 중에서 가장 기본적인 v3 모델과
NER 작업에 사용되는 ner 모델, 다른 제작자가 감정 분석에 맞게 fine-tuning한 jaehyeong 모델,
마지막으로 RoBERTa Large 모델을 선정하였고, 동일한 설정으로 2 epoch를 학습한 결과를 비교했습니다.</li><li>Base 모델은 64, Large 모델엔 32 batch size를 적용하였고(Colab RAM 제한),
valid size 0.1, learning rate 1e-5 설정에 대해 2 epochs를 수행하여 accuracy를 평가했습니다.</li><li>파라미터 수 때문이지 검증 데이터에 대한 평가 점수에서는 RoBERTa 모델이 앞섰지만,
대회용 테스트 데이터에 대해서는 KoELECTRA jaehyeong 모델과 RoBERTa 모델의 성능이 유사했습니다.</li></ul><p><img src="https://dl.dropboxusercontent.com/scl/fi/86pzwauzd9uts1myl21u6/shop-review-07-compare-by-name.webp?rlkey=gsd34tnzqyow9rwjrhxiup5a8&amp;dl=0" alt="Compare Models by Name"></p><h3 id=학습-데이터-간-비교>학습 데이터 간 비교
<a class=anchor href=#%ed%95%99%ec%8a%b5-%eb%8d%b0%ec%9d%b4%ed%84%b0-%ea%b0%84-%eb%b9%84%ea%b5%90>#</a></h3><ul><li>앞선 작업에서 KoELECTRA 모델과 RoBERTa 모델 간 성능 차이가 극심하지 않은 것을 확인하고,
KoELECTRA 모델 중 가장 성능이 높은 jaehyeong 모델을 기준으로 학습 데이터 간 비교를 수행했습니다.</li><li>원본 데이터(vanilla), 증강된 데이터(aug), 정규화된 원본 데이터(cleaned_vanilla),
정규화된 증강 데이터(cleaned_aug)를 각각 활용해 학습한 결과를 비교했습니다.</li><li>하이퍼파라미터는 앞선 작업과 동일하며, 2 epochs를 수행하여 accuracy를 평가했습니다.</li><li>검증 데이터에 대한 평가 점수는 aug 데이터가 앞섰지만,
대회용 테스트 데이터에 대해서는 aug 데이터의 예측 성능이 가장 낮고 vanilla 데이터가 가장 높았습니다.</li></ul><p><img src="https://dl.dropboxusercontent.com/scl/fi/fy14x71t04r1udwrm7k6i/shop-review-08-compare-by-train.webp?rlkey=je32ev8bve698nplkuo1qmr3z&amp;dl=0" alt="Compare Models by Train Data"></p><h3 id=테스트-데이터-간-비교>테스트 데이터 간 비교
<a class=anchor href=#%ed%85%8c%ec%8a%a4%ed%8a%b8-%eb%8d%b0%ec%9d%b4%ed%84%b0-%ea%b0%84-%eb%b9%84%ea%b5%90>#</a></h3><ul><li>서로 다른 학습 데이터에 대해 최적화된 모델 간에 테스트 데이터 별 예측 성능을 비교했습니다.</li><li>테스트 데이터는 원본 데이터(vanilla)와 정규화된 데이터(cleaned)로 정의했습니다.</li><li>전체 테스트 데이터 중 50%에 대한 점수를 기록하는 대회의 평가 기준을 활용해
각각의 예측 결과 간에 점수를 비교했을 때, 오히려 원본 데이터가 높은 성능을 보이는 것을 확인했습니다.</li></ul><p><img src="https://dl.dropboxusercontent.com/scl/fi/gcaazirdyss91li24phet/shop-review-09-compare-by-test.webp?rlkey=md944nzaa3h2fthmmkoz7g1md&amp;dl=0" alt="Compare Models by Test Data"></p><ul><li>이러한 결과가 발생한 원인을 파악하기 위해 각각의 데이터에 대해 EDA를 다시 수행했을 때,
가장 많은 데이터 증강이 발생한 평점 4점 리뷰의 단어 비율이 크게 변화함을 확인했습니다.</li></ul><table><thead><tr><th style=text-align:center>원본 데이터에서 평점 4점 리뷰의 단어 비율</th><th style=text-align:center>증강/정규화된 데이터에서 평점 4점 리뷰의 단어 비율</th></tr></thead><tbody><tr><td style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/mg197ah0insbj3rk97i7m/shop-review-03-wc-score-4.webp?rlkey=t134xfyr6x1385mc2j8zhd6jo&amp;dl=0" alt="워드클라우드 평점 4점 - 좋아요, 잘, 배송, 재구매, 사용, 가격"></td><td style=text-align:center><img src="https://dl.dropboxusercontent.com/scl/fi/9gebebysb1wja53uoinqh/shop-review-10-wc-score-4-aug.webp?rlkey=ceqf40buo1s000xgq4ja49lnd&amp;dl=0" alt="워드클라우드 평점 4점 증강 - 정보기술, 잘, 정보, 기술, 생각, 배송"></td></tr></tbody></table><ul><li>NLPAUG의 동의어 변환이 원인인 것으로 추정되어 다른 증강법을 적용할 필요가 있지만,
데이터 전처리부터 다시 수행하는 것과 모델링을 개선하는 것을 병행할만한 여유가 없다고 판단해
더이상의 데이터 변환 없이 다음 단계인 앙상블로 전환했습니다.</li></ul><h3 id=ensemble>Ensemble
<a class=anchor href=#ensemble>#</a></h3><ul><li>KoELECTRA, RoBERTa 모델과 다양한 종류의 데이터를 활용해 예측한 결과를 통해
hard-voting 및 soft-voting 수행했습니다.</li><li>원본 데이터를 활용해 학습한 KoELECTRA, RoBERTa 모델의 예측값에 hard-voting을 적용한
결과가 가장 높은 점수를 보였으며, soft-voting은 상대적으로 낮은 점수를 보였습니다.</li></ul><h2 id=conclusion>Conclusion
<a class=anchor href=#conclusion>#</a></h2><ul><li>라벨 간 불균형을 극복하기 위해 역번역, 동의어 변환 등의 다양한 자연어 데이터 증강 기법을 적용했습니다.</li><li>각각의 ELECTRA 모델과 RoBERTa Large 모델을 비교했을 때,
파라미터의 수가 가장 많은 RoBERTa 모델의 성능이 앞섰지만 ELECTRA 모델과의 차이가 크지 않았습니다.</li><li>모델 경량화를 고려할 경우엔 ELECTRA를 활용하는게 더 유리할 것입니다.</li><li>데이터에 따른 성능 변화를 비교하는 과정에서 전처리된 데이터가 원본 데이터보다 낮은 성능을
발생시키는 것을 인지하고 두 데이터를 비교하였을 때 잘못된 전처리로 인해 노이즈가 발생한 것을 확인했습니다.</li><li>텍스트 정규화를 수행한 경우가 그렇지 않은 경우보다 낮은 성능을 보이는 경향이 있었고,
이를 통해 비정규화된 텍스트에서 나타나는 말투나 이모티콘 등의 표현이
감정 분석 작업에 적지 않은 영향을 주는 것이라 추측합니다.</li></ul><h2 id=post-project>Post-Project
<a class=anchor href=#post-project>#</a></h2><ul><li>자연어 처리에서 활용되는 데이터 증강 기법에 대해 알아볼 수 있는 좋은 기회가 되었습니다.</li><li>ELECTRA 모델을 활용한 덕분에 짧은 시간 안에 다양한 조건에서 성능을 평가할 수 있었고,
분류 작업 파이프라인을 만드는 과정에서 HuggingFace의 활용법에 대해서도 익힐 수 있게 되었습니다.</li><li>하지만, HuggingFace의 경우 너무 간략화된 부분이 많아 PyTorch를 배운다는 목적에는 부합하지 않았고,
Dropout과 같은 과적합 방지 기법들을 적용하는데도 어려움을 겪었습니다.</li><li>고수준의 라이브러리는 사용하기엔 편리하지만 작업의 복잡도가 증가할수록 제약이 많아짐을 느꼈고,
이를 극복하기 위해 바닥부터 모델링 코드를 짜는 경험의 중요성을 다시 한번 인식합니다.</li></ul></article><div class=book-nav><button class=book-nav-btn3 onclick='window.scrollTo({top:0,behavior:"smooth"})' title="Go to top">
<i class="fa fa-chevron-up"></i>
</button>
<button class=book-nav-btn3 onclick='window.scrollTo({top:document.body.scrollHeight,behavior:"smooth"})' title="Go to bottom">
<i class="fa fa-chevron-down"></i>
<button class=book-nav-btn3 onclick=history.back() title="Go back">
<i class="fa-solid fa-arrow-left"></i></button></div><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class=post-tags><a href=/tags/dacon/ class=tag>#DACON</a>
<a href=/tags/nlp/ class=tag>#NLP</a>
<a href=/tags/%ED%85%8D%EC%8A%A4%ED%8A%B8-%EB%B6%84%EB%A5%98/ class=tag>#텍스트 분류</a>
<a href=/tags/%EA%B0%90%EC%A0%95-%EB%B6%84%EC%84%9D/ class=tag>#감정 분석</a>
<a href=/tags/koelectra/ class=tag>#KoELECTRA</a>
<a href=/tags/roberta/ class=tag>#RoBERTa</a>
<a href=/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A6%9D%EA%B0%95/ class=tag>#데이터 증강</a>
<a href=/tags/%EC%95%99%EC%83%81%EB%B8%94/ class=tag>#앙상블</a>
<a href=/tags/%EC%97%AD%EB%B2%88%EC%97%AD/ class=tag>#역번역</a>
<a href=/tags/nlpaug/ class=tag>#NLPAUG</a>
<a href=/tags/%EC%87%BC%ED%95%91%EB%AA%B0-%EB%A6%AC%EB%B7%B0/ class=tag>#쇼핑몰 리뷰</a></div><div class=post-navigation><a href=/blog/dacon-audio-mnist/ class="post-nav-link post-nav-prev"><span class=post-nav-direction><i class="fa-solid fa-backward"></i> PREV</span>
<span class=post-nav-title>DACON 음성 분류 경진대회 - Mel Spectrogram과 MFCC 앙상블로 97% 정확도 달성</span>
</a><a href class="post-nav-link post-nav-next post-nav-disabled"><span class=post-nav-direction>NEXT <i class="fa-solid fa-forward"></i></span>
<span class=post-nav-title>다음 게시글이 없습니다</span></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script><div class=book-comments><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://minyeamer.github.io/blog/dacon-shop-review/",this.page.identifier="https://minyeamer.github.io/blog/dacon-shop-review/"};(function(){var e=document,t=e.createElement("script");t.src="https://minyeamer.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})();function reloadDisqus(){window.DISQUS&&DISQUS.reset({reload:!0,config:function(){this.page.url="https://minyeamer.github.io/blog/dacon-shop-review/",this.page.identifier="https://minyeamer.github.io/blog/dacon-shop-review/"}})}</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#data>Data</a></li><li><a href=#eda>EDA</a></li><li><a href=#data-augmentation>Data Augmentation</a><ul><li><a href=#reverse-translation>Reverse Translation</a></li><li><a href=#nlpaug>NLPAUG</a></li><li><a href=#hanspell>hanspell</a></li></ul></li><li><a href=#experiments>Experiments</a><ul><li><a href=#서로-다른-모델-간-비교>서로 다른 모델 간 비교</a></li><li><a href=#학습-데이터-간-비교>학습 데이터 간 비교</a></li><li><a href=#테스트-데이터-간-비교>테스트 데이터 간 비교</a></li><li><a href=#ensemble>Ensemble</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#post-project>Post-Project</a></li></ul></nav></div></aside></main></body></html>