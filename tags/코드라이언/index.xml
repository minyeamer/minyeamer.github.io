<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>코드라이언 on Minystory</title>
    <link>https://minyeamer.github.io/tags/%EC%BD%94%EB%93%9C%EB%9D%BC%EC%9D%B4%EC%96%B8/</link>
    <description>Recent content in 코드라이언 on Minystory</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 13 Apr 2022 22:13:00 +0900</lastBuildDate><atom:link href="https://minyeamer.github.io/tags/%EC%BD%94%EB%93%9C%EB%9D%BC%EC%9D%B4%EC%96%B8/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - Pipeline</title>
      <link>https://minyeamer.github.io/blog/aischool-06-09-pipeline/</link>
      <pubDate>Wed, 13 Apr 2022 22:13:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-09-pipeline/</guid>
      <description>Feature Transformer Import Libraries 1 2 3 from sklearn.preprocessing import StandardScaler, OneHotEncoder from sklearn.compose import ColumnTransformer from sklearn.pipeline import Pipeline ColumnTransformer 1 2 3 4 5 6 7 8 9 10 numeric_features = [&amp;#39;CRIM&amp;#39;, &amp;#39;ZN&amp;#39;, &amp;#39;INDUS&amp;#39;, &amp;#39;NOX&amp;#39;, &amp;#39;RM&amp;#39;, &amp;#39;AGE&amp;#39;, &amp;#39;DIS&amp;#39;, &amp;#39;TAX&amp;#39;, &amp;#39;PTRATIO&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;LSTAT&amp;#39;] numeric_transformer = StandardScaler() categorical_features = [&amp;#39;CHAS&amp;#39;, &amp;#39;RAD&amp;#39;] categorical_transformer = OneHotEncoder(categories=&amp;#39;auto&amp;#39;) preprocessor = ColumnTransformer( transformers=[ (&amp;#39;num&amp;#39;, numeric_transformer, numeric_features), (&amp;#39;cat&amp;#39;, categorical_transformer, categorical_features)]) OneHotEncoder()의 handle_unknown 설정
error: 숫자로 변환된 분류형 범주에 새로운 문자열 데이터가 들어올 경우 에러를 발생시킴 ignore: 카테고리에 해당되는 번호가 없으면 자동으로 0으로 바꿈 Preprocessing-Only 1 preprocessor_pipe = Pipeline(steps=[(&amp;#39;preprocessor&amp;#39;, preprocessor)]) steps: 전처리 도구를 순서대로 적용 (모델도 입력 가능) Model Fitting 1 2 3 4 preprocessor_pipe.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - Model Stacking</title>
      <link>https://minyeamer.github.io/blog/aischool-06-08-model-stacking/</link>
      <pubDate>Wed, 13 Apr 2022 22:10:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-08-model-stacking/</guid>
      <description>Model Stacking 서로 다른 모델들을 모으고 Ensemble 기법을 사용해 개선된 모델을 만드는 것 기존 모델들로부터 예측 결과를 도출하는 1st Stage와
이를 기반으로 추가적인 판단을 진행하는 2nd Stage로 나뉨 1st Stage train_X를 가지고 1번 모델을 Training Training을 거친 1번 모델에 train_X를 넣었을 때 결과(예측값)을 저장 다른 모델에도 동일한 작업을 했을 때 나온 1열의 예측값들을 묶어 S_train을 생성 (기존 Ensemble은 S_train을 행별로 투표해서 분류함) 2nd Stage 새로운 모델 생성 (1st Stage에서 사용한 것과 다른 모델 사용 가능) S_train_X, train_Y를 가지고 새로운 모델을 Training Test Model test_X를 1st Stage 모델에 넣고 결과로 나온 예측값들의 묶음 S_test를 생성 (2nd Stage 모델의 학습 데이터는 원본 데이터와 다르기 때문에 test_X를 바로 넣으면 안됨) S_train_X, train_Y를 2nd Stage 모델에 넣었을 때 결과를 가지고 Accuracy 계산 Functional API Import Library 1 from vecstack import stacking 1st Level Models 1 2 3 4 models = [ ExtraTreesClassifier(random_state = 0, n_jobs = -1, n_estimators = 100, max_depth = 3), RandomForestClassifier(random_state = 0, n_jobs = -1, n_estimators = 100, max_depth = 3), XGBClassifier(seed = 0, n_jobs = -1, learning_rate = 0.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - PCA</title>
      <link>https://minyeamer.github.io/blog/aischool-06-07-pca/</link>
      <pubDate>Wed, 13 Apr 2022 22:03:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-07-pca/</guid>
      <description>Principal Component Analysis 차원 축소를 통해 최소 차원의 정보로 원래 차원의 정보를 모사하는 알고리즘 데이터의 열의 수가 많아 학습 속도가 느려질 때 열의 수를 줄이기 위해 사용 Dimension Reduction: 고차원 벡터에서 일부 차원의 값을 모두 0으로 만들어 차원을 줄임 원래의 고차원 벡터의 특성을 최대한 살리기 위해 가장 분산이 높은 방향으로 회전 변환 진행 전체 데이터를 기반으로 분산이 가장 큰 축을 찾아 PC 1으로 만들고,
PC 1에 직교하는 축 중에서 분산이 가장 큰 축을 PC 2로 만드는 과정 반복 정보의 누락이 있기 때문에 경우에 따라 모델의 성능 하락 발생 Feature Selection: 기존에 존재하는 열 중에 n개를 선택 Feature Extraction: 기존에 있는 열들을 바탕으로 새로운 열들을 만들어냄 (차원 축소) Learning Process Import Libraries 1 2 from sklearn import decomposition from sklearn import datasets Load Model 1 2 3 iris = datasets.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - K-Means</title>
      <link>https://minyeamer.github.io/blog/aischool-06-06-k-means/</link>
      <pubDate>Wed, 13 Apr 2022 21:50:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-06-k-means/</guid>
      <description>1. K-Means Algorithm K는 전체 데이터를 몇 개의 그룹으로 묶어낼 것인지 결정하는 상수 어떤 K 값이 적절한 것인지 파악하는 것이 중요 각각의 데이터마다 중심값까지의 거리를 계속 물어보기 때문에 계산량이 많음 클러스터링 성능을 향상시키기 위해 GPU Accelerated t-SNE for CUDA 활용 Clustering Process K개의 임의의 중심값을 선택 각 데이터마다 중심값까지의 거리를 계산하여 가까운 중심값의 클러스터에 할당 각 클러스터에 속한 데이터들의 평균값으로 각 중심값을 이동 데이터에 대한 클러스터 할당이 변하지 않을 때까지 2와 3을 반복 2.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - Kernelized SVM</title>
      <link>https://minyeamer.github.io/blog/aischool-06-05-kernelized-svm/</link>
      <pubDate>Wed, 13 Apr 2022 21:19:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-05-kernelized-svm/</guid>
      <description>Support Vector Machine 패턴 인식을 위한 지도 학습 모델 데이터를 분류하는 Margin을 최대화하는 결정 경계(Decision Boundary)를 찾는 기법 결정 경계와 가장 가까운 데이터를 가로지르는 선을 기준으로 Plus &amp;amp; Minus Plane 설정 Support Vector: 결정 경계와 가장 가까운 데이터의 좌표 Margin: b11(plus-plane)과 b12(minus-plane) 사이의 거리, 2/w 기존의 Hard Margin SVM은 소수의 Noise로 인해 결정 경계를 찾지 못할 수 있음 Plus &amp;amp; Minus Plane에 약간의 여유 변수를 두어 에러를 무시하는 Soft Margin SVM로 발전 arg min $$arg\ min\lbrace\frac{1}{2}{||w||}^2+C\Sigma^n_{i=1}\xi_i\rbrace$$ $$\text{단, }y_i({w}\cdot{x_i}-b)\ge{1-\xi_i},\quad{\xi_i\ge{0}},\quad{\text{for all }1\le{i}\le{n}}$$</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - KNN</title>
      <link>https://minyeamer.github.io/blog/aischool-06-04-knn/</link>
      <pubDate>Wed, 13 Apr 2022 20:57:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-04-knn/</guid>
      <description>K-Nearest Neightbor Algorithm 기존의 가까운 이웃 데이터를 살펴 새로운 데이터를 분류하는 알고리즘 K=3일 경우, 가장 가까운 나머지 3개 중 2개가 Red면 Red로 판단 K 값이 작아질수록 아주 작은 영향에로 판단이 바뀌는 Overfitting 발생 K 값이 커질수록 멀리보고 결정이 느려져 Overfitting 감소 Learning Process Load Data 1 iris = datasets.load_iris() # 붓꽃 데이터 (150행, 4열) Select Feature 1 2 x = iris.data[:, :2] # [꽃받침 길이, 꽃받침 넓이] y = iris.target Create Model 1 model = neighbors.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - Gradient Boosting</title>
      <link>https://minyeamer.github.io/blog/aischool-06-03-gradient-boosting/</link>
      <pubDate>Wed, 13 Apr 2022 20:51:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-03-gradient-boosting/</guid>
      <description>XG Boost Extreme Gradient Boosting 대용량 분산 처리를 위한 Gradient Boosting 라이브러리 Decision Tree(의사결정나무) 에 Boosting 기법을 적용한 알고리즘 AdaBoost는 학습 성능은 좋으나, 모델의 학습 시간이 오래 걸리는 단점 병렬 처리 기법을 적용하여 Gradient Boost보다 학습 속도를 끌어올림 Hyper-Parameter가 너무 많기 때문에 권장 세팅 사용 @ http://j.mp/2PukeTS Decision Tree 이해하기 쉽고 해석도 용이함 입력 데이터의 작은 변동에도 Tree의 구성이 크게 달라짐 과적합이 쉽게 발생 (중간에 멈추지 않으면 Leaf 노드에 하나의 데이터만 남게 됨) 의사결정나무의 문제를 해결하기 위해 Boosting 기법 활용 ex) 테니스를 쳤던 과거 데이터를 보고 날씨 정보를 이용해 의사결정 AdaBoost Adaptive Boosting 데이터를 바탕으로 여러 weak learner 들을 반복적으로 생성 앞선 learner가 잘못 예측한 데이터에 가중치를 부여하고 학습 최종적으로 만들어진 strong learner를 이용하여 실제 예측 진행 에러를 최소화하는 weight를 매기기 위해 경사 하강법 사용 ex) Regression: 평균/가중평균, Classification: 투표 XG Boost References NGBoost Explained (Comparison to LightGBM and XGBoost) Gradient Boosting Interactive Playground Gradient Boosting explained Comparison for hyperparams of XGBoost &amp;amp; LightGBM XGBoost Parameters XG Boost 하이퍼 파라미터 상세 설명 Complete Guide to Parameter Tuning in XGBoost (with python codes) Microsoft EBM (Explainable Boosting Machine) 정형데이터를 위한 인공신경망 모델, TabNet Ensemble 주어진 데이터를 이용하여 여러 개의 서로 다른 예측 모형을 생성한 후,</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - 로지스틱 회귀</title>
      <link>https://minyeamer.github.io/blog/aischool-06-02-logistic-regression/</link>
      <pubDate>Wed, 13 Apr 2022 17:03:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-02-logistic-regression/</guid>
      <description>Logistic Regression 이진 분류(0 또는 1) 문제를 해결하기 위한 모델 다항 로지스틱 회귀(k-class), 서수 로지스틱 회귀(k-class &amp;amp; ordinal)도 존재 Sigmoid Function을 이용하여 입력값이 양성 클래스에 속할 확률을 계산 로지스틱 회귀를 MSE 식에 넣으면 지수 함정의 특징 때문에 함정이 많은 그래프가 나옴 분류를 위한 Cost Function인 Cross-Entropy 활용 성능 지표로는 Cross-Entropy 외에 Accuracy 등을 같이 사용 ex) 스팸 메일 분류, 질병 양성/음성 분류 등 양성/음성 분류 모델 선형 모델은 새로운 데이터가 들어오면 양성/음성 판단 기준이 크게 바뀜 모델을 지수 함수인 Sigmoid Function으로 변경 Sigmoid Function θ 값에 따라 기울기나 x축의 위치가 바뀌는 지수 함수 y축을 이동하는 선형 함수와 다르게 x축을 이동 y가 0.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝</title>
      <link>https://minyeamer.github.io/blog/aischool-06-00-machine-learning/</link>
      <pubDate>Wed, 13 Apr 2022 16:31:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-00-machine-learning/</guid>
      <description>인공지능 Intelligent Agents를 만드는 것 주변 환경들을 인식하고 원하는 행동을 취하여 목표를 성취하는 것 Artificial Narrow Intelligence 제한된 기능만 수행할 수 있는 인공지능 weak AI Artificial General Intelligence 사람만큼 다양한 분야에서 기능을 수행할 수 있는 인공지능 strong AI Artificial Super Intelligence 모든 분야에서 사람보다 뛰어난 인공지능 모델 데이터를 가장 잘 설명할 수 있는 함수 (y = ax + b) 모델에서 θ는 Parameter(가중치, Weight) 의미 모델에서 h(x)는 Hypotheses(가설) 의미 모델에서 b는 Bias(편향, 보정치) 의미 머신러닝 어떠한 과제를 해결하는 과정에서 특정한 평가 기준을 바탕으로 학습의 경험을 쌓는 프로그램 머신러닝 분류 Supervised 입력값에 대한 정답을 예측하기 위해 학습 데이터와 정답이 같이 존재 회귀(Regression): 결과가 실수 영역 전체에서 나타남 분류(Classification): 결과가 특정 분류에 해당하는 불연속값으로 나타남 ex) 주식 가격 예측, 이미지 인식 등 Unsupervised 입력값 속에 숨어있는 규칙성을 찾기 위해 학습 정답이 없는 데이터를 주고 비슷한 집단을 분류 ex) 고객군 분류, 장바구니 분석(Association Rule) 등 Reinforcement Trial &amp;amp; Error를 통한 학습 최종적으로 얻게 될 기대 보상을 최대화하기 위한 행동 선택 정책 학습 각 상태에 대해 결정한 행동을 통해 환경으로부터 받는 보상을 학습 ex) 로봇 제어, 공정 최적화 등 Automated ML 어떤 모델(함수, 알고리즘)을 써야할지를 컴퓨터가 알아서 정하게 함 인공신경망 레이어의 범위, 후보 등을 정해놓고 그 안에서 가장 좋은 조합을 찾음 ex) AutoML Tables (행의 수가 1000건이 넘어야하는 제약) 학습 데이터를 가장 잘 설명하는 방법을 찾는 과정 데이터에 맞는 모델을 찾는 과정 (= Model Fitting) 실제 정답과 예측 결과 사이의 오차(Loss, Cost, Error)를 줄여나가는 최적화 과정 학습 과정 초기 모델에 데이터를 입력 결과를 평가 (예측/분류의 정확도 등) 결과를 개선하기 위해 모델을 수정 (모델 내부 Parameter 수정 등) Model&amp;rsquo;s Capacity 2번 모델은 3번 모델보다 오차가 크지만 새로운 데이터가 생겼을 때 비슷하게 예측 가능 3번 모델은 오차가 가장 적지만 새로운 데이터가 생겼을 때 오차가 매우 커질 수 있음 3번 모델과 같은 Overfitting(과적합)이 발생하기 전에 학습을 멈춤 Cross Validation 새로운 데이터들에 대해서도 좋은 결과를 내게 하기 위해 데이터를 3개 그룹으로 나눠 학습 60%의 Training Data로 모델을 학습 20%의 Validation Data로 모델을 최적화/선택 20%의 Test Data로 모델을 평가 데이터를 분리하는 비율은 모델에 따라 달라짐 K-Fold Cross Validation 후보 모델 간 비교 및 선택을 위한 알고리즘 Training Data를 K 등분하고 그 중 하나를 Validation Data로 설정 K 값은 자체적으로 결정하며 보통 10-Fold 사용 (시간이 없으면 5-Fold) 머신러닝에서 K는 주로 사용자가 결정하는 상수 Stratified: 층화 표집 방법, 데이터의 분류 별 비율이 다르면 K-Fold 조각 안에서 비율을 유지시킴 10-Fold 학습 과정 데이터를 80%의 Training Data와 20%의 Test Data로 나누고 Training Data를 10등분</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - 선형 회귀</title>
      <link>https://minyeamer.github.io/blog/aischool-06-01-linear-regression/</link>
      <pubDate>Wed, 13 Apr 2022 16:31:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-01-linear-regression/</guid>
      <description>Linear Regression 종속 변수 y와 독립 변수 x 사이의 선형 상관 관계를 모델링하는 회귀분석 기법 정답이 있는 데이터의 추세를 잘 설명하는 선형 함수를 찾아 x에 대한 y를 예측 Linear Combination (선형 결합): 더하기와 곱하기로만 이루어진 식 단순 회귀분석: 1개의 독립변수(x)가 1개의 종속변수(y)에 영향을 미칠 때 다중 회귀분석: 2개 이상의 독립변수(x)가 1개의 종속변수(y)에 영향을 미칠 때 선형 회귀는 가장 적합한 θ들의 집합을 찾는 것이 목표 Cost Function 예측 값과 실제 값의 차이를 기반으로 모델의 성능(정확도)을 판단하기 위한 함수 Objective (MIN or MAX) 함수 안에 Cost Function이 존재 선형 회귀에서는 Mean Squre(d) Error Function (평균 제곱 오차 함수) 활용 MSE(Cost)가 최소가 되는 θ(a &amp;amp; b)를 찾아야하며,</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] SQL 프로그래밍 실습 - Merge</title>
      <link>https://minyeamer.github.io/blog/aischool-05-03-merge/</link>
      <pubDate>Mon, 11 Apr 2022 20:20:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-05-03-merge/</guid>
      <description>INNER JOIN 1 2 3 4 5 6 7 8 9 SELECT l.Title, r.Name FROM albums AS l INNER JOIN artists AS r ON r.ArtistId = l.ArtistId; 1 2 3 4 5 6 SELECT Title, Name FROM albums INNER JOIN artists USING(ArtistId); LEFT JOIN 1 2 3 4 5 6 7 8 SELECT Name, Title FROM artists LEFT JOIN albums ON artists.ArtistId = albums.ArtistId ORDER BY Name; SELF JOIN 1 2 3 4 5 6 7 8 9 10 SELECT m.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] SQL 프로그래밍 실습 - SQL CRUD</title>
      <link>https://minyeamer.github.io/blog/aischool-05-02-sql-crud/</link>
      <pubDate>Mon, 11 Apr 2022 20:11:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-05-02-sql-crud/</guid>
      <description>SELECT 1 SELECT 10 / 5, 2 * 4; 1 SELECT trackid, name FROM tracks; 1 SELECT * FROM tracks; INSERT 1 INSERT INTO artists (name) VALUES(&amp;#39;Bud Powell&amp;#39;); 1 2 3 4 5 6 7 8 9 10 11 script = &amp;#34;&amp;#34;&amp;#34; INSERT INTO artists (name) VALUES (&amp;#34;?&amp;#34;); &amp;#34;&amp;#34;&amp;#34; data = [ (&amp;#34;Buddy Rich&amp;#34;), (&amp;#34;Candido&amp;#34;), (&amp;#34;Charlie Byrd&amp;#34;) ] cur.executemany(script, data) 1 2 3 4 5 6 7 SELECT ArtistId, Name FROM Artists ORDER BY ArtistId DESC; UPDATE 1 UPDATE employees SET lastname = &amp;#39;Smith&amp;#39; WHERE employeeid = 3; 1 2 3 4 5 6 UPDATE employees SET city = &amp;#39;Toronto&amp;#39;, state = &amp;#39;ON&amp;#39;, postalcode = &amp;#39;M5P 2N7&amp;#39; WHERE employeeid = 4; 1 2 UPDATE employees SET email = UPPER(firstname || &amp;#34;.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] SQL 프로그래밍</title>
      <link>https://minyeamer.github.io/blog/aischool-05-00-sql-programming/</link>
      <pubDate>Mon, 11 Apr 2022 19:52:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-05-00-sql-programming/</guid>
      <description>DBMS DataBase Management System 하드웨어에 저장된 데이터베이스를 관리해주는 소프트웨어 관계형 데이터베이스(RDBMS)가 주로 사용 Oracle, MySQL(MariaDB), SQLite, MS SQL, PstgreSQL 데이터 모델링 현실 세계 E-R 다이어그램 (개념 스키마) Relation 모델 (논리적 스키마) 물리적인 SQL 코드 (데이터베이스 스키마) 개념적 데이터 모델링 현실 세계로부터 개체를 추출, 개체들의 관계를 정의, E-R 다이어그램 생성 개체(Entity): 회원, 제품 등 저장할 가치가 있는 데이터를 포함한 개체 속성(Attribute): 이름, 이메일 등 의미 있는 데이터의 가장 작은 논리적 단위 관계(Relationship): 구매 등 개체와 개체 사이의 연관성 및 개체 집합 간 대응 관계 논리적 데이터 모델링 E-R 다이어그램을 바탕으로 논리적인 구조를 Relation 모델로 표현 릴레이션(Relation): 개체에 대한 데이터를 2차원 테이블 구조로 표현한 것 속성(Attribute): 열, 필드 튜플(Tuble): 행, 레코드, 인스턴스 차수(Degree): 릴레이션 내 속성(Column)의 총 개수 카디널리티(Cardinality): 릴레이션 내 튜플(Row)의 총 개수 물리적 데이터 모델링 Relation 모델을 물리 저장 장치에 저장할 수 있는 물리적 구조로 구현 SQL Structured Query Language RDBMS에서 데이터를 관리 및 처리하기 위해 만들어진 언어 DDL(Data Definition Language): CREATE, ALTER, DROP DML(Data Manipulation Language): SELECT, INSERT, UPDATE, DELETE DCL(Data Control Language): GRANT, REVOKE NoSQL 관계형 모델을 사용하지 않음, 명시적인 스키마가 없음 대용량 데이터 분산 저장에 특화 Kye-Value, Document, Wide Column, Graph 등 </description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] SQL 프로그래밍 실습 - SQLite3</title>
      <link>https://minyeamer.github.io/blog/aischool-05-01-sqlite3/</link>
      <pubDate>Mon, 11 Apr 2022 19:52:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-05-01-sqlite3/</guid>
      <description>Connect SQLite3 1 2 3 4 5 import sqlite3 dbpath = &amp;#34;maindb.db&amp;#34; conn = sqlite3.connect(dbpath) cur = conn.cursor() connnect(): DBMS와 연결 conn.commit(): 현재 변경사항 저장 conn.rollback(): 마지막 commit 시점으로 되돌리기 cursor(): DB에서 SQL문을 실행하는 객체 Execute Scripts Datatypes NULL: 결측치 INTEGER (or INT): 정수 (양수 또는 음수), int 값 REAL: 실수, float 값 TEXT (or VARCHAR): 텍스트, string 값 BLOB: 모든 종류의 파일을 저장하는 바이너리 객체 Scripts DROP TABLE IF EXISTS: 테이블이 이미 있으면 제거 CREATE TABLE: 테이블 생성 AUTOINCREMENT: 값을 따로 입력하지 않으면 자동 증가 숫자 부여 NOT NULL: 빈 값이 저장되는 것을 허용하지 않음 INSERT INTO TABLE(FIELD, &amp;hellip;) VALUES(VALUE, &amp;hellip;):</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 통계분석 실습 - A/B Test</title>
      <link>https://minyeamer.github.io/blog/aischool-04-04-ab-test/</link>
      <pubDate>Sat, 02 Apr 2022 22:50:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-04-04-ab-test/</guid>
      <description>마케팅 비용 분석 매월 유튜브에 광고 비용을 지출하여 신규 유저(구매 고객 or 회원가입 고객)를 획득 월별로 10,000원 단위의 유튜브 광고 비용과 해당 월에 신규로 획득된 유저 수가 측정되었다고 가정 비교 데이터 단순 CAC 계산 CAC(Customer Acquisition Cost, 신규고객 유치 비용) @ https://j.mp/35O5NRe 1 2 3 4 5 cac = ad_df[&amp;#39;Marketing_Costs&amp;#39;].sum() / ad_df[&amp;#39;User_Acquired&amp;#39;].sum() print(cac * 10000) # Output 446원 위의 금액에 추가로 획득하기를 원하는 유저 수를 곱한 금액을
유튜브 광고 비용으로 쓰면 그만큼 유저가 늘어날까?</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 통계분석 실습 - T-Test &amp; 상관관계 분석</title>
      <link>https://minyeamer.github.io/blog/aischool-04-03-test-statistics/</link>
      <pubDate>Sat, 02 Apr 2022 22:40:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-04-03-test-statistics/</guid>
      <description>Import Libraries 1 2 3 4 5 6 7 8 import pandas as pd import seaborn as sns import scipy as sp from scipy import stats import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) 교차분석 교차표 (Cross-Table) 1 2 3 4 crosstab = pd.crosstab(df.propensity, df.skin, margins=True) crosstab.columns=[] crosstab.index=[] margins: 합계(All) 추가 여부 normalize: Normalization 여부 Chi-square 검정 두 범주형 변수 사이의 관계가 있는지 없는지를 검정 (독립성 검정) 귀무가설: Indepedent (vice versa) 대립가설: Not Independent 1 2 3 4 stats.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 통계분석 실습 - 빈도 분석 &amp; 기술통계량 분석</title>
      <link>https://minyeamer.github.io/blog/aischool-04-02-descriptive-statistics/</link>
      <pubDate>Sat, 02 Apr 2022 22:09:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-04-02-descriptive-statistics/</guid>
      <description>Chart Pie Chart 1 df[&amp;#39;column&amp;#39;].value_counts().plot(kind = &amp;#39;pie&amp;#39;) Bar Chart 1 df[&amp;#39;column&amp;#39;].value_counts().plot(kind = &amp;#39;bar&amp;#39;) Descriptive Statistics df[&#39;column&#39;].max(): 최댓값 (행방향 기준: axis=1) df[&#39;column&#39;].min(): 최솟값 df[&#39;column&#39;].sum(): 합계 df[&#39;column&#39;].mean(): 평균 df[&#39;column&#39;].variance(): 분산 df[&#39;column&#39;].std(): 표준편차 df[&#39;column&#39;].describe(): 기술통계량 분포의 왜도와 첨도 df[&#39;column&#39;].hist(): 히스토그램 df[&#39;column&#39;].skew(): 왜도 (분포가 좌우로 치우쳐진 정도) 왜도(Skewness): 0에 가까울수록 정규분포 (절대값 기준 3 미초과)
우측으로 치우치면 음(negative)의 왜도, 좌측으로 치우치면 양(positive)의 왜도 df[&#39;column&#39;].kurtosis(): 첨도 (분포가 뾰족한 정도) 첨도(Kurtosis): 1에 가까울수록 정규분포 (절대값 기준 8 또는 10 미초과) 왜도가 0, 정도가 1일 때 완전한 정규분포로 가정 sns.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 통계분석 실습 - Numpy &amp; Pandas</title>
      <link>https://minyeamer.github.io/blog/aischool-04-01-numpy-pandas/</link>
      <pubDate>Tue, 29 Mar 2022 16:11:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-04-01-numpy-pandas/</guid>
      <description>Numpy Numpy Array 내부의 데이터는 하나의 자료형으로 통일 Numpy Array에 값을 곱하면 전체 데이터 그대로 복사되는 리스트와 달리 데이터에 각각 곱해짐 np.array([]): Numpy Array 생성 np.dtype: Numpy Array의 Data Type np.shape: Numpy Array 모양(차원) np.arange(): range를 바탕으로 Numpy Array 생성 np.reshape(): Numpy Array 모양을 변경, 열에 -1을 입력하면 자동 계산 np.dot(): 행렬곱 Pandas pd.Series([], index=[]): Key가 있는 리스트(Series) 생성 Series.values: Series의 값 Series.index: Series의 키 값 df.ammount: 띄어쓰기 없이 영단어로 구성된 열은 변수처럼 꺼내 쓸 수 있음 df.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 웹 크롤링 실습 - 웹 크롤링</title>
      <link>https://minyeamer.github.io/blog/aischool-03-04-web-crawling/</link>
      <pubDate>Tue, 29 Mar 2022 16:09:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-03-04-web-crawling/</guid>
      <description>Wadis 마감 상품 재고 체크 Google 메일 설정 1 2 3 4 5 6 7 8 9 10 11 12 import smtplib from email.mime.text import MIMEText def sendMail(sender, receiver, msg): smtp = smtplib.SMTP_SSL(&amp;#39;smtp.gmail.com&amp;#39;, 465) smtp.login(sender, &amp;#39;your google app password&amp;#39;) msg = MIMEText(msg) msg[&amp;#39;Subject&amp;#39;] = &amp;#39;Product is available!&amp;#39; smtp.sendmail(sender, receiver, msg.as_string()) smtp.quit() Wadis 상품 재고 체크 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 라이브러리 선언 check_status = 1 url = &amp;#39;https://www.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 웹 크롤링 실습 - 셀레니움</title>
      <link>https://minyeamer.github.io/blog/aischool-03-03-selenium/</link>
      <pubDate>Mon, 28 Mar 2022 21:23:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-03-03-selenium/</guid>
      <description>Selenium 브라우저의 기능을 체크할 때 사용하는 도구 브라우저를 조종해야할 때도 사용 Import Libraries 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 크롬 드라이버 파일 자동 다운로드 from webdriver_manager.chrome import ChromeDriverManager # 크롬 드라이버를 파일에 연결 from selenium.webdriver.chrome.service import Service from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.common.keys import Keys from bs4 import BeautifulSoup import time import pandas as pd import warnings warnings.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 텍스트 분석 실습 - 워드클라우드</title>
      <link>https://minyeamer.github.io/blog/aischool-02-04-word-cloud/</link>
      <pubDate>Mon, 28 Mar 2022 20:54:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-02-04-word-cloud/</guid>
      <description>Okt Library 한국어 형태소 분석기 KoNLPy 패키지에 속한 라이브러리 KoNLPy 테스트 1 2 3 4 5 from konlpy.tag import Okt tokenizer = Okt() tokens = tokenizer.pos(&amp;#34;아버지 가방에 들어가신다.&amp;#34;, norm=True, stem=True) print(tokens) norm: 정규화(Normalization), &amp;lsquo;안녕하세욯&amp;rsquo; -&amp;gt; &amp;lsquo;안녕하세요&amp;rsquo; stem: 어근화(Stemming, Lemmatization), (&amp;lsquo;한국어&amp;rsquo;, &amp;lsquo;Noun&amp;rsquo;) Pickle Library (Extra) 파이썬 변수를 pickle 파일로 저장/불러오기 1 2 3 4 5 with open(&amp;#39;raw_pos_tagged.pkl&amp;#39;, &amp;#39;wb&amp;#39;) as f: pickle.dump(raw_pos_tagged, f) with open(&amp;#39;raw_pos_tagged.pkl&amp;#39;,&amp;#39;rb&amp;#39;) as f: data = pickle.load(f) 크롤링 데이터 전처리 크롤링 데이터 불러오기 1 2 3 df = pd.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 웹 크롤링 실습 - 웹 스크래핑 심화</title>
      <link>https://minyeamer.github.io/blog/aischool-03-02-web-scraping-advanced/</link>
      <pubDate>Mon, 28 Mar 2022 20:31:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-03-02-web-scraping-advanced/</guid>
      <description>Import Libraries 1 2 3 4 5 6 7 import requests from bs4 import BeautifulSoup import pandas as pd from datetime import datetime import time # time.sleep() import re 뉴스 검색 결과에서 네이버 뉴스 추출 네이버 뉴스 검색 결과 URL 분석 1 2 3 4 https://search.naver.com/search.naver? where=news&amp;amp; sm=tab_jum&amp;amp; &amp;lt;!-- 불필요 --&amp;gt; query=데이터분석 네이버 뉴스 검색 URL 불러오기 1 2 3 4 5 query = input() # 데이터분석 url = f&amp;#39;https://search.naver.com/search.naver?where=news&amp;amp;query={query}&amp;#39; web = requests.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 텍스트 분석 실습 - 텍스트 분석</title>
      <link>https://minyeamer.github.io/blog/aischool-02-03-text-analysis/</link>
      <pubDate>Fri, 25 Mar 2022 19:18:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-02-03-text-analysis/</guid>
      <description>Scikit-learn Library Traditional Machine Learning (vs DL, 인공신경을 썼는지의 여부) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from sklearn import datasets, linear_model, model_selection, metrics data_total = datasets.load_boston() x = data_total.data y = data_total.target train_x, test_x, train_y, test_y = model_selection.train_test_split(x, y, test_size=0.3) # 학습 전의 모델 생성 model = linear_model.LinearRegression() # 모델에 학습 데이터를 넣으면서 학습 진행 model.fit(train_x, train_y) # 모델에게 새로운 데이터를 주면서 예측 요구 predictions = model.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 텍스트 분석 실습 - 텍스트 데이터 분석</title>
      <link>https://minyeamer.github.io/blog/aischool-02-02-text-data-exploration/</link>
      <pubDate>Fri, 25 Mar 2022 19:09:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-02-02-text-data-exploration/</guid>
      <description>Tokenizing Text Data Import Libraries 1 2 3 import nltk from nltk.corpus import stopwords from collections import Counter Set Stopwords 1 2 3 4 5 6 stop_words = stopwords.words(&amp;#34;english&amp;#34;) stop_words.append(&amp;#39;,&amp;#39;) stop_words.append(&amp;#39;.&amp;#39;) stop_words.append(&amp;#39;’&amp;#39;) stop_words.append(&amp;#39;”&amp;#39;) stop_words.append(&amp;#39;—&amp;#39;) Open Text Data 1 2 file = open(&amp;#39;movie_review.txt&amp;#39;, &amp;#39;r&amp;#39;, encoding=&amp;#34;utf-8&amp;#34;) lines = file.readlines() Tokenize 1 2 3 4 5 6 tokens = [] for line in lines: tokenized = nltk.word_tokenize(line) for token in tokenized: if token.lower() not in stop_words: tokens.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 텍스트 분석 실습 - 텍스트 분석</title>
      <link>https://minyeamer.github.io/blog/aischool-02-01-processing-text-data/</link>
      <pubDate>Fri, 25 Mar 2022 19:00:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-02-01-processing-text-data/</guid>
      <description>NLTK Library NLTK(Natural Language Toolkit)은 자연어 처리를 위한 라이브러리 1 2 3 import nltk nltk.download() 문장을 단어 수준에서 토큰화 1 2 3 sentence = &amp;#39;NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 웹 크롤링 실습 - 웹 스크래핑 기본</title>
      <link>https://minyeamer.github.io/blog/aischool-03-01-web-scraping-basic/</link>
      <pubDate>Fri, 25 Mar 2022 18:43:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-03-01-web-scraping-basic/</guid>
      <description>BeautifulSoup Library 1 2 from bs4 import BeautifulSoup from urllib.request import urlopen 단어의 검색 결과 출력 다음 어학사전 URL 불러오기 1 2 3 4 5 6 # 찾는 단어 입력 word = &amp;#39;happiness&amp;#39; url = f&amp;#39;https://alldic.daum.net/search.do?q={word}&amp;#39; web = urlopen(url) web_page = BeautifulSoup(web, &amp;#39;html.parser&amp;#39;) 찾는 단어 출력 1 2 text_search = web_page.find(&amp;#39;span&amp;#39;, {&amp;#39;class&amp;#39;: &amp;#39;txt_emph1&amp;#39;}) print(f&amp;#39;찾는 단어: {text_search.get_text()}&amp;#39;) 단어의 뜻 출력 1 2 3 4 list_search = web_page.find(&amp;#39;ul&amp;#39;, {&amp;#39;class&amp;#39;: &amp;#39;list_search&amp;#39;}) list_text = list_search.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 웹 크롤링</title>
      <link>https://minyeamer.github.io/blog/aischool-03-00-web-crawling/</link>
      <pubDate>Fri, 25 Mar 2022 18:33:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-03-00-web-crawling/</guid>
      <description>Web Crawling vs Web Scraping Web Crawling: Bot이 web을 link를 통해 돌아다니는 것 Web Scraping: Webpage에서 원하는 자료를 긇어오는 것 HTML Tags Tag&amp;rsquo;s Name: html, head, body, p, span, li, ol, ul, div Tag&amp;rsquo;s Attribute: class, id, style, href, src The Process of Web Scraping URL 분석 (query 종류 등) URL 구성 HTTP Response 얻기 (urlopen(URL) or request.get(URL).content) HTTP source 얻기 (BeautifulSoup(HTTP Response, &#39;html.parser&#39;)) HTML Tag 꺼내기 (.find(&#39;tag_name&#39;, {&#39;attr_name&#39;:&#39;attr_value&#39;})) Tag로부터 텍스트 혹은 Attribute values 꺼내기 (Tag.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 데이터 분석 실습 - 데이터 시각화</title>
      <link>https://minyeamer.github.io/blog/aischool-01-03-data-visualization/</link>
      <pubDate>Thu, 24 Mar 2022 19:41:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-01-03-data-visualization/</guid>
      <description>Visualization Libraries Plotly Altair Bokeh (Website Graph) @ https://j.mp/30772sU Data Chart Types Numeric: 숫자 자체에 의미가 있음 (온도 등), 연속형 Categoric: 숫자 너머에 의미가 있음 (성별, 강아지 품종 등), 불연속형 @ https://goo.gl/ErLHCY @ http://j.mp/2JcEENe GeoJSON Data 1 2 3 4 5 6 import json # 한국의 지도 데이터 참조 # @ https://github.com/southkorea/southkorea-maps geo_path = &amp;#39;skorea_municipalities_geo_simple.json&amp;#39; geo_str = json.load(open(geo_path, encoding=&amp;#39;utf-8&amp;#39;)) JSON(Javascript Object Notation): 데이터 교환을 위한 표준 포맷 GeoJSON: 지도 데이터 포맷 json.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 데이터 분석 실습 - 데이터 탐색</title>
      <link>https://minyeamer.github.io/blog/aischool-01-02-data-exploration/</link>
      <pubDate>Wed, 23 Mar 2022 21:20:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-01-02-data-exploration/</guid>
      <description>Visualization Library 1 2 3 import seaborn as sns sns.heatmap(gu_df[]) Visualization Issues 한글 데이터 표시 오류 서로 다른 자릿수로 구성된 열에 동일한 스케일 적용 시각화된 테이블 형태의 비직관성 문제 인구수가 고려되지 않은 부정확한 데이터 한글 데이터 시각화 1 2 3 4 5 6 7 8 matplotlib inline # Windows font_name = font_manager.FontProperties(fname=&amp;#34;C:/~/malgun.ttf&amp;#34;).get_name() rc(&amp;#39;font&amp;#39;, family=font_name) # Mac rc(&amp;#39;font&amp;#39;, family=&amp;#39;AppleGothic&amp;#39;) Feature Scaling/Normalization Min-Max Algorithm 열에 대한 최솟값(min)을 0, 열에 대한 최댓값(max)를 1로 맞춤 기존 열을 old_x, 새로운 열을 new_x라 할 때,</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 데이터 분석 실습 - 데이터 분석</title>
      <link>https://minyeamer.github.io/blog/aischool-01-01-data-analysis/</link>
      <pubDate>Wed, 23 Mar 2022 21:08:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-01-01-data-analysis/</guid>
      <description>Practice Data 서울시 범죄현황 통계자료 범죄별로 검거율 계산 1 2 3 4 5 6 7 # gu_df는 실습 자료에 서울시 경찰청의 소속 구 데이터를 추가한 DataFrame gu_df[&amp;#39;강간검거율&amp;#39;] = gu_df[&amp;#39;강간(검거)&amp;#39;]/gu_df[&amp;#39;강간(발생)&amp;#39;]*100 gu_df[&amp;#39;강도검거율&amp;#39;] = gu_df[&amp;#39;강도(검거)&amp;#39;]/gu_df[&amp;#39;강도(발생)&amp;#39;]*100 gu_df[&amp;#39;살인검거율&amp;#39;] = gu_df[&amp;#39;살인(검거)&amp;#39;]/gu_df[&amp;#39;살인(발생)&amp;#39;]*100 gu_df[&amp;#39;절도검거율&amp;#39;] = gu_df[&amp;#39;절도(검거)&amp;#39;]/gu_df[&amp;#39;절도(발생)&amp;#39;]*100 gu_df[&amp;#39;폭력검거율&amp;#39;] = gu_df[&amp;#39;폭력(검거)&amp;#39;]/gu_df[&amp;#39;폭력(발생)&amp;#39;]*100 gu_df[&amp;#39;검거율&amp;#39;] = gu_df[&amp;#39;소계(검거)&amp;#39;]/gu_df[&amp;#39;소계(발생)&amp;#39;]*100 해당 계산법의 문제:
이전 연도에 발생한 사건이 많이 검거될 경우 검거율이 100%를 초과 발생 건수가 0인 경우 검거율에 결측치(N/A)가 발생 초과된 검거율을 최댓값으로 조정:
1 2 # 검거율에 해당되는 열의 집합 columns columns = [&amp;#39;강간검거율&amp;#39;, &amp;#39;강도검거율&amp;#39;, &amp;#39;살인검거율&amp;#39;, &amp;#39;절도검거율&amp;#39;, &amp;#39;폭력검거율&amp;#39;] 모든 행에 대해 반복문 실행 1 2 3 4 for row_index, row in gu_df_rate.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 데이터 분석</title>
      <link>https://minyeamer.github.io/blog/aischool-01-00-data-analysis/</link>
      <pubDate>Wed, 23 Mar 2022 21:04:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-01-00-data-analysis/</guid>
      <description>Data Types Structured Data Relational Database Spread Sheets Semi-structured Data System Logs Sensor Data HTML Unstructured Data Image / Video Sound Document Data Collection Tools Logstash: 로그 데이터 (SQL 구조화) Elasticsearch: 데이터가 자유로움 Kibana: 그래프 자동화 Elastic Stack, Zepplin API Meanings 웹 상에서의 API 라이브러리/프로그램 도구 (텐서플로우에서의 함수 등) Open API 공익적인 목적 서비스 활성화 목적 (서드파티 앱 지원) SNS에서 무분별한 크롤링으로 인한 서버 과부하 대비 Missing Data Handling 랜덤하게 채워넣기 주변 (행의) 값들로 채워넣기 열의 대푯값을 계싼해서 채워넣기 (mea, median) 전체 행들을 그룹으로 묶어낸 후 그룹 내 해당 열의 값을 예측해 채워넣기 나머지 열들로 머신러닝 예측모델을 만든 후 해당 열의 값을 예측해 채워넣기 특정 기준 비율 이상으로 빠져있을 시 해당 열 삭제 Pandas Functions Referring df = pd.</description>
    </item>
    
    <item>
      <title>[코드라이언] 파이썬 심화</title>
      <link>https://minyeamer.github.io/blog/aischool-00-02-python-advanced/</link>
      <pubDate>Sun, 20 Mar 2022 17:59:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-00-02-python-advanced/</guid>
      <description>Crawling 크롤러는 웹 페이지의 데이터를 모아주는 소프트웨어 크롤링은 크롤러를 사용해 웹 페이지의 데이터를 추출해 내는 행위 Request request 모듈의 get() 함수는 서버에게 html 정보를 요청 get() 함수는 url, 파라미터 값을 받고 request.Response를 반환 정상적인 응답을 받을 경우 Response [200] 반환 응답값을 reponse 변수에 넣고 response.text를 출력하면 html 코드 출력 BeautifulSoup bs4 모듈의 BeautifulSoup 기능은 입력값을 의미있는 데이터로 변환 1 2 3 4 5 soup = BeautifulSoup(response.text, &amp;#39;html.parser&amp;#39;) soup.title # html 코드에서 title에 해당하는 태그를 반환 soup.</description>
    </item>
    
    <item>
      <title>[코드라이언] 파이썬 기초</title>
      <link>https://minyeamer.github.io/blog/aischool-00-01-python-basic/</link>
      <pubDate>Sun, 20 Mar 2022 16:53:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-00-01-python-basic/</guid>
      <description>for문 문장을 여러 번 실행할 떄 복사 붙여넣기로 길게 늘이지 않고 단순하게 표현하기 위한 구문 for문에 적용되는 문장은 들여쓰기를 해야 함 1 2 for _ in range(30): print(random.choice([&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;])) while문 for문과 마찬가지로 문장을 반복실행할 수 있는 구문 조건을 충족할 경우 반복을 멈춤 True를 조건으로 사용 시 무한루프 발생 while True: break 명령어를 통해 반복문 종료 가능 변수 객체에 이름표를 붙이고 이름표가 불리면 내용물인 객체를 반환
lunch = random.choice([&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;]) 딕셔너리 &amp;ldquo;xx은 xx이다&amp;quot;를 코드로 표현한 자료구조 딕셔너리의 get 명령어는 Key에 해당하는 값을 반환 값을 추가할 때는 dict[a] = b 형식으로 추가 딕셔너리의 clear 명령어는 딕셔너리 내용을 초기화 집합 중복된 값을 제거하여 표현하는 자료구조 set()으로 집합 생성 합집합: set1 | set2 교집합: set1 &amp;amp; set2 차집합: set1 - set2 조건문 상황에 따른 처리를 하기 위한 구문 if 조건:으로 조건문 선언 같은 경우를 구할 땐 a == b 나머지 경우에 대해서는 else 사용 pip/conda pip: 파이썬에서 지원받는 패키지만을 가져옴 (라이브러리만 맞으면 설치) conda: 아나콘다에서 지원받는 패키지만을 가져옴 (아나콘다에서 유리) conda의 장점: 기존 Python 및 라이브러리 버전 충돌을 체크함 conda의 단점: 설치 속도가 너무 느림 설치가 너무 느리거나 다른 라이브러리에 대한 영향이 없을 경우 pip 사용 라이브러리 참조 파일 생성 시 pip install -r requirements.</description>
    </item>
    
    <item>
      <title>[AI SCHOOL 5기] 첫 주차</title>
      <link>https://minyeamer.github.io/blog/ai-school-00-00-start/</link>
      <pubDate>Sun, 20 Mar 2022 11:38:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/ai-school-00-00-start/</guid>
      <description>AI SCHOOL 지원 과정 아직 군에 복무 중이던 시절, 전역한 후 바로 취업하기 위해 국비, 부트캠프 과정을 탐색하던 중 AI SCHOOL을 발견했다. 이떄 개인적으로 가격 비교, 사용자 맞춤 추천 등의 기능을 포함한 서비스를 구상하고 있었는데 AI 기술이 바로 그것이었다. AI SCHOOL과 함께 눈에 들었던 게 SW마에스트로였지만 5월까지는 군인 신분인 나와는 맞지 않아 아쉽게 포기했다. AI SCHOOL의 지원 과정은 서류(자기소개서)와 과제(영상) 순으로 진행되었다. 영상을 찍어야 할 때 아직 군대 안에 있었기에 어려웠지만 모종의 방법으로 촬영에 성공했다.</description>
    </item>
    
  </channel>
</rss>
