<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PySpark on Minystory</title>
    <link>https://minyeamer.github.io/tags/pyspark/</link>
    <description>Recent content in PySpark on Minystory</description>
    <generator>Hugo</generator>
    <language>ko-kr</language>
    <lastBuildDate>Sat, 19 Jul 2025 23:53:45 +0900</lastBuildDate>
    <atom:link href="https://minyeamer.github.io/tags/pyspark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Apache Spark - 고차함수(Higher-Order Functions)</title>
      <link>https://minyeamer.github.io/blog/spark-study-8/</link>
      <pubDate>Sat, 19 Jul 2025 23:53:45 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-8/</guid>
      <description>&lt;h2 id=&#34;user-defined-functions&#34;&gt;User-Defined Functions&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#user-defined-functions&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;스파크는 자신의 기능을 정의할 수 있는 유연성을 제공한다.&#xA;이를 사용자 정의 함수(User-Defined Function, UDF)라고 한다.&lt;/p&gt;&#xA;&lt;p&gt;UDF를 생성하는 이점은 스파크 SQL 안에서 이를 사용할 수 있다는 것이다.&lt;/p&gt;&#xA;&lt;h3 id=&#34;spark-sql-udf-활용&#34;&gt;Spark SQL UDF 활용&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-sql-udf-%ed%99%9c%ec%9a%a9&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;다음은 스파크 SQL UDF를 만드는 예시로, 인수를 세제곱하는 함수 &lt;code&gt;cubed()&lt;/code&gt; 를 생성한다.&lt;/p&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;python&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;python&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyspark.sql.types&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LongType&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 큐브 함수 생성&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cubed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# UDF로 등록&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;udf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;register&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cubed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cubed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LongType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;p&gt;스파크 SQL을 사용하여 &lt;code&gt;cubed()&lt;/code&gt; 함수를 실행할 수 있다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark - 데이터 소스</title>
      <link>https://minyeamer.github.io/blog/spark-study-6/</link>
      <pubDate>Thu, 10 Jul 2025 23:56:54 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-6/</guid>
      <description>&lt;h2 id=&#34;data-source-api&#34;&gt;Data Source API&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#data-source-api&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;dataframereader&#34;&gt;DataFrameReader&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#dataframereader&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;DataFrameReader는 데이터 소스에서 DataFrame으로 데이터를 읽는 방식이다. 아래와 같이 권장되는 사용 패턴이 있다.&lt;/p&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;python&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;python&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;DataFrameReader&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 데이터 소스 형식&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;option&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;key&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 키/값 쌍으로 연결되는 옵션&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# DDL 문자열 또는 StructType&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 데이터 소스의 경로&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;p&gt;데이터 소스 형식에는 인수로 &amp;quot;parquet&amp;quot;, &amp;quot;csv&amp;quot;, &amp;quot;txt&amp;quot;, &amp;quot;json&amp;quot;, &amp;quot;jdbc&amp;quot;, &amp;quot;orc&amp;quot;, &amp;quot;avro&amp;quot; 등이 전달된다.&#xA;기본값은 &amp;quot;parquet&amp;quot; 또는 &lt;code&gt;spark.sql.sources.default&lt;/code&gt; 에 지정된 항목이 설정된다.&lt;/p&gt;&#xA;&lt;p&gt;JSON이나 CSV 형식은 &lt;code&gt;option()&lt;/code&gt; 함수에서 스키마를 유추하는 &lt;code&gt;inferSchema&lt;/code&gt; 옵션을 적용할 수 있지만,&#xA;스키마를 제공하면 로드 속도가 빨라진다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark - 스파크 SQL</title>
      <link>https://minyeamer.github.io/blog/spark-study-5/</link>
      <pubDate>Sat, 05 Jul 2025 23:03:04 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-5/</guid>
      <description>&lt;h2 id=&#34;spark-sql&#34;&gt;Spark SQL&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-sql&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;스파크 SQL은 다음과 같은 특징을 갖는다.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;정형화 API가 엔진으로 제공한다.&lt;/li&gt;&#xA;&lt;li&gt;다양한 정형 데이터(Parquet 등)를 읽거나 쓸 수 있다.&lt;/li&gt;&#xA;&lt;li&gt;외부 BI 툴(태블로 등)의 데이터 소스나 RDBMS(MySQL 등)의 데이터를 쿼리할 수 있다.&lt;/li&gt;&#xA;&lt;li&gt;정형 데이터에 대해 SQL 쿼리를 실행할 수 있는 대화형 쉘을 제공한다.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;spark-sql-사용법&#34;&gt;Spark SQL 사용법&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-sql-%ec%82%ac%ec%9a%a9%eb%b2%95&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;python&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;python&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;SELECT * FROM table&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;p&gt;&lt;code&gt;SparkSession&lt;/code&gt; 객체에 &lt;code&gt;sql()&lt;/code&gt; 함수를 사용한다. 쿼리 결과로는 &lt;code&gt;DataFrame&lt;/code&gt; 객체가 반환된다.&lt;/p&gt;&#xA;&lt;h3 id=&#34;spark-sql-활용-python&#34;&gt;Spark SQL 활용 (Python)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-sql-%ed%99%9c%ec%9a%a9-python&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/databricks/LearningSparkV2/tree/master/databricks-datasets/learning-spark-v2/flights&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;databricks/LearningSparkV2&lt;/a&gt;의&#xA;&lt;code&gt;databricks-datasets/learning-spark-v2/flights&lt;/code&gt; 경로에서 미국 항공편 운항 지연 데이터세트&#xA;&lt;code&gt;departuredelays.csv&lt;/code&gt; 를 가져온다. 해당 데이터를 활용해 아래와 같이 임시뷰를 생성한다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark - Structured API</title>
      <link>https://minyeamer.github.io/blog/spark-study-4/</link>
      <pubDate>Sun, 29 Jun 2025 20:01:48 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-4/</guid>
      <description>&lt;h2 id=&#34;spark-structure&#34;&gt;Spark Structure&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-structure&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;정형화 API에 대해 알아보기에 앞서, 정형적 모델 이전의 RDD 프로그래밍 API 모델을 확인해본다.&lt;/p&gt;&#xA;&lt;h3 id=&#34;rdd&#34;&gt;RDD&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#rdd&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;RDD는 Spark 1.x 버전에 있던 저수준의 DSL을 의미하고, 스파크에서 가장 기본적인 추상적인 부분이다.&#xA;RDD에는 세 가지의 핵심으로 특성이 있다.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;의존성&lt;br&gt;&#xA;어떤 입력을 필요로 하고 RDD가 어떻게 만들어지는지 Spark에게 가르쳐 주는 의존성이 필요하다.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;파티션&lt;br&gt;&#xA;Executor들에 작업을 분산해 파티션별로 병렬 연산할 수 있는 능력을 부여한다. 지역성 정보를 사용하여&#xA;각 Executor가 가까이 있는 Executor에게 우선적으로 작업을 보낸다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark - 설치하고 PySpark 실행하기</title>
      <link>https://minyeamer.github.io/blog/spark-study-2/</link>
      <pubDate>Sat, 28 Jun 2025 21:55:14 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-2/</guid>
      <description>&lt;h2 id=&#34;spark-installation&#34;&gt;Spark Installation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-installation&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;  &lt;p&gt;Apple Silicon 환경에서 스파크 설치를 진행합니다.&lt;br&gt;&#xA;각 섹션의 이미지를 클릭하면 설치 페이지 또는 관련 문서로 이동합니다.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;h3 id=&#34;spark-설치&#34;&gt;Spark 설치&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-%ec%84%a4%ec%b9%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;div&gt;&lt;a href=&#34;https://spark.apache.org/downloads.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://dl.dropboxusercontent.com/scl/fi/ziy6h7z1oxy7puilm5ml2/spark-03-download-spark.webp?rlkey=bv8ckikaauinh733icd2l9gem&amp;amp;dl=0&#34; alt=&#34;Download Apache Spark&#34;style=&#34;width: 100%; &#34;&gt;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://spark.apache.org/downloads.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;아파치 스파크 다운로드 페이지&lt;/a&gt;로 가서&#xA;최신 버전 4.0.0 및 &amp;quot;Pre-built for Apache Hadoop&amp;quot; 옵션을 선택하면 해당 버전의 다운로드 링크&#xA;&lt;a href=&#34;https://www.apache.org/dyn/closer.lua/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;spark-4.0.0-bin-hadoop3.tgz&lt;/a&gt;&#xA;가 나타난다. 해당 링크로 이동하면 아래와 같이 Hadoop 관련 바이너리 파일이 포함된 압축 파일의 설치 경로를 확인할 수 있다.&lt;/p&gt;&#xA;&lt;div&gt;&lt;a href=&#34;https://www.apache.org/dyn/closer.lua/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://dl.dropboxusercontent.com/scl/fi/20hbdfye2kl3jvmytp6bk/spark-04-download-spark-tgz.webp?rlkey=o7zeq22r59epazjwef0ck0s10&amp;amp;dl=0&#34; alt=&#34;https://www.apache.org/dyn/closer.lua/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz&#34;style=&#34;width: 100%; &#34;&gt;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;브라우저 또는 &lt;code&gt;curl&lt;/code&gt;, &lt;code&gt;wget&lt;/code&gt; 등 명령어를 통해 압축 파일을 내려받을 수 있다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;bash&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;bash&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://dlcdn.apache.org/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;압축 해제 프로그램을 사용하거나, 터미널에서 아래 명령어를 입력하여 압축 해제한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;bash&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;bash&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar zxvf spark-4.0.0-bin-hadoop3.tgz&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;Spark 경로에 접근하기 위해 환경변수를 설정한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;bash&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;bash&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vi ~/.zshrc&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;vi 편집기로 .zshrc 파일에 Spark 경로를 등록한다. &lt;code&gt;SPARK_HOME&lt;/code&gt; 은 압축 해제한 Spark 경로를 입력한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;bash&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;bash&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;SPARK_HOME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/Users/&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;username&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;/spark-4.0.0&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;:&lt;span class=&#34;nv&#34;&gt;$SPARK_HOME&lt;/span&gt;/bin:&lt;span class=&#34;nv&#34;&gt;$SPARK_HOME&lt;/span&gt;/sbin&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;변경 사항을 적용하기 위해 터미널을 재시작하거나 아래 명령어를 실행한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;text&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;source ~/.zshrc&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;주의할 점은 Spark를 실행하기 전에 Java와 Hadoop이 설치되어 있어야 한다.&#xA;보통은 Java 또는 Hadoop 버전에 맞춰서 Spark를 설치하지만,&#xA;어떤 것도 설치되어 있지 않기 때문에 스파크 버전에 맞춰서 Java와 Hadoop을 설치한다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark - 스파크의 기본 개념과 아키텍처</title>
      <link>https://minyeamer.github.io/blog/spark-study-1/</link>
      <pubDate>Sun, 22 Jun 2025 18:42:10 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-1/</guid>
      <description>&lt;h2 id=&#34;study-overview&#34;&gt;Study Overview&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#study-overview&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=296379664&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;러닝 스파크 2nd 개정판&lt;/a&gt; 과정을 따릅니다.&lt;/p&gt;&#xA;&lt;h3 id=&#34;목적&#34;&gt;목적&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%eb%aa%a9%ec%a0%81&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;대용량 데이터 처리를 위한 아파치 스파크를 이론적으로 학습&lt;/li&gt;&#xA;&lt;li&gt;책에서 대상으로 하는 스파크 3.x 버전과 25년 5월 출시된 Spark 4.0 버전을 비교&lt;/li&gt;&#xA;&lt;li&gt;각 챕터에서 배운 것으로 실습할만한 것이 있다면 추가로 시도하기&lt;/li&gt;&#xA;&lt;li&gt;실습은 PySpark API를 사용하며, 최신화된&#xA;&lt;a href=&#34;https://spark.apache.org/docs/4.0.0/api/python/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;PySpark 4.0.0 문서&lt;/a&gt;를 참조&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;챕터&#34;&gt;챕터&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%ec%b1%95%ed%84%b0&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;  &lt;ol&gt;&#xA;&lt;li&gt;아파치 스파크 소개: 통합 분석 엔진&lt;/li&gt;&#xA;&lt;li&gt;아파치 스파크 다운로드 및 시작&lt;/li&gt;&#xA;&lt;li&gt;아파치 스파크의 정형화 API&lt;/li&gt;&#xA;&lt;li&gt;스파크 SQL과 데이터 프레임: 내장 데이터 소스 소개&lt;/li&gt;&#xA;&lt;li&gt;스파크 SQL과 데이터 프레임: 외부 데이터 소스와 소통하기&lt;/li&gt;&#xA;&lt;li&gt;스파크 SQL과 데이터세트&lt;/li&gt;&#xA;&lt;li&gt;스파크 애플리케이션의 최적화 및 튜닝&lt;/li&gt;&#xA;&lt;li&gt;정형화 스트리밍&lt;/li&gt;&#xA;&lt;li&gt;아파치 스파크를 통한 안정적인 데이터 레이크 구축&lt;/li&gt;&#xA;&lt;li&gt;MLlib을 사용한 머신러닝&lt;/li&gt;&#xA;&lt;li&gt;아파치 스파크로 머신러닝 파이프라인 관리, 배포 및 확장&lt;/li&gt;&#xA;&lt;li&gt;에필로그: 아파치 스파크 3.0&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/blockquote&gt;&lt;h2 id=&#34;spark-overview&#34;&gt;Spark Overview&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-overview&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;스파크의-시작&#34;&gt;스파크의 시작&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%ec%8a%a4%ed%8c%8c%ed%81%ac%ec%9d%98-%ec%8b%9c%ec%9e%91&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;RDBMS 같은 전통적인 저장 시스템으로는 구글이 방대한 규모의 인터넷 문서를 다룰 수 없어&#xA;구글 파일 시스템(GFS), 맵리듀스(MapReduce), 빅테이블(BigTable) 등을 만들어 냈다.&#xA;GFS는 클러스터 환경에서 분산 파일시스템을 제공하고, 빅테이블은 GFS를 기반으로 대규모 데이터 저장 수단을 제공한다.&#xA;맵리듀스는 함수형 프로그래밍 기반으로 대규모 데이터 분산 처리를 구현했다. 클러스터의 워커 노드들이&#xA;분산된 데이터에 연산을 하고(Map), 그 결과를 하나로 합쳐(Reduce) 최종 결과를 생성해낸다.&#xA;이러한 접근 방식은 네트워크 트래픽을 크게 감소시키면서 로컬 디스크에 대한 I/O를 극대화한다.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
