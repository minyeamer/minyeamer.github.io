<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Gradient Boosting on Minystory</title>
    <link>https://minyeamer.github.io/tags/gradient-boosting/</link>
    <description>Recent content in Gradient Boosting on Minystory</description>
    <image>
      <url>https://github.com/minyeamer/til/blob/main/.media/main/thumbnail.png?raw=true</url>
      <link>https://github.com/minyeamer/til/blob/main/.media/main/thumbnail.png?raw=true</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 13 Apr 2022 20:51:00 +0900</lastBuildDate><atom:link href="https://minyeamer.github.io/tags/gradient-boosting/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - Gradient Boosting</title>
      <link>https://minyeamer.github.io/blog/aischool-06-03-gradient-boosting/</link>
      <pubDate>Wed, 13 Apr 2022 20:51:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-03-gradient-boosting/</guid>
      <description>XG Boost Extreme Gradient Boosting 대용량 분산 처리를 위한 Gradient Boosting 라이브러리 Decision Tree(의사결정나무) 에 Boosting 기법을 적용한 알고리즘 AdaBoost는 학습 성능은 좋으나, 모델의 학습 시간이 오래 걸리는 단점 병렬 처리 기법을 적용하여 Gradient Boost보다 학습 속도를 끌어올림 Hyper-Parameter가 너무 많기 때문에 권장 세팅 사용 @ http://j.mp/2PukeTS Decision Tree 이해하기 쉽고 해석도 용이함 입력 데이터의 작은 변동에도 Tree의 구성이 크게 달라짐 과적합이 쉽게 발생 (중간에 멈추지 않으면 Leaf 노드에 하나의 데이터만 남게 됨) 의사결정나무의 문제를 해결하기 위해 Boosting 기법 활용 ex) 테니스를 쳤던 과거 데이터를 보고 날씨 정보를 이용해 의사결정 AdaBoost Adaptive Boosting 데이터를 바탕으로 여러 weak learner 들을 반복적으로 생성 앞선 learner가 잘못 예측한 데이터에 가중치를 부여하고 학습 최종적으로 만들어진 strong learner를 이용하여 실제 예측 진행 에러를 최소화하는 weight를 매기기 위해 경사 하강법 사용 ex) Regression: 평균/가중평균, Classification: 투표 XG Boost References NGBoost Explained (Comparison to LightGBM and XGBoost) Gradient Boosting Interactive Playground Gradient Boosting explained Comparison for hyperparams of XGBoost &amp;amp; LightGBM XGBoost Parameters XG Boost 하이퍼 파라미터 상세 설명 Complete Guide to Parameter Tuning in XGBoost (with python codes) Microsoft EBM (Explainable Boosting Machine) 정형데이터를 위한 인공신경망 모델, TabNet Ensemble 주어진 데이터를 이용하여 여러 개의 서로 다른 예측 모형을 생성한 후,</description>
    </item>
    
  </channel>
</rss>
