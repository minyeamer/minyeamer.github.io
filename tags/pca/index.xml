<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>PCA on Minystory</title>
    <link>https://minyeamer.github.io/tags/pca/</link>
    <description>Recent content in PCA on Minystory</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 13 Apr 2022 22:03:00 +0900</lastBuildDate><atom:link href="https://minyeamer.github.io/tags/pca/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[AI SCHOOL 5기] 머신 러닝 실습 - PCA</title>
      <link>https://minyeamer.github.io/blog/aischool-06-07-pca/</link>
      <pubDate>Wed, 13 Apr 2022 22:03:00 +0900</pubDate>
      
      <guid>https://minyeamer.github.io/blog/aischool-06-07-pca/</guid>
      <description>Principal Component Analysis 차원 축소를 통해 최소 차원의 정보로 원래 차원의 정보를 모사하는 알고리즘 데이터의 열의 수가 많아 학습 속도가 느려질 때 열의 수를 줄이기 위해 사용 Dimension Reduction: 고차원 벡터에서 일부 차원의 값을 모두 0으로 만들어 차원을 줄임 원래의 고차원 벡터의 특성을 최대한 살리기 위해 가장 분산이 높은 방향으로 회전 변환 진행 전체 데이터를 기반으로 분산이 가장 큰 축을 찾아 PC 1으로 만들고,
PC 1에 직교하는 축 중에서 분산이 가장 큰 축을 PC 2로 만드는 과정 반복 정보의 누락이 있기 때문에 경우에 따라 모델의 성능 하락 발생 Feature Selection: 기존에 존재하는 열 중에 n개를 선택 Feature Extraction: 기존에 있는 열들을 바탕으로 새로운 열들을 만들어냄 (차원 축소) Learning Process Import Libraries 1 2 from sklearn import decomposition from sklearn import datasets Load Model 1 2 3 iris = datasets.</description>
    </item>
    
  </channel>
</rss>
