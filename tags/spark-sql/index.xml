<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark SQL on Minystory</title>
    <link>https://minyeamer.github.io/tags/spark-sql/</link>
    <description>Recent content in Spark SQL on Minystory</description>
    <generator>Hugo</generator>
    <language>ko-kr</language>
    <lastBuildDate>Sat, 19 Jul 2025 23:53:45 +0900</lastBuildDate>
    <atom:link href="https://minyeamer.github.io/tags/spark-sql/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Apache Spark - 고차함수(Higher-Order Functions)</title>
      <link>https://minyeamer.github.io/blog/spark-study-8/</link>
      <pubDate>Sat, 19 Jul 2025 23:53:45 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-8/</guid>
      <description>&lt;h2 id=&#34;user-defined-functions&#34;&gt;User-Defined Functions&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#user-defined-functions&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;스파크는 자신의 기능을 정의할 수 있는 유연성을 제공한다.&#xA;이를 사용자 정의 함수(User-Defined Function, UDF)라고 한다.&lt;/p&gt;&#xA;&lt;p&gt;UDF를 생성하는 이점은 스파크 SQL 안에서 이를 사용할 수 있다는 것이다.&lt;/p&gt;&#xA;&lt;h3 id=&#34;spark-sql-udf-활용&#34;&gt;Spark SQL UDF 활용&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-sql-udf-%ed%99%9c%ec%9a%a9&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;다음은 스파크 SQL UDF를 만드는 예시로, 인수를 세제곱하는 함수 &lt;code&gt;cubed()&lt;/code&gt; 를 생성한다.&lt;/p&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;python&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;python&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyspark.sql.types&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LongType&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 큐브 함수 생성&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cubed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# UDF로 등록&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;udf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;register&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cubed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cubed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LongType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;p&gt;스파크 SQL을 사용하여 &lt;code&gt;cubed()&lt;/code&gt; 함수를 실행할 수 있다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark - 데이터 소스</title>
      <link>https://minyeamer.github.io/blog/spark-study-6/</link>
      <pubDate>Thu, 10 Jul 2025 23:56:54 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-6/</guid>
      <description>&lt;h2 id=&#34;data-source-api&#34;&gt;Data Source API&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#data-source-api&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;dataframereader&#34;&gt;DataFrameReader&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#dataframereader&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;DataFrameReader는 데이터 소스에서 DataFrame으로 데이터를 읽는 방식이다. 아래와 같이 권장되는 사용 패턴이 있다.&lt;/p&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;python&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;python&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;DataFrameReader&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 데이터 소스 형식&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;option&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;key&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 키/값 쌍으로 연결되는 옵션&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# DDL 문자열 또는 StructType&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 데이터 소스의 경로&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;p&gt;데이터 소스 형식에는 인수로 &amp;ldquo;parquet&amp;rdquo;, &amp;ldquo;csv&amp;rdquo;, &amp;ldquo;txt&amp;rdquo;, &amp;ldquo;json&amp;rdquo;, &amp;ldquo;jdbc&amp;rdquo;, &amp;ldquo;orc&amp;rdquo;, &amp;ldquo;avro&amp;rdquo; 등이 전달된다.&#xA;기본값은 &amp;ldquo;parquet&amp;rdquo; 또는 &lt;code&gt;spark.sql.sources.default&lt;/code&gt; 에 지정된 항목이 설정된다.&lt;/p&gt;&#xA;&lt;p&gt;JSON이나 CSV 형식은 &lt;code&gt;option()&lt;/code&gt; 함수에서 스키마를 유추하는 &lt;code&gt;inferSchema&lt;/code&gt; 옵션을 적용할 수 있지만,&#xA;스키마를 제공하면 로드 속도가 빨라진다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark - 스파크 SQL</title>
      <link>https://minyeamer.github.io/blog/spark-study-5/</link>
      <pubDate>Sat, 05 Jul 2025 23:03:04 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-5/</guid>
      <description>&lt;h2 id=&#34;spark-sql&#34;&gt;Spark SQL&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-sql&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;스파크 SQL은 다음과 같은 특징을 갖는다.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;정형화 API가 엔진으로 제공한다.&lt;/li&gt;&#xA;&lt;li&gt;다양한 정형 데이터(Parquet 등)를 읽거나 쓸 수 있다.&lt;/li&gt;&#xA;&lt;li&gt;외부 BI 툴(태블로 등)의 데이터 소스나 RDBMS(MySQL 등)의 데이터를 쿼리할 수 있다.&lt;/li&gt;&#xA;&lt;li&gt;정형 데이터에 대해 SQL 쿼리를 실행할 수 있는 대화형 쉘을 제공한다.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;spark-sql-사용법&#34;&gt;Spark SQL 사용법&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-sql-%ec%82%ac%ec%9a%a9%eb%b2%95&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;python&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;python&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;SELECT * FROM table&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;p&gt;&lt;code&gt;SparkSession&lt;/code&gt; 객체에 &lt;code&gt;sql()&lt;/code&gt; 함수를 사용한다. 쿼리 결과로는 &lt;code&gt;DataFrame&lt;/code&gt; 객체가 반환된다.&lt;/p&gt;&#xA;&lt;h3 id=&#34;spark-sql-활용-python&#34;&gt;Spark SQL 활용 (Python)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-sql-%ed%99%9c%ec%9a%a9-python&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/databricks/LearningSparkV2/tree/master/databricks-datasets/learning-spark-v2/flights&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;databricks/LearningSparkV2&lt;/a&gt;의&#xA;&lt;code&gt;databricks-datasets/learning-spark-v2/flights&lt;/code&gt; 경로에서 미국 항공편 운항 지연 데이터세트&#xA;&lt;code&gt;departuredelays.csv&lt;/code&gt; 를 가져온다. 해당 데이터를 활용해 아래와 같이 임시뷰를 생성한다.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
