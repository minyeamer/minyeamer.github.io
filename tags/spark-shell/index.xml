<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark Shell on Minystory</title>
    <link>https://minyeamer.github.io/tags/spark-shell/</link>
    <description>Recent content in Spark Shell on Minystory</description>
    <generator>Hugo</generator>
    <language>ko-kr</language>
    <lastBuildDate>Sun, 29 Jun 2025 12:50:06 +0900</lastBuildDate>
    <atom:link href="https://minyeamer.github.io/tags/spark-shell/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Apache Spark - 스파크 애플리케이션 및 RDD</title>
      <link>https://minyeamer.github.io/blog/spark-study-3/</link>
      <pubDate>Sun, 29 Jun 2025 12:50:06 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-3/</guid>
      <description>&lt;h2 id=&#34;spark-application&#34;&gt;Spark Application&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-application&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Spark Application은 Driver Process 하나와 일련의 일련의 Executors로 구성된다.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://dl.dropboxusercontent.com/scl/fi/efpu71pb72iioxddwha2y/spark-09-spark-applications.webp?rlkey=p9badhgpaaylfwocm4hq7mpsg&amp;amp;dl=0&#34; alt=&#34;Spark Applications Explained | Databricks&#34; /&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;driver-process&#34;&gt;Driver Process&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#driver-process&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Driver Process는 main() 함수를 실행하고 클러스터 내 노드에서 세 가지 작업을 담당한다.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Spark Application 관련 정보를 유지한다.&lt;/li&gt;&#xA;&lt;li&gt;사용자의 프로그램이나 입력에 대응한다.&lt;/li&gt;&#xA;&lt;li&gt;Executor 작업을 분석, 배포, 예약한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;executor&#34;&gt;Executor&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#executor&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Executor는 Driver가 할당한 작업을 실제로 실행하는 역할을 하는데, 두 가지 작업을 담당한다.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Driver가 할당한 Task를 실행한다.&lt;/li&gt;&#xA;&lt;li&gt;Task의 상태와 결과를 Driver 노드에 보고한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;cluster-manager&#34;&gt;Cluster Manager&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#cluster-manager&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;실물 시스템을 제어하고 Spark Application에 리소스를 할당하는 작업은 Cluster Manager가 맡는다.&#xA;Spark Application의 실행 과정에서 Cluster Manager는 Application이 실행되는 물리적인 머신을 관리한다.&#xA;Spark Application은 클러스터에서 독립적인 프로세스로 실행되며, SparkContext 객체에 의해 조정된다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark - 설치하고 PySpark 실행하기</title>
      <link>https://minyeamer.github.io/blog/spark-study-2/</link>
      <pubDate>Sat, 28 Jun 2025 21:55:14 +0900</pubDate>
      <guid>https://minyeamer.github.io/blog/spark-study-2/</guid>
      <description>&lt;h2 id=&#34;spark-installation&#34;&gt;Spark Installation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-installation&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;  &lt;p&gt;Apple Silicon 환경에서 스파크 설치를 진행합니다.&lt;br&gt;&#xA;각 섹션의 이미지를 클릭하면 설치 페이지 또는 관련 문서로 이동합니다.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;h3 id=&#34;spark-설치&#34;&gt;Spark 설치&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#spark-%ec%84%a4%ec%b9%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;div&gt;&lt;a href=&#34;https://spark.apache.org/downloads.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://dl.dropboxusercontent.com/scl/fi/ziy6h7z1oxy7puilm5ml2/spark-03-download-spark.webp?rlkey=bv8ckikaauinh733icd2l9gem&amp;amp;dl=0&#34; alt=&#34;Download Apache Spark&#34;style=&#34;width: 100%; &#34;&gt;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://spark.apache.org/downloads.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;아파치 스파크 다운로드 페이지&lt;/a&gt;로 가서&#xA;최신 버전 4.0.0 및 &amp;ldquo;Pre-built for Apache Hadoop&amp;rdquo; 옵션을 선택하면 해당 버전의 다운로드 링크&#xA;&lt;a href=&#34;https://www.apache.org/dyn/closer.lua/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;spark-4.0.0-bin-hadoop3.tgz&lt;/a&gt;&#xA;가 나타난다. 해당 링크로 이동하면 아래와 같이 Hadoop 관련 바이너리 파일이 포함된 압축 파일의 설치 경로를 확인할 수 있다.&lt;/p&gt;&#xA;&lt;div&gt;&lt;a href=&#34;https://www.apache.org/dyn/closer.lua/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://dl.dropboxusercontent.com/scl/fi/20hbdfye2kl3jvmytp6bk/spark-04-download-spark-tgz.webp?rlkey=o7zeq22r59epazjwef0ck0s10&amp;amp;dl=0&#34; alt=&#34;https://www.apache.org/dyn/closer.lua/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz&#34;style=&#34;width: 100%; &#34;&gt;&lt;/a&gt;&lt;/div&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;브라우저 또는 &lt;code&gt;curl&lt;/code&gt;, &lt;code&gt;wget&lt;/code&gt; 등 명령어를 통해 압축 파일을 내려받을 수 있다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;bash&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;bash&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://dlcdn.apache.org/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;압축 해제 프로그램을 사용하거나, 터미널에서 아래 명령어를 입력하여 압축 해제한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;bash&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;bash&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar zxvf spark-4.0.0-bin-hadoop3.tgz&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;Spark 경로에 접근하기 위해 환경변수를 설정한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;bash&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;bash&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vi ~/.zshrc&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;vi 편집기로 .zshrc 파일에 Spark 경로를 등록한다. &lt;code&gt;SPARK_HOME&lt;/code&gt; 은 압축 해제한 Spark 경로를 입력한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;bash&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;bash&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;SPARK_HOME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/Users/&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;username&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;/spark-4.0.0&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;:&lt;span class=&#34;nv&#34;&gt;$SPARK_HOME&lt;/span&gt;/bin:&lt;span class=&#34;nv&#34;&gt;$SPARK_HOME&lt;/span&gt;/sbin&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;변경 사항을 적용하기 위해 터미널을 재시작하거나 아래 명령어를 실행한다.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;book-codeblock&#34; data-lang=&#34;&#34;&gt;&#xA;  &lt;div class=&#34;code-actions&#34;&gt;&#xA;&#xA;    &lt;button class=&#34;code-copy-btn code-action&#34; onclick=&#34;copyCode(this)&#34;&gt;&#xA;      &lt;i class=&#34;fa-solid fa-copy&#34;&gt;&lt;/i&gt;Copy&#xA;    &lt;/button&gt;&#xA;&#xA;    &lt;span class=&#34;code-language code-action&#34;&gt;text&lt;/span&gt;&#xA;&#xA;  &lt;/div&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;source ~/.zshrc&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;주의할 점은 Spark를 실행하기 전에 Java와 Hadoop이 설치되어 있어야 한다.&#xA;보통은 Java 또는 Hadoop 버전에 맞춰서 Spark를 설치하지만,&#xA;어떤 것도 설치되어 있지 않기 때문에 스파크 버전에 맞춰서 Java와 Hadoop을 설치한다.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
